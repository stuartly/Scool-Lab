篇名,作者,页数,关键词,摘要,filename
语言知识驱动的词嵌入向量的可解释性研究,"林星星1:45737698|邱晓枫2,3:45737699|刘扬2:06269306|虞梦夏2,3:45737688|祁晶2,3:45737700|康司辰2:36636922",9,可解释性; 词嵌入向量; 伪语料法;,"神经网络语言模型应用广泛但可解释性较弱,其可解释性的一个重要而直接的方面表现为词嵌入向量的维度取值和语法语义等语言特征的关联状况。先前的可解释性工作集中于对语料库训得的词向量进行知识注入,以及基于训练和任务的算法性能分析,对词嵌入向量和语言特征之间的关联缺乏直接的验证和探讨。该文应用基于语言知识库的伪语料法,通过控制注入语义特征,并对得到的词嵌入向量进行分析后取得了一些存在性的基础性结论:语义特征可以通过控制注入到词嵌入向量中;注入语义特征的词嵌入向量表现出很强的语义合成性,即上层概念可以由下层概念表示;语义特征的注入在词嵌入向量的所有维度上都有体现。 ",MESS202008001
基于长时间跨度语料的词义演变计算研究,"孙琦鑫1,2:45737689|饶高琦1,2,3:28523622|荀恩东1,2:06433984",13,词义演变; 历时语料; 分布式表示;,"该文收集了自晚清到21世纪间长达144年的连续历时报刊语料,通过统计分析和词语分布式表示两类方法展开研究,计算并辅助识别汉语词语的词义历时演变现象。采用TF-IDF、词频比例等多种统计分析的评价指标和目标词语在文段中的共现实词及其重合度挖掘出现词义演变的词语。针对历时语料上不同时间段的词向量对齐,采用SGNS训练词向量加正交矩阵投影、SGNS递增训练和""锚点词""二阶词向量表示三种方法,其中以SGNS递增训练效果最佳。针对自动发现的词义演变现象,采用目标词历时自相似度和锚点词历时相似度的分析方法,并利用近邻词来明确目标词变迁前后的词义。 ",MESS202008002
基于平行周遍原则的汉语未登录词的知识表示与预测,"康司辰1:36636922|虞梦夏1,2:45737688|刘扬1:06269306",9,汉语未登录词; 平行周遍条件; 语义构词; 知识表示; 知识预测;,"汉语未登录词的知识表示与预测,包括词性、构词结构、词义等项目,是计算语言学领域中的基础性问题。该文依据""平行周遍""原则,从现有的语义构词知识中提取""平行条件"",将未登录词潜在的构词因素与这些""平行条件""进行适应性匹配,从而对其知识表示进行相对完整的预测。该方法将新的语言学理论与未登录词的理解应用问题结合,取得了显著的效果,其解释能力、便捷性和精细程度优于此前方法。这些研究,除了在自然语言处理领域有实用价值,也有望推动词典编撰、语言研究与教学等人文领域的进展。 ",MESS202008003
汉语委婉语语言资源建设,张辰麟1:41405525|王明文1:08472511|谭亦鸣2:45737691|肖文艳1:36646388,9,委婉语; 语义辨析; 语言资源构建;,"委婉语是语言交流中不可或缺的交际手段,委婉语研究一直是语言学界的热门话题之一,但在自然语言处理领域,尚未有委婉语相关研究。该文借助现有纸质词典,基于语料库检索和专家人工判别的方式,初步构建了规模为63 000余条语料的汉语委婉语语言资源;并根据自然语言处理的相关任务需求,结合词典释义对委婉语进行分类。该文提出了利用同类委婉语的上下文语境辅助进行标注的方法。经过实验,对简单语义委婉语的语义判别准确率达89.71%,对语义复杂的兼类委婉语的语义判别准确率达74.65%,初步验证了利用计算机辅助人工标注构建委婉语语言资源的可行性。 ",MESS202008005
面向国防科技领域的技术和术语语料库构建方法,冯鸾鸾:45737690|李军辉:09886805|李培峰:09886822|朱巧明:05968617,10,面向国防科技领域; 技术和术语; 标注规范; 语料库;,"互联网存在海量的文献和科技信息,隐含着大量高价值情报。识别国防科技领域中的技术和术语可以为构建国防科技知识图谱奠定基础。该文基于此领域的海量军事文本,以维基百科中军事领域的新技术为基点采集语料,涵盖了新闻、文献和维基百科三种体裁。在分析军事技术文本特点的基础上制定了一系列标注规范,开展了大规模语料的标注工作,构建了一个面向国防科技领域的技术和术语语料库。该语料库共标注了479篇文章,包含24 487个句子和33 756个技术和术语。同时,该文探讨了模型预标注策略的可行性,并对技术和术语类别在不同体裁上的分布以及语料标注的一致性进行了统计分析。基于该语料库的实验表明,技术和术语识别性能F1值达到70.40%,为进一步的技术和术语识别研究提供了基础。 ",MESS202008006
利用门控机制融合依存与语义信息的事件检测方法,陈佳丽:39439171|洪宇:25038035|王捷:41912763|张婧丽:41863735|姚建民:13898051,10,语义信息; 依存信息; 门控机制; 事件检测;,"句子级事件检测任务目的是识别和分类事件触发词。现阶段工作主要将句子作为神经分类网络的输入,学习句子的深层语义信息,从而优化句子表示来改进事件检测任务的性能。该文发现除句子语义信息外,依存树包含的句法结构信息也有助于获取准确的句子表示。为此,该文采用双向长短时记忆网络对句子进行编码,捕获其语义信息;同时,设计图神经网络对句子的依存结构进行表示,获取其依存信息;此外,在对句子进行语义编码与依存编码时,该文利用自注意力机制使模型选择性地关注句子中的不同词,从而捕获句子中有助于事件检测的关键信息,并尽可能避免无关词的干扰;最后,该文提出门控机制,通过加权实现上述两种信息的动态融合。该文在自动文本抽取（automatic content extraction, ACE）数据集上进行实验,结果显示,该文提出的动态融合语义信息与依存信息的方法能更加有效地对句子进行编码,并捕获句子中的事件信息,在触发词识别与事件类型分类这两个子任务中,F1值均有较大提升,分别达到76.3%和73.9%。 ",MESS202008007
用于社交媒体的中文命名实体识别,李源:17353669|马磊:22166752|邵党国:30696523|袁梅宇:10593261|张名芳:45737692,9,位置编码; 多种注意力机制; 对抗学习; 中文命名实体识别;,"社交领域的中文命名实体识别（NER）是自然语言处理（NLP）中一项重要的基础任务。目前基于词粒度信息或者外部知识的中文命名实体识别方法,都会受到中文分词（CWS）和溢出词（OOV）等问题的影响。因此,该文提出了一种基于字符的使用位置编码和多种注意力的对抗学习模型。联合使用位置编码和多头注意力能够更好地捕获字序间的依赖关系,而使用空间注意力的判别器则能改善对外部知识的提取效果。该文模型分别在Weibo2015数据集和Weibo2017数据集上进行了实验,实验结果中的F1值分别为56.79%和60.62%。与多个基线模型相比,该文提出的模型性能更优。 ",MESS202008008
融合空洞卷积神经网络与层次注意力机制的中文命名实体识别,"陈茹1,2:11507352|卢先领2,3:07769353",8,注意力机制; 迭代空洞卷积神经网络; 中文命名实体识别;,"该文针对现有的命名实体识别(named entity recognition,NER)模型未考虑到文本层次化结构对实体识别的重要作用,以及循环神经网络受其递归性的限制导致计算效率低下等问题,构建了IDC-HSAN模型(Iterated Dilated Convolutions Neural Networks and Hierarchical Self-attention Network)。该模型通过迭代的空洞卷积神经网络(ID-CNN)充分利用GPU的并行性大大降低了使用长短时记忆网络的时间代价。然后,采用层次化注意力机制捕获重要的局部特征和全局上下文中的重要语义信息。此外,为了丰富嵌入信息,加入了偏旁部首信息。最后,在不同领域数据集上的实验结果表明,IDC-HSAN模型能够从文本中获取有用的实体信息,和传统的深度网络模型、结合注意力机制的命名实体识别模型相比识别效果有所提升。 ",MESS202008009
基于HRED模型的中文多轮对话任务方法研究,王孟宇:45737693|俞鼎耀:45737694|严睿:29558002|胡文鹏:45737695|赵东岩:06277286,8,多轮对话; 生成式模型; 自然语言处理;,"多轮对话任务是自然语言处理中最具有实用价值的技术之一,该任务要求系统在产生通顺回答语句的同时能够照顾到上下文信息。近年来,出现了一大批以HRED(hierarchical recurrent encoder-decoder)模型为基础的多轮对话模型,其运用多层级的循环神经网络来编码上下文信息,并在Movie-DiC等英文对话数据集上取得了不错的结果。在2018年京东举办的中文多轮对话大赛中,京东向参赛选手公布了一批高质量的真实客服对话语料。该文在此数据上进行实验,针对HRED模型的缺点以及在中文语料下的表现进行改进,提出基于注意力和跨步融合机制与HRED模型结合的方案,实验结果表明,该方案取得了较大的性能提升。 ",MESS202008010
卷积重提取特征的文档列表排序学习方法,曹军梅:09303644|马乐荣:09290371,8,排序学习; 文档列表; 梯度下降; 卷积神经网络;,"在许多信息检索任务中,为了进一步提高检索性能,通常需要对检索到的文档进行重新排序,目前的排序学习方法主要集中在损失函数的构造上,而没有考虑特征之间的关系。该文将多通道深度卷积神经网络作用于文档列表排序学习方法,即ListCNN,实现了信息检索的精确重排序。由于从文档中提取的多个特征中有一些特征具有局部相关性和冗余性,因此,文中使用卷积神经网络来重新提取特征,以提高列表方法的性能。ListCNN架构考虑了原始文档特征的局部相关性,能够有效地重新提取代表性特征。在公共数据集LETOR 4.0上对ListCNN进行实验验证,结果表明其性能优于已有文档列表方法。 ",MESS202008011
基于粗糙集和多通道词向量的中文文本情感特征分析,陈波1:24742237|谢珺1:08893125|苗夺谦2:08963093|王雨竹1:45737697|续欣莹3:08866885,11,属性约简; 情感特征提取; 词向量; 情感分类;,"粗糙集是一种能够有效处理不精确、不完备和不确定信息的数学工具,粗糙集的属性约简可以在保持文本情感分类能力不变的情况下对文本情感词特征进行约简。针对情感词特征空间维数过高、情感词特征表示缺少语义信息的问题,该文提出了RS-WvGv中文文本情感词特征表示方法。利用粗糙集决策表对整个语料库进行情感词特征建模,采用Johnson粗糙集属性约简算法对决策表进行化简,保留最小的文本情感词特征属性集,之后再对该集合中的所有情感特征词进行词嵌入表示,最后用逻辑回归分类器验证RS-WvGv方法的有效性。另外,该文还定义了情感词特征属性集覆盖力,用于表示文本情感词特征属性集合对语料库的覆盖能力。最后,在实验对比的过程中,用统计检验进一步验证了该方法的有效性。 ",MESS202008012
基于对话结构和联合学习的情感和意图分类,张伟生:45737696|王中卿:23843509|李寿山:27030929|周国栋:13898054,8,情感分类; 联合学习; 注意力机制;,"在社交媒体中存在大量的对话文本,而在这些对话中,说话人的情感和意图通常是相关的。不仅如此,对话的整体结构也会影响对话的情感和意图,因此,需要对对话中的情感和意图进行联合学习。为此,该文提出了基于对话结构的情感、意图联合学习模型,考虑对话内潜在的情感与意图的关联性,并且利用对话的内在结构与说话人的情感和意图之间的关系,提升多轮对话文本的每一子句情感及其意图的分类性能。同时,通过使用注意力机制,利用对话的前后联系来综合考虑上下文对对话情感的影响。实验表明,联合学习模型能有效地提高对话子句情感及意图分类的性能。 ",MESS202008014
ACL-IJCAI-SIGIR顶级会议论文报告会(AIS2020)成功在线举办,,1, ,"<正>ACL、IJCAI和SIGIR是自然语言处理、人工智能和信息检索领域的三大顶级国际学术会议。AIS顶级会议论文报告会是由中国中文信息学会青年工作委员会主办的系列学术活动,该活动邀请被三大顶级国际会议录用的文章作者进行报告交流,将三大会议的精彩内容融为一体,为国内学者和研究人员提供更快速、更便捷的学习交流机会。自2017年起AIS已连续举办四届,往年会议吸引数千名专家学者和学生进行线上线下交流。 ",MESS202008004
"全国社会媒体处理大会(SMP 2020)召开,98场报告日程全公开",,1, ,"<正>全国社会媒体处理大会(SMP)专注于以社会媒体处理为主题的科学研究与工程开发,为传播社会媒体处理最新的学术研究与技术成果提供广泛的交流平台,旨在构建社会媒体处理领域的产学研生态圈,成为中国乃至世界社会媒体处理的风向标。会议将采取大会报告、专题研讨、张贴报告等形式进行交流。全国社会媒体处理大会创办于2012年,每年举办一次,现已成为社会媒体处理的重要学术活动。 ",MESS202008013
《基于深度学习的自然语言处理》,,1, ,"<正>自然语言处理旨在使计算机能够智能地处理人类语言,是人工智能的前沿研究领域之一,相关应用已经开始深刻影响社会大众识别、获取和利用信息的方式。自然语言处理的发展历经三大浪潮:理性主义、经验主义和深度学习。在第三大浪潮中,深度学习利用非线性处理的层次模型,通过从数据中自动学习语言内在表征的方式,对推动自然语言处理研究与应用的发展发挥了重要作用。本书旨在对基于深度学习的自然语言处理领域所取得的最新进展进行全面回顾,重点介绍了深度学习在主要自然语言处理任务中的应用。全书共11章,主要内容如下: ",MESS202008015
神经机器翻译前沿综述,"冯洋1,2:22036015|邵晨泽1,2:43419620",18,神经机器翻译; 模型训练; 同声传译; 多模态机器翻译; 非自回归机器翻译; 篇章翻译; 领域自适应; 多语言翻译;,"机器翻译是指通过计算机将源语言句子翻译到与之语义等价的目标语言句子的过程,是自然语言处理领域的一个重要研究方向。神经机器翻译仅需使用神经网络就能实现从源语言到目标语言的端到端翻译,目前已成为机器翻译研究的主流方向。该文选取了近期神经机器翻译的几个主要研究领域,包括同声传译、多模态机器翻译、非自回归模型、篇章翻译、领域自适应、多语言翻译和模型训练,并对这些领域的前沿研究进展做简要介绍。 ",MESS202007002
从视觉到文本:图像描述生成的研究进展综述,魏忠钰1:45383643|范智昊1:45383644|王瑞泽2:45383645|承怡菁1:45383646|赵王榕1:45383647|黄萱菁3:06698167,11,图像描述生成; 跨模态特征对齐; 文献综述;,"近年来,跨模态研究吸引了越来越多学者的关注,尤其是连接视觉和语言的相关课题。该文针对跨视觉和语言模态研究中的核心任务——图像描述生成,进行文献综述。该文从基于视觉的文本生成框架、基于视觉的文本生成研究中的关键问题、图像描述生成模型的性能评价和图像描述生成模型的主要发展过程四个方面对相关文献进行介绍和总结。最后,该文给出了几个未来的重点研究方向,包括跨视觉和语言模态的特征对齐、自动化评价指标的设计以及多样化图像描述生成。 ",MESS202007003
句法分析前沿动态综述,屠可伟:45383650|李俊:36163270,12,句法分析;,"句法分析的目标是分析输入句子并得到其句法结构,是自然语言处理领域的经典任务之一。目前针对该任务的研究主要集中于如何通过从数据中自动学习来提升句法分析器的精度。该文对句法分析方向的前沿动态进行了调研,分别从有监督句法分析、无监督句法分析和跨领域跨语言句法分析三个子方向梳理和介绍了2018—2019年发表的新方法和新发现,并对句法分析子方向的研究前景进行了分析和展望。 ",MESS202007004
融合实体知识描述的实体联合消歧方法,"范鹏程1,2:40343850|沈英汉1,2:43663605|许洪波1:10348532|程学旗1:09559496|廖华明1:09559592",9,实体消歧; 深度学习; 注意力机制;,"实体消歧（entity disambiguation）是指将文档中识别出的实体指称（entity mention）链向其在特定知识库中相应条目的过程。该文结合主流的基于深度学习的实体消歧方法并融合实体知识描述展开了实验性研究。实验结果表明,融合实体知识描述的实体消歧方法在公开数据集上取得了与已有最好算法相当的F1性能。 ",MESS202007005
融合实体描述及类型的知识图谱表示学习方法,杜文倩:42579764|李弼程:36009308|王瑞:14446905,10,人工智能; 知识图谱; 表示学习; 链接预测; 三元组分类;,"知识图谱在很多人工智能领域发挥着越来越重要的作用。知识图谱表示学习旨在将三元组中的实体和关系映射到低维稠密的向量空间。TransE、TransH和TransR等基于翻译操作的表示学习方法,只考虑了知识图谱的三元组信息孤立的学习表示,未能有效利用实体描述、实体类型等重要信息,从而不能很好地处理一对多、多对多等复杂关系。针对这些问题,该文提出了一种融合实体描述及类型的知识图谱表示学习方法。首先,利用Doc2Vec模型得到全部实体描述信息的嵌入;其次,对实体的层次类型信息进行表示,得到类型的映射矩阵,结合Trans模型的三元组嵌入,得到实体类型信息的表示;最后,对三元组嵌入、实体描述嵌入及实体类型嵌入进行连接操作,得到最终实体嵌入的表示,通过优化损失函数训练模型,在真实数据集上分别通过链接预测和三元组分类两个评测任务进行效果评估,实验结果表明新方法优于TransE、TransR、DKRL、SimplE等主流模型。 ",MESS202007006
基于补全信息的篇章级神经机器翻译,张培1:14257535|张旭2:45383820|熊德意1:32622753,8,神经机器翻译; 篇章; 补全;,"对于句子级别的神经机器翻译,由于不考虑句子所处的上下文信息,往往存在句子语义表示不完整的问题。该文通过依存句法分析,对篇章中的每句话提取有效信息,再将提取出的信息,补全到源端句子中,使得句子的语义表示更加完整。该文在汉语-英语语言对上进行了实验,并针对篇章语料稀少的问题,提出了在大规模句子级别的平行语料上的训练方法。相比于基准系统,该文提出的方法获得了1.47个BLEU值的提高。实验表明,基于补全信息的篇章级神经机器翻译,可以有效地解决句子级别神经机器翻译语义表示不完整的问题。 ",MESS202007007
融合图像注意力的多模态机器翻译模型,"李霞1,2:06840132|马骏腾2:44764574|覃世豪2:45383651",11,多模态机器翻译; 图像注意力; 图像全局语义; 图像局部语义;,"已有工作表明,融入图像视觉语义信息可以提升文本机器翻译模型的效果。已有的工作多数将图片的整体视觉语义信息融入到翻译模型,而图片中可能包含不同的语义对象,并且这些不同的局部语义对象对解码端单词的预测具有不同程度的影响和作用。基于此,该文提出一种融合图像注意力的多模态机器翻译模型,将图片中的全局语义和不同部分的局部语义信息与源语言文本的交互信息作为图像注意力融合到文本注意力权重中,从而进一步增强解码端隐含状态与源语言文本的对齐信息。在多模态机器翻译数据集Multi30k上英语—德语翻译对以及人工标注的印尼语—汉语翻译对上的实验结果表明,该文提出的模型相比已有的基于循环神经网络的多模态机器翻译模型效果具有较好的提升,证明了该模型的有效性。 ",MESS202007008
基于变分自编码器的无监督文本风格转换,聂锦燃:45383653|魏蛟龙:32148439|唐祖平:07592272,10,文本风格转换; 变分自编码器; 对抗性训练; 联合表征;,"近年来,文本风格转换作为一种可控的文本生成任务受到学者们越来越多的关注。该文基于变分自编码器模型,通过鉴别器与变分自编码器的对抗性训练,将源端句子的内容和风格在隐变量空间进行分离,从而实现无监督的文本风格转换。针对文本语义内容和风格的解纠缠过程中利用固定的二进制向量通过线性变换来对风格进行表征的方法的不足,该文提出更具细腻度的联合表征方法:利用独立的编码器从原句中提取风格的连续隐向量,再和标签向量结合作为最终风格的表征,以提升风格转换的准确率。该文提出的联合表征方法在常用数据集Yelp上进行评测,与两个基线方法相比,风格转换准确率均有显著提升。 ",MESS202007009
Q2SM:基于BERT的多领域任务型对话系统状态跟踪算法,张家培:45383652|李舟军:22036031,7,任务型对话系统; 对话状态跟踪; 多领域; BERT;,"基于管道的方法是目前任务型对话系统的主要构建方式,在工业界具有广泛应用,而对话状态跟踪（dialogue state tracking,DST）是任务型对话系统中的核心任务。面对传统的方法在多领域场景下表现较差的问题,该文结合语言模型预训练的最新研究成果,该文提出了一种基于BERT的对话状态跟踪算法Q2SM（query to state model）。该模型的上游使用了基于BERT的句子表征与相似度交互的槽判定模块,下游使用了一种面向对话状态跟踪任务的自定义RNN:DST-RNN。在WOZ 2.0和MultiWOZ 2.0两个数据集上的实验表明,Q2SM相比于之前的最好模型,分别在联合准确率和状态F1值两个评价指标上提升了1.09%和2.38%。此外,模型消融实验验证了,DST-RNN相比于传统的RNN或LSTM,不仅可以提升评价指标值,还可以加快模型的收敛速度。 ",MESS202007010
基于性格情绪特征的改进主题情感模型,李玉强1:09034736|黄瑜1:29292375|孙念1:31659632|李琳1:10152840|刘爱华2:10153434,9,主题情感模型; 时间; 性格特征; 表情符号;,"近年来,以微博为代表的社交媒体在情感分析中备受关注。然而,绝大多数现有的主题情感模型并没有充分考虑到用户性格特征,导致情感分析结果难尽人意。故该文在现有的JST模型基础上进行改进,提出一种基于时间的性格建模方法,将用户性格特征纳入主题情感模型中;鉴于微博数据包含大量的表情符号之类的特有信息,为了充分利用表情符号来提升微博情感识别性能,该文将情感符号融入JST模型中,进而提出了一种改进的主题情感联合模型UC-JST(Joint Sentiment/Topic Model Based on User Character)。通过在真实的新浪微博数据集上进行实验,结果表明UC-JST情感分类效果优于JST、TUS-LDA、JUST、TSMMF四种典型的无监督情感分类方法。 ",MESS202007011
基于门控化上下文感知网络的词语释义生成方法,"张海同1,2:42539367|孔存良3,2,4:38690065|杨麟儿3,2,4:41093928|何姗5:27973424|杜永萍1:14336680|杨尔弘3,2:06429879",8,释义生成; GRU; 编码器—解码器; 注意力机制;,"传统的词典编纂工作主要采用人工编纂的方式,效率较低且耗费大量的资源。为减少人工编纂的时间和经济成本,该文提出一种基于门控化上下文感知网络的词语释义生成方法,利用门控循环神经网络(GRU)对词语释义生成过程进行建模,自动为目标词生成词语释义。该模型基于编码器—解码器架构。编码器首先利用双向GRU对目标词的上下文进行编码,并采用不同的匹配策略进行目标词与上下文的交互,结合注意力机制分别从粗粒度和细粒度两个层次将上下文信息融合到目标词的向量表示中,最终获得目标词在特定语境中的编码向量。解码器则同时基于目标词的语境与语义信息为目标词生成上下文相关的词语释义。此外,通过向模型提供目标词字符级特征信息,进一步提高了生成释义的质量。在英文牛津词典数据集上进行的实验表明,该文提出的方法能够生成易于阅读和理解的词语释义,在释义建模的困惑度和生成释义的BLEU值上分别超出此前模型4.45和2.19,性能有显著提升。 ",MESS202007012
《神经网络与深度学习》,,1, ,"<正>《神经网络与深度学习》是深度学习领域的入门教材,系统地整理了深度学习的知识体系,并由浅入深地阐述了深度学习的原理、模型以及方法,使得读者能全面地掌握深度学习的相关知识,并提高以深度学习技术来解决实际问题的能力。鉴于深度学习涉及的知识点较多,本书系统整理了深度学习的知识体系,从机器学习基础、神经网络模型以及概率图模型三个层面来串联深度学习所涉及的知识点,使读者对深度学习技术的理解更具系统性、条理性和全面性。 ",MESS202007001
基于非参数贝叶斯模型和深度学习的古文分词研究,俞敬松1:22512348|魏一1:43231202|张永伟2:29003088|杨浩3:06276686,8,古文分词; 非参数贝叶斯模型; 深度学习; 无指导学习; 弱指导学习;,"古汉语文本中,汉字通常连续书写,词与词之间没有明显的分割标记,为现代人理解古文乃至文化传承带来许多障碍。自动分词是自然语言处理技术的基础任务之一。主流的自动分词方法需要大量人工分词语料训练,费时费力,古文分词语料获取尤其困难,限制了主流自动分词方法的应用。该文将非参数贝叶斯模型与BERT（Bidirectional Encoder Representations from Transformers）深度学习语言建模方法相结合,进行古文分词研究。在《左传》数据集上,该文提出的无监督多阶段迭代训练分词方法获得的F1值为93.28%;仅使用500句分词语料进行弱监督训练时,F1值可达95.55%,高于前人使用6/7语料（约36 000句）进行有监督训练的结果;使用相同规模训练语料时,该文方法获得的F1值为97.40%,为当前最优结果。此外,该文方法还具有较好的泛化能力,模型代码已开源发布。 ",MESS202006002
基于句内注意力机制多路CNN的汉语复句关系识别方法,孙凯丽1:45235713|邓沌华2:21476186|李源1:07646009|李妙1:42889263|李洋1:17391651,10,关系识别; 非充盈态汉语复句; 双向长短期记忆网络(Bi-LSTM); 句内注意力机制; 卷积神经网络;,"复句的关系识别是对分句间语义关系的甄别,是复句语义分析的关键,旨在从文本中识别句间的关系类型。非充盈态汉语复句存在隐式关系的特点给语义关系识别造成了困难。为了深度挖掘复句中隐含的语义信息,正确地实现关系分类,该文提出了一种基于句内注意力机制的多路CNN网络结构Inatt-MCNN。其中句内注意力机制模型是基于Bi-LSTM的,使其能够学习到句子的双向语义特征以及分句间的关联特征。同时,为了充分利用文本特征,联合使用卷积神经网络（CNN）对复句表示再次建模获得句子局部特征。与其他基于汉语复句语料库（CCCS）和清华汉语树库（TCT）的实验结果相比,该文方法的宏平均F1值为85.61%,提升约6.08%,平均召回率为84.87%,提升约3.05%。 ",MESS202006003
基于序列图模型的多标签序列标注,王少敬:45235719|刘鹏飞:27624356|邱锡鹏:06699441,9,多标签序列标注; 多任务学习; 图模型;,"该文针对实际中存在对同一句话标注多种序列标签问题,定义了多标签序列标注任务,并提出了一种新的序列图模型。序列图模型主要为了建模两种依赖关系:不同单词在时序维度上面的关系和同一单词在不同任务之间的依赖关系。该文采用LSTM或根据Transformer修改设计的模型处理时序维度上的信息传递。同一单词在不同任务之间使用注意力机制处理不同任务之间的依赖关系,以获得每个单词更好的隐状态表示,并作为下次递归处理的输入。实验表明,该模型不仅能够在Ontonotes 5.0数据集上取得更好的结果,而且可以获取不同任务标签之间可解释的依赖关系。 ",MESS202006004
基于成分共享的英汉小句对齐语料库标注体系研究,"葛诗利1:24597890|宋柔1,2:34071693",9,成分共享; 话头共享; 小句; 小句复合体; 英汉机器翻译;,"英汉小句对齐语料库服务于英语和汉语小句的语法结构对应关系研究和应用,对于语言理论和语言翻译(包括人的翻译和机器翻译)有重要意义。前人的语法理论和相关语料库的工作对于小句复合体和小句的界定缺乏充分研究,在理论上有缺陷,难以支持自然语言处理的应用。该文首先为英汉小句对齐语料库的建设做理论准备。从近年提出的汉语小句复合体的理论出发,该文界定了成分共享的概念,基于话头共享和引语共享来界定英语的小句和小句复合体,使小句和小句复合体具有功能的完整性和单一性。在此基础上,该文设计了英汉小句对齐的标注体系,包括英语NT小句标注和汉语译文生成及组合。语料库的标注表明,在小句复合体层面上英汉翻译涉及到的结构变换,其部件可以限制为英语小句和话头、话体,无须涉及话头和话体内部的结构。基于这些工作的英汉小句对齐语料库为语言本体研究和英汉语言对比、英汉机器翻译等应用提供了结构化的标注样本。 ",MESS202006005
面向医疗文本的实体及关系标注平台的构建及应用,"张坤丽1,2:10310465|赵旭1,2:26769033|关同峰1,2:43563153|尚柏羽1,2:45235716|李羽蒙1,2:45235718|昝红英1,2:09467924",9,文本标注; 标注平台; 实体标注; 关系标注; 数据分析;,"医疗文本数据是推行智慧医疗的重要数据基础,而医疗文本为半结构或非结构化数据,难以对其直接进行应用。对医疗文本中所包含的实体及实体关系进行标注是文本结构化的重要手段,也是命名实体识别、关系自动抽取研究的基础。传统的人工标注方法费力费时,已难以适应大数据发展的需求。该文以构建中文医学知识图谱的任务为驱动,构建了半自动化实体及关系标注平台。该平台融合多种算法,能够实现文本预标注、进度控制、质量把控和数据分析等多种功能。利用该平台,进行了医学知识图谱中实体和关系标注,结果表明该平台能够在文本资源建设中控制标注过程,保证标注质量,提高标注效率。同时该平台也被应用于其他文本标注任务,表明该平台具有较好的任务移植性。 ",MESS202006006
家谱文本中实体关系提取方法研究,"任明1,2:29257210|许光2:45235714|王文祥2:45235715",10,家谱; 命名实体识别; 关系提取; 深度学习;,"实现家谱资源的高效的组织和利用,需要从非结构化的家谱文本中提取实体及关系,进行结构化的表示。实体和关系的提取通常被作为序列标注任务来解决,输入的句子被映射到标签序列。针对家谱文本中实体和关系高度密集、关系重叠很常见的特点,该文构建了相应的概念模型来指导整个提取过程。在序列标注部分,该文在真实数据上检验了常用的深度学习模型的表现。实验结果显示,BERT-BiLSTM-CRF模型的精确率、召回率和F1值均优于所对比的其他模型,该文所提出的方法能够有效地解决家谱文本中的实体关系提取问题。 ",MESS202006007
旅游场景下的实体别名抽取联合模型,杨一帆:45152821|陈文亮:33224970,9,旅游景点; 实体别名; 联合模型; 实体识别;,"目前互联网中包含了大量的实体介绍文本,为实体知识构建提供了资源基础。别名作为实体的一种属性,是实体正式名称的不同表达,在知识图谱构建中具有重要意义。该文以景点介绍文本作为语料,结合不同别名描述方式提出别名标注策略,人工构建别名标注数据集。别名抽取可分为实体识别与关系分类两个子任务。该文提出基于深度学习的景点实体别名抽取联合模型,同时完成两个子任务。在该文构建的数据集上的实验结果表明,联合模型与流水线式处理模型相比性能有显著提高。 ",MESS202006008
基于远程监督的人物属性抽取研究,马进:35630578|杨一帆:45152821|陈文亮:33224970,9,属性抽取; 标注数据; 远程监督;,"属性抽取的主要目标是从非结构化文本中获取实体的属性值。为了从文本中抽取出人物属性,通常需要大量的标注数据,然而这些数据资源却十分稀少。为了解决这个问题,该文从百科类网页的表格数据出发,构建了人物属性表,然后采用远程监督的方法得到大规模、多类别的人物属性标注语料,从而免去了人工标注的繁琐流程。针对新构建的数据集,分别使用条件随机场（CRF）和双向长短期记忆-条件随机场（BiLSTM-CRF）构建了属性抽取的两个基线模型。实验结果表明,BiLSTM-CRF取得比CRF更好的性能,其中BiLSTM-CRF的平均F1值为83.39%。 ",MESS202006009
用于文本分类的均值原型网络,"线岩团1,2:23245672|相艳1,2:24386401|余正涛1,2:05982358|文永华1,2:07896638|王红斌1,2:21967787|张亚飞1,2:38072297",9,文本分类; 均值原型网络; 自集成学习;,"文本分类是自然语言处理的基本任务之一。该文在原型网络基础上,提出了按时序移动平均方式集成历史原型向量的均值原型网络,并将均值原型网络与循环神经网络相结合,提出了一种新的文本分类模型。该模型利用单层循环神经网络学习文本的向量表示,通过均值原型网络学习文本类别的向量表示,并利用文本向量与原型向量的距离训练模型并预测文本类别。与己有的神经网络文本分类方法相比,模型在训练和预测过程中有效利用了样本间的特征相似关系,并具有网络深度浅、参数少的特点。该方法在多个公开的文本分类数据集上取得了最好的分类准确率。 ",MESS202006010
面向多类型问题的阅读理解方法研究,"谭红叶1,2:08402552|屈保兴1:45235721",8,阅读理解; 分类; 注意力机制; 多类型问题;,"机器阅读理解是基于给定文本,自动回答与文本内容相关的问题。针对此任务,学术界与工业界提出多个数据集与模型,促使阅读理解取得了一定的进步,但提出的模型大多只是针对某一类问题,不能满足现实世界问题多样性的需求。因此,该文针对阅读理解中问题类型多样性的解答展开研究,提出一种基于Bert的多任务阅读理解模型,利用注意力机制获得丰富的问题与篇章的表示,并对问题进行分类,然后将分类结果用于任务解答,实现问题的多样性解答。该文在中文公共阅读理解数据集CAIL2019-CJRC上对所提模型进行了实验,结果表明,系统取得了比所有基线模型都要好的效果。 ",MESS202006011
阅读理解中观点类问题的扩展研究,"张兆滨1:45207648|王素格1,2:08454306|陈鑫1:08400749|赵琳玲1:45235722|王典1:45235723",9,问题扩展; 高考语文; 阅读理解; 观点类题型;,"在高考语文阅读理解中,观点类问题中的观点表达较为抽象,为了从阅读材料中获取与问题相关的答案信息,需要对问题中的抽象词语进行扩展,达到扩展观点类问题的目的。该文提出了基于多任务层级长短时记忆网络(Multi-HLSTM)的问题扩展建模方法。首先将阅读材料与问题进行交互注意,同时建模问题预测和答案预测两个任务,使模型对问题进一步扩展。最后将扩展后的问题与原问题同时应用于问题的答案候选句抽取中。通过在高考语文观点类的真题、模拟题以及DuReader的描述观点类数据集上进行实验,验证了本文的问题扩展模型对答案候选句的抽取性能具有一定的提升作用。 ",MESS202006012
一种基于CW-RNN的多时间尺度序列建模推荐算法,"袁涛1,2:33234208|牛树梓2:36310961|李会元2:22125714",9,序列推荐; 多时间尺度; 动态建模;,"序列化推荐试图利用用户与物品的历史交互序列,预测下次即将交互的物品。针对序列化推荐中推荐物品依赖于用户的长时间全局兴趣、中时间兴趣还是短时间局部兴趣的不确定性,该文提出了一种基于CW-RNN的多时间尺度序列建模推荐算法。首先,该算法引入CW-RNN层,从用户与物品的历史交互序列中抽取多个时间尺度的用户兴趣特征。然后,通过尺度维卷积来建模对不同时间尺度的用户兴趣特征的依赖,生成多时间尺度用户兴趣特征的统一表示。最后,利用全连接层建模统一的多尺度用户兴趣特征和隐式物品特征的交互关系。在MovieLens-1M和Amazon Movies and TV两个公开数据集上的实验结果表明,相比于现有最优的序列推荐算法,该文提出的算法在准确率上分别提升了3.80%和8.63%。 ",MESS202006013
基于Transformer增强架构的中文语法纠错方法,"王辰成1,2:37800399|杨麟儿2,3:41093928|王莹莹2,3:24189605|杜永萍1:14336680|杨尔弘2,3:06429879",9,语法纠错; 多头注意力; 动态残差结构; 数据增强;,"语法纠错任务是自然语言处理领域的一项重要任务,近年来受到了学术界广泛关注。该任务旨在自动识别并纠正文本中所包含的语法、拼写以及语序错误等。该文将语法纠错任务看作是翻译任务,即将带有错误表达的文本翻译成正确的文本,采用基于多头注意力机制的Transformer模型作为纠错模型,并提出了一种动态残差结构,动态结合不同神经模块的输出来增强模型捕获语义信息的能力。受限于目前训练语料不足的情况,该文提出了一种数据增强方法,通过对单语语料的腐化从而生成更多的纠错数据,进一步提高模型的性能。实验结果表明,该文所提出的基于动态残差的模型增强以及腐化语料的数据增强方法对纠错性能有着较大的提升,在NLPCC 2018中文语法纠错共享评测数据上达到了最优性能。 ",MESS202006014
《知识图谱与深度学习》,,1, ,"<正>《知识图谱与深度学习》总结介绍了清华大学自然语言处理与社会人文计算实验室(THUNLP)在知识图谱与深度学习方面的研究成果,围绕世界知识与语言知识这两类对自然语言理解至关重要的知识系统,介绍了在知识表示、知识获取和计算推理方面的研究成果,展现了数据驱动的深度学习与符号表示的知识图谱之间相互补充和促进的技术趋势。其中,知识表示旨在对符号化的知识图谱进行高效表征,这是在深度学习中充分利用大规模知识图谱的计算基础;知识获取旨在从大规模的有结构、半结构和无结构化数据中自动获取知识,辅以少量人工校验,是构建大规模知识图谱的必由之路;知识计算旨在系统探索如何在不同自然语言处理任务中充分利用这些知识,实现知识指导的自然语言深度理解。 ",MESS202006001
基于局部语义相关性的定义文本义原预测,"杜家驹1,2,3:45043949|岂凡超1,2,3:41844649|孙茂松1,2,3:08823738|刘知远1,2,3:10812645",9,义原预测; HowNet; 语义相关性;,"作为人类语言的最小语义单位,义原已被成功应用于许多自然语言处理任务。人工构造和更新义原知识库成本较大,因此义原预测被用来辅助义原标注。该文探索了利用定义文本为词语自动预测义原的方法。词语的各个义原通常都与定义文本中的不同词语的语义有相关关系,这种现象被称为局部语义相关性。与之对应,该文提出了义原相关池化(SCorP)模型,该模型能够利用局部语义相关性来预测义原。在HowNet上的评测结果表明,SCorP取得了当前最好的义原预测性能。大量的定量分析进一步证明了SCorP模型能够正确地学习义原与定义文本之间的局部语义相关性。 ",MESS202005002
结合特殊领域实体识别的远监督话语领域分类,何宇虹:45043948|黄沛杰:24966316|杜泽峰:40934794|刘威:07569115|朱建恺:45043950|章锦川:44542756,9,领域分类; 外部知识; 远监督; 话语表达; 神经分类器;,"近年来,基于注意力(attention)机制的循环神经网络在文本分类中表现出显著的性能。然而,当训练集数据有限时,测试集数据中许多领域实体指称项在训练集中处于低频,甚至从未出现,如中文话语领域分类任务。该文提出结合特殊领域实体识别的远监督话语分类模型。首先,通过远监督(distant supervision)的方式获取数据集中的领域知识,显著地减少了人工操作;其次,利用特殊领域实体识别和本地构建的补充性知识库去补全远监督获取的领域知识,旨在为模型提供更加全面的领域知识;最后,对基于上下文的语义特征和知识特征这两种异构信息提出了细粒度拼接机制,在词级上融合了预训练词汇语义表达和领域知识表达,有效提升了分类模型的性能。通过与研究进展的文本分类模型的对比实验表明,该文模型在中文话语领域分类基准数据集的实验上取得了较高的正确率,特别是在知识敏感型领域,较研究进展方法具有显著优势。 ",MESS202005003
面向儿科疾病的命名实体及实体关系标注语料库构建及应用,"昝红英1,2:09467924|刘涛1,2:09465037|牛常勇1:10309361|赵悦淑2,3:44380440|张坤丽1,2:10310465|穗志方2,4:43922301",8,儿科疾病; 语料库建设; 命名实体; 实体关系; 知识图谱;,"当前医学语料库实体及实体关系的分类体系难以满足精准医学发展需求的问题,该文针对儿科疾病开展研究。在医学领域专家的指导下制定了适合儿科学的命名实体和实体关系的标注体系及详细标注规范;融合国内外相关医学标准资源,利用标注工具对298余万字儿科医学文本中实体及实体关系进行机器预标注、人工标注及人工校对,构建了面向儿科疾病的医学实体及关系语料库。所构建的语料库包含504种儿科常见疾病,共标注命名实体23 603个,实体关系36 513个,多轮标注一致性分别为0.85和0.82。基于该语料库构建了儿科医学知识图谱,并开发了基于知识图谱的儿科医学知识问答系统。 ",MESS202005004
基于历时语料库的在线词典编纂系统设计,"吴先1,2:45043951|胡俊峰1,2:06243608",9,词典编纂; 历时语料库; 系统设计; 词义发现;,"语料库语言学是借助大规模语料库对语言现象进行发现、挖掘的学科,目前已经存在很多在线语料库辅助语言学的研究。该文提供了一个按时间分片进行管理的语料库,并基于此提出了一个由社区维护的在线词典编纂系统,该系统将语料库查询结果动态结合在被编辑的词条中。该文还介绍了一个多义词词义发现和层次化聚类算法,用以自动生成一个默认的词条框架。该文概述了词典编纂系统的总体情况,重点介绍系统的设计和使用方法。 ",MESS202005005
基于数据扩充的翻译记忆库与神经机器翻译融合方法,曹骞:37444116|熊德意:32622753,8,神经机器翻译; 翻译记忆; 数据扩充;,"神经机器翻译是目前机器翻译领域的主流方法,而翻译记忆是一种帮助专业翻译人员避免重复翻译的工具,其保留之前完成的翻译句对并存储在翻译记忆库中,进而在之后的翻译过程中通过检索去重用这些翻译。该文基于数据扩充提出两种将翻译记忆与神经机器翻译相结合的方法:(1)直接拼接翻译记忆在源语句后面;(2)通过标签向量拼接翻译记忆。该文在中英与英德数据集上进行了实验,实验表明,该方法可以使翻译性能获得显著提升。 ",MESS202005006
一种多基元联合训练的藏文词向量表示方法,"才智杰1,2,3,4:08166533|才让卓玛1,2,3,4:11447913|孙茂松5:08823738",6,自然语言处理; 藏文; 神经网络; 词向量表示;,"词向量表示是机器学习的基础性工作,其目标是以优化的向量表示词,以便计算机能更好地理解自然语言。随着神经网络技术的发展,词向量在自然语言处理领域发挥着重要作用。藏文词向量表示技术的研究对藏文特征分析以及用深度学习技术处理藏文具有重要意义。该文提出了一种构件、字和词多基元联合训练的藏文词向量表示方法,设计了多基元联合训练藏文词向量的模型TCCWE,并采用内部评测中的词相似度/相关性评价方式验证了其有效性。实验表明,该文提出的藏文词向量表示方法有效,其性能在TWordSim215上提高了3.35%,在TWordRel215上提高了4.36%。 ",MESS202005007
一种基于TC_LSTM的藏文词拼写检查方法,"华旦扎西1,2,3,4:45044627|才智杰1,5,2,3:08166533|班玛宝1,2,3:41329890",6,自然语言处理; LSTM; 藏文词; 拼写检查;,"拼写检查能够快速检测文本错误,提高文本校对效率,在语料库建设、文本编辑、语音和文字识别等诸多方面具有广阔的应用前景。该文在分析藏文拼写检查技术和语言模型的基础上,以藏文词拼写检查为目标,选用具有长远距离记忆功能的LSTM建立TC_LSTM语言模型,设计基于TC_LSTM的藏文词拼写检查算法。经测试,基于TC_LSTM语言模型的藏文词拼写检查取得了较好的效果。 ",MESS202005008
基于案件要素指导的涉案舆情新闻文本摘要方法,"韩鹏宇1,2:43293733|高盛祥1,2:07892541|余正涛1,2:05982358|黄于欣1,2:42865248|郭军军1,2:42356071",9,涉案舆情摘要; 案件要素; 双层编码; 多特征分类;,"涉案舆情新闻文本摘要任务是从涉及特定案件的舆情新闻文本中,获取重要信息作为其简短摘要,因此对于相关人员快速掌控舆情态势具有重要作用。涉案舆情新闻文本摘要相比开放域文本摘要任务,通常涉及特定的案件要素,这些要素对摘要生成过程有重要的指导作用。因此,该文结合深度学习框架,提出了一种融入案件要素的涉案舆情新闻文本摘要方法。首先构建涉案舆情新闻摘要数据集并定义相关案件要素,然后通过注意力机制将案件要素信息融入新闻文本的词、句子双层编码过程中,生成带有案件要素信息的新闻文本表征,最后利用多特征分类层对句子进行分类。为了验证算法有效性,在构造的涉案舆情新闻摘要数据集上进行实验。实验结果表明,该方法相比基准模型取得了更好的效果,具有有效性和先进性。 ",MESS202005009
基于文献链接信息分析的科技资源风险评估,罗准辰1:40654876|赵赫2:41554515|叶宇铭1:43756465|刘晓鹏1:43756466,10,科技资源风险评估; 文献; 链接信息;,"文献中的链接将文献与数据、代码、文档、网页等科技资源相关联,资源链接引用的上下文信息反映了科研活动中科研主体与科技资源形成的关系。该文通过对文献中的链接信息进行细粒度分析,提出了一种对其关联的科技资源种类和引用目的进行知识建模的方法,并在大规模文献数据集上进行了实证。同时从国内外科技资源的利用情况出发,对科技资源的重要程度、发展方向、使用风险等进行了深入的探索。该文可为了解国内外前沿技术进展,以及我国科研活动中科技资源风险评估判定提供科学依据,且对于自然语言处理领域中对科技文献文本的分析研究具有重大意义。 ",MESS202005010
基于答案及其上下文信息的问题生成模型,"谭红叶1,2:08402552|孙秀琴1:45043953|闫真1:08409258",8,问题生成; 神经网络; 问题相关词;,"基于文本的问题生成是从给定的句子或段落中生成相关问题。目前,主要采用序列到序列的神经网络模型来研究包含答案的句子生成问题,然而这些方法存在以下问题:①生成的疑问词与答案类型不匹配;②问题与答案的相关性不强。该文提出一个基于答案及其上下文信息的问题生成模型。该模型首先根据答案与上下文信息的关系确定与答案类型匹配的疑问词;然后利用答案及其上下文信息确定问题相关词,使问题尽可能使用原文中的词;最后结合原句作为输入来生成问题。相关实验表明,该文提出的模型性能明显优于基线系统。 ",MESS202005011
基于BERT的任务导向对话系统自然语言理解的改进模型与调优方法,周奇安:45043954|李舟军:22036031,9,任务导向对话系统; 自然语言理解; BERT;,"任务导向对话系统的自然语言理解,其目的就是解析用户以自然语言形式输入的语句,并提取出可以被计算机所理解的结构化信息,其包含意图识别和槽填充两个子任务。BERT是近期提出来的一种自然语言处理预训练模型,已有研究者提出基于BERT的任务导向对话系统自然语言理解模型。在此基础上,该文提出一种改进的自然语言理解模型,其编码器使用BERT,而解码器基于LSTM与注意力机制构建。同时,该文提出了该模型的两种调优方法:锁定模型参数的训练方法、使用区分大小写的预训练模型版本。在基线模型与改进模型上,这些调优方法均能够显著改进模型的性能。实验结果显示,利用改进后的模型与调优方法,可以分别在ATIS和Snips两个数据集上得到0.883 3和0.925 1的句子级准确率。 ",MESS202005012
双特征空间的实体排序学习,赵以昕1:43696164|牛树梓1:36310961|纪春岩2:08858594|卢菲2:24272673,9,知识图谱; 实体检索; 双特征空间;,"随着大规模知识图谱的出现以及企业高效管理领域知识图谱的需求,知识图谱中的自组织实体检索成为研究热点。给定知识图谱以及用户查询,实体检索的目标在于从给定的知识图谱中返回实体的排序列表。从匹配的角度来看,传统的实体检索模型大都将用户查询和实体统一映射到词的特征空间。这样做具有明显的缺点,例如,将同属于一个实体的两个词视为独立的。为此,该文提出将用户查询和实体同时映射到实体与词两个特征空间方法,称为双特征空间的排序学习。首先将实体抽象成若干个域。之后从词空间和实体空间两个维度分别抽取排序特征,最终应用于排序学习算法中。实验结果表明,在标准数据集上,双特征空间的实体排序学习模型性能显著优于当前先进的实体检索模型。 ",MESS202005013
基于混合多头注意力和胶囊网络的特定目标情感分析,王家乾:41840949|龚子寒:44021566|薛云:23329502|庞士冠:45043955|古东宏:40215764,11,特定目标情感分析; 胶囊网络; 多头注意力;,"特定目标情感分析旨在判断上下文语境在给定目标词下所表达的情感倾向。对句子语义信息编码时,目前大部分循环神经网络或注意力机制等方法,不能充分捕捉上下文中长距离的语义信息,同时忽略了位置信息的重要性。该文认为句子的语义信息、位置信息和多层次间的信息融合对该任务至关重要,从而提出了基于混合多头注意力和胶囊网络的模型。首先,使用多头自注意力分别在位置词向量基础上对上下文长句子和在双向GRU基础上对目标词进行语义编码;然后,使用胶囊网络在语义信息交互拼接基础上进行位置信息编码;最后,在融入原始语义信息基础上,使用多头交互注意力对上下文与目标词并行融合的方法得到情感预测结果。在公开数据集SemEval 2014 Task4和ACL 14 Twitter上的实验表明,该文模型性能较传统深度学习和标准注意力方法有显著提升,验证了模型的有效性和可行性。 ",MESS202005014
疫情防控外语通（41语种版）,,1, ,"<正>新冠肺炎疫情是一场全球性灾难,随着国内疫情逐渐得到控制、国际疫情日益严重,为防止境外疫情输入、避免国内疫情反弹、尽快向国际传播中国抗疫经验,在教育部、国家语委的支持指导下,""战疫语言服务团""骨干单位北京语言大学语言资源高精尖创新中心牵头组织30多家单位的100余位专家学者和专业人士紧急研发了""疫情防控外语通"",面向我国海外留学生和同胞以及在华来华外国留学生和其他外籍人员,提供疫情防控和诊疗方面的语言服务。""疫情防控外语通""根据国家卫健委发布的新冠肺炎防控方案、诊疗方案、公众防护指南并参考国家有关防控政策, ",MESS202005001
基于BiLSTM-CRF的古汉语自动断句与词法分析一体化研究,"程宁1:42140999|李斌1,2:08075606|葛四嘉1:38352969|郝星月1:42141000|冯敏萱1:08753478",9,古文断句; 分词; 词性标注; BiLSTM-CRF; 古汉语信息处理;,"古汉语信息处理的基础任务包括自动断句、自动分词、词性标注、专名识别等。大量的古汉语文本未经标点断句,所以词法分析等任务首先需要建立在断句基础之上。然而,分步处理容易造成错误的多级扩散,该文设计实现了古汉语断句与词法分析一体化的标注方法,基于BiLSTM-CRF神经网络模型在四种跨时代的测试集上验证了不同标注层次下模型对断句、词法分析的效果以及对不同时代文本标注的泛化能力。研究表明,一体化的标注方法对古汉语的断句、分词及词性标注任务的F1值均有提升。综合各测试集的实验结果,断句任务F1值达到78.95%,平均提升了3.5%;分词任务F1值达到85.73%,平均提升了0.18%;词性标注任务F1值达到72.65%,平均提升了0.35%。 ",MESS202004001
一种轻量级的汉语语义角色标注规范,刘亚慧:44830346|杨浩苹:44830347|李正华:32629227|张民:31758527,11,语义角色标注; 标注规范; 浅层语义分析; 论元角色; 谓词;,"作为主流的浅层语义表示形式,语义角色标注一直是自然语言处理领域的研究热点之一。目前学术界已有的语义角色标注规范(PropBank规范和北大规范)主要存在三个问题:①基于片段的论元表示让标注难度加大;②PropBank中谓词框架的定义难度较大;③北大规范缺乏省略论元的标注。经过充分调研,该文尝试融合已有的中英文语义角色标注规范的优点,同时结合实际标注中遇到的问题,制定了一种轻量级的适合非语言学背景的标注者参与的中文语义角色标注规范。第一,采用基于词的论元表示,避免了片段边界的确定,从而降低标注难度;第二,标注者直接根据句子上下文信息,标注谓词相关论元角色,而无须预先定义每个谓词的所有语义框架;第三,显式标注句子中省略的核心论元,更准确地刻画句子的语义信息。此外,为了保证标注一致性和提高数据标注质量,规范针对各种复杂语言现象,给出了明确的优先级规定和难点分析。 ",MESS202004002
基于关系对齐的汉语虚词抽象语义表示与分析,"戴玉玲1:44300232|戴茹冰1:34205747|冯敏萱1:08753478|李斌1,2:08075606|曲维光3:08112756",9,虚词; 抽象语义表示; 关系对齐; 语言知识库;,"虚词具有丰富的语法意义,对句子理解起着不可或缺的作用。虚词的语言学研究成果丰富,但缺乏形式化表示,无法直接被计算机利用。为了表示虚词的句法语义信息,该文首先在抽象语义表示(abstract meaning representation,AMR)这种基于概念图的语义表示方法的基础上,增加了词语和概念关系的对齐信息,使得虚词对应于概念节点或节点之间的关系弧。其次,选取了语言规范的人教版小学语文课本8 587句作为语料,进行AMR的标注。然后,针对语料中24 801个虚词实例进行统计,发现介词、连词、结构助词对应概念间的关系,占虚词总数的58.80%;而语气词和体助词表示概念,占41.20%。这表明AMR可以动态地描写出虚词功能,为整句句法语义分析提供更好的理论与资源。 ",MESS202004003
中文症状知识库的建立与分析,"昝红英1,2:09467924|韩杨超1,2:44830341|范亚鑫1:44830344|牛承志2,3:44830345|张坤丽1,2:10310465|穗志方2,4:43922301",8,中文症状知识库; 医学知识图谱; 知识标注;,"构建大规模的知识库是人工智能、自然语言理解等领域的基础任务之一。症状作为描述病人的主观感受和诊断疾病的重要依据,更是优化智能导诊、医学问答等任务的重要因素。该文在现有的医学症状知识库研究的基础上,结合症状的概念、特征及在医学诊断中发挥的作用,构建了一个公开的中文症状知识库。该知识库从症状的本体分类、相关疾病、发作部位及多发人群等层面对相关属性进行了详细描述,涵盖了8 772种症状,共计146 631条属性关系。所构建的症状知识库(CSKB)是中文医学知识图谱的重要组成部分,并为KBQA、知识推理及决策支持等应用提供了数据基础。 ",MESS202004004
基于同义推理的篇章级实体上下位关系语料库构建,吴婷:24597332|李明扬:40949853|孔芳:08865090,9,上下位关系; 跨篇章; 同义推理; 国防科技领域;,"伴随信息时代的快速发展,网络中的数据资源呈现井喷式增长趋势。如何从无序繁多的信息中挖掘深层次的结构化信息,构建一定规模的可用知识库,对于自然语言处理相关任务的研究具有重要意义。上下位关系作为知识库的基本框架,受到国内外专家学者的一致青睐。而目前已经存在的语料库大多局限在通用领域,对跨句子的上下位关系的关注相对较少,而对跨篇章的上下位关系目前还未见到相关标注。该文提出了一种基于同义推理的篇章级实体上下位关系标注策略,并以国防科技领域的文本作为具体实施对象,最终构建了一个中等规模的篇章级上下位关系语料库,该语料库涵盖国防军事领域的新闻文本和科技文献两种题材,共计962篇文本,共标注了11 020个语义关系。实体上下位关系的标注一致性达到0.82,为国防科技领域的上下位关系识别研究奠定了语料基础。 ",MESS202004005
基于GAN模型优化的神经机器翻译,"明玉琴1,2:44830343",8,NMT; 对抗学习; Transformer; BLEU;,"在机器翻译任务中,输入端的一些微小的干扰信息,可能引起NMT的模型翻译性能的下降。该文提出了一种融入对抗学习的神经机器翻译方法。给出一个源句子序列,构造了一个将源句子添加了微小噪声的新序列,并且两者的语义相近。然后把这两个序列交由编码器处理,产生各自的向量表示;并将处理结果交给判别器和解码器做进一步处理,最后比较加入噪声前后的翻译性能。实验表明,在多个语言对的翻译任务上,使用该模型的方法不仅提升了翻译性能,而且对噪声输入也表现出了鲁棒性。 ",MESS202004006
基于条件生成对抗网络的蒙古文字体风格迁移模型,"李进1,2:44830353|高静1,2:08643488|陈俊杰1,2:25765519|王永军1,2:08005509",6,字素; 蒙文字体; 条件生成对抗网络; 风格迁移; 自动生成;,"蒙古文的每个字素在词的不同位置有着不同的书写形式,使得蒙古文字形结构多样且数量庞大,从而导致利用计算机辅助和传统人工方式设计蒙古文字体需要耗费大量的人力物力。故创建一种能自动生成蒙文字体风格的模型十分必要。国内外已有学者开展了对汉字和英文字体风格自动迁移的研究,但蒙古文领域仍处于空白阶段。因此,该文提出将条件生成对抗网络模型应用于蒙古文字体风格迁移,并给出了相关模型,实现了相应的算法和软件。在蒙古文字体数据集上进行实验,模型采用生成损失和判别损失衡量模型,Adam优化器自动调整学习率,逐渐减少差异值,直到生成器和判别器达到纳什平衡状态,可直接从蒙古文标题字体生成蒙古文手写体等字体,得到的生成字体样式基本接近真实字体样式,达到字体风格迁移的效果。 ",MESS202004007
基于联合学习的生物医学因果关系抽取,刘苏文:39243002|邵一帆:44830349|钱龙华:08844995,9,因果关系抽取; 联合学习; 门控机制;,"生物医学因果关系抽取是BioCreative社区提出的一项评测任务,旨在挖掘生物医学实体间丰富的语义关系,并用生物医学表征语言(biological expression language, BEL)来表示。与传统的实体关系抽取不同,该任务不仅包含实体间因果关系的抽取,还包含实体功能的识别。此前已经提出了一些该任务的解决方法,但均未考虑这两个子任务间的关联性。该文基于多任务的思想,提出一种二元关系抽取和一元功能识别共同决策的联合学习模式。首先两个任务共享底层向量表示,然后利用长短期记忆(long short-term memory, LSTM)网络和门控机制学习两个任务之间的交互表示,最后分别进行分类预测。实验结果表明,该方法能够融合两个子任务的信息,在2015 BC-V测试集上获得了45.3%的F值。 ",MESS202004008
融合词典特征的Bi-LSTM-WCRF中文人名识别,成于思1:26996265,8,人名识别; 双向长短期记忆网络; 加权条件随机场; 词典特征;,"受限于标注语料的领域和规模以及类别不均衡,中文人名识别性能偏低。相比人名识别训练语料,人名词典获取较为容易,利用词典提升人名识别性能有待进一步研究。该文提取人名词典特征,融入到双向长短期记忆（Bi-LSTM）网络模型中,在损失函数中提高人名标签权重,设计加权条件随机场（WCRF）。从人名词典中获取姓和名相关的特征信息,Bi-LSTM网络捕获句子中上下文信息,WCRF提高人名识别的召回率。在《人民日报》语料和工程法律领域语料上进行实验,结果表明:在领域测试语料上,与基于隐马尔可夫模型的方法相比,人名识别的F1值提高18.34%,与传统Bi-LSTM-CRF模型相比,召回率提高15.53%,F1提高8.83%。WCRF还可以应用到其他类别不均衡的序列标注或分类问题中。 ",MESS202004009
面向短文本理解的省略恢复研究,郑杰:11228316|孔芳:08865090|周国栋:13898054,8,省略; 短文本; 注意力;,"省略作为一种普遍存在的语言现象,在中文文本尤其是对话、问答等短文本中频繁出现。该文从服务于短文本理解的视角出发,针对省略恢复问题提出了一种多重注意力融合的省略恢复模型。该模型融合交叉注意力机制和自注意力机制,借助门控机制将上下文信息与当前文本信息进行有效结合。在短文本问答语料上的多组实验结果表明,该文给出的模型能有效地识别并恢复短文本中的省略,从而更好地服务于短文本的理解。 ",MESS202004010
基于外部知识和层级篇章表示的阅读理解方法,"谭红叶1,2:08402552|李宣影1:44830350|刘蓓1:41405524",7,阅读理解; 外部知识; 篇章表示;,"阅读理解指的是基于给定文章自动回答相关问题,这是人工智能及自然语言处理领域的一个研究热点。目前已提出许多基于深度学习的阅读理解方法,但是这些方法对问题理解及篇章建模不充分,导致模型获取答案准确率不高。为了解决上述问题,该文提出一个基于外部知识和层级篇章表示的阅读理解方法。该方法特点有:①通过引入问题重要词的字典释义、HowNet义原,并结合问题类型,加强问题理解;②使用层级篇章表示,提升模型对篇章的理解;③在一个框架下联合优化问题类型预测与答案预测两个子任务。在DuReader数据集上的实验结果表明,该方法与基线系统性能相比最大提升了8.2%。 ",MESS202004011
融合CNN和EWC算法的不平衡文本情绪分类方法,程艳1:24528277|朱海1:44830351|项国雄2:07873528|唐天伟3:10744864|钟林辉1:07871298|王国玮1:44830352,9,情绪分类; 不平衡分类; CNN; EWC算法;,"文本情绪分类是自然语言处理领域的一个基本任务。然而,基于不平衡数据的学习使得传统文本情绪分类方法的分类性能降低。针对这个问题,该文提出了一种融合CNN和EWC算法的不平衡文本情绪分类方法。首先,该方法使用随机欠采样方法得到多组平衡数据;其次,按顺序单独使用每一组平衡数据输入CNN训练,同时在训练过程中引入EWC算法用以克服CNN中的灾难性遗忘;最后,把使用最后一组平衡数据输入CNN训练得到的模型作为最终分类模型。实验结果表明,该方法在分类性能上明显优于基于欠采样和多分类算法的集成学习框架,且该方法比基于多通道LSTM神经网络的不平衡情绪分类方法在Accuracy和G-mean上分别提高了1.9%和2.1%。 ",MESS202004012
基于多元语言特征与深度特征融合的中文文本阅读难度自动分级研究,程勇:07985194|徐德宽:07962449|董军:44100184,10,语言特征; 深度特征; 阅读难度分级;,"文本阅读难度自动分级是让计算机能够根据文本特征自动判断文本所属的难度级别,该文以此为目标,提出一种基于多元语言特征与深度特征相融合的方法来实现对文本难度的自动分级。其中多元语言特征考虑了汉字、词汇、句子等不同的语言层面,同时涉及到频率、长度、复杂度、丰富度、连贯度等不同维度的信息。另一方面,该文利用了基于BERT的神经网络预训练模型来提取文本中句子的深度特征,在此基础上构建了一个端到端神经网络来将语言特征与深度特征进行融合,最终在自动分级任务上取得了不错的效果,分级正确率超过了基于传统语言特征的方法和基于主流神经网络的方法,充分表明了所提出的特征融合方法在文本阅读难度自动分级任务上的有效性。 ",MESS202004013
全国知识图谱与语义计算大会(CCKS 2020)技术评测任务发布,,1, ,"<正>全国知识图谱与语义计算大会(CCKS:China Conference on Knowledge Graph and Semantic Computing)是由中国中文信息学会语言与知识计算专委会定期举办的全国年度学术会议。CCKS2019吸引了来自学术界和工业界的超800人参加。2020年全国知识图谱和语义计算大会(http://sigkg.cn/ccks2020)将于2020年8月15日至8月18日在南昌召开。CCKS 2020的主题是""知识图谱与认知智能""。CCKS系列评测旨在为研究人员提供测试知识图谱与语义计算技术、算法、及系统的平台和资源,促进 ",MESS202004014
疫情防控外语通（41语种版）,,1, ,"<正>新冠肺炎疫情是一场全球性灾难,随着国内疫情逐渐得到控制、国际疫情日益严重,为防止境外疫情输入、避免国内疫情反弹、尽快向国际传播中国抗疫经验,在教育部、国家语委的支持指导下,""战疫语言服务团""骨干单位北京语言大学语言资源高精尖创新中心牵头组织30多家单位的100余位专家学者和专业人士紧急研发了""疫情防控外语通"",面向我国海外留学生和同胞以及在华来华外国留学生和其他外籍人员,提供疫情防控和诊疗方面的语言服务。 ",MESS202004015
汉语零形回指消解研究综述,"蒋玉茹1,2:28368047|张禹尧1:37891746|毛腾1:37891747|张仰森1,2:15552896",12,零形回指消解; 语言学规则; 机器学习; 深度学习;,"关于零形回指的研究一直是语言学研究中的一个热点,零形回指消解是自然语言处理中一项十分重要的任务。20多年来,学者们基于语言学规则、机器学习、深度学习等方面,提出了各种研究方法,并取得了大量研究成果。该文首先介绍零形回指的相关概念;接着介绍目前国际上汉语零形回指消解的公开评测资源OntoNotes 5.0数据集及评价指标;其次,系统梳理和对比了国内外汉语零形回指消解所采用的方法;最后,总结和分析了目前零形回指消解研究的主要制约因素,这些因素也正是未来可能的研究方向。 ",MESS202003002
基于知网相关概念场的中文词向量,冯煜博1:44646202|蔡东风1:24679274|宋彦2:44646204,10,词向量; 知网相关概念场; 低频词; 神经网络语言模型;,"词向量是词的低维稠密实数向量表示,在自然语言处理的各项任务中都扮演了重要角色。目前词向量大多都是通过构造神经网络模型,在大规模语料库上以无监督学习的方式训练得到,这样的模型存在着两个问题:一是低频词词向量的语义表示质量较差;二是忽视了知识库可以对该模型提供的帮助。该文提出了利用知网相关概念场来提升词向量语义表示质量的模型。实验结果表明,在词语相似度任务、词语相关度任务和词语类比任务上,该模型使得斯皮尔曼相关性系数和准确率都得到了显著的提升。 ",MESS202003003
基于多头注意力机制Tree-LSTM的句子语义相似度计算,胡艳霞1:43378542|王成1:29411755|李弼程1:36009308|李海林2:28840290|吴以茵1:07573119,11,句子语义相似度计算; 多头注意力机制; Tree-LSTM; 语义依存树;,"针对现有句子语义相似度计算由于缺乏语义结构信息导致精度低的问题,该文在依存关系树的基础上,提出了一种基于多头注意力机制Tree-LSTM(multi-head attention Tree-LSTM,MA-Tree-LSTM)的句子语义相似度计算方法。首先,MA-Tree-LSTM将外部具有指导意义的特征作为输入,再将输入结合多头注意力机制作用在Tree-LSTM树节点的所有孩子节点上,为每个孩子节点赋予不同的权重值,从而实现多头注意力机制和Tree-LSTM的融合;其次,将三层的MA-Tree-LSTM应用于句子语义相似度计算并实现句子对的相互指导,从而得到句子对语义特征的多层表示;最后联合多层的语义特征建立句子对语义相似度计算模型,从而实现句子对间相关的语义结构特征的充分利用。该文提出的方法鲁棒性强,可解释性强,对句子单词的顺序不敏感,不需要特征工程。在SICK和STS数据集上的实验结果表明,基于MA-Tree-LSTM的句子语义相似度计算的精度优于非注意力机制的Tree-LSTM方法以及融合了多头注意力机制的BiLSTM方法。 ",MESS202003004
中文矛盾语块数据集构建和边界识别研究,李博涵:44646203|姜姗:41329881|刘畅:29143943|于东:26514992,10,自然语言理解; 文本矛盾; 矛盾语块;,"文本矛盾是自然语言理解的一项基础性问题。目前的研究大多针对矛盾识别任务,而深入文本内部探究矛盾产生原因的工作较少,且缺乏专门的中文矛盾数据集。该文在前人矛盾研究基础上,提出矛盾语块的概念,将其划分为7种类型,并根据标注规范构建了包含16 224条数据的中文矛盾语块(CCB)数据集。基于此数据集,利用序列标注及抽取式阅读理解类模型开展矛盾语块边界识别实验,以检验模型对矛盾内部语义信息的理解能力,结果显示阅读理解类模型在该任务上的性能优于序列标注模型。该文通过三个角度对影响语块边界识别的因素进行分析,为文本矛盾后续研究工作提供可靠的数据集和基线模型。 ",MESS202003005
融合覆盖机制的多模态神经机器翻译,李志峰:17552946|张家硕:37736060|洪宇:25038035|尉桢楷:44646205|姚建民:13898051,12,多模态神经机器翻译; 覆盖机制; 过翻译及欠翻译;,"多模态神经机器翻译是指直接采用神经网络,以端到端方式融合图像和文本两种模态信息,以此进行翻译建模的机器学习方法。传统多模态机器翻译,是在将源语言翻译成目标语言时,借助图像中的重要特征信息优化翻译过程。但是观察发现,图像里的信息不一定出现在文本中,对翻译也会带来干扰;与参考译文对比,翻译结果中出现了过翻译和欠翻译的情况。针对以上问题,该文提出一种融合覆盖机制双注意力解码方法,用于优化现有多模态神经机器翻译模型。该模型借助覆盖机制分别作用于源语言和源图像,在注意力计算过程中,可以减少对过去重复信息的关注。在WMT16、WMT17测试集上进行实验,验证了上述方法的有效性,在WMT16英德和英法以及WMT17英德和英法测试集上,对比基准系统BLEU值分别提升了1.2,0.8,0.7和0.6个百分点。 ",MESS202003006
融合BERT语境词向量的译文质量估计方法研究,李培芸:43713763|李茂西:29475622|裘白莲:22194496|王明文:08472511,8,神经译文质量估计; 语境词向量; 循环神经网络; 编码器—解码器网络; 质量向量;,"蕴含语义、句法和上下文信息的语境词向量作为一种动态的预训练词向量,在自然语言处理的下游任务中有着广泛应用。然而,在机器译文质量估计中,没有相关研究工作涉及语境词向量。该文提出利用堆叠双向长短时记忆网络将BERT语境词向量引入神经译文质量估计中,并通过网络并联的方式与传统的译文质量向量相融合。在CWMT18译文质量估计评测任务数据集上的实验结果表明,融合中上层的BERT语境词向量均显著提高了译文质量估计与人工评价的相关性,并且当对BERT语境词向量的最后4层表示平均池化后引入译文质量估计中对系统性能的提高幅度最大。实验分析进一步揭示了融合语境词向量的方法能利用译文的流利度特征来提高翻译质量估计的效果。 ",MESS202003007
多原型词向量与文本主题联合学习模型,"曹中华1,2:35147388|夏家莉1:07854667|彭文忠1:35286170|张志斌1:41271724",9,多原型词向量; 多义词; 主题模型; 神经网络;,"常见的词嵌入向量模型存在每个词只具有一个词向量的问题,词的主题值是重要的多义性条件,可以作为获得多原型词向量的附加信息。在skip-gram(cbow)模型和文本主题结构基础上,该文研究了两种改进的多原型词向量方法和基于词与主题的嵌入向量表示的文本生成结构。该模型通过联合训练,能同时获得文本主题、词和主题的嵌入向量,实现了使用词的主题信息获得多原型词向量,和使用词和主题的嵌入式向量学习文本主题。实验表明,该文提出的方法不仅能够获得具有上下文语义的多原型词向量,也可以获得关联性更强的文本主题。 ",MESS202003008
基于远程监督的藏文实体关系抽取,"王丽客1,2:42205003|孙媛1,2:31992289|夏天赐1,2:40934791",8,藏文实体关系抽取; 语言模型; 注意力机制;,"关系抽取任务是对句子中的实体对进行关系分类。基于远程监督的关系抽取是用预先构建的知识库来对齐朴素文本,自动标注数据,在一定程度上减少了人工标注的成本,缓解了藏文材料语料不足的问题。但是基于远程监督的实体关系抽取还存在错误标记、提取特征时出现噪声等问题。该文用远程监督方法进行藏文实体关系抽取,基于已经构建的藏文知识库,利用分段卷积神经网络结构,加入语言模型和注意力机制来改善语义歧义问题以及学习句子的信息;在训练过程中加入联合得分函数来动态修正错误标签问题。实验结果表明改进的模型有效提高了藏文实体关系抽取的准确率,且优于基线模型效果。 ",MESS202003009
基于边界识别与组合的裁判文书证据抽取方法研究,"杨健1:06940617|黄瑞章1,2:31170296|丁志远1,2:40009360|陈艳平1,2:39335717|秦永彬1,2:14022636",8,裁判文书; 证据抽取; 智慧法院; 边界识别与组合;,"裁判文书中的证据是法官量刑的基础。通过证据抽取可以对案件审判质量进行评估,从而支撑""智慧法院""建设。裁判文书中的证据大多数都比较长且存在嵌套现象,例如,""张X的身份证复印件""中的""身份证复印件"",而传统的命名实体识别模型BiLSTM-CRF对较长实体和嵌套实体的识别性能较低。为了解决因裁判文书中的证据长度较长和嵌套现象而导致证据抽取性能较低的问题,该文提出了一种基于边界识别与组合的证据抽取模型。该模型首先使用BiLSTM-CRF模型识别证据的开始边界和结束边界;然后组合开始边界和结束边界,形成携带大量丰富细粒度边界信息的候选证据;最后使用基于三通道的多核CNN模型,融合细粒度的边界信息特征,对候选证据进行筛选,识别候选证据中正确的证据。实验结果表明,该文提出的模型能有效地抽取裁判文书中的证据。 ",MESS202003010
基于句法规则和HowNet的商品评论细粒度观点分析,韦婷婷1:41233812|陈伟生1:44646210|胡勇军2:32076105|骆威1:41233810|包先雨3:24133959,11,商品评论; 细粒度观点分析; 句法规则; HowNet;,"该文提出一种基于句法规则和HowNet词典的商品评论细粒度观点分析方法,主要包括三个模块:评价对象抽取、评价对象—评价词对抽取、评价对象总体观点得分计算。具体思路为:首先,结合词性标注和频繁项集方法构建一个初始的评价对象词典,便于重用和修正商品的总体评价维度;其次,基于爬取的电商评论文本真实数据设计了评价对象—评价词对抽取规则;最后,借助HowNet词典分别计算不同评价维度的观点综合得分,进而对比同一商品不同品牌在各个维度下的总体观点评价,该方法在商品评论语料集上验证了有效性。 ",MESS202003011
基于非对称孪生网络的新闻与案件相关性分析,"赵承鼎1,2:43840371|郭军军1,2:42356071|余正涛1,2:05982358|黄于欣1,2:42865248|刘权1,2:42938376|宋燃1,2:42985550",8,非对称孪生网络; 案件要素; 相关性分析;,"新闻与案件的相关性分析是法律领域新闻舆情分析的重要环节,可转化为新闻文本与案件文本的相似度计算任务。借助孪生网络计算文本相似度是一种有效途径,其对平衡样本具有良好的学习能力,但在新闻与案件的相关性计算中面临文本不平衡和新闻文本冗余的问题,因此,该文提出了基于非对称孪生网络的新闻与案件相关性计算方法。通过计算文本中句子与标题的相似度选取与新闻标题最相关的句子表征文档,去除新闻文本中的冗余句子,利用非对称孪生网络建模,考虑到案件要素蕴含案件的关键语义信息,将案件要素作为监督信息融入到非对称孪生网络中对新闻文档和案件描述进行编码,解决新闻和案件在结构和语义上不平衡的问题,最终实现新闻与案件的相关性判断。实验表明该模型相比基线模型准确率提升了2.52%。 ",MESS202003012
面向法律文书的量刑预测方法研究,谭红叶:08402552|张博文:44646211|张虎:08403299|李茹:08453268,8,量刑预测; 区间划分; 多模型投票; 量刑属性;,"大规模法律文书数据为智能司法审判研究提供了重要的数据基础。量刑预测是智能司法审判中的一个关键环节,对维护司法审判的公平与公正具有重要意义。该文首先基于区间划分和多模型投票方法进行了量刑预测初探,发现区间划分策略可以有效缓解刑期类别众多和数据不平衡问题;在此基础上,又采用基于量刑属性的预测方法来充分理解量刑情节。在CAIL2018评测数据上的实验表明:该文所提出的两种方法,性能明显超过其他基线系统。 ",MESS202003013
中华科学技术大词典,,1, ,"<正>涵盖96个学科约50万条科技名词大陆名与台湾名,中文名与英文名科学对照数据来源可靠条目权威规范《中华科学技术大词典》(10卷)是《2013—2025年国家辞书编纂出版规划》项目,得到国家出版基金支持。全国科学技术名词审定委员会组织编写,白春礼院士担任总主编,路甬祥院士为名誉总主编。各领域先 ",MESS202003001
基于深度学习的关系抽取研究综述,"庄传志1,2:43614160|靳小龙1,2:26681578|朱伟建1,2:43614162|刘静伟1,2:43614164|白龙1,2:42465458|程学旗1,2:09559496",18,关系抽取; 深度学习; 远程监督; 联合学习;,"关系抽取(RE)是为了抽取文本中包含的关系,是信息抽取(IE)的重要组成部分。近年来,研究人员利用深度学习技术在该领域开展了深入研究。由于神经网络类型丰富,基于深度学习的关系抽取方法也更加多样。该文从关系抽取的基本概念出发,对关系抽取方法依据不同的视角进行了类别划分。随后,介绍了基于深度学习的关系抽取方法常用的数据集,并总结出基于深度学习的关系抽取框架。在此框架下,对关系抽取方法在面向深度学习的输入数据预处理、面向深度学习的神经网络模型设计等方面的具体工作进行了分析与评述,最后对未来的研究方向进行了探讨和展望。 ",MESS201912001
基于结构化表示的中文事件同指消解方法,宦敏:43614153|程昊熠:41677863|李培峰:09886822,9,中文事件同指消解; 结构化表示; 注意力机制;,"事件同指消解是自然语言处理中一个具有挑战性的任务,它在事件抽取、问答系统和阅读理解中具有重要作用。针对事件的语义信息主要由触发词和论元表示这一个特点,该文将事件进行结构化表示并输入一个基于门控和注意力机制的模型GAN-SR(gated attention network with structured representation),在文档内进行中文事件同指消解。首先,该模型采用语义角色标注和依存句法分析技术对事件句进行浅层语义分析,抽取事件句信息并表示为一个事件五元组。其次,将各种事件信息输入GRU进行编码,然后使用多头注意力机制挖掘事件句和事件对之间的重要特征。在ACE2005中文语料库上的实验表明,GAN-SR的性能优于目前性能最好的基准系统。 ",MESS201912002
汉语基本复合名词短语语义关系知识库构建与识别,张文敏:43614154|李华勇:43614155|邵艳秋:32278869,9,汉语基本复合名词短语; 语义关系体系; 定界识别;,"汉语复合名词短语因其使用范围广泛、结构独特、内部语义复杂的特点,一直是语言学分析和中文信息处理领域的重要研究对象。国内关于复合名词短语的语言资源极其匮乏,且现有知识库只研究名名复合形式的短语,包含动词的复合名词短语的知识库构建仍处于空白阶段,同时现有的复合名词短语知识库大部分脱离了语境,没有句子级别的信息。针对这一现状,该文从多个领域搜集语料,建立了一套新的语义关系体系,标注构建了一个具有相当规模的带有句子信息的基本复合名词语义关系知识库。该库的标注重点是标注句子中基本复合名词短语的边界以及短语内部成分之间的语义关系,总共收录27 007条句子。该文对标注后的知识库做了详细的计量统计分析。最后基于标注得到的知识库,使用基线模型对基本复合名词短语进行了自动定界和语义分类实验,并对实验结果和未来可能的改进方向做了总结分析。 ",MESS201912003
基于平行语料和翻译概率的多语种词对齐方法,杨飞扬:42141004|赵亚慧:10826481|崔荣一:09291242|易志伟:42141001,8,词对齐; 平行语料; 翻译概率; Zipf定律;,"为了实现多语种词对齐,该文提出一种以点互信息为基础的翻译概率作为改进的多语种单词关联强度度量方法。首先,论证了在服从Zipf定律的普通频级词区域,单词间关联强度的点互信息度量法可简化为翻译概率;其次,对汉语、英语、朝鲜语平行语料进行句子对齐、分词和去停用词等预处理后计算平行语料单词之间的翻译概率,取翻译概率最高的前k个词作为候选翻译词,并通过优化处理提高了词对齐准确率。实验结果表明,该方法可以不完全依赖语料规模,在小规模语料中取得94%以上的准确率,为跨语言小众文献及低资源语言词对齐提供了技术基础。 ",MESS201912004
基于联合注意力机制的篇章级机器翻译,"李京谕1,2:41393558|冯洋1,2:22036015",9,神经机器翻译; 注意力机制; 篇章级机器翻译;,"近年来,神经机器翻译(neural machine translation, NMT)表现出极大的优越性,然而如何在翻译一个文档时考虑篇章上下文信息仍然是一个值得探讨的问题。传统的注意力机制对源端的所有词语进行计算,而在翻译当前句子时篇章中大量的信息中只有小部分是与之相关的。在篇章级机器翻译中,采用传统的注意力机制建模篇章信息存在着信息冗余的问题。该文提出了一种联合注意力机制,结合""硬关注""和""软关注""的机制对篇章上下文的信息进行建模。关键思想是通过""硬关注""筛选出与翻译当前句子相关的源端历史词语,然后采用""软关注""的方法进一步抽取翻译中所需的上下文信息。实验表明,相比于基线系统,该方法能使翻译性能获得明显提升。 ",MESS201912006
中文字粒度切分在蒙汉机器翻译的应用,苏依拉:07987316|高芬:39185562|仁庆道尔吉:22393973,7,字粒度切分; Transformer; LSTM;,"在机器翻译任务中,主流的深度学习算法大多使用词或子词作为基础的语义单元,在词或子词层面学习嵌入表征。然而,词粒度层面存在一系列缺点。该文基于LSTM和Transformer蒙汉翻译模型,对蒙文进行子词粒度切分,对中文分别进行子词和字粒度切分对比实验。实验结果显示,相比于子词粒度切分,基于Transformer的蒙汉翻译模型和基于LSTM的蒙汉翻译模型的字粒度切分有极大的BLEU值提升,字级别的蒙汉翻译模型在验证集和测试集上都显著优于混合字和词的子词级别的蒙汉翻译模型。其表明,字级别的蒙汉翻译模型更能捕捉单元之间的语义联系,提高蒙汉翻译性能。 ",MESS201912007
融合单语语言模型的藏汉机器翻译方法研究,"慈祯嘉措1,2:41751738|桑杰端珠1,2:41044863|孙茂松3:08823738|色差甲1,2:38298547|周毛先1,2:25202339",6,藏语; 语言模型; 机器翻译; 融合; 神经网络;,"由于藏汉平行语料匮乏,导致藏汉神经网络机器翻译效果欠佳,该文提出了一种将藏语单语语言模型融合到藏汉神经网络机器翻译的方法,首先利用神经网络实现藏语单语语言模型,然后使用Transformer实现藏汉神经网络机器翻译模型,最后将藏语单语语言模型融合到藏汉神经网络机器翻译中。实验表明,该方法能显著提升藏汉神经网络机器翻译质量。基线系统藏语到汉语的BLEU值为21.1,汉语到藏语的BLEU值为18.6,融合藏语单语语言模型后,藏语到汉语的BLEU值为24.5,汉语到藏语的BLEU值为23.3,比原有基线系统的BLEU值分别提高了3.4和4.7。 ",MESS201912008
融入分类词典的汉越混合网络神经机器翻译集外词处理方法,"车万金1,2:43210207|余正涛1,2:05982358|郭军军1,2:42356071|文永华1,2:07896638|于志强1,2:23303809",9,神经机器翻译; 分类词典; 资源稀缺; 集外词;,"在神经机器翻译中,因词表受限导致的集外词问题很大程度上影响了翻译系统的准确性。对于训练语料较少的资源稀缺型语言的神经机器翻译,这种问题表现得更为严重。近几年,受到外部知识融入的启发,该文在RNNSearch模型基础上,提出了一种融入分类词典的汉越混合网络神经机器翻译集外词处理方法。对于给定的源语言句子,扫描分类词典以确定候选短语句对并标签标记,解码端利用词级组件和短语组件的混合解码网络,很好地生成单词集外词和短语集外词的翻译,从而改善汉越神经机器翻译的性能。在汉越、英越和蒙汉翻译实验上表明,该方法显著提高了准确率,对于资源稀缺型语言的神经机器翻译性能有一定的提升。 ",MESS201912010
基于循环卷积神经网络的藏文句类识别,"柔特1,2:31056708|才让加1,2:08163475",7,藏文句类; 循环卷积神经网络; 词向量; 句类识别;,"句子是语言的最小使用单位,句类识别是为了进一步细化句法和句义研究。由于藏文句尾通常没有特殊的标点符号来识别不同句类,因此这一藏文语言特性就变成了一大难题。该文提出了基于语境和功能特征为一体的句子用途分类方案。首先,该文介绍了文法中藏文句子分类及其特征。其次,收集了大量藏文句子并对其进行了人工标注。最后,采用循环卷积神经网络对藏文句类进行了自动识别。实验表明,该模型对藏文句类识别有较为显著的效果。 ",MESS201912011
基于数据增强的藏文改写检测研究,赵小兵1:22390615|鲍薇2:43614157|董建2:33019021|包乌格德勒3:25810569,8,改写检测; 数据增强; 孪生网络; 低资源语言;,"该文针对藏文语料稀缺的问题,在藏汉双语、藏文单语文本改写检测任务中使用数据增强的方法,在一定程度上解决了低资源语言训练语料规模小的问题。在藏汉跨语言文本改写检测任务中,该文使用数据增强方法,有效利用目前公开的藏汉平行语料,扩充藏汉跨语言文本改写检测训练语料,当扩充至20万句对时,藏汉改写检测模型的皮尔森系数(pearson correlation)达到0.547 6,比基线系统的皮尔森系数提升了0.397 1,表明藏汉改写检测模型检测出的句对相似度值与人工标注的相似度值已达到中等程度相关。在藏文单语言任务中,该文采用训练藏文音节向量的方法,以缓解语料稀缺带来的词向量稀疏问题。实验结果表明,基于藏文音节向量的藏文改写检测模型的皮尔森系数可达到0.678 0,比相应的基于藏文词向量实验的结果提升了0.1,使得藏文单语言文本改写检测模型的检测结果与人工标注的结果达到了强相关程度。 ",MESS201912013
融入注意力机制的越南语组块识别方法,王闻慧1:43614156|毕玉德2:41405517|雷树杰1:43614158,10,越南语; 组块识别; Bi-LSTM+CRF模型; 注意力机制;,"对于越南语组块识别任务,在前期对越南语组块内部词性构成模式进行统计调查的基础上,该文针对Bi-LSTM+CRF模型提出了两种融入注意力机制的方法:一是在输入层融入注意力机制,从而使得模型能够灵活调整输入的词向量与词性特征向量各自的权重;二是在Bi-LSTM之上加入了多头注意力机制,从而使模型能够学习到Bi-LSTM输出值的权重矩阵,进而有选择地聚焦于重要信息。实验结果表明,在输入层融入注意力机制后,模型对组块识别的F值提升了3.08%,在Bi-LSTM之上加入了多头注意力机制之后,模型对组块识别的F值提升了4.56%,证明了这两种方法的有效性。 ",MESS201912015
基于LambdaMART算法的微信公众号排序,渠北浚1:43618854|白宇1:24679275|蔡东风1:24679274|陈建军2:43618855,9,微信公众号; 排序学习; LambdaMART; 主成分分析;,"随着移动应用的普及,微信公众号已经成为人们获取信息的重要来源之一。微信公众号排序是获取优质信息、节约信息管理成本的必要手段。现有的公众号排序方法主要是对总阅读数、总点赞数等量化指标进行人工经验赋权得到排序结果,忽略了文章内容对公众号选择的影响。该文在保留量化指标的基础上,提出了主题垂直性、发文稳定性、主题覆盖率和主题相关性等微信篇章排序特征,使用LambdaMART算法针对上述特征集合进行排序学习,并通过主成分分析进行特征选择优化。实验结果表明,在公众号排序方面,LambdaMART方法优于现有其他方法,相关实验也证明了基于微信篇章内容分析特征的有效性。 ",MESS201912017
融合注意力LSTM的协同过滤推荐算法,"罗洋1:43614159|夏鸿斌1,2:07759781|刘渊1,2:07780067",9,注意力机制; 长短期记忆网络; 推荐系统; 附加堆叠降噪自编码器; 协同过滤;,"针对传统协同过滤算法难以学习深层次用户和项目的隐表示,以及对文本信息不能充分提取单词之间的前后语义关系的问题,该文提出一种融合辅助信息与注意力长短期记忆网络的协同过滤推荐模型。首先,附加堆叠降噪自编码器利用评分信息和用户辅助信息提取用户潜在向量;其次,基于注意力机制的长短期记忆网络利用项目辅助信息来提取项目的潜在向量;最后,将用户与项目的潜在向量用于概率矩阵分解中,从而预测用户偏好。在两个真实数据集MovieLens-100k和MovieLens-1M上进行实验,采用RMSE和Recall指标进行评估。实验结果表明,该模型与其他相关推荐算法相比在推荐性能上有所提升。 ",MESS201912019
基于多通道双向长短期记忆网络的情感分析,李卫疆:21665210|漆芳:42891910,10,情感分析; 长短期记忆; 多通道; 层归一化;,"当前存在着大量的语言知识和情感资源,但在基于深度学习的情感分析研究中,这些特有的情感信息,没有在情感分析任务中得到充分利用。针对以上问题,该文提出了一种基于多通道双向长短期记忆网络的情感分析模型(multi-channels bidirectional long short term memory network,Multi-Bi-LSTM),该模型对情感分析任务中现有的语言知识和情感资源进行建模,生成不同的特征通道,让模型充分学习句子中的情感信息。与CNN相比,该模型使用的Bi-LSTM考虑了词序列之间依赖关系,能够捕捉句子的上下文语义信息,使模型获得更多的情感信息。最后在中文COAE2014数据集、英文MR数据集和SST数据集进行实验,取得了比普通Bi-LSTM、结合情感序列特征的卷积神经网络以及传统分类器更好的性能。 ",MESS201912021
先秦诸家学派的相关系数与特征词研究,马创新1:34584698|梁社会2:08081243|陈小荷3:08109709,6,数字人文; 诸子百家; 相关度; 主题;,"为了发现先秦诸家学派之间的相关度,找出能够代表各学派主题特征的特征词,该文首次对诸家学派之间的相关关系作量化考察,对诸家思想的主题特征作统计分析。通过研究发现,儒家与道家之间的相关度最高,兵家与墨家之间的相关度最低,道家与其他各学派之间的相关系数的均值最大。该文还通过分析特定学派中各个词型与其他各学派中相同词型的等级之间差额大小,筛选出能够代表学派主题的特征词。 ",MESS201912023
第八届全国社会媒体处理大会在深圳成功举办,,1, ,"<正>2019年8月16日—18日,由中国中文信息学会主办,学会社会媒体处理专委会主办,哈尔滨工业大学(深圳)承办的第八届全国社会媒体处理大会(SMP2019)在深圳成功举办。中国中文信息学会理事长方滨兴院士、深圳市科技创新委梁永生主任、哈尔滨工业大学(深圳)常务副校长甄良教授、学会社会媒体处理专 ",MESS201912005
CCKS 2019全国知识图谱与语义计算大会在杭州隆重召开,,1, ,"<正>2019年全国知识图谱与语义计算大会(CCKS 2019)于8月24日至27日在杭州召开,由中国中文信息学会语言与知识计算专业委员会主办,浙江大学承办。本次会议主题是""知识智能""。大会吸引了来自海内外的800多名科研学者、工业界专家和知名企业代表参加。会议回顾了知识图谱与语义计算的进展情况,探 ",MESS201912009
“CIPS高校行”活动之江西师范大学,,1, ,"<正>9月26日下午,首次""中国中文信息学会(CIPS)高校行""活动在江西师范大学计算机信息工程学院学术报告厅隆重举行。计算机学院院长王明文教授,以及100余名师生代表参加了此次活动。中国中文信息学会副理事长、中科院自动化研究所宗成庆研究员,中国中文信息学会副理事长兼秘书长、中科院软件所孙 ",MESS201912012
第十五届全国机器翻译大会(CCMT2019)在南昌召开,,1, ,"<正>第十五届全国机器翻译大会(CCMT2019)于9月27日-29日在江西南昌召开。本次会议由中国中文信息学会主办,江西师范大学承办。大会吸引了来自全国高校、科研院所和企业界的近三百位专家学者代表参加。会议报告了机器翻译领域的最新研究成果、讨论了机器翻译评测相关的任 ",MESS201912014
第十八届中国计算语言学大会(CCL 2019)在昆明成功举办,,1, ,"<正>2019年10月18-20日,第十八届中国计算语言学大会(CCL2019)在云南省昆明市成功召开,会议由中国中文信息学会主办,昆明理工大学承办,组织单位为清华大学人工智能研究院。大会主席由中国中文信息学会理事长方滨兴院士和香港城市大学邹嘉彦教授担任,程序委员会主 ",MESS201912016
第五届中国健康信息处理大会(CHIP 2019)在广州隆重召开,,1, ,"<正>2019年11月22日-24日,由中国中文信息学会(CIPS)医疗健康与生物信息处理专业委员会(以下简称""专委会"")主办,中山大学健康医疗大数据国家研究院、中山大学中山医学院、广东省健康医疗大数据工程技术研究中心承办,鹏城实验室、广州健康医疗大数据技术创新联盟协办的第五届中国健康信息处理大会 ",MESS201912018
第八届未来数据论坛暨第六届大搜索论坛在海南召开,,1, ,"<正>2019年11月21-22日,由中国工程院、中国中文信息学会和FFD&Big Search Steering Committee主办,中国电子长城网际系统应用(海南)有限公司和中国工程院信息与电子工程学部联合承办的第八届未来数据论坛暨第六届大搜索论坛在中电长城网际海南信息安全基地顺利召开。中国中文信息学会理事长方 ",MESS201912020
欢迎订阅《中文信息学报》,,1, ,"<正>《中文信息学报》(Journal of Chinese Information Processing)是全国一级学会—社团法人中国中文信息学会和中国科学院软件研究所联合主办的学术性刊物,创刊于1986年10月,现为单月刊。由商务印书馆出版,为商务印书馆期刊方阵中的期刊之一,清华大学印刷厂印刷。《中文信息学报》是我国计算机、计算技术类中 ",MESS201912022
中文信息学报(月刊) 2019年 第33卷 总目次,,18, , ,MESS201912024
"一本书,走进120岁的甲骨学",,1, ,"<正>""一片甲骨惊天下。""甲骨文的发现,诞生了""甲骨学""这门新的综合性学科,影响巨大而深远。甲骨学不仅促进了相关的考古学、历史学、文献学、语言文字学、地理学、天文学等学科的发展,而且引起社会各界和国际组织的广泛关注。今年是甲骨文发现120周年,我们如何用一本书认识它?甲骨文是什么?甲骨文记载了什么?甲 ",MESS201912025
基于弱标注数据的汉语分词领域移植,朱运:42315319|李正华:32629227|黄德朋:40224590|张民:31758527,8,汉语分词; 领域移植; 弱标注数据;,"近年来,基于神经网络的分词模型在封闭领域文本上取得了很高的性能。然而,在领域移植场景下,即测试数据与训练数据的领域差异较大时,分词的性能会显著下降。该文尝试利用自动获取的弱标注数据来提升领域移植场景下的分词性能。首先,对目前性能最好的BiLSTM-CRF分词模型进行扩展,引入适用于弱标注数据的损失函数;进而提出一种简单有效的数据筛选方法,从海量弱标注数据中筛选和目前领域更相关的数据;最后,该文发现数据预处理和在神经网络中引入传统特征均可以有效提高分词性能。在SIGHAN Bakeoff 2010和ZhuXian标注测试集上的实验结果表明,该文所提方法可有效提升汉语分词领域移植性能,平均F值提高了3.6%。 ",MESS201909001
基于深度学习和迁移学习的领域自适应中文分词,成于思1:26996265|施云涛2:23981745,9,深度学习; 迁移学习; 领域分词; 工程法律;,"为了提高专业领域中文分词性能,以及弥补专业领域大规模标注语料难以获取的不足,该文提出基于深度学习以及迁移学习的领域自适应分词方法。首先,构建包含词典特征的基于深度学习的双向长短期记忆条件随机场(BI-LSTM-CRF)分词模型,在通用领域分词语料上训练得到模型参数;接着,以建设工程法律领域文本作为小规模分词训练语料,对通用领域语料的BI-LSTM-CRF分词模型进行参数微调,同时在模型的词典特征中加入领域词典。实验结果表明,迁移学习减少领域分词模型的迭代次数,同时,与通用领域的BI-LSTM-CRF模型相比,该文提出的分词方法在工程法律领域的分词结果F1值提高了7.02%,与预测时加入领域词典的BI-LSTM-CRF模型相比,分词结果的F1值提高了4.22%。该文提出的分词模型可以减少分词的领域训练语料的标注,同时实现分词模型跨领域的迁移。 ",MESS201909002
基于联合学习的跨领域法律文书中文分词方法,江明奇:41751735|严倩:36786845|李寿山:27030929,7,中文分词; 法律文书; 联合学习;,"中文分词任务是自然语言处理的一项基本任务。但基于统计的中文分词方法需要大规模的训练样本,且拥有较差的领域适应性。然而,法律文书涉及众多领域,对大量的语料进行标注需要耗费大量的人力、物力。针对该问题,该文提出了一种基于联合学习的跨领域中文分词方法,该方法通过联合学习将大量的源领域样本辅助目标领域的分词,从而提升分词性能。实验结果表明,在目标领域标注样本较少的条件下,该文方法的中文分词性能明显优于传统方法。 ",MESS201909003
基于膨胀卷积神经网络模型的中文分词方法,王星:24228226|李超:14291131|陈吉:27878388,7,中文分词; 膨胀卷积; 深度学习; 自然语言处理;,"目前,许多深度神经网络模型以双向长短时记忆网络结构处理中文分词任务,存在输入特征不够丰富、语义理解不全、计算速度慢的问题。针对以上问题,该文提出一种基于膨胀卷积神经网络模型的中文分词方法。通过加入汉字字根信息并用卷积神经网络提取特征来丰富输入特征;使用膨胀卷积神经网络模型并加入残差结构进行训练,能够更好理解语义信息并提高计算速度。基于Bakeoff 2005语料库的4个数据集设计实验,与双向长短时记忆网络模型的中文分词方法做对比,实验表明该文提出的模型取得了更好的分词效果,并具有更快的计算速度。 ",MESS201909004
一种面向生文本的事件同指消解神经网络方法,方杰:37694780|李培峰:09886822|朱巧明:05968617,8,事件抽取; 事件同指消解; 注意力池化; 门控卷积;,"事件同指消解在自然语言理解中是一项复杂的任务,它需要在理解文本信息的基础上,发现其中的同指事件。事件同指消解在信息抽取、问答系统、阅读理解等自然语言任务中均有重要作用。该文提出了一个事件同指消解框架,包括事件抽取(ENS_NN)、真实性识别(ENS_NN)和事件同指消解(AGCNN)三个部分。事件同指消解模型(AGCNN)利用注意力池化机制来捕获事件的全局特征,利用门控卷积抽取复杂语义特征,提高了事件同指消解的性能。在KBP 2015和KBP 2016数据集上的实验结果表明,该文提出的方法优于目前最优的系统。 ",MESS201909005
基于新HSK词汇大纲的词汇等级类推分析,"张引兵1,2:39414490|宋继华1:06364557|彭炜明1:24186788|郭冬冬1:38128587|张金1:42886361",11,新HSK大纲; 等级类推; 词法知识库; 相对熵;,"HSK是一项国际汉语能力标准化考试。新HSK大纲中附表所列650个""默认词""多依据专家知识人工列举式的扩充。该文在《现代汉语词典》《现代汉语语法信息词典》等资源的基础上,利用知识工程的方法,迭代使用减字默认、组合默认等词汇等级类推规则,力争实现类推过程中隐性知识的显性化、分散知识的系统化,使得词汇等级类推的每一个环节都有章可循、有据可依,完成了基于新HSK大纲词汇等级的系统类推工作。接着,结合所构建的汉语词法知识库对类推结果进行了筛选,最终得到了23 762个词语的类推等级。最后,通过对类推结果的统计分析,表明该文的研究工作可以更好地发挥新HSK词汇大纲在汉语词汇定级、文本难度分级中的指导作用,也可为其他领域教学词汇大纲的制定提供一定的借鉴。 ",MESS201909006
面向机器学习的流式文档逻辑结构标注方法研究,刘倩:32560702|李宁:17409216|田英爱:22065610,11,结构标注; 文档结构识别; 机器学习;,"针对采用机器学习方法识别流式文档结构时语料库稀少、语料标注复杂的问题,该文在研究文档的逻辑结构和编辑语义特征的基础上,确立流式文档逻辑结构标注体系,并提出一种三段式的半自动文档逻辑结构标注方法:第一阶段通过机助人工实现文档元数据的分离式标注,第二阶段自动重建逻辑结构,第三阶段自动填充特征向量。实验结果表明,该文提出的文档逻辑结构标注方法能够节省人工成本、提高机器学习算法对文档结构识别的准确率与召回率,F值达到97.5%。 ",MESS201909007
基于ATT-IndRNN-CNN的维吾尔语名词指代消解,祁青山1:35078771|田生伟1:09220503|禹龙2:09256058|艾山·吾买尔2:10775068,9,注意力机制; 独立循环神经网络; CNN; 指代消解; 维吾尔语;,"该文提出一种基于注意力机制(attention mechanism,ATT)、独立循环神经网络(independently recurrent neural network,IndRNN)和卷积神经网络(convolutional neural network,CNN)结合的维吾尔语名词指代消解模型(ATT-IndRNN-CNN)。根据维吾尔语的语法和语义结构,提取17种规则和语义信息特征。利用注意力机制作为模型特征的选择组件计算特征与消解结果的关联度,结果分别输入IndRNN和CNN得到包含上下文信息的全局特征和局部特征,最后融合两类特征并使用softmax进行分类完成消解任务。实验结果表明,该方法优于传统模型,准确率为87.23%,召回率为88.80%,F值为88.04%,由此证明了该模型的有效性。 ",MESS201909008
融合图结构与节点关联的关键词提取方法,"马慧芳1,2:09161418|王双1:39449793|李苗1:28498522|李宁3:38292566",10,关键词提取; 随机游走; 节点属性; 语义信息; 节点关联;,"单篇文本的关键词提取可应用于网页检索、知识理解与文本分类等众多领域。该文提出一种融合图结构与节点关联的关键词提取方法,能够在脱离外部语料库的情况下发现单篇文本的关键词。首先,挖掘文本的频繁封闭项集并生成强关联规则集合;其次,取出强关联规则集合中的规则头与规则体作为节点,节点之间有边当且仅当彼此之间存在强关联规则时,边权重定义为关联规则的关联度,将强关联规则集合建模成关联图;再次,综合考虑节点的图结构属性、语义信息和彼此的关联性,设计一种新的随机游走算法计算节点的重要性分数;最后,为了避免抽取的词项之间有语义包含关系,对节点进行语义聚类并选取每个类的类中心作为关键词提取结果。通过设计关联图模型参数的选取、关键词的提取规模、不同算法对比3个实验,在具有代表性的中英文数据上证明了该方法能够有效提升关键词提取的效果。 ",MESS201909009
结合注意力机制与双向LSTM的中文事件检测方法,沈兰奔:42886362|武志昊:26078459|纪宇泽:42886363|林友芳:06327199|万怀宇:11653168,9,中文事件检测; 注意力机制; 长短期记忆模型;,"事件检测是信息抽取领域的重要任务之一。已有的方法大多高度依赖复杂的语言特征工程和自然语言处理工具,中文事件检测还存在由分词带来的触发词分割问题。该文将中文事件检测视为一个序列标注而非分类问题,提出了一种结合注意力机制与长短期记忆神经网络的中文事件检测模型ATT-BiLSTM,利用注意力机制来更好地捕获全局特征,并通过两个双向LSTM层更有效地捕获句子序列特征,从而提高中文事件检测的效果。在ACE 2005中文数据集上的实验表明,该文提出的方法与其他现有的中文事件检测方法相比性能得到明显提升。 ",MESS201909010
基于联合标注和全局推理的篇章级事件抽取,"仲伟峰1:07009143|杨航1,2:42886364|陈玉博2:29895348|刘康2:13898613|赵军2:10891784",9,篇章级事件抽取; 联合标注; 全局推理;,"事件抽取可以帮助人们从海量的文本中快速、准确地获取感兴趣的事件知识。然而,目前事件抽取的研究主要集中在从单一句子中抽取事件,由于事件构成的复杂性和语言表述的多样性,多数情况下多句才能完整地描述一个事件。因此,从篇章中抽取出完整的结构化事件信息,显得更有价值和意义。该文首先利用基于注意力机制的序列标注模型联合抽取句子级事件的触发词和实体,与独立进行实体抽取和事件识别相比,联合标注的方法在F值上提升了1个百分点。然后利用多层感知机判断实体在事件中扮演的角色。最后,在句子级事件抽取的基础上,利用整数线性规划的方法进行全局推理,融合句子级事件信息,实现篇章级事件抽取,与基线模型相比,这种基于全局推理的篇章级事件抽取在F值上提升了3个百分点。 ",MESS201909011
图像标题生成中的人物类名实体填充方法研究,张家硕:37736060|洪宇:25038035|唐建:37885116|程梦:41251072|姚建民:13898051,11,图像标题生成; 实体信息; 阅读理解;,"得益于深度学习的发展和大规模图像标注数据集的出现,图像标题生成作为一种结合了计算机视觉和自然语言处理的综合任务得到了广泛关注。受到神经机器翻译任务的启发,前人将图像标题生成任务看作是一种特殊的翻译任务,即将一张图像视作源端的信息表述,通过编码解码过程,翻译为目标端的自然语言语句。因此,现有研究引入了端到端的神经网络模型,并取得了较好的生成效果。然而,图像标题生成研究依然面临许多挑战,其中最值得关注的难点之一是解决确切性文字表述的问题。一条确切的标题往往是有形且具体的表述,例如""梅西主罚点球"",而目前机器生成的标题则较为粗浅和单调,例如""一个人在踢球""。针对这一问题,该文尝试开展标题生成的有形化研究,并在前瞻性实验中聚焦于标题中人名实体的识别与填充。在技术层面,该文将机器自动生成的图像标题作为处理对象,去除其中抽象人名实体的名称(例如,一个人、男人和他等)或错误的称谓,并将由此形成的带有句法空缺的表述视作完型填空题目,从而引入了以Who问题为目标的阅读理解技术。具体地,该文利用R-NET阅读理解模型实现标题中人名实体的抽取与填充。此外,该文尝试基于图像所在文本的局部信息和外部链接的全局信... ",MESS201909012
基于文本和用户信息的在线评论质量检测,吴璠:41405523|王中卿:23843509|周夏冰:42886366|李寿山:27030929|周国栋:13898054,9,评论质量; 用户表示; 神经网络模型; 注意力机制;,"随着互联网的迅速发展,越来越多的用户评论出现在社交网站上。面对迅速增长的评论数据,如何为阅读评论的消费者提供准确、真实的高质量评论就显得尤为重要。评论质量检测旨在判断在线评论的质量,在传统的研究中,文本信息通常独立地被用于预测评论质量。但是在社交媒体上,每个文本之间不是独立的,而是可以通过发表文本的作者与其他文本相关联,即同一个用户或相近的用户发表的评论质量具有一定的相似性。因此,为了更好的构建文本的表示和研究文本之间基于用户的关联,该文基于神经网络模型分别构建用户和文本的表示,同时,为了放大用户信息的作用,我们进一步将基于注意力机制的用户信息融合到文本中,从而提高文本评论质量检测的效果。在Yelp 2013数据集上进行实验的结果表明,该模型能有效地提高在线评论质量检测的性能。 ",MESS201909013
融合社交网络用户自身属性的信息传播数学建模与舆情演化分析,刘小洋:30298854|唐婷:41639984|何道兵:41639982,8,社交网络; 信息传播; 舆情演化;,"针对传统的社交网络信息传播模型极少将用户属性和信息特征这两个因素纳入到信息传播模型研究中的不足,该文提出了一种基于用户自身属性的信息传播模型。首先该文抽取用户影响力、用户态度、用户年龄、信息能量、信息价值等特征并构建交互规则;其次,根据这些特征建立信息传播的数学模型,模拟社交网络舆情演化过程;最后,为验证模型的有效性,开展了与真实事件的实证分析对比实验。实验结果表明:仿真结构与真实数据的相似度大于0.97,因而该模型符合社交网络舆情信息传播的特性,能够较为准确地描述社交网络中的舆情传播过程。 ",MESS201909014
基于循环实体网络的细粒度情感分析,贾川:38989577|方睿:36188802|浦东:38989576|康刚:42886367,6,细粒度情感分析; 循环网络; 属性嵌入;,"目前,深度神经网络模型已经在文本情感分析领域取得了较好的效果,但是对于属性相关的细粒度的情感分析任务,现有研究方法的效果仍有待改进。该文提出了一种基于循环实体网络来进行细粒度情感分析的方法,在网络中嵌入预定义的评价属性类别信息,利用扩大的内部记忆链来抽取与每个属性类别相关的情感特征,并通过动态记忆单元控制与属性相关情感信息的远距离依赖,然后,对于给定的单个属性类别,利用注意力机制从内部记忆链中抽取该属性类别的情感特征进行分类。该文提出的方法在Sentihood数据上与目前精度最高的方法相比,取得了近1个百分点的提升,而且模型的收敛速度更快。 ",MESS201909015
基于自动提取句法模板的情感分析,"潘浩1:10615459|卫宇杰1,2:41694675|潘尔顺1,2:08570170",12,情感分析; 依存关系; 分枝; 剪枝; 遗传算法;,"提出了一种自动化提取情感依存句法关系的分析方法。在待分析语句依存句法树的基础上,结合中文语法特点,定义了分枝、嫁接、剪枝和枝解四种基本操作,压缩依存树的特征空间的同时将语句转换成表征句法关系的子树集合,最后利用遗传算法求解最优情感子树集。针对第三届自然语言处理及中文计算会议(NLPCC 2014)评测数据的实验结果表明,该方法在语句是否表达情感的判别上具有优异效果。与基于词典的情感分析结合,可降低词典对客观句的高误判缺陷,进而明显改进基于词典的情感分析方法。 ",MESS201909016
商务印书馆图书介绍,,1, ,"<正>中国语言文字事业发展报告ISBN978-7-100-17498-5定价:60.00""语言生活皮书""由国家语言文字工作委员会组织编写,旨在贯彻落实《国家通用语言文字法》,提倡""语言服务""理念,贯彻""大语言文字工作""发展新思路,为语言文字事业更好服务国家发展需求做贡献。""语言生活皮书""分A、B、C、D、E五个系列,各自连续编号发布出版。其中,A系列为《中国语言文字事业发展报告》(""白皮书""),B系列为《中国语言生活状况报告》(""绿 ",MESS201909017
融合概念与逻辑的中文深层语义描述体系,夏乔林:42557277|穗志方:06268960|常宝宝:06253581|詹卫东:06264050|张坤丽:10310465|柯永红:35817146,11,中文语义; 意义表示; 资源构建;,"自然语言的语义理解涉及多个层面的问题,包括以谓词为中心的基本命题义、命题义之外的概念义、逻辑补足义等。目前主流的浅层语义分析主要集中在对命题义的分析上,缺少对概念义和逻辑义的支持,难以辅助计算机对文本的深度理解与推理。该文借鉴论元结构理论、事件语义学等相关语言学理论,突破语义角色标注等浅层语义分析的局限,建立了一种融合概念与逻辑的中文深层语义描述体系;并在该体系基础上,采用层层渲染的标注策略,构建了基于真实语料的大规模中文深层语义标注语料库,通过语言工程实践验证该描述体系的完备性和覆盖度。这一理论体系的建立和语言资源的构建,有望推动中文自动语义分析技术和人工智能等相关工作的创新发展。 ",MESS201908001
基于统计语言模型改进的Word2Vec优化策略研究,张克君:06281785|史泰猛:41133368|李伟男:42246263|钱榕:33300882,9,词向量; 统计语言模型; TFIDF; 文本关键词; CBOW-TFIDF;,"该文从训练词向量的语言模型入手,研究了经典skip-gram、CBOW语言模型训练出的词向量的优缺点,引入TFIDF文本关键词计算法,提出了一种基于关键词改进的语言模型。研究发现,经典skip-gram、CBOW语言模型只考虑到词本身与其上下文的联系,而改进的语言模型通过文本关键词建立了词本身与整个文本之间的联系,在词向量训练结果的查准率和相似度方面,改进模型训练出的词向量较skip-gram、CBOW语言模型有一个小幅度的提升。通过基于维基百科1.5GB中文语料的词向量训练实验对比后发现,使用CBOW-TFIDF模型训练出的词向量在相似词测试任务中结果最佳;把改进的词向量应用到情感倾向性分析任务中,正向评价的精确率和F1值分别提高了4.79%、4.92%,因此基于统计语言模型改进的词向量,对于情感倾向性分析等以词向量为基础的应用研究工作有较为重要的实践意义。 ",MESS201907002
面向中文的修辞结构关系分类体系及无歧义标注方法,侯圣峦:31827376|费超群:41863749|张书涵:36543178,11,自然语言处理; 修辞结构理论; 修辞结构关系; 篇章结构分析;,"修辞结构理论是一种重要的篇章结构理论,其核心是修辞结构关系。该文基于修辞结构理论,结合中文文本特点,提出面向中文的层次化修辞结构关系分类体系及多元定义。同时,针对标注者遇到的歧义问题,提出了无歧义标注方法。为了便于标注,设计并实现了基于Java图形界面的标注工具RSTTagger,该工具以句子的主谓结构关键词构成的元组作为基本标注单位,自底向上逐级标注,最终标注成一棵完整的修辞结构关系树。为验证标注结果的一致性,选取160篇中文外贸领域语料进行标注,不同标注者同时标注其中50篇,标注一致性达到76.63%。该标注框架可以应用到其他领域语料标注中,已标注的160篇语料可以作为篇章结构理论研究的基础语料库。 ",MESS201907004
基于词对关联网络的句子对齐研究,丁颖:24458318|李军辉:09886805|周国栋:13898054,9,句子对齐; 词对关联网络; 神经网络;,"句子对齐能够为跨语言的自然语言处理任务提供高质量的对齐句子对。受对齐句子对通常包含大量对齐的单词对这种直觉的启发,该文通过探索神经网络框架下词对间的语义相互作用来解决句子对齐问题。特别地,该文提出的词对关联网络通过融合三种相似性度量方法从不同角度来捕获词对之间的语义关系,并进一步融合它们之间的语义关系来确定两个句子是否对齐。在单调和非单调文本上的实验结果表明,该文提出的方法显著提高了句子对齐的性能。 ",MESS201907005
融合单词翻译的神经机器翻译,韩冬:13969117|李军辉:09886805|周国栋:13898054,6,单词翻译; Transformer; 神经机器翻译;,"神经机器翻译由于无法完全学习源端单词语义信息,往往造成翻译结果中存在着大量的单词翻译错误。该文提出了一种融入单词翻译用以增强源端信息的神经机器翻译方法。首先使用字典方法找到每个源端单词对应的目标端翻译,然后提出并比较两种不同的方式,用以融合源端单词及其翻译信息:①Factored编码器:单词及其翻译信息直接相加;②Gated编码器:通过门机制控制单词翻译信息的输入。基于目前性能最优的基于自注意力机制的神经机器翻译框架Transformer,在中英翻译任务的实验结果表明,与基准系统相比,该文提出的两种融合源端单词译文的方式均能显著提高翻译性能,BLEU值获得了0.81个点的提升。 ",MESS201907006
利用单语数据改进神经机器翻译压缩模型的翻译质量,李响:25670932|刘洋:45684033|陈伟:44628874|刘群:37515014,10,神经机器翻译; 知识蒸馏; 单语数据;,"该文提出利用一个大型且精度高的神经机器翻译模型(教师模型)从单语数据中提取隐性双语知识,从而改进小型且精度低的神经机器翻译模型(学生模型)的翻译质量。该文首先提出了""伪双语数据""的教学方法,利用教师模型翻译单语数据获得的合成双语数据改进学生模型,然后提出了""负对数似然—知识蒸馏联合优化""教学方法,除了利用合成双语数据,还利用教师模型获得的目标语言词语概率分布作为知识,从而在知识蒸馏框架下提高学生模型的翻译质量。实验证明,在中英和德英翻译任务上,使用该方法训练的学生模型不仅在领域内测试集上显著超过了基线学生模型,而且在领域外测试集上的泛化性能也得到了提高。 ",MESS201907007
基于领域特征的神经机器翻译领域适应方法,谭敏:31371820|段湘煜:31758526|张民:31758527,9,领域适应; 判别器; 系统集成;,"神经机器翻译在资源丰富领域上训练的翻译模型往往在其他资源稀缺领域中表现较差,领域适应是利用资源丰富的领域帮助资源稀少的领域提升翻译质量的一种方法。该文提出基于领域特征的领域适应方法以提升资源稀缺领域的神经机器翻译质量。具体而言,该文尝试构建领域敏感网络以获得领域特有特征,构建领域不敏感网络以获得领域间的共有特征。一个领域判别器被用于区分领域。该文通过训练领域敏感网络使得该领域判别器更易做出准确判断,同时引入对抗机制,使得领域不敏感网络欺骗该领域判别器。最后,提出一种系统集成机制,融合基准神经翻译网络、领域敏感网络、领域不敏感网络以完成神经机器翻译的领域适应。实验结果显示,该方法在中英广播对话领域上和英德口语领域上的翻译效果均有显著提升。 ",MESS201907008
融合图片主题信息的图片描述翻译,唐建:37885116|洪宇:25038035|刘梦眙:38128588|姚亮:08849993|姚建民:13898051,10,图片描述翻译; 主题差异性; 图片检索;,"图片描述翻译是给定图片及图片在某一语言的描述,利用翻译技术为图片生成目标语言描述的任务。观察发现,不同图片表达的场景往往不同,对应的图片描述具有明显的主题差异性。因此,利用主题信息能够提升翻译效果。然而,图片描述的内容通常较短,无法有效反映其主题。针对该问题,该文提出了一种融合图片主题信息的图片描述翻译方法。对于任意的图片描述对,该方法首先借助相似图片检索技术从维基百科图片库中检索与源图片相似的目标图片,进而利用包含目标图片的文档学习源图片的主题表示。最终,利用训练集中所有图片描述对的主题表示重新学习并获取适应主题的翻译模型。实验结果表明,借助相似图片获取信息量更为丰富的描述文本,并利用文本的主题信息强化翻译模型的方法,能够提高现有统计机器翻译系统的性能,在WMT16测试集上进行的评测显示,翻译质量的BLEU值提升了0.74个百分点。 ",MESS201907009
基于混合策略的藏文虚词识别方法,拉玛扎西:39041770|才智杰:08166533|班玛宝:41329890,6,自然语言处理; 藏文虚词; 基于规则; 最大熵模型;,"藏文虚词在歧义消解、句法、句型和语义处理等方面起着重要的语法作用。该文在分析传统藏文虚词研究成果的基础上,统计了面向自然语言处理的藏文虚词及特征,提出了基于规则和最大熵模型相结合的藏文虚词识别策略。实验表明,该方法识别藏文虚词的准确率、召回率和F1值分别达98.39%、98.75%、98.57%。 ",MESS201907010
藏文词向量相似度和相关性评测集构建,才智杰:08166533|孙茂松:08823738|才让卓玛:11447913,8,自然语言处理; 藏文; 词向量; 评测集;,"词向量评测是词向量研究的基础,包括内部评测(intrinsic evaluation)和外部评测(extrinsic evaluations)。外部评测是将得到的词向量应用到具体某个任务中进行评测,是词向量研究的目标。内部评测是通过建立词之间的语义相似度或相关性能力的评测集,评价词向量模型的性能,是一种常用的词向量评测方式。该文通过分析英文、汉文词向量评测集构建方法,结合藏文的特点,研究藏文词向量评测集构建方法,构建了用于评价藏文词向量相似度和相关性的评测集TWordSim215和TWordRel215,并分析其有效性。 ",MESS201907011
探究复述策略对获取实体属性槽“源信息”的意义,宋睿:40409098|陈鑫:22061606|洪宇:25038035,13,槽填充; 复述; 树编辑模型;,"实体属性槽填充是一种抽取命名实体特定属性(slot)实例(也称槽值,即filler)的自然语言处理研究。其中,""源信息""特指属性实例的来源,即一段或一句佐证实例正确反映属性的文本片断。观测语料可以发现,实体属性源信息中存在大量同质异构现象,即复述现象。因此,该文结合复述技术与现有知识库,探究了复述识别模型在仅有小规模种子""源信息""的基础上,对于实体属性槽源信息分类的有效性。实验证明,基于树编辑模型的复述识别方法在先验知识较少的情况下,能够很好地捕获实体属性的相关""源信息""。 ",MESS201907012
一种基于时间序列预测的重采策略,史存会:40978252|孟剑:42104904|俞晓明:09560060|刘悦:09639001|靳小龙:26681578|程学旗:09559496,9,网络采集; 采集策略; 时间序列预测;,"及时获取新增内容,是采集器的重要衡量指标。基于版块页-内容页架构设计的网络采集器通过定期重采入口的版块页,能够有效地快速识别新产生内容页面并进行扩展。然而获取内容的实时性与对网站访问的友好性存在一定的折中。传统的重采策略关注时效性,而忽略了对网站访问的友好性。该文提出了一种基于时间序列预测的改进重采策略兼顾时效性和友好性。实验表明,该方法可以在保证数据采集实时性的情况下,有效降低访问量,提升对网站访问的友好性。 ",MESS201907013
基于语言学扰动的事件检测数据增强方法,陆垚杰:41808446|林鸿宇:41808445|韩先培:26496192|孙乐:10352504,8,事件检测; 数据增强; 多实例学习;,"近年来,深度学习在事件检测领域取得了长足进展。但是,现有方法通常受制于事件检测标注数据的规模和训练阶段的不稳定性。针对上述问题,本文提出了基于语言学扰动的事件检测数据增强方法,从语法和语义两个角度生成伪数据来提升事件检测的性能。为了有效的利用生成的伪数据,该文探索了数据增加和多实例学习两个训练策略。在KBP 2017事件检测数据集上的实验验证了我们方法的有效性。此外,在人工构造的少量ACE2005数据集上的实验结果证明该文方法可以大幅度提升小数据情况下的模型学习性能。 ",MESS201907014
基于轨迹时空词向量的用户年龄特征识别,吴浩:09602368|张威强:42245896|张朋柱:08533877,10,语义轨迹; 词频—逆文本频率; 词向量; Word2vec; 分类;,"用户移动上网访问基站的轨迹数据从时间和空间上反映了用户的生活习惯和行为模式。时间和空间信息同时产生不应分别考虑。因此,该文在传统的TF-IDF方法基础上提出了与时间相关的TFT-IDFT方法,用以提取轨迹点语义信息,进而采用word2vec方法将轨迹数据转化为文档分析。提取包含位置信息和语义信息的轨迹时空词向量,在此基础上建立多分类模型对用户所属年龄段进行识别。实验结果表明,改进的TFT-IDFT方法在提取轨迹语义时更具合理性,且基于此方法构建的轨迹时空词向量应用于分类模型,对用户所属年龄阶段的识别效果更好。 ",MESS201907015
基于相似主题和HITS的微博用户推荐算法研究,王嵘冰:22033947|徐红艳:08562732|冯勇:07932283|安维凯:38685099,8,微博用户推荐; HITS; 权威度; 中心度; 主题相似度;,"为了准确地为微博用户推荐相近兴趣领域的重要用户,有效提高用户对微博平台的依赖度。该文对传统的HITS算法进行了改进:通过分析微博用户社交网络结构,运用改进算法将微博用户划分为3类,在微博主题相似度计算中引入用户的权威度和中心度,最后根据用户类别进行微博用户推荐。实验中,使用爬取的微博数据对传统的推荐算法和该文的改进算法进行对比实验,由于所提算法在分析过程中考虑了用户结构信息、用户的权威度与中心度等多种因素,因而在准确率、召回率、F1值上均有明显提高。 ",MESS201907016
ISO/IEC 10646国际编码标准下的香港电脑汉字编码及字形原则,熊丹:31878007|陆勤:09238733,7,电脑汉字编码; 字形; 字符集;,"在ISO/IEC 10646国际编码标准中,香港使用的汉字载于H列。该文介绍了如何在ISO/IEC 10646国际编码标准下进一步完善香港电脑汉字的扩展机制及H列字符字源资料的编码方案。由于目前H列的很多字形并未完全反映香港的实际习惯写法,因此香港制定了一套适用于香港常用写法的电脑汉字参考字形,该文介绍了此套字形的原则。 ",MESS201907017
新编红楼梦辞典,,1, ,"<正>ISBN:978-7-100-12332-7周汝昌、晁继周主编定价:99元出版日期:2019年4月收词宏富、释义精准的最新版《红楼梦》百科辞典。1.收词宏富,典章、职官、建筑、器物、服饰、医药等词语之外,《红楼梦》文本和《红楼梦》时代所特有的词语,均收入辞典,为阅读、研究《红楼梦》和研究语言提供方便。2.释义精准到位,既注出词语本义、引申义,又照顾语境义,一些条目纠正了前人的误释。 ",MESS201907018
中国中文信息学会主办第四届亚洲信息获取暑期学校,,1, ,"<正>7月10日,由中国中文信息学会主办,海南大学、清华大学、中科院计算所、中国人民大学协办的第四届亚洲信息获取暑期学校(The fourth Asian Summer School in Information Access,ASSIA2019)在海口举行。本次暑期学校邀请了包括荷兰皇家科学院院士、阿姆斯特丹大学Maarten de Rijke教授,国际计算机学 ",MESS201907003
基于转移神经网络的中文AMR解析,吴泰中1:40934786|顾敏1:36391428|周俊生1:08116958|曲维光1:08112756|李斌2:08075606|顾彦慧1:08080677,11,抽象语义表示; 转移神经网络; 概念识别;,"抽象语义表示(abstract meaning representation,AMR)是一种领域无关的句子语义表示方法,它将一个句子的语义抽象为一个单根有向无环图,AMR解析旨在将句子解析为对应的AMR图。目前,中文AMR研究仍然处于起步阶段。该文结合中文AMR特性,采用基于转移神经网络的方法对中文AMR解析问题展开了试验性研究。首先,实现了一个基于转移解码方法的增量式中文AMR解析神经网络基线系统;然后,通过引入依存路径语义关系表示学习和上下文相关词语语义表示学习,丰富了特征的表示;最后,模型中应用序列化标注的模型实现AMR概念识别,优化了AMR概念识别效果。实验结果表明,该模型在中文AMR解析任务中达到了0.61的Smatch F1值,明显优于基线系统。 ",MESS201904001
基于潜在语义特性的语义双关语检测及双关词定位,"刁宇峰1,2:25202941|杨亮1:14244075|林鸿飞1:06504899|吴迪1:06532630|樊小超1,3:39770371|徐博1:23769215|许侃1:11286125",9,语义双关句; 潜在语义特性; 双关词定位; 词向量; 同义词;,"语义双关语是幽默、笑话和喜剧等作品的来源之一,在人类写作的发展进程中具有重要的历史地位。由于语义双关语存在歧义难懂的特点,因此难以挖掘语义双关语的潜在语义信息,故目前语义双关语的检测和双关词的定位是自然语言处理任务中的一项困难和挑战。该文在语义双关语的理论基础上,挖掘了一系列的潜在语义特性,并构建了对应每个特性的特征集,用以检测语义双关语;同时从潜在语义特性出发,提出了一种基于词向量和同义词融合的语义相似度匹配算法实现语义双关词的定位。在SemEval 2017Task 7和Pun of the Day数据集上均取得了较好的实验结果,验证了该文所提出的检测算法和定位算法。 ",MESS201904002
中文基本复合名词短语语义关系体系及知识库构建,刘鹏远:27489874|刘玉洁:41751727,9,基本复合名词短语; 语义关系体系; 知识库;,"名词短语一直是中外语言学领域的重要研究对象,近年来在自然语言处理领域也受到了研究者的持续关注。英文方面,已建立了一定规模的名词短语语义关系知识库。但迄今为止,尚未建立相应或更大规模的描述名词短语语义关系的中文资源。该文借鉴国内外诸多学者对名词短语语义分类的研究成果,对大规模真实语料中的基本复合名词短语实例进行试标注与分析,建立了中文基本复合名词短语语义关系体系及相应句法语义知识库,该库能够为中文基本复合名词短语句法语义的研究提供基础数据资源。目前该库共含有18 281条高频基本复合名词短语,每条短语均标注了语义关系、短语结构及是否指称实体等信息,每条短语包含的两个名词还分别标注了语义类信息。语义类信息基于北京大学《现代汉语语义词典》。基于该知识库,该文还做了基本复合名词短语句法语义的初步统计与分析。 ",MESS201904003
基于描述约束的词表示学习,"冶忠林1,2,3:40587943|赵海兴1,4,2,3:31156614|张科4,2,3:08166737|朱宇4,2,3:40587946",8,词表示学习; 语义嵌入; 词表示联合模型; 词嵌入; 词语结构矩阵;,"词语作为语言模型中的基本语义单元,在整个语义空间中与其上下文词语具有很强的关联性。同样,在语言模型中,通过上下文词可判断出当前词的含义。词表示学习是通过一类浅层的神经网络模型将词语和上下文词之间的关联关系映射到低维度的向量空间中。然而,现有的词表示学习方法往往仅考虑了词语与上下文词之间的结构关联,词语本身所蕴含的内在语义信息却被忽略。因此,该文提出了DEWE词表示学习算法,该算法可在词表示学习的过程中不仅考量词语与上下文之间的结构关联,同时也将词语本身的语义信息融入词表示学习模型,使得训练得到的词表示既有结构共性也有语义共性。实验结果表明,DEWE算法是一种切实可行的词表示学习方法,相较于该文使用的对比算法,DEWE在6类相似度评测数据集上具有优异的词表示学习性能。 ",MESS201904004
基于领域知识的增强约束词向量,"王恒升1,2:10474429|刘通1:37773486|任晋1:22674527",11,增强约束词向量; 语义表达; 本体知识;,"词向量是一种词语的数字化的表达。基于神经网络模型,利用语料中词语之间的上下文关系这一约束条件,通过大量训练得到词向量。词向量在表达词的语义上的表现给人以无限的希望与想象空间,基于词向量的文本分类、人机对话、智能检索等得到了广泛的研究。该文针对校园信息查询的特定应用,建立了所涉及词语的分类本体,除了利用语料中词语上下文关系外,还将本体知识作为约束条件进行词向量的训练,增强了词向量的语义表达。基于skip-gram模型,采用多任务的神经网络训练方法,在自己收集的语料上训练得到了针对领域的词向量。实验表明,基于领域知识的增强约束词向量能够更准确地表达词的语义信息。 ",MESS201904005
基于语义分类和描述框架的网络攻击知识抽取研究及其应用,"方芳1,2:22655000|王亚1:35384665|王石1:23246662|符建辉1:25121025|曹存根1:10348278",12,语义分类和描述框架; 知识抽取; 语义文法; 遭受语义类; 网络安全知识库;,"随着计算机技术的迅猛发展,自然语言处理成为计算机科学领域与人工智能领域中的一个重要方向,且文本知识获取(knowledge acquisition from text,KAT)是人工智能的重要研究内容。当前对于文本研究,大多采用关键字以及机器学习方法,准确率并不高。该文提出了一种基于语义文法的中文网络攻击事件知识获取方法。首先介绍参考FrameNet构建的语义分类和描述框架,它在现代汉语基本句模分类的基础上进行了扩充和改进。其次,重点介绍了攻击文本中最常见的遭受类语义类的设计和形成过程。然后将语义分类和描述框架应用在""网络安全""领域,形成""网络攻击语义类"",并介绍在建立""网络攻击语义类""时遇到的难题,包括文法的设计中对事元的确定、复合句的处理、""的是""结构句型的分析设计、谓词设计等。最后,使用国家某安全部门提供的真实数据进行网络攻击知识抽取,实验表明该方法具有较高的准确率。 ",MESS201904006
基于汉盲对照语料库和深度学习的汉盲自动转换,"蔡佳1,2:34366294|王向东1:13898596|唐李真3:10799256|崔晓娟1,2:41751729|刘宏1:09559922|钱跃良1:09639409",8,汉盲转换; 中国盲文; 盲文语料库; 深度学习;,"汉盲转换是指将汉字文本自动转换为对应的盲文文本,其在盲文出版、盲人教育等领域具有重要应用价值,但当前已有系统性能难以满足实用需求。该文提出一种基于汉盲对照语料库和深度学习的汉盲自动转换方法,首次将深度学习技术引入该领域,采用按照盲文规则分词的汉字文本训练双向LSTM模型,从而实现准确度高的盲文分词。为支持模型训练,提出了从不精确对照的汉字和盲文文本中自动匹配抽取语料的方法,构建了规模为27万句、234万字、448万方盲文的篇章、句子、词语多级对照的汉盲语料库。实验结果表明,该文所提出的基于汉盲对照语料库和深度学习的汉盲转换方法准确率明显优于基于纯盲文语料库和传统机器学习模型的方法。 ",MESS201904008
注意力的端到端模型生成藏文律诗,"色差甲1,2:38298547|华果才让1,2:36254586|才让加1,2:08163475|慈祯嘉措1,2:41751738|柔特1,2:31056708",7,藏文律诗生成; 字嵌入; 注意力机制; 编码—解码器;,"文本自动撰写在自然语言处理中是一个重要的研究领域,可通过人工智能的方法来提升文本的生成结果。目前主流的生成方法是基于深度学习的方法,而该文则提出了一种基于注意力的端到端模型生成藏文律诗法。该方法基本框架是一个双向LSTM的编码—解码模型,在此基础上引入了藏文字嵌入、注意力机制和多任务学习法。实验结果表明,该文提出的方法在藏文律诗生成结果中BLEU值和ROUGE值分别能达到59.27%、62.34%,并无需任何人为的特征设置。 ",MESS201904009
基于等价压缩快速聚类的Web表格知识抽取,"吴小龙1,2:41751731|曹存根1:10348278",10,Web表格; 知识抽取; 表格聚类; 等价压缩; 快速聚类;,"Web表格知识抽取是一种重要的获取高质量知识的途径,在知识图谱、网页挖掘等方面具有广泛的研究意义与应用价值。传统的Web表格知识抽取方法主要依赖于良好的表格结构和足够的先验知识,但在复杂的表格结构以及先验知识不足等情形下难以奏效。针对这类方法的问题,该文通过充分利用表格自身的结构特点,提出了一套可面向大规模数据的基于等价压缩快速聚类的Web表格知识抽取方法,以无监督的聚类方式获得相似形式结构的表格,从而推测其语义结构以抽取知识。实验结果表明,基于等价压缩的快速聚类算法在保持同水平的聚类准确率的前提下,在时间性能上相比传统方法有大幅度的提升,5 000个表格的聚类时间由72小时缩短为20分钟,且在表格聚类后利用表格模板所抽取的知识三元组的准确率也达到了令人满意的结果。 ",MESS201904010
基于混合表示的中文事件检测方法研究,秦彦霞1:30396860|王中卿2:23843509|郑德权1:06997784|张民2:31758527,8,中文; 事件检测; 神经网络; 混合表示;,"传统中文事件检测方法采用人工定义的特征表示候选触发词,耗时耗力。基于神经网络的特征学习方法在中英文事件检测任务中得到了验证。现有的基于神经网络的中文事件检测方法初步探索了字信息对解决分词错误的作用。字是中文的最小结构单元和语义表示单元。词语的字符级信息能够提供词语的结构性信息和辅助词语级语义。该文研究了字/词混合神经网络特征对于解决中文事件数据集未登录词问题的作用。采用神经网络模型分别学习词语的词语级表示和字符级表示,进而拼接得到词语的混合表示。实验结果表明,基于字/词混合表示的中文神经网络事件检测模型的F1值比当前最好的模型高2.5%。 ",MESS201904011
基于查询的新闻多文档自动摘要技术研究,王凯祥:40421352|任明:29257210,8,自动文本摘要; 基于查询的摘要; 新闻文本; 分布式表示;,"针对新闻文本领域,该文提出一种基于查询的自动文本摘要技术,更加有针对性地满足用户信息需求。根据句子的TF-IDF、与查询句的相似度等要素,计算句子权重,并根据句子指示的时间给定不同的时序权重系数,使得最近发生的新闻内容具有更高的权重,最后使用最大边界相关的方法选择摘要句。通过与基于TF-IDF、TextRank、LDA等六种方法的对比,该摘要方法 ROUGE评测指标上优于其他方法。从结合评测结果及摘要示例可以看出,该文提出的方法可以有效地从新闻文档集中摘取核心信息,满足用户查询内容的信息需求。 ",MESS201904012
基于卷积神经网络与篇章结构的足球新闻自动生成方法,"刘茂福1,2:11187335|齐乔松1,2:39843073|胡慧君1,2:10948134",8,足球新闻生成; 卷积神经网络; 篇章结构; 句子抽取; 句子生成;,"当前的足球比赛新闻通常是由专家或记者手工撰写的,足球比赛新闻的手工写作既费时又低效。随着在线直播平台与社交媒体的流行,体育网络直播脚本大幅增加,但网络直播脚本通常只记载一场比赛的流水,具有冗长且重点模糊的特性,不适宜于赛后直接阅读。为了解决以上问题,在比赛之后,可以基于直播脚本撰写和发布足球比赛新闻。因此,该文提出一种从网络直播脚本直接生成足球比赛新闻的方法。该方法基于卷积神经网络和足球新闻篇章结构,从足球比赛过程中的多个时间段提取出已发生的重要事件,进而抽取相关句子来生成足球新闻,同时,该方法还会针对比赛评价生成一个简短总结。实验结果表明,使用该方法从网络直播脚本生成足球新闻是可行的。 ",MESS201904013
金庸小说中主角复杂爱情模式的识别与分析,张旋:41751733|梁循:25202919|李志宇:31829552|张树森:36626078|赵晓磊:41751734,11,小说社会网络; 长文本处理; 关系识别; 爱情模式;,"该文提出了一种基于复杂网络分析方法的小说人物关系识别模型。通过以金庸14部武侠小说的分析过程为样例,首先提出了基于小说社会网络关系的降噪分析框架,然后在此基础上构建了人物亲密度评估与关系判别模型,最后给出了一种识别小说主角复杂爱情模式的通用模型。实验发现该模型能够有效地分析出小说中的复杂爱情模式,且在保证识别效率的同时还具备较高的精准度。在模型训练时,设置了变尺度窗口,发现随着窗口的变小,模型识别的主角复杂爱情模式呈现出召回率会不断上升至稳定,同时精确率则会维持相对稳定至超过一个阈值后不断下降这一重要现象。该文提出的复杂爱情模式识别框架,不仅对长文本小说人物关系分析具有较好的借鉴意义,还可以应用于判断小说精彩性和小说内容个性化推荐的图书决策支持系统。 ",MESS201904014
面向问答文本的属性分类方法,江明奇:41751735|沈忱林:41751736|李寿山:27030929,7,属性分类; 问答文本; 多维文本表示;,"属性分类是属性级情感分析中的一个重要任务。该任务旨在对文本包含的某些具体属性进行自动分类。已有的属性分类方法研究基本都是面向新闻、评论等文本类型。与已有研究不同的是,该文的研究主要面向问答文本的属性分类任务。针对问答文本的属性分类问题,该文提出了一种多维文本表示的方法。首先,该方法进行中文句子切分;其次,使用LSTM模型对每个子问题和答案学习一个隐层表示;再其次,通过融合多个隐层表示,形成多维文本表示;最后,使用卷积层处理多维文本表示,获得最终分类结果。实验结果表明该方法明显优于传统的属性分类方法。 ",MESS201904015
基于声学音素向量和孪生网络的二语者发音偏误确认,王振宇:41751737|解焱陆:27065196|张劲松:23592433,8,发音偏误确认; 音素向量; 孪生网络;,"随着自动大规模语音识别的不断发展,以自动语音识别为基础的计算机辅助发音教学也随之进步,作为传统教学方法的补充,它极大地弥补了传统教育资源不足以及传统教育方法无法及时给学习者反馈的缺陷。二语学习者的发音偏误确认和评价在计算机辅助发音训练中是较为重要的研究课题之一。针对二语者发音偏误的确认任务中缺少二语偏误发音标注问题,该文提出了一种基于声学音素向量和孪生网络的方法,将带有配对信息的成对的语音特征作为系统输入,通过神经网络将语音特征映射到高层表示,期望将不同的音素区分开。训练过程引入了孪生网络,依照输出的两个音素向量是否来自于同一类音素来调整和优化输出向量之间的距离,并通过相应的损失函数实现优化过程。结果表明使用基于余弦最大间隔距离损失函数的孪生网络获得了89.93%的准确率,优于实验中其它方法。此方法应用在发音偏误确认任务时,不使用标注的二语发音偏误数据训练的情况下,也获得了89.19%的诊断正确率。 ",MESS201904016
联机汉字篇章书写质量评价研究,许明月:38652769|姜杰:08753756|李艺:08081219|仇宏斌:30426921,8,联机书写; 手写汉字; 篇章书写; 书写质量评价;,"该文的研究工作针对硬笔汉字篇章书写练习的智能评价与指导需求展开。在PAD等数字录入设备支持的联机书写状态下,以记录书写笔迹的时序点集为依据,先实现分行割字,再进行行水平、行间距稳定性、行间距均匀性、字间距均匀性和左对齐等的计算并获得特征参量。最终通过专家经验赋权法给出直观的书写质量评价结果。实验表明,该系统可以对篇章书写质量给出较符合主观习惯的评价,能够用于指导书写者进行汉字篇章书写练习。 ",MESS201904017
《中国语言学文库》第三辑已出版作品目录,,1, ,<正>刘丹青《语序类型学与介词理论》郭锐《现代汉语词类研究》(修订本)万波《赣语声母的历史层次研究》曹志耘《南部吴语语音研究》杨荣祥《近代汉语副词研究》张民权《宋代古音学与吴棫〈诗补音〉研究》万献初《〈经典释文〉音切类目研究》刘子瑜《〈朱子语类〉述补结构研究》 ,MESS201904018
第十六届全国自然语言处理青年学者研讨会(YSSNLP 2019)在海南琼海顺利召开,,1, ,"<正>2019年5月3日至5日,第十六届全国自然语言处理青年学者研讨会(YSSNLP 2019)在海南琼海顺利召开。本次研讨会由中国中文信息学会主办,海南大学承办,近200名代表参会。本次研讨会的主题为""探索学科交叉,聚焦挑战和机遇"",旨在促进自然语言处理领域国内外学者间的学术互动,加强认知学、语言学和自然语言处理的学科交叉和融合,总结学科方向面临的挑战并展望未来发展 ",MESS201904007
基于宏观语义表示的宏观篇章关系识别方法,周懿:24326884|褚晓敏:21810477|朱巧明:05968617|蒋峰:17629626|李培峰:09886822,8,宏观篇章关系识别; 宏观篇章结构特征; 宏观篇章语义表示;,"宏观篇章分析旨在分析相邻段落或段落群之间的语义联系,是自然语言处理领域其他任务的工作基础。该文研究了宏观篇章分析中的关系识别问题,提出了一个宏观篇章关系识别模型。该模型利用基于词向量的宏观篇章语义表示方法和适用于宏观篇章关系识别的结构特征,从两个层面提高了模型分辨宏观篇章关系的能力。在汉语宏观篇章树库(MCDTB)上的实验表明,该模型在大类分类中F1值达到了68.22%,比基准系统提升了4.17%。 ",MESS201903001
一种针对成分树的混合神经网络模型,"霍欢1,2:23576979|薛瑶环1:40687398|黄君扬1:39359013|金轩城1:40687397|邹依婷1:40687396",9,成分树; C-TreeLSTM; 短语语义向量; 混合模型;,"为了提高自然语言处理的准确度,很多工作将句法成分树与LSTM相结合,提出了各种针对成分树的LSTM模型(文中用C-TreeLSTM统称这类模型)。考虑到C-TreeLSTM模型在计算内部节点隐藏状态的过程中,由于一个重要信息来源(即单词)的缺失导致文本建模的准确度不高,该文提出一种针对成分树的混合神经网络模型,通过在C-TreeLSTM模型的节点编码过程中注入各节点所覆盖的短语语义向量来增强节点对文本语义的记忆,故将此模型命名为SC-TreeLSTM。实验结果表明,该模型在情感分类和机器阅读理解两类任务上表现优异。 ",MESS201903002
面向非任务型对话系统的人工标注中文数据集,李菁:41408861|张海松:40737514|宋彦:39802722,8,对话系统; 人工标注; 中文数据集;,"该文针对非任务导向型对话的回复质量构建了一个大规模的人工标注中文数据集,该数据集包含了从社交媒体收集到的超过27 000个对话问题以及超过82 000个对话问题的回复①。为了产生高质量的标注数据,邀请了专业人员根据对话回复的相关性、连贯性、信息性、趣味性,以及是否潜在地具有让对话继续延续的特性进行标注,在标注中定义了一个五级评分方法,分别是:极差的、较差的、一般的、较好的、极好的。为了测试标注产生的数据集是否具有有效性和实用性,以对话回复选择为任务,在标注数据集上测试了多种无监督和有监督模型。实验结果表明,该数据集对于提升对话回复选择的质量有显著效果。 ",MESS201903003
基于门控联合池化自编码器的通用性文本表征,张明华1:29483972|吴云芳1:06270718|李伟康1:38526148|张仰森2:15552896,8,文本表征; 自编码器; 多头自注意力机制;,"为了学习文本的语义表征,以往的研究者主要依赖于复杂的循环神经网络(recurrent neural networks,RNNs)和监督式学习方法。该文提出了一种门控联合池化自编码器(gated mean-max AAE)用于学习中英文的文本语义表征。该文的自编码器完全通过多头自注意力机制(multi-head self-attention mechanism)来构建编码器和解码器网络。在编码阶段,提出了均值—最大化(mean-max)联合表征策略,即同时运用平均池化(mean pooling)和最大池化(max pooling)操作来捕获输入文本中多样性的语义信息。为促使联合池化表征可以全面地指导重构过程,解码器采用门控操作进行动态关注。通过在大规模中英文未标注语料上训练模型,获得了高质量的句子编码器。在重构文本段落的实验中,该文模型在实验效果和计算效率上均超越了传统的RNNs模型。将公开训练好的文本编码器,使其可以方便地运用于后续的研究。 ",MESS201903004
基于HowNet的语义表示学习,朱靖雯1:41408862|杨玉基2:38562370|许斌2:08184020|李涓子2:08821985,9,HowNet; 知识图谱; 语义表示; 表示学习;,"HowNet是一个大规模高质量的跨语言(中英)常识知识库,蕴含着丰富的语义信息。该文利用知识图谱领域的方法将HowNet复杂的结构层层拆解,得到了知识图谱形式的HownetGraph,进而利用网络表示学习以及知识表示学习方法得到了跨语言(中、英)、跨语义单位(字词、义项①、DEF_CONCEPT②和义原)的向量表示,在词语相似度(word similarity)和词语类比(word analogy)任务上对中英文数据集进行了实验,实验结果显示该文提出的方法在词语语义相似度的任务上取得了最好效果。 ",MESS201903005
面向神经机器翻译的集成学习方法分析,李北1:41394705|王强1:06573471|肖桐1:11698781|姜雨帆1:41093935|张哲旸1:41405515|刘继强1:41405516|张俐1:06574957|于清2:17460448,10,集成学习; 参数平均; 模型融合; 多样性;,"集成学习是一种联合多个学习器进行协同决策的机器学习方法,应用在机器翻译任务的推断过程中可以有效整合多个模型预测的概率分布,达到提升翻译系统准确性的目的。虽然该方法的有效性已在机器翻译评测中得到了广泛验证,但关于子模型的选择与融合的策略仍鲜有研究。该文主要针对机器翻译任务中的参数平均与模型融合两种集成学习方法进行大量的实验,分别从模型与数据层面、多样性与模型数量层面对集成学习的策略进行了深入探索。实验结果表明在WMT中英新闻任务上,所提模型相比Transformer单模型有3.19个BLEU值的提升。 ",MESS201903006
神经机器翻译中英语单词及其大小写联合预测模型,"张楠1:06291119|李响2,3:25670932|靳晓宁1:36763916|陈伟4:44628874",7,机器翻译; 大小写恢复; 联合预测;,"英文中单词有大小写之分,如果使用不规范,会降低语句的可读性,甚至造成语义上的根本变化。当前的机器翻译处理流程一般先翻译生成小写的英文译文,再采用独立的大小写恢复工具进行还原,这种方式步骤繁琐且没有考虑上下文信息。另一种方式是抽取包含大小写的词表,但这种方式扩大了词表,增加了模型参数。该文提出了一种在神经机器翻译训练中联合预测英语单词及其大小写属性的方法,在同一个解码器输出层分别预测单词及其大小写属性,预测大小写时充分考虑源端语料和目标端语料上下文信息。该方法不仅减小了词表的大小和模型参数,译文的质量也得到提升。在WMT 2017汉英新闻翻译任务测试集上,相比基线方法,该方法在大小写敏感和大小写不敏感两个评价指标上分别提高0.97BLEU和1.01BLEU,改善了神经机器翻译模型的性能。 ",MESS201903007
韩国语句子结构相似度计算方法研究,"毕玉德1,2:41405517|姜博文2:41405519",6,韩国语; 句子结构; 相似度;,"句子相似度计算是信息处理领域一项基础技术,在基于实例的机器翻译中直接影响译文质量。该文以韩国语句子为研究对象,结合韩国语的句子特点提出了一种句子结构相似度的计算方法。该方法通过先提取句子的骨架结构,然后结合韩国语的句法特点制定标记转换规则,最后用转换后的句子结构与实例库中句子匹配得到与之相似的句子,得出两个句子间的结构相似度,并且通过实验验证了该方法的可行性,提高了相似度计算效果。 ",MESS201903008
基于深度神经网络的维吾尔文命名实体识别研究,"王路路1,2:35686939|艾山·吾买尔1,2:10775068|吐尔根·依布拉音1,2:17705003|买合木提·买买提1,2:22440290|卡哈尔江·阿比的热西提1,2:31758537",7,维吾尔文命名实体识别; 长短时记忆网络; 条件随机场; 注意力机制;,"现有的维吾尔文命名实体识别主要采用基于条件随机场的统计学习方法,但依赖于人工提取的特征工程和领域知识。针对该问题,该文提出了一种基于深度神经网络的学习方法,并引入不同的特征向量表示。首先利用大规模未标注语料训练的词向量模型获取每个单词具有语义信息的词向量;其次,利用Bi-LSTM提取单词的字符级向量;然后,利用直接串联法或注意力机制处理词向量和字符级向量,进一步获取联合向量表示;最后,用BiLSTM-CRF深度神经网络模型进行命名实体标注。实验结果表明,以基于注意力机制的联合向量表示作为输入的Bi-LSTM-CRF方法在维吾尔文命名实体识别上F值达到90.13%。 ",MESS201903009
利用领域外数据对口语风格短文本的相近语种识别研究,"何峻青1,2:38524023|黄娴3:41405520|赵学敏1:26574826|张克亮3:39864403",8,相近语种识别; 领域外数据; 口语风格短文本; 字符的形态学特征;,"该文以维吾尔语和哈萨克语这一组相近语言为例,在哈语语料受限的情况下,使用领域外语料增补原始语料,经同化后提高了在口语风格短文本上进行语种识别的精确度。该文分析了维、哈两种语言的词形学特点,设计了多种特征,构建了一个最大熵分类器,在测试集上识别维语和哈语口语风格短文本的精确度达到95.7%,而CNN分类器的精确度仅为69.1%。实验结果证明该系统对其他语种口语风格短文本的语种识别亦具有适用性。 ",MESS201903010
基于主题模型的古典乐器诗词文本挖掘,申资卓:41405521|杨莹:23678922|邵艳秋:32278869,8,唐诗宋词; “八音”; 主题模型;,"古代先贤将乐器按其制作材料分为八类,《周礼·春官·大师》中记载""皆播之以八音:金石土革丝木匏竹。""该文将《全唐诗》、《全宋词》中有关""八音""的诗句、词句作为研究对象,使用基于LDA和NMF的主题挖掘、基于Author-Topic-Model的作者相似度计算等方法。从宏观到微观,从整体诗词到具体诗人/词人,从主题的聚类、动词形容词的抽取到具体诗人词人作品相似度的计算,多维度、多层次、多角度研究了唐诗宋词中的中国古典乐器。 ",MESS201903011
基于注意力机制与文本信息的用户关系抽取,赵赟:41405522|吴璠:41405523|王中卿:23843509|李寿山:27030929|周国栋:13898054,7,好友判断; 关系预测; 社交网络; 注意力机制;,"随着社交媒体的发展,用户之间的关系网络对于社交媒体的分析有很大的帮助。因此,该文主要研究用户好友关系检测。以往的关于用户好友关系抽取的研究主要基于社交媒体上的结构化信息,比如其他好友关系,用户的不同属性等。但是,很多时候用户本身并没有大量的好友信息存在,同时也不一定有很多确定的属性。因此,我们希望基于用户发表的文本信息来对用户关系进行预测。不同于以往的潜在好友推荐算法,该文提出了一种基于注意力机制以及长短时记忆网络(long short-term memory,LSTM)的好友关系预测模型,将好友之间的评论分开处理,通过分析用户之间的评论来判断是否具备一定的好友关系。该模型将好友双方信息拼接后的结果作为输入,并将注意力机制应用于LSTM的输出。实验表明,用户之间的评论对于好友关系预测确实有较大的实际意义,该文提出的模型较之于多个基准系统的效果,取得了明显的提升。在不加入任何其它非文本特征的情况下,实验结果的准确率达到了77%。 ",MESS201903012
基于多特征Bi-LSTM-CRF的影评人名识别研究,"禤镇宇1:40744777|蒋盛益1,2:06844554|张礼明1:41408863|包睿1:41408864",8,影评; LSTM; CRF; 多特征; 人名识别;,"近年来电影行业蓬勃发展,相关的信息抽取和分析技术日益受到行业内的重视,其中对电影主创人物的分析尤为重要。而电影评论作为观影群体的主要反馈信息,具有重要的分析价值。如何从影评中自动抽取主创人名成为重要的基础工作。然而评论中观众对人物的称谓方式多样复杂,而且新电影的影评中往往存在大量人名未登录词,传统方法难以有效识别。针对影评的这些特点,该文提出一种基于多特征Bi-LSTM-CRF的影评人名识别方法。该方法通过利用外部人名语料和未标注影评提取字符级的特征,并采用Bi-LSTM-CRF模型进行人名字符序列标注。实验结果表明,该方法能够有效识别影评中的复杂称谓和人名未登录词,从而有效地抽取影评中的人名实体。 ",MESS201903013
基于QU-NNs的阅读理解描述类问题的解答,"谭红叶1,2:08402552|刘蓓1:41405524|王元龙1:34932595",8,阅读理解; 描述类问题; 问题理解; 神经网络;,"机器阅读理解是自然语言处理(NLP)领域的一个研究热点,目前大部分的研究是针对答案简短的问题,而具有长答案的问题,如描述类问题是现实世界无法避免的,因此有必要对该类问题进行研究。该文采用QU-NNs模型对阅读理解中描述类问题的解答进行了探索,其框架为嵌入层、编码层、交互层、预测层和答案后处理层。由于该类问题语义概括程度高,所以对问题的理解尤为重要,该文在模型的嵌入层和交互层中分别融入了问题类型和问题主题、问题焦点这三种问题特征,其中问题类型通过卷积神经网络进行识别,问题主题和问题焦点通过句法分析获得,同时采用启发式方法对答案中的噪音和冗余信息进行了识别。在相关数据集上对QU-NNs(Question UnderstandingNeural Networks)模型进行了实验,实验表明加入问题特征和删除无关信息可使结果提高2%～10%。 ",MESS201903014
基于枢轴语言的图像描述生成研究,张凯:22035999|李军辉:09886805|周国栋:13898054,8,图像描述生成; 机器翻译; 神经网络; 枢轴语言;,"当前图像描述生成的研究主要仅限于单语言（如英文）,这得益于大规模的已人工标注的图像及其英文描述语料。该文探索零标注资源情况下,以英文作为枢轴语言的图像中文描述生成研究。具体地,借助于神经机器翻译技术,该文提出并比较了两种图像中文描述生成的方法:（1）串行法,该方法首先将图像生成英文描述,然后由英文描述翻译成中文描述;（2）构建伪训练语料法,该方法首先将训练集中图像的英文描述翻译为中文描述,得到图像-中文描述的伪标注语料,然后训练一个图像中文描述生成模型。特别地,对于第二种方法,该文还比较了基于词和基于字的中文描述生成模型。实验结果表明,采用构建伪训练语料法优于串行法,同时基于字的中文描述生成模型也要优于基于词的模型,BLEU4值达到0.341。 ",MESS201903015
基于情感分析的“真假美猴王”存疑研究,张辰麟1:41405525|王明文1:08472511|谭亦鸣1:39050236|陈志明1:07871885|左家莉1:07871349|罗远胜2:21963305,9,情感分析; 文学情感分析; 情感词典; 《西游记》; 真假美猴王;,"《西游记》是我国四大名著之一。""真假美猴王""事件作为《西游记》的高潮部分,留下了不少伏笔,也引发了多种解读。该文通过运用情感分析的方法,对""真假美猴王""事件前后孙悟空与其他角色的对话进行分析。通过比较孙悟空在""真假美猴王""事件前后,对其他角色情感值的变化,得到了""孙悟空并没有被如来打死,‘真假美猴王’事件消灭的‘心魔’是孙悟空的反抗精神。事件之后,孙悟空选择屈服于神权""的结论。初步探索了情感分析技术对文学研究的可行性。 ",MESS201903016
基于神经网络的集句诗自动生成,"梁健楠1,2,3:41405526|孙茂松1,2,3:08823738|矣晓沅1,2,3:34683035|杨成1,2,3:08184851|陈慧敏1,2,3:36658976|刘正皓1,2,3:41405527",10,神经网络; 中国古典诗歌; 自动诗歌生成;,"集句诗是中国古典诗歌的一种特殊体裁。是从前人的诗篇中选取已有诗句,再将其巧妙组合形成一首新诗,是一种艺术的再创造形式。集句诗的生成要求集辑而成的诗不仅合辙押韵,且有完整的内容、连贯的上下文和新颖的主旨意境,对创作者的知识储备和诗词鉴赏能力有极高的要求。该文基于计算机的海量存储和快速检索能力,以及神经网络模型对文本语义较强的表示和理解能力,提出一种新颖的集句诗自动生成模型。该模型以数十万首古诗作为基础,利用循环神经网络(RNN)自动学习古诗句的语义表示,并设计了多种方法自动计算两句诗句的上下文关联性。根据用户输入的首句,模型能够自动计算选取上下文语义最相关连贯的诗句进行集辑,从而形成一首完整的集句诗。自动评测和人工评测的实验结果都表明,该文模型能够生成质量较好的集句诗,远远超过基线模型的效果。 ",MESS201903017
交通事故的自动判案研究,尹何举1:41405528|昝红英1:09467924|陈俊怡1:41405529|翟新丽2:41405530,9,自动判案; 神经网络; 支持向量机; 交通事故;,"该文针对法律领域民事案件中的""交通事故""类案件进行研究,期望在该""交通事故""数据集上实现自动判案。从""中国裁判文书网""采集14 000条数据文本,并对数据进行人工标注。基于对数据集的分析,分别对数据进行粗粒度和细粒度分类,粗粒度为4类,细粒度为8类。该文使用了三种模型:基于SVM的模型、基于BI-GRU的模型和基于Attention+BI-GRU的模型。实验结果表明:在该数据集上,对数据进行粗粒度分类时,基于Attention+BI-GRU的模型F1值为80.26%,基于SVM的模型为77.24%,基于BI-GRU的模型为72.65%。在细粒度分类时,基于BI-GRU的模型F1值为48.59%,基于SVM的模型为38.29%,基于Attention+BI-GRU的模型为40.87%。 ",MESS201903018
中国语言文化典藏,,1, ,"<正>书号:略定价:每卷168元开本:16开内容介绍:""中国语言文化典藏""丛书是教育部哲学社会科学研究重大课题攻关项目,教育部国家语委""中国语言资源保护工程""标志性成果,国家""十三五""出版规划项目、国家出版基金项目。该丛书在""语言文化""和""典藏""上精细打磨,""语言文化""是指用语言形式所表达的具有地方特色的文化现象,包 ",MESS201903020
第十五届全国机器翻译大会(CCMT 2019)征文通知,,1, ,"<正>第十五届全国机器翻译大会(The 15th China Conference on Machine Translation,CCMT)将于2019年9月27日至29日在江西南昌举行。本次会议由中国中文信息学会主办,江西师范大学承办。CCMT旨在为国内外机器翻译界同行提供一个交互平台,加强国内外同行的学术交流,召集各路专家学者针对机器翻译的理论方法、应用技术和评测活动等若干关键问题进行深入的研讨,为促进中国机器翻译事业的发展,起 ",MESS201903019
文本可读性的自动分析研究综述,"吴思远1,2:40934849|蔡建永2,3:26104385|于东1:26514992|江新2:06427948",10,文本可读性; 可读性分析; 特征提取;,"文本可读性问题最初由教育学家提出,初衷是辅助教师为语言学习者推荐适合其阅读水平的文本。随着计算机技术的发展及网页文本的涌现,对文本进行可读性分析有了更加丰富的技术手段和应用场景。该文对可读性自动分析的相关研究进行了梳理,将可读性自动分析的方法总结为公式法、分类法和排序法三类;然后进一步介绍了可读性自动分析中的两项重要内容:文本特征的选择和数据集的使用;最后对可读性研究的发展方向进行展望。 ",MESS201812001
怎样利用语言知识资源进行语义理解和常识推理,袁毓林1:06263991|卢达威2:39938181,13,语言知识资源; 语义理解; 常识推理; 基于知识/统计; 语义角色; 物性角色;,"该文讨论怎样利用语言知识资源来帮助机器进行语义理解和常识推理。首先,指出人类生活在常识和意义世界中,人工智能机器人必须理解自然语言的意义,能够在此基础上进行常识推理。接着,简单梳理了基于知识和基于统计两种自然语言处理路线各自的优长和短缺。然后,说明完全绕开知识的统计方法和深度学习,都不能真正理解概念和语言。该文通过具体案例说明,《实词信息词典》已经配备了有关词项的语义角色关系及其句法配置信息;把这种语言知识加入知识图谱和内容计算中,可以为人工智能提供理解和解释从而造就一种可解释的人工智能。由于""物性角色""描述了名词所指事物的百科知识,可用以回答相关事物是什么(形式角色)、有哪些部件(构成角色)、用什么做的(材料)、怎么形成的(施成)、有什么用途(功用)等常识性问题。 ",MESS201812002
句法网与语义网的对比研究,马丹:40660849|赵怿怡:30602481,7,句法网; 语义网; 虚词;,"基于网络观的语言研究已经成为语言分析的趋势之一。但不同语言单位层级、不同语言单位关系的选取导致了语言网络的差异。从词的同现网到句法网再到语义网所需要的语言学知识也逐步深化,该文旨在构建语义学理论支撑的语义网络,并把虚词纳入语义分析过程,分别以句法关系和语义关系作为联结,用Cytoscape构建了句法网和语义网。结果发现:语义网的直径、平均最短距离比句法网大,层级性比句法网差,聚集系数比句法网小,虚词节点""的""""和""""个""等有可能是局部的中心节点。 ",MESS201812003
基于中文AMR语料库的非投影结构研究,"闻媛1:36638639|宋丽1:36382828|吴泰中2:40934786|李斌1:08075606|周俊生2:08116958|曲维光2,3:08112756",10,抽象语义表示; 概念对齐; 非投影; 语义分析; 中文信息处理;,"非投影结构是指依存树上的词语节点与原句中的词语序列出现错位的现象,对于句法分析器的影响较大,在语言理论上也有较大研究价值。在世界多种语言的依存树或图库上,都发现了含有非投影结构的句子,并对比展开了相关研究。而汉语的非投影结构尚未得到重视,语料库构建过程中也因遵循了投影性原则而缺乏对非投影结构的标注。该文基于概念对齐版的中文AMR语料库,在10 149句语料上统计出带有非投影结构的句子比例为31.62%,其三种主要类型为模态词提升、话题化和成分分离,并提出了相应的自动分析方案,以提高中文AMR自动分析效果。 ",MESS201812004
基于多特征融合编码的神经网络依存句法分析模型,刘明童:38949160|张玉洁:10874141|徐金安:25200603|陈钰枫:33219873,7,依存句法分析; 多特征融合编码; 依存子树; TreeLSTM神经网络;,"在基于神经网络的依存句法分析中,对分析栈和决策层信息的表示和利用依然有值得深入研究的空间。针对分析栈的表示,已有工作并没有对单棵依存子树独立编码的表示,导致无法利用各个依存子树的局部特征;也没有对生成的依存弧序列进行编码,导致无法利用依存弧的全局信息。针对决策层的表示,已有工作利用MLP预测转移动作,该结构无法利用历史决策动作的信息。对此,该文提出基于多特征融合编码的神经网络依存句法分析模型,基于依存子树和历史生成的依存弧表示分析栈,利用TreeLSTM网络编码依存子树信息,利用LSTM网络编码历史生成的依存弧序列,以更好地表示分析栈的局部信息和全局信息。进一步提出基于LSTM网络的结构预测转移动作序列,引入历史决策动作信息作为特征辅助当前决策。该文以汉语为具体研究对象,在CTB5汉语依存分析数据上验证所提出的多特征融合编码的神经网络模型。实验结果显示,汉语依存句法分析性能得到改进,在目前公布的基于转移的分析系统中取得最好成绩,在UAS和LAS评价指标上分别达到87.8%和86.8%的精度,表明所提出的对依存子树局部特征及历史依存弧信息和历史决策动作信息的编码方法,在改进依存分析模型性... ",MESS201812006
基于转移的中文篇章结构解析研究,孙成:40934787|孔芳:08865090,9,篇章分析; 中文篇章结构; 转移系统;,"篇章结构解析作为篇章分析的子任务,对于篇章理解和下游篇章应用至关重要。该文基于中文连接依存树篇章标注语料,利用转移系统和深度学习的方法,给出了一个完整的从平文本到树形结构的篇章结构自动解析框架。该文统计了中文篇章语料的基本特点,提出了针对树形篇章结构的评测方法,并采用不同的方法对篇章解析过程的篇章子结构进行分布式表示,对比了不同方法下篇章结构解析的性能。 ",MESS201812007
航空术语语义知识库辅助构建方法,王思博:38996471|王裴岩:24679272|张桂平:24679273,10,航空术语; 语义知识库; 知网; 概念描述;,"语义知识库是自然语言处理任务的基础性资源,广泛应用于语义计算和语义推理等任务。现有的大规模语义知识库基本都是通用型知识库,缺乏特定领域的语义知识。为了弥补这种不足,该文基于HowNet的语义理论体系,提出了一种辅助构建航空术语语义知识库的方法。该方法根据航空术语的特点将辅助构建分成四个关键过程,构建了2 000条术语概念描述(DEF)。最后通过对人工标注的术语间相似度与根据术语DEF计算的术语间相似度结果的对比,验证了该构建方法的有效性。 ",MESS201812009
基于多译文的中文转述语料库建设及转述评价方案,"阮翀1,2:40934788|施文娴1,2:33210795|李岩昊2:40934789|翁伊嘉2:40934790|胡俊峰1,2:06243608",9,转述知识挖掘; 转述评价指标; 转述语料库建设;,"转述语料是转述现象研究的基础。针对目前学术界中文转述语料稀缺的现状,该文以《简爱》的多个中文译本为基础,通过句对齐得到五万句级别的平行转述语料(1)。使用无监督的小句对齐和词对齐算法,从语料中挖掘到九千多对词汇转述知识。同时,还复现和改进了机器翻译测评指标Meteor,使得该指标更适合于中文转述句子的测评,并构造了一个中文句子转述测评数据集,以便对不同的转述知识和评价指标进行比较。实验表明,该文算法挖掘到的词汇转述知识在封闭测试中不逊于《同义词词林》。 ",MESS201812010
基于联合模型的藏文实体关系抽取方法研究,"夏天赐1,2:40934791|孙媛1,2:31992289",8,联合模型; 藏文实体关系; 词性标注;,"从无结构文本中抽取实体与实体之间的关系是自然语言处理领域的重要研究内容,同时也为构建知识图谱、问答系统等应用提供重要支撑。基于联合模型的实体关系抽取任务将实体识别和关系抽取同时进行,克服了传统实体关系抽取任务中先识别句子中的实体,然后再进行实体关系判断这两次任务中的错误累加。该文针对藏文语料匮乏、实体识别准确率不高等问题,提出了基于联合模型抽取藏文实体关系的方法。基于藏文实体关系抽取任务,提出以下方案:(1)针对藏文分词准确率不高的问题,对藏文进行字级和词级两种方式进行预处理,并给出对比实验,结果表明采用字级处理方式较词级处理方式效果有所提高。(2)藏文是一种语法规则比较强的语言,名词、格助词等能明确指示句子各组块之间的语法和语义结构关系,因此该文将藏文的词性标注特征加入到藏文的字词向量中,实验结果证明了方法的有效性。(3)该文借鉴了联合模型处理的优势,提出基于联合模型处理方式,采用端到端的BiLSTM框架将藏文实体关系抽取任务转变为藏文序列标注的问题,实验结果表明,该文的方法较传统的基于藏文处理方式,如SVM算法和LR算法,准确率提高了30%～40%。 ",MESS201812011
多特征融合的汉越双语新闻摘要方法,叶雷:36636449|余正涛:05982358|高盛祥:07892541|刘书龙:35402323|张亚飞:38072297,8,双语新闻; 多特征; 句子无向图; 自动摘要;,"为了获取同一事件的汉越双语新闻的自动摘要,该文提出了一种多特征融合的汉越双语新闻摘要方法。关于同一事件的新闻文本,其句子间具有一定的关联关系,利用这些关联关系有助于生成摘要。根据该思想,首先计算句子间的新闻要素共现程度及句子间的相似度;然后将这两种特征融入句子无向图,并利用图排序算法对句子进行排序;之后结合句子的位置特征对排序结果进行调序;最后挑选重要句子并去除冗余生成摘要。在汉越双语新闻文档集上进行了摘要实验,结果表明该方法取得了较好的结果,具有有效性。 ",MESS201812012
基于序列到序列的中文短文本省略补全,郑杰:11228316|孔芳:08865090|周国栋:13898054,8,序列到序列; 对话; 省略;,"省略作为一种常见的语言现象,在上下文中普遍存在,特别是在问答、对话等短文本中出现的频率更高。不同于传统的机器学习方法,该文针对问答、对话这样的短文本,构建了一个序列到序列的神经网络模型来实现对上下文中出现的省略进行识别和补全。在搜集和整理的短文本问答和对话语料上进行了各种实验,验证了该模型在省略识别和恢复上能够取得较好的性能。 ",MESS201812013
基于主题网络的伪主题分析,"闫蓉1,2:10588313|高光来1,2:05981929",9,伪主题分析; 主题网络; 文本理解;,"传统无监督的主题建模方法利用相互独立的主题变量抽象描述文本语义,忽略了各主题内部隐含的结构和联系,粗粒化的文本主题分析加剧了""强制主题""问题对文本建模的影响。该文通过研究主题网络社区内部结构,结合主题内部语义耦合关系与网络拓扑结构,提出伪主题分析方法来识别和解释主题,实现从网络结构角度描述文本语义特征,弥补统计主题分析方法对文本语义结构刻画的不足。 ",MESS201812015
面向任务口语对话系统中不含槽信息话语的端到端对话控制,黄锵嘉:40934792|黄沛杰:24966316|李杨辉:40934793|杜泽峰:40934794,9,口语对话系统; 端到端; 卷积神经网络; 显式话语特征; 隐式上下文;,"端到端(end-to-end)模型因其能有效避免传统管道式设计存在的错误传递与累积问题,成为了近年来口语对话系统(spoken dialogue system,SDS)的研究热点。在面向任务SDS的end-to-end对话控制中,处理携带任务领域语义信息(槽信息)的话语可以结合命名实体识别、数据库查询结果等语义特征,而不含槽信息的话语,由于缺乏领域语义信息以及表达多样,其有效对话控制仍然是一个挑战。该文提出一种融合""显式""话语特征和""隐式""上下文信息的end-to-end混合编码网络用于处理不含槽信息话语。具体地,在应用卷积神经网络(convolutional neural network,CNN)对""显式""话语序列提取得到的特征表达的基础上,通过构造和捕获对话序列中""隐式""的系统后台上下文信息,进一步丰富了系统动作分类模型的特征表达。在限定领域面向中文任务SDS中的评估结果表明,与传统的管道式SDS和经典的end-to-end SDS相比,该文的方案在不含槽信息话语的单回合处理以及对话段整体性能上都得到了显著提升。 ",MESS201812017
基于自联想记忆与卷积神经网络的跨语言情感分类,刘娇:31307479|崔荣一:09291242|赵亚慧:10826481,7,跨语言情感分类; 自联想记忆; 词共现; 卷积神经网络;,"该文提出了一种以商品评论为对象的基于语义融合的跨语言情感分类算法。该算法首先从短文本语义表示的角度出发,基于开源工具Word2Vec预先生成词嵌入向量来获得不同语言下的信息表示;其次,根据不同语种之间的词向量的统计关联性提出使用自联想记忆关系来融合提取跨语言文档语义;然后利用卷积神经网络的局部感知性和权值共享理论,融合自联想记忆模型下的复杂语义表达,从而获得不同长度的短语融合特征。深度神经网络将能够学习到任意语种语义的高层特征致密组合,并且输出分类预测。为了验证算法的有效性,将该模型与最新几种模型方法的实验结果进行了对比。实验结果表明,此模型适用于跨语言情感语料正负面情感分类,实验效果明显优于现有的其他算法。 ",MESS201812018
基于自注意力机制的阅读理解模型,张浩宇:36005643|张鹏飞:20759187|李真真:40863832|谭庆平:20886081,7,机器阅读理解; 深度学习; 自注意力机制;,"机器阅读理解是自然语言处理领域一项得到广泛关注与研究的任务。该文针对中文机器阅读理解数据集DuReader,分析其数据集的特点及难点,设计了一种基于循环神经网络和自注意力机制的抽取式模型Mixed Model。通过设计段落融合等策略,该文提出的模型在DuReader测试集上达到了54.2的Rouge-L得分和49.14的Bleu-4得分。 ",MESS201812019
基于深度层次特征的阅读理解模型,"霍欢1,2:23576979|王忠萌1:40934795",11,机器阅读; 层次特征; 卷积;,"对于面向真实场景的中文机器阅读,理解文本所呈现的复杂信息至关重要。针对多篇章的连续答案片段型中文机器阅读任务,该文提出一种基于深度层次特征的模型,来提取细节、片段、全文三个层次的深度特征,从而多角度把握篇章包含的信息。在该模型中,词语经过词向量表示后,经过循环(recurrent)层编码后得到细节特征,并经过若干卷积(convolution)层和高速公路(highway)层等构造片段特征,同时对候选篇章进行全文特征的提取来进行整体的考察。最后,通过这些特征来确定答案所在篇章以及该篇章内的答案片段所在位置。在2018机器阅读理解技术竞赛中,单模型取得57.55的Rouge-L分数和50.87的Bleu-4分数,实验取得较好效果。 ",MESS201812020
张谊生虚词研究系列著作,,1, ,"<正>张谊生,上海师范大学教授、博士生导师、博士后联系导师。汉语言文字学硕士点、博士点学科带头人,语言研究所副所长;中文系学科建设委员会主任,上海师范大学学位委员会委员;中国语言学会常务理事。学术专长为现代汉语虚词及相关现象,尤其是与汉语虚词有关的语法化、词汇化、主观化、构式化、附缀化等演化规律与趋势。 ",MESS201812021
欢迎订阅《中文信息学报》,,1, ,"<正>《中文信息学报》(Journal of Chinese Information Processing)是全国一级学会—社团法人中国中文信息学会和中国科学院软件研究所联合主办的学术性刊物,创刊于1986年10月,现为单月刊。由商务印书馆出版,为商务印书馆期刊方阵中的期刊之一,清华大学印刷厂印刷。《中文信息学报》是我国计算机、计算技术类中文核心期刊。主要刊登中文信息处理基础理论与应用技术方面的高水平学术论文,内容涵盖计算语言学(包括语音与音位、词法、句法、语义、语用等各个层面上的计算),语言资源建设(包括计算词汇学、术语学、电子词典、语料库、知识本体等),机器翻译或机器辅助翻译,汉 ",MESS201812005
“中国法研杯”司法人工智能挑战赛(CAIL 2018)颁奖会举行,,1, ,"<正>2018年10月12日,首届""中国法研杯""司法人工智能挑战赛(CAIL 2018)颁奖典礼暨学术交流研讨会在国家审判资源信息管理中心举行。中国电子科技集团副书记、董事胡爱民,最高人民法院信息中心副主任孙福辉,中国中文信息学会副理事长、秘书长孙乐,共青团中央青年发展部副部长赵宝东,中国电科团委书记金铁增,中国司法大数据研究院总经理王珩、副总经理艾中良,清华大学副教授刘知远,北京大学副教授冯岩松等与参赛选手共同出席了活动。本挑战赛立足于推动司法人工智能技术发展,为学术界和科技界提供统一评测平台,由最高人民法院信 ",MESS201812008
“鹏城杯”网络安全竞赛开赛 复现真实网络靶场环境,,1, ,"<正>12月8日,由中国网络空间安全人才教育联盟、中国中文信息学会评测工作委员会指导,鹏城实验室、中国网络空间安全协会竞评演练工作委员会主办的首届""鹏城杯""网络安全竞赛决赛在深圳市鹏城实验室正式举行。鹏城实验室坐落在国家改革开放的前哨站-深圳市,是广东省政府批准设立的省重点实验室,目前拥有院士专家12人,高文院士担任实验室主任,网络空间安全方向由方滨兴院士领衔,靶场项目由贾焰教授负责。实验室现已建成具备10万级节点规模网络空间靶场,可作为网络攻防演练和网络新技术评测的重要基 ",MESS201812014
全国机器翻译研讨会(CWMT 2018)在福建隆重召开,,1, ,"<正>2018年全国机器翻译研讨会(CWMT 2018)于10月24日至27日在福建召开,本次会议由中国中文信息学会机器翻译专业委员会主办,福建省人工智能学会承办,武夷学院协办。参加本次会议的代表来自全国从事机器翻译研究和应用的高校、科研机构和企业,共200余人,既有享誉国内外学术界和产业界的资深专家,也有崭露头角的青年学者。开幕式由福建省人工智能学会秘书长、厦门大学副教授陈毅东主持,中国中文信息学会名誉理事长、哈尔滨工业大学李生教授,中国中文信息学会副理事长、北京理工大学黄河燕教 ",MESS201812016
中国中文信息学会2018学术年会暨理事会暨“钱伟长中文信息处理科学技术奖”颁奖大会在京召开,,1, ,"<正>2018年11月10-11日,中国中文信息学会2018学术年会暨理事会在北京隆重举行,会上颁发了""钱伟长中文信息处理科学技术奖"",""青年创新奖"",以及中国中文信息学会""优秀博士学位论文奖""。大会邀请了4位国内外著名专家做学术报告,还邀请了6位领域专家进行了主题为""自然语言理解""的专题讨论。来自中教育部国家语委领导、学会支撑单位领导和中文信息处理领域的专家学者共300多人参 ",MESS201812022
基于统计和神经网络的蒙汉机器翻译研究,任众:40673556|侯宏旭:08012191|武静:37906617|王洪彬:37906618|李金廷:37906616|樊文婷:37906619|申志鹏:34205755,7,汉蒙机器翻译; 蒙古文形态分析; 融合训练方法;,"该文对基于传统统计模型的蒙汉机器翻译模型和基于神经网络机器翻译模型进行了研究。其中,神经网络翻译模型分别为基于CNN、RNN的翻译模型,并通过将所有翻译模型结果进行句子级融合得到一个融合模型。面对蒙汉翻译面临资源稀少、蒙古文形态复杂等困难,该文提出多种翻译技术,对各个模型进行改进,并对蒙古文进行形态分析与处理。在翻译效果最好的CNN模型上,采用字和短语融合训练方法;基于RNN的翻译模型除用上述方法外,还采用Giza++指导对齐技术调整RNN注意力机制;针对SMT采用了实验室提出的重对齐技术。该文对实验结果进行了对比和分析,这三种技术方法对相应系统翻译效果有显著提升。此外,蒙古文形态分析与处理对缓解数据稀疏、提升译文质量也有重要作用。 ",MESS201811003
维吾尔语依存树库构建及统计分析,麦热哈巴·艾力:26179697|吐尔根·依布拉音:17705003|加米拉·吾守尔:22592621,8,依存句法; 依存树库; 维吾尔语;,"本着构建维吾尔语依存树库的目的,该文根据黏着性语言的结构特点及其在依存属性中对依存角色的影响,提出构建维吾尔语依存树库时需要考虑的几点要素。其包含依存粒度的确定、维吾尔语依存关系、标注原则、依存树结构以及标注工具的设计与实现。然后根据《维吾尔语依存树库标注手册》人工标注了3 400多条句子并从三个角度对依存树库信息做了统计分析。 ",MESS201811004
基于CRF和半监督学习的维吾尔文命名实体识别,"王路路1,2:35686939|艾山·吾买尔1,2:10775068|买合木提·买买提1,2:22440290|卡哈尔江·阿比的热西提1,2:31758537|吐尔根·依布拉音1,2:17705003",12,维吾尔文命名实体识别; 条件随机场; 半监督学习;,"目前,维吾尔文命名实体识别研究主要集中在单类实体,且没有引入半监督学习方法,从而无法利用未标注语料的无监督语义和结构信息。该文以条件随机场为基本框架,提出了一种基于半监督学习的维吾尔文命名实体识别方法。通过引入词法特征、词典特征、以及基于词向量的无监督学习特征,对比不同特征对识别的影响,并对模型进行优化。实验表明,CRF模型融合多种特征时维吾尔文命名实体识别的F值达到87.43%,说明词法特征和无监督学习特征的有机结合,可以大大减少人工选取特征的工作量,同时也可提高维吾尔文命名实体识别的性能;CRF模型相比于神经网络模型,更适合用于实际应用中。 ",MESS201811005
维吾尔语词缀变体搭配规则研究及算法实现,"艾孜麦提·艾尼瓦尔1,2,3:37829926|董军1,3:25565755|李晓1,3:09602585",7,维吾尔语; 语音和谐律; 词缀变体; 变体搭配; 结构特征;,"该文介绍了维吾尔语词干结构特征、词缀结构特征及维吾尔语语音和谐律;以维吾尔语语音和谐律为基础,在充分考虑基本搭配规则和特殊规则的前提下,提出一种基于词干、词缀结构特征的维吾尔语词缀变体搭配算法;验证词干、词缀结构特征提取的正确性和完整性,并对500个名词词干和300个动词词干进行词缀变体搭配,分别生成9 000个名词和37 800个动词。借助维吾尔语文字校对系统和人工验证的方法,对生成的所有单词进行词缀变体搭配准确性验证;实验结果表明,名词和动词词干搭配词缀准确率分别为98.40%和96.49%,整体搭配准确率为96.86%;最后对搭配错误原因进行了分析。 ",MESS201811006
基于Tree-based CNN的关系抽取,刘伟:40673564|陈鸿昶:17500125|黄瑞阳:32951678,7,关系抽取; 语法分析; CNN;,"该文基于语法树和卷积神经网络(Convolutional Neural Network,CNN)构建了一种树形结构的卷积神经网络Tree-based CNN,以解决在关系抽取的任务中传统CNN对句法信息编码不足的问题。该文实验中,Treebased CNN相对于CNN和LSTM,在关系抽取方面准确率分别提高了3%和5%。实验证明,Tree-based CNN在关系抽取任务中,可以同时具有CNN和LSTM的优势。 ",MESS201811007
基于条件随机场的方志古籍别名自动抽取模型构建,李娜:25936997,9,方志古籍; 条件随机场; 别名; 古籍整理;,"近年来,我国数字图书馆发展迅速,为馆藏资源的深度挖掘和利用提供了基础。该文以数字化的方志古籍为研究语料,在全文人工标注的基础上,通过分析物产别名的内外部特征,构建基于条件随机场的别名自动抽取模型,精确率达到了93.52%。实验结果表明,条件随机场模型能够较好的应用于方志类古籍内容挖掘,为数字图书馆资源利用提供借鉴。 ",MESS201811008
基于小波分析的特征提取文本分类方法研究,朱晋1:40673565|怀丽波1:21778908|崔荣一1:09291242|尹慧2:09292906,6,压缩; 小波分析; TF-IDF; KNN; 分类正确率; 压缩感知;,"该文提出了基于小波分析的文本特征提取方法,对传统TF-IDF向量空间模型下的特征向量进行了该文的小波变换、逆小波变换。使用KNN分类方法检验这两空间下的文本分类准确率。实验结果表明,该文的小波变换方法在减少了TF-IDF向量空间模型近一半的维度下在各种实验条件中都能和向量空间模型保持一致的分类准确率;该文的逆小波变换方法在大幅度降低TF-IDF向量空间模型维度的基础上,同实验中其他特征提取方法相比,在特定条件下有着卓越的特定文本类别分类优势,这也在一定程度上检验了压缩感知理论的正确合理性。 ",MESS201811009
基于BiLSTM-CRF模型的汉语否定信息识别,陈世梅1:40675828|伍星1:10033479,7,BiLSTM-CRF; 否定触发词; 否定覆盖域;,"否定信息识别是将自然语言中的肯定信息与否定信息分离,它对信息检索、文本挖掘、情感分析等都有重要作用。该文主要对汉语否定信息中的触发词识别和覆盖域识别进行研究,采用双向长短期记忆网络结合条件随机场(BiLSTM-CRF)为模型,预训练的词向量为输入特征对触发词进行识别,在此基础上添加已知触发词特征对覆盖域进行识别。中文否定与不确定信息语料上,触发词识别取得F1值为91.03%,覆盖域识别在该语料的子语料财经新闻上取得F1值最高为73.91%。实验结果表明,这一模型在汉语否定触发词识别和覆盖域识别上取得的效果优于CRF模型和BiLSTM模型。 ",MESS201811011
基于细粒度词表示的命名实体识别研究,"林广和1:40094985|张绍武1,2:06536175|林鸿飞1:06504899",11,命名实体识别; 端到端模型; 字符级词表示模型; 注意力机制;,"命名实体识别(NER)是自然语言处理中的一项基础任务,其性能的优劣极大地影响着关系抽取、语义角色标注等后续任务。传统的统计模型特征设计难度大、领域适应性差,一些神经网络模型则忽略了词本身所具有的形态学信息。针对上述问题,该文构建了一种基于细粒度词表示的端到端模型(Finger-BiLSTM-CRF)来进行命名实体识别任务。该文首先提出一种基于注意力机制的字符级词表示模型Finger来融合形态学信息和单词的字符信息,然后将Finger与BiLSTM-CRF模型联合进行实体识别,最终该方法以端到端、无任何特征工程的方式在CoNLL 2003数据集上取得了F1为91.09%的结果。实验表明,该文设计的Finger模型显著提升NER系统的召回率,从而使得模型的识别能力显著提升。 ",MESS201811012
基于协同表示学习的个性化新闻推荐,"梁仕威1,2:40673574|张晨蕊1,2:40673576|曹雷1:27513925|程军军3:38432679|许洪波1:10348532|程学旗1,2:09559496",7,新闻推荐; 协同过滤; 表示学习;,"新闻推荐是互联网推荐系统的研究热点之一,传统的协同过滤算法应用于新闻推荐中会面临严重的新闻冷启动问题,而且也没有考虑新闻内容本身包含的丰富的语义信息。该文将文档与词的表示学习模型与基于矩阵分解的协同过滤算法结合起来,提出一种用于推荐领域的协同表示学习模型,能同时学习带有语义信息的用户和文档的表示向量。在真实的新闻点击数据集上的实验表明,该文提出的模型优于其他基准模型。 ",MESS201811014
基于相似消息的流行度预测方法,"高金华1,2:40417058|沈华伟1,2:23136281|程学旗1,2:09559496|刘悦1:09639001",7,流行度预测; 相似消息; LDA模型;,"社交网络中消息的流行度预测问题在很多应用领域都有着重要意义。传统的流行度预测方法包括基于特征的方法和基于点过程的方法。基于点过程的方法无法利用历史消息的信息,而基于特征的方法则使用一个统一的模型来对所有的消息进行预测,没有考虑消息的特异性。因此,该文提出了一种基于相似消息的流行度预测方法。对于待预测微博,我们从历史消息选取出与之最相似的前K条消息来进行预测。在计算消息相似度时,我们借助了文档建模领域的LDA模型来学习消息的表示。在数据集上的实验结果表明,该方法可以有效发现在传播模式上与待预测消息相似的历史消息,并在流行度预测任务上取得了比对比模型更好的预测效果。 ",MESS201811015
ACMF:基于卷积注意力模型的评分预测研究,"商齐1:39593359|曾碧卿1,2:07578703|王盛玉1:37607191|周才东1:39593358|曾锋1:40673578",11,卷积神经网络; 注意力机制; 评分预测;,"评分数据稀疏是影响评分预测的主要因素之一。为了解决数据稀疏问题,一些推荐模型利用辅助信息改善评分预测的准确率。然而大多数推荐模型缺乏对辅助信息的深入理解,因此还有很大的提升空间。鉴于卷积神经网络在特征提取方面和注意力机制在特征选择方面的突出表现,该文提出一种融合卷积注意力神经网络(Attention Convolutional Neural Network,ACNN)的概率矩阵分解模型:基于卷积注意力的矩阵分解(Attention Convolutional Model based Matrix Factorization,ACMF),该模型首先使用词嵌入将高维、稀疏的词向量压缩成低维、稠密的特征向量;接着,通过局部注意力层和卷积层学习评论文档的特征;然后,利用用户和物品的潜在模型生成评分预测矩阵;最后计算评分矩阵的均方根误差。在ML-100k、ML-1m、ML-10m、Amazon数据集上的实验结果表明,与当前取得最好预测准确率的PHD模型相比,ACMF模型在预测准确率上分别提高了3.57%、1.25%、0.37%和0.16%。 ",MESS201811016
从高频词等级相关角度探析《红楼梦》作者,马创新1:34584698|陈小荷2:08109709,6,高频词; 等级; 相关度; 作者信息;,"该文提出一种""基于高频词等级相关度的方法""来探析存疑文献的作者信息,把各份语料中的词型均按照出现频次递减排列并确定等级,然后通过计算出语料之间高频词等级的相关度,来推断语料之间语言风格的相似度,并且把这种方法与""基于词型共现率的方法""和""基于词例共现率的方法""相比较。把《红楼梦》的120回均分为12份语料,使用""基于高频词等级相关度的方法""计算这12份语料两两之间的相关度。研究发现《红楼梦》的前8份语料两两之间相关度高,后4份语料两两之间相关度也高,而前8份语料与后4份语料这两部分语料之间相关度低。推断《红楼梦》前80回应是同一人所写,后40回应是另一人所写。 ",MESS201811017
基于多篇章多答案的阅读理解系统,"刘家骅1,2:40675829",9,机器阅读理解; 问答系统; 深度循环神经网络;,"机器阅读理解任务一直是自然语言处理领域的重要问题。2018机器阅读理解技术竞赛提供了一个基于真实场景的大规模中文阅读理解数据集,对中文阅读理解系统提出了很大的挑战。为了应对这些挑战,我们在数据预处理、特征表示、模型选择、损失函数的设定和训练目标的选择等方面基于以往的工作做出了对应的设计和改进,构建出一个最先进的中文阅读理解系统。我们的系统在正式测试集ROUGE-L和BLEU-4上分别达到了63.38和59.23,在105支提交最终结果的队伍里面取得了第一名。 ",MESS201811018
一种基于数据重构和富特征的神经网络机器阅读理解模型,尹伊淳:40673579|张铭:06276534,5,机器阅读理解; 数据重构; 神经网络;,"该文描述了ZWYC团队在""2018机器阅读理解技术竞赛""上提出的机器理解模型。所提出模型将机器阅读理解问题建模成连续文本片段抽取问题,提出基于富语义特征的神经交互网络模型。为了充分使用答案标注信息,模型首先对数据进行细致的重构,让人工标注的多个答案信息都能融合到数据中。通过特征工程,对每个词构建富语义表征。同时提出一种简单有效的问题和文档交互的方式,得到问题感知的文档表征。基于多个文档串接的全局表征,模型进行答案文本预测。在最终测试集上,该模型获得了目前先进的结果,在105支队伍中排名第2。 ",MESS201811019
基于BiDAF多文档重排序的阅读理解模型, ,11,机器阅读理解; 多文档投票; ParaRanking;,"随着互联网的兴起和发展,数据规模急速增长,如何利用机器阅读理解技术对海量的非结构化数据进行解析,从而帮助用户快速、准确地查找到满意答案,是目前自然语言理解领域中的一个热门课题。该文通过对机器阅读理解中的深度神经网络模型进行研究,构建了RBiDAF模型。首先,通过对DuReader数据集进行数据探索,并对数据进行预处理,从中提取出有利于模型训练的特征。其次在BiDAF模型的基础上提出了基于多文档重排序的RBiDAF机器阅读理解模型,该模型在BiDAF模型四层网络框架的基础上添加了ParaRanking层。其中在ParaRanking层,该文提出了多特征融合的ParaRanking算法,此外在答案预测层,提出了基于先验知识的多答案交叉验证算法,进而对答案进行综合预测。在""2018机器阅读理解技术竞赛""的最终评测中,该模型表现出了不错的效果。 ",MESS201811021
T-Reader:一种基于自注意力机制的多任务深度阅读理解模型,郑玉昆1:40675830|李丹2:40675831|范臻1:40675832|刘奕群1:08176974|张敏1:08186086|马少平1:08177513,7,机器阅读理解; 问答系统; 深度学习; 强化学习;,"该文介绍THUIR团队在""2018机器阅读理解技术竞赛""中的模型设计与实验结果。针对多文档机器阅读理解任务,设计了基于自注意力机制的多任务深度阅读理解模型T-Reader,在所有105支参赛队伍中取得了第八名的成绩。除文本信息外,提取了问题与段落精准匹配等特征作为模型输入;在模型的段落匹配阶段,采用跨段落的文档级自注意力机制,通过循环神经网络实现了跨文档的问题级信息交互;在答案范围预测阶段,通过进行段落排序引入强化学习的方法提升模型性能。 ",MESS201811022
D-Reader:一种以全文预测的阅读理解模型,赖郁婷1:40675833|曾俋颖1:40675834|林柏诚2:40675835|萧瑞辰2:40675836|邵志杰1:40675837,8,机器阅读理解; DuReader; 双向注意流; 集成学习;,"该文针对2018机器阅读理解技术竞赛提出一个基于双向注意流(BiDAF)BiDAF的阅读理解模型,实作于DuReader中文问答数据集。该文观察到基线系统采用与问题最相近的段落,作为预测的筛选条件,而改以完整段落来预测答案,结果证实优于原方法。并利用fastText训练词向量以强化上下文信息,最后通过集成学习优化结果,提升效能与稳定性。此外,针对DuReader的是非类题型,该文集成两个分类模型,分别基于注意力机制(attention)与相似性机制(similarity)来预测答案类别。该模型最终在""2018机器阅读理解技术竞赛""的评比中得到了ROUGE-L 56.57与BLEU-4 48.03。 ",MESS201811023
商务印书馆新书介绍,,1, ,"<正>书名:东方服饰研究书号:ISBN978-7-100-16092-6出版时间:2018年9月作者:华梅等定价:109元内容简介:本书以东方服饰设计审美为主题,从设计、审美、文献三个角度,运用以文释图、以图证史、文图互证的研究手段,结合文献学、考古学、人类学、社会学、图像学、结构 ",MESS201811024
第七届未来数据论坛暨第五届大搜索论坛在哈尔滨举办,,1, ,"<正>2018年8月2日—4日,第七届未来数据论坛暨第五届大搜索论坛在黑龙江省哈尔滨市举行。本次大会由中国工程院、FFD and BigSearch Steering Committee主办,哈尔滨工业大学、国防科技大学与中国中文信息学会网络空间大搜索专委会联合承办。来自中国、美国、澳大利亚、香港等国家和地区共30多位大数据及相关领域杰出科学家应邀出席大会,交流研讨大数据研究最新成果。中国中文信息学会理事长方滨兴院 ",MESS201811025
全国知识图谱与语义计算大会(CCKS 2018)在天津隆重召开,,1, ,"<正>2018年全国知识图谱与语义计算大会(CCKS 2018)于8月14日至17日在天津召开,本次会议由中国中文信息学会语言与知识计算专业委员会主办,南开大学软件学院承办,天津大学智能与计算学部协办。会议主题为""知识计算与语言理解""。大会吸引了来自海内外的千余名知名学者、工业界专家和知名企业代表参加,其中主会注册人数超860人。会议回顾了知识图谱与语义计算的进展情况,探讨了领域内的新发现、 ",MESS201811026
受控自然语言的应用和处理,薛平:40414743,10,受控自然语言; 工业语言规范; 语言自动检测; 知识表达; 人机互动; 人工智能;,"自然语言是人类交流最自然的方式。但其复杂性和模糊性常常给有效的交流带来问题。现代社会尤其是当前信息时代面对大量的信息数据,不少工业场景和科研领域以及各种人机交互的应用要求清晰精准、标准化而又较为自然的表达和交流,受控自然语言随着这些需求应运而生。该文讨论受控自然语言及其性质、分类和应用,以及受控自然语言的计算处理方法。该文将以航空工业民用飞机所涉及的英语文本数据为例来阐述受控自然语言在工业场景中的作用和重要性,并且简要讨论受控自然语言更为广泛的意义和价值,涉及其他领域包括当前热门的人工智能等相关的课题。 ",MESS201810002
基于融合策略的机器翻译自动评价方法,"马青松1,2,3:40190907|张金超1,2,3:34658917|刘群1,4:09638994",9,机器翻译自动评价; 融合; 直接评估;,"机器翻译自动评价发展至今,各种自动评价方法不断涌现。不同的自动评价方法从不同的角度评价机器译文的质量。该文提出了基于融合策略的自动评价方法,该方法可以融合多个自动评价方法,多角度地综合评价机器译文质量。该文主要在以下几个方面探索进行:(1)对比分别使用相对排序(RR)和直接评估(DA)两种人工评价方法指导训练融合自动评价方法,实验表明使用可靠性高的DA形成的融合自动评价方法(Blend)性能更好;(2)对比Blend分别使用支持向量机(SVM)和全连接神经网络(FFNN)机器学习算法,实验表明在当前数据集上,使用SVM效果更好;(3)进而在SVM基础上,探索使用不同的评价方法对Blend的影响,为Blend寻找在性能和效率上的平衡;(4)把Blend推广应用到其他语言对上,说明它的稳定性及通用性。在WMT16评测数据上的实验,以及参加WMT17评测的结果均表明,Blend与人工评价的一致性达到领先水平。 ",MESS201809002
基于多编码器多解码器的大规模维汉神经网络机器翻译模型,"张金超1,2,3:34658917|艾山·吾买尔4:10775068|买合木提·买买提4:22440290|刘群1,5:09638994",8,维汉机器翻译; 神经网络; 多编码器多解码器;,"为提升维汉机器翻译模型的翻译能力,该文提出使用多编码器多解码器的结构,搭建大规模的维汉神经网络机器翻译模型。相比于单编码器单解码器的浅层的小模型,多编码器多解码器模型具有多个编码器,可以对源语言进行多层次、多视角的压缩表示;同时具有多个解码器,可以增强目标语言的生成能力。实验证明,在大规模的训练数据上,使用该方法搭建的大规模维汉神经网络机器翻译模型,译文质量可以大幅度地超过基于短语的统计机器翻译模型和基本的神经网络翻译模型。该文还针对维汉翻译源端语言和目标端语言的翻译单元粒度进行了实验,发现维吾尔语端使用字节对编码单元、汉语端使用字单元,可以消除对汉语分词器的依赖,做到和双端都使用字节对编码单元可比的效果。 ",MESS201809004
基于TDNN-FSMN的蒙古语语音识别技术研究,王勇和:39770378|飞龙:23670720|高光来:05981929,7,蒙古语; 语音识别; 时延神经网络; 前馈型序列记忆网络;,"为了提高蒙古语语音识别性能,该文首先将时延神经网络融合前馈型序列记忆网络应用于蒙古语语音识别任务中,通过对长序列语音帧建模来充分挖掘上下文相关信息;此外研究了前馈型序列记忆网络""记忆""模块中历史信息和未来信息长度对模型的影响;最后分析了融合的网络结构中隐藏层个数及隐藏层节点数对声学模型性能的影响。实验结果表明,时延神经网络融合前馈型序列记忆网络相比深度神经网络、时延神经网络和前馈型序列记忆网络具有更好的性能,单词错误率与基线深度神经网络模型相比降低22.2%。 ",MESS201809005
基于多策略的乌孜别克语名词词干识别研究,"艾孜海尔江1,2:32674441|祖力克尔江1,2:34722235|艾孜尔古丽1:26177339|玉素甫·艾白都拉1:22251454",6,乌孜别克语; 形态分析; 多策略; 名词词干识别;,"乌孜别克语名词词干识别是自然语言处理领域的基础研究,主要方法是从句子中提取名词词干,提高名词标注效率和准确性。该文首先陈述形态分析、形态特征对识别其词性的作用,然后讨论乌孜别克语的词类划分标准、名词的形态特征,乌孜别克语西尔里文转换拉丁文,乌孜别克语词汇翻译、标注技术,总结词缀歧义及消解规则。该文提出利用形态规则、词典、最大熵融合策略,设计现代乌孜别克语新词中名词词干识别算法,其中包括特征选择及参数估计、词内部特征、前后依存词特征等。最后以乌孜别克语网站文本作为验证对象,对名词词干进行统计与分析。 ",MESS201809006
面向语言信息处理的藏语短语及其分类方法研究,"才藏太1,2,3:08163472|索南才让1,4:27164062|才让加1,2,3:08163475",6,藏语; 短语; 分类; 标记;,"短语作为语言分析的一个层次,占有十分重要的位置。有效的短语分析对降低其后句法分析的难度,缩小句法分析器的搜索空间,提高机器翻译的翻译正确率是很有帮助的。而目前面向信息处理的藏语短语的研究刚刚起步,有待于进一步发展。该文在藏语短语与藏语句子的界线研究的基础上,根据藏语信息处理的特点和要求,按照语法功能和便于计算机自动分析和处理的原则对短语进行分类,并规定了信息处理中藏语短语类别单位的标记代码。 ",MESS201809007
一种基于向量模型的藏文字拼写检查方法,才智杰1:08166533|孙茂松2:08823738|才让卓玛1:11447913,9,自然语言处理; 向量模型; 藏文字; 拼写检查; 非真字;,"自动拼写检查是自然语言处理领域一项极具挑战性的研究课题,在语料库建设、文本编辑、语音和文字识别等诸多方面具有广阔的应用前景。藏文字是一种表音拼音文字,由1~7个基本构件横向和纵向拼接而成。藏文文本中非真字出现的频率很高,是藏文字拼写检查的基础和重点。该文通过分析藏文文法中的构字规则,利用藏文字向量模型将藏文字用计算机易于操作的数字(向量)表示,建立基于规则约束的藏文字向量模型,进而设计该模型下的藏文字拼写检查模型及算法。算法简单易实现,经测试算法拼写检查的平均准确率达99.995%,平均每秒检查1 060个字。 ",MESS201809008
基于文体和词表的突发事件信息抽取研究,邱奇志:09061306|周三三:38494591|刘长发:38972641|陈晖:38972642,11,文体; 词表; 信息抽取; 突发事件;,"非结构化数据的结构化任务是大数据环境下管理信息系统面临的新课题。该文从文体的角度研究自由文本的特性,提出了从Web新闻中抽取突发事件属性的方法,该方法首先分析研究了Web文本和新闻文体的特征,利用Google Word2Vec对领域专家构建的词表进行扩展,针对突发事件的不同属性制定了不同的抽取方法:采用词表实现事件分类,采用文体特征进行时间、事件摘要的抽取,采用文体和词表进行地点、伤亡情况和经济损失属性的抽取。实验表明,采用基于文体和词表方法在爬取的Web新闻语料库和公开语料库进行突发事件的属性进行抽取时,平均准确率分别为87.89%、91.29%,平均召回率分别为81.76%、87.91%,能满足应急管理需求。 ",MESS201809009
一种改进的实体关系抽取算法——OptMultiR,"延浩然1,2:40183716|靳小龙1,2:26681578|贾岩涛1,2:29294835|程学旗1,2:09559496",9,关系抽取; 远程监督; 多实例多标签学习;,"作为知识图谱构建过程中的关键步骤,关系抽取这一从海量自然语言文本中抽取实体间关系的任务近年来得到了越来越广泛的关注。如今,远程监督(distant supervision)方法通过与已有知识库(knowledge base)中的实体和关系进行对齐,可以直接使用源文本进行训练从而省去了人工标记数据的过程。其中,使用了多实例多标签(multi-instance multi-label)模型的MultiR算法取得了很好的抽取效果。但该算法存在两个问题:抽取过程中未考虑实体对之间可能已存在的关系,以及概率图匹配计算中使用的贪心算法无法获得最优解。该文针对上述问题进行了改进。首先,在关系抽取的打分过程中,考虑到同一实体对可能存在的多个关系之间具有一定关联性,该文引入了关系权重矩阵,使其在抽取过程中将实体对已知的关系转换为权重向量对打分进行干预,以此减少个别文本特征的干扰,提高抽取准确率。其次,在概率图匹配过程中,为了将图的匹配从局部最优值提升为全局最优值,该文将原有的贪心算法替换为基于状态压缩的动态规划算法。实验结果证明,优化后的MultiR模型,称之为OptMultiR,其关系抽取性能得到了显... ",MESS201809010
一种基于局部—全局主题关系的演化式摘要系统,吴仁守:38733883|刘凯:23751807|王红玲:08848649,9,主题关系; PageRank; 演化式摘要; 多文档文摘;,"带有时间标志的演化式摘要是近年来提出的自然语言处理任务,其本质是多文档自动文摘,它的研究对象是互联网上连续报道的热点新闻文档。针对互联网新闻事件报道的动态演化、动态关联和信息重复等特点,该文提出了一种基于局部—全局主题关系的演化式摘要方法,该方法将新闻事件划分为多个不同的子主题,在考虑时间演化的基础上同时考虑子主题之间的主题演化,最后将新闻标题作为摘要输出。实验结果表明,该方法是有效的,并且在以新闻标题作为输入输出时,和当前主流的多文档摘要和演化摘要方法相比,在Rouge评价指标上有显著提高。 ",MESS201809011
跨数据源论文集成,张帆进:40183718|顾晓韬:36220552|姚沛然:40183719|唐杰:08180247,10,数据集成; 卷积神经网络; 哈希学习; 网络爬虫;,"该文研究跨数据源的论文集成问题,旨在将不同数据源中的同一论文匹配起来。该文提出了两个算法来解决论文匹配的问题,第一个算法(MHash)利用哈希算法来加速匹配,第二个算法(MCNN)利用卷积神经网络(CNN)来提高匹配的准确率。实验表明,结合论文的各种属性,MHash能够在快速得到匹配结果的同时,保持较高的准确率(93%+),而MCNN能够达到非常高的准确率(98%+)。同时,设计了一个针对大规模论文匹配的异步搜索框架,在15天内得到了64 639 608对AMiner(1)和MAG(2)论文的匹配结果。论文匹配结果和AMiner、MAG的全部论文数据已作为公开数据集发布(3)。 ",MESS201809013
利用准私密社交网络文本数据检测抑郁用户的可行性分析,"刘德喜1,2:13897196|邱家洪1,2:39026457|万常选1,2:07848038|刘喜平1,2:07847937|钟敏娟1,2:11617711|郭海峰3:25935818|邓松4:26718875",10,准私密社交网络文本; 抑郁用户检测; 可行性分析;,"社交媒体的发展为抑郁用户的检测提供了一条新的途径。已有的相关研究通常是利用用户在Twitter、微博等社交网络平台上的用户行为数据或公开发表的文本内容,较少有利用微信朋友圈、QQ空间这种相对比较私密的社交网络数据。直观地,这类准私密社交网络数据更能反映用户的心理健康状况。该文主要讨论利用准私密社交网络文本数据检测抑郁用户的可行性,包括训练样本的选择、特征量化方法、检测模型选择和不同文本特征下的模型分类效果等。实验表明,采用平衡高低分组的方法选择样本比非平衡高低分组样本和离散化的高低分组样本训练的分类器要好;利用Z-score标准化的特征量化方法比直接使用频次或归一化频率要好;随机梯度下降模型SGD较支持向量机SVM等其他用于对比的分类模型要好。实验还发现,相对于词袋、词向量等文本特征,主题特征有较好的效果,可以使社交网络用户抑郁检测模型的F值达到0.753,而对抑郁用户的检测精度达到0.813。 ",MESS201809014
微博网络用户的活跃性判定方法,"仲兆满1,2:27149673|戴红伟1:24573378|管燕1:27611341",10,微博推荐系统; 用户活跃性判定; 用户背景; 用户社交关系; 用户发表内容质量; 用户社交行为;,"推荐系统的冷启动问题是近期的研究热点,而用户的活跃性判定是冷启动问题的基础。已有方法在判定用户的活跃性时,单纯地考虑了用户发表信息量,对社交媒体的社交关系及行为等特征利用不够。该文面向微博网络,提出了系统的用户活跃性判定方法,创新性主要体现在:(1)提出了微博网络影响用户活跃性的四类指标,包括用户背景、社交关系、发表内容质量及社交行为,避免了仅仅使用用户发表信息数量判定用户是否活跃的粗糙方式;(2)提出了用户活跃性判定流程,提出了基于四类指标的用户与用户集的差异度计算模型。以新浪微博为例,选取了学术研究、企业管理、教育、文化、军事五个领域的900个用户作为测试集,使用准确率P、召回率R及F值为评价指标,进行了实验分析和比较。结果显示,该文所提用户活跃性判定方法的准确率P、召回率R、F值比传统的判定方法分别提高了21%、13%和16%,将该文所提方法用于用户推荐,得到的P、R和F值比最新的方法分别提高了5%、2%和3%,验证了所提方法的有效性。 ",MESS201809015
面向中文网络评论情感分类的集成学习框架,"黄佳锋1:38376035|薛云1,2:23329502|卢昕1:38376037|刘志煌1:37751868|吴威1:17555004|黄英仁1:34350172|李万理1:38671783|陈鑫1,3:28470071",10,网络评论; 情感分类; 集成学习; 特征提取;,"该文针对中文网络评论情感分类任务,提出了一种集成学习框架。首先针对中文网络评论复杂多样的特点,采用词性组合模式、频繁词序列模式和保序子矩阵模式作为输入特征。然后采用基于信息增益的随机子空间算法解决文本特征繁多的问题,同时提高基分类器的分类性能。最后基于产品属性构造基分类器算法综合评论文本中每个属性的情感信息,进而判别评论的句子级情感倾向。实验结果表明了该框架在中文网络评论情感分类任务上的有效性,特别是在Logistic Regression分类算法上准确率达到90.3%。 ",MESS201809016
基于词注意力卷积神经网络模型的情感分析研究,"王盛玉1:37607191|曾碧卿1,2:07578703|商齐1:39593359|韩旭丽1:40183720",9,卷积神经网络; 注意力模型; 情感分类;,"情感分类任务需要捕获文本中的情感特征,利用重要的局部特征构建文本的特征表示。卷积神经网络(convolutional neural networks,CNN)已经被证明拥有出色的特征学习能力,但是该模型无法判别输入文本中特征词与情感的相关性,卷积层缺乏对单一词特征的提取。基于目前运用非常成功的注意力模型,该文提出一种基于词注意力的卷积神经网络模型(word attention-based convolutional neural networks,WACNN)。相比于卷积神经网络,该模型以篇章的文本信息作为输入,首先在词嵌入层之后增加注意力机制层,获取重要的局部特征词,使模型有选择地进行特征提取;然后在卷积层中增加大小为1的卷积核,提取单一词的特征;最后该方法对输入文本进行适当的文本填充,保证每个词都存在上下文信息,使模型有效提取到每个词的n-grams局部特征,避免卷积处理过程中局部信息的丢失。该模型在MR5K和CR数据集上进行验证,较普通卷积神经网络和传统机器学习方法,在准确率上分别取得0.5%和2%的提升。 ",MESS201809017
异质信息网络中基于元路径的社团发现算法研究,郑玉艳1:35773538|王明省2:34220606|石川1:24914968|王锐1:17472205,11,异质信息网络; 社团发现; 元路径; 语义相似性度量;,"实际的网络化数据往往包含多种类型的对象和关系,采用异质信息网络可以更好地对其建模,因此异质信息网络分析逐渐成为数据挖掘的研究热点。虽然同质信息网络中的社团发现已经被深入研究,但是异质信息网络中的社团发现还很少被研究。该文研究异质信息网络中的社团发现问题,提出了一个新的社团发现算法框架HCD(heterogeneous community detection)。该框架由两部分组成:基于单条元路径的社团发现算法HCD_sgl和融合多条元路径的社团发现算法HCD_all。HCD_sgl首先确定在给定元路径下所有节点的初始标签,再利用改进的标签传递算法进行最终的社团发现;HCD_all是在HCD_sgl的基础上将基于多条元路径的社团发现结果进行融合。通过在真实数据集和人工数据集上的实验验证了HCD算法的有效性。 ",MESS201809018
第三届IEEE网络空间数据科学国际会议在广州顺利召开,,1, ,"<正>2018年6月18—21日,由IEEE(国际电气和电子工程师协会)、IEEE可扩展计算技术委员会、IEEE计算机协会、中国工程院、中国中文信息学会主办,广州大学、北京大学和国防科技大学承办的""第三届IEEE网络空间数据科学国际会议(IEEE DSC’2018)""在广州白云国际会议中心召开。 ",MESS201809019
中国中文信息学会大数据安全与隐私保护专业委员会成立大会暨第二届网络空间安全学术前沿与学科建设研讨会在西安召开,,1, ,"<正>2018年7月25日下午,中国中文信息学会大数据安全与隐私保护专业委员会在西安召开成立大会,中国中文信息学会理事长方滨兴院士、副理事长兼秘书长孙乐研究员,中国科学院信息工程研究所副总工李凤华研究员及中文信息学会大数据安全与隐私保护专业委员会委员等50余名专家学者出席大会,会议由中国中文信息学会副理事长兼秘书长孙乐主持。 ",MESS201809003
文本可读性的自动分析研究综述,"吴思远1,2:40934849|蔡建永2,3:26104385|于东1:26514992|江新2:06427948",10,文本可读性; 可读性分析; 特征提取;,"文本可读性问题最初由教育学家提出,初衷是辅助教师为语言学习者推荐适合其阅读水平的文本。随着计算机技术的发展及网页文本的涌现,对文本进行可读性分析有了更加丰富的技术手段和应用场景。该文对可读性自动分析的相关研究进行了梳理,将可读性自动分析的方法总结为公式法、分类法和排序法三类;然后进一步介绍了可读性自动分析中的两项重要内容:文本特征的选择和数据集的使用;最后对可读性研究的发展方向进行展望。 ",MESS201812001
引入词性标记的基于语境相似度的词义消歧,孟禹光:38972609|周俏丽:25068859|张桂平:24679273|蔡东风:24679274,10,语境向量; 语境相似度; 词义消歧; 词性特征;,"目前的语境向量模型在对语义空间建模的时候,没有考虑到同一个词的不同词性具有不同的含义,将它们看作同一个点进行建模,导致得到的语境向量质量不高,使用这种语境向量计算语境相似度效果不好。针对该类问题,提出了一种加入词性特征的语境向量模型,加入词性后,可以将原本用语义空间中一个点表示的几个语义区分出来,得到质量更好的语境向量和语境相似度,进而得到更好的消歧效果。实验结果表明,这种建模方式可以有效区分不同词性的语义,在2004年的Senseval-3测试集上进行测试,准确率达到了75.3%,并在SemEval-13和SemEval-15公开测试集上进行了测试,消歧效果相比未引入词性特征的模型均得到了提升。 ",MESS201808002
中文嵌套命名实体识别语料库的构建,"李雁群1,2:40031756|何云琪1,2:39243003|钱龙华1,2:08844995|周国栋1,2:13898054",8,中文嵌套命名实体识别; 条件随机场; 信息抽取; 语料库;,"嵌套命名实体含有丰富的实体和实体间语义关系,有助于提高信息抽取的效率。由于缺少统一的标准中文嵌套命名实体语料库,目前中文嵌套命名实体的研究工作难于比较。该文在已有命名实体语料的基础上采用半自动化方法构建了两个中文嵌套命名实体语料库。首先利用已有中文命名实体语料库中的标注信息自动地构造出尽可能多的嵌套命名实体,然后再进行手工调整以满足对中文嵌套实体的标注要求,从而构建高质量的中文嵌套命名实体识别语料库。语料内和跨语料嵌套实体识别的初步实验表明,中文嵌套命名实体识别仍是一个比较困难的问题,需要进一步研究。 ",MESS201808003
基于统计和词典方法相结合的韩汉双语语料库名词短语对齐,, , , ,MESS201808004
大规模中文实体情感知识的自动获取,"卢奇1,2:37744215|陈文亮1,2:33224970",10,情感分析; 情感词典; 情感挖掘; 信息抽取;,"目前中文情感分析的主要资源以情感词典为主,缺乏针对实体或属性的情感知识资源。该文主要研究如何从大规模文本语料中自动获取实体情感知识。在该文方法中,用情感表达组合来表示实体情感知识。首先,基于二部图排序算法对情感表达组合候选集合进行排序。然后,提出了一种基于语义相似的提炼算法对于排序靠后的表达组合进行选择。在提炼选择过程中,充分考虑实体之间和情感词之间的约束。最后,该文在三种大规模不同领域的语料上进行实验,并进行人工评价。评价结果表明,从三个领域数据集上获取的实体情感表达组合正确率均高于90%。最终我们获得了一个大规模情感知识词典,包括约30万对的情感表达组合。 ",MESS201808005
神经机器翻译中数据泛化与短语生成方法研究,"李强1:06579825|韩雅倩1:40032970|肖桐1,2:11698781|朱靖波1,2:06569435",11,自然语言处理; 神经机器翻译; 数据泛化; 短语生成;,"该文对神经机器翻译中的数据泛化方法和短语生成方法进行研究。在使用基于子词的方法来缓解未登录词和稀疏词汇问题的基础上,提出使用数据泛化的方法来进一步优化未登录词和稀疏词汇的翻译,缓解了子词方法中出现的错译问题。文中对基于子词的方法和基于数据泛化的方法进行了详细的实验对比,对两种方法的优缺点进行了讨论和说明。针对数据泛化的处理方法,提出了一致性检测方法和解码优化方法。由于标准的神经机器翻译模型以词汇为基础进行翻译建模,因此该文提出了一种规模可控的短语生成方法,通过使用该文方法生成的源语言短语,神经机器翻译的翻译性能进一步提高。最终,在汉英和英汉翻译任务上,翻译性能与基线翻译系统相比分别提高了1.3和1.2个BLEU值。 ",MESS201808006
训练语料的不同利用方式对神经机器翻译模型的影响,邝少辉:35773323|熊德意:32622753,8,神经机器翻译; 批; dropout; 数据打乱;,"神经机器翻译(NMT)是近两年刚出现的一种新型机器翻译方法,是一种端到端的翻译模型。目前,影响NMT模型效果的因素有很多,其一,当训练语料规模较大时,梯度下降更新方法会对机器的内存要求很高,因此大多研究工作中采用随机梯度下降(SGD)的方法来更新模型的训练参数,即每输入一定数量(批:batch)的训练样例,就利用局部的训练样例更新一次模型参数;其二,参数dropout可以防止系统训练时出现过拟合,提高系统泛化能力;其三,数据打乱(shuffle)也对翻译结果有着重要影响。因此,该文的研究内容主要是探索批、dropout和打乱这三个因素在训练神经机器翻译模型中对模型翻译质量的影响,并得出以下三条结论:一是批的大小将影响神经机器翻译(NMT)模型的收敛速度,二是dropout可以提升神经机器翻译模型的性能,三是数据打乱可以在一定程度上提升神经机器翻译(NMT)系统的翻译质量。 ",MESS201808007
基于RNN和CNN的蒙汉神经机器翻译研究,"包乌格德勒1,2:25810569|赵小兵2:22390615",8,循环神经网络; 卷积神经网络; 神经机器翻译;,"该文探讨了基于RNN和CNN的蒙汉神经机器翻译模型,分别采用蒙古语的词模型、切分模型和子词模型作为翻译系统的输入信号,并与传统的基于短语的SMT进行了比较分析。实验结果表明,子词模型可以有效地提高RNN NMT和CNN NMT的翻译质量。同时实验结果也表明,基于RNN的蒙汉NMT模型的翻译性能已经超过传统的基于短语的蒙汉SMT模型。 ",MESS201808008
基于门控循环神经网络词性标注的蒙汉机器翻译研究,刘婉婉:36383308|苏依拉:07987316|乌尼尔:36383307|仁庆道尔吉:22393973,7,机器翻译; 门控循环神经网络; 注意力机制; 对齐;,"统计机器翻译可以通过统计方法预测出目标词,但没有充分理解原文语义关系,因而得到的译文质量不高。针对该问题,利用一种基于门控单元循环神经网络结构来对蒙汉神经机器翻译系统进行建模,引入注意力机制来获取双语词语的对齐信息,并在构建字典过程中对双语词语进行词性标注来强化语义,以此来缓解因欠训练导致的错译问题。实验结果表明,与RNN的基准系统和传统的统计机器翻译方法相比,该方法 BLEU值得到一定的提升。 ",MESS201808009
哈萨克语句法分析辅助特征提取研究,陈雪:27763516|古丽拉·阿东别克:22101463,6,柱搜索; 双向LSTM; 前瞻特征;,"在哈萨克语句法分析中,该文用平均感知器算法训练句法分析模型,用柱搜索算法进行解码,可以快速准确地对哈萨克语句子进行短语结构句法分析。在解析句子过程中,构建了一个双向LSTM模型,利用它提取句子中每个单词之间组成结构的信息,以预测每个单词在句法树中的句法组成部分,然后将结果作为辅助前瞻特征传递给句法分析过程。实验证明,此方法与基线模型相比,在准确率和召回率上均有提高。 ",MESS201808010
基于Bi-tagged特征的维吾尔文情感分类方法研究,"热西旦木·吐尔洪太1,2:36636459|吾守尔·斯拉木1:17705001",11,情感分类; Bi-tagged特征; 组合特征; 维吾尔文;,"现有的维吾尔文文本情感分类方法以从空格分词中得到的unigram特征作为文本表示,因而无法挖掘与情感表达相关的深层语言现象。该文从维吾尔文词汇之间的顺序依赖关系入手,总结若干个词性组合规则,提取能够表达丰富情感信息的Bi-tagged特征,并基于支持向量机(SVM)分类器对维吾尔文情感语料库进行了正负情感分类。实验结果表明,在维吾尔文文本情感分类中:(1)当包含该文提出的各项词性规则时,Bi-tagged特征的性能最优;(2)Bi-tagged特征不仅能够提取情感丰富的信息,而且可以提取否定信息;(3)与常用的unigram、bigram特征以及unigram和bigram的组合特征在该文数据集上的分类效果相比,该文所提取的Bi-tagged与unigram的组合特征分类效果更佳,比该文的Baseline的分类准确率提高了4.225%。该研究成果不但可以进一步提高维吾尔文文本情感分类效率,也可为哈萨克语、柯尔克孜语等亲属语言的情感分类提供借鉴。 ",MESS201808011
基于包含度和频繁模式的文本特征选择方法,"池云仙1,2:37561827|赵书良2:07149329|李仁杰1:07151829",12,大数据; 文本挖掘; 文本频繁模式; 包含度; 文本特征选择;,"大数据时代,文本数据量的爆炸式增长使得特征选择成为文本挖掘领域最关键的任务之一。文档中的词语和模式规模庞杂,故需保证所挖掘特征的质量充满挑战。""基于模式""特征选择方法具有传统""基于词语""方法所没有的优越特性,可以进行有效地信息去噪,提升文本挖掘性能。该文提出基于包含度和频繁模式的文本特征选择方法:首先,定义基于包含度的相似性度量原理;然后,提出基于包含度的冗余文本频繁模式过滤方法。基于包含度度量文本频繁模式间相似性,以此去除子模式及相似度较高的交叉模式。再通过冗余模式去噪,提升文本频繁模式挖掘性能;提出基于关联度的文本特征选择方法。以经过过滤处理后的非冗余文本频繁模式为基础,进行文本特征选择,并利用词语与文档的关联度进行词语类别划分及权重分配。使所选特征与文档关联度更加清晰,分类效果更好。通过在数据集Reuters-21578上的实验得知,基于包含度和频繁模式的文本特征选择算法性能,优于当前普遍应用的传统文本特征选择方法和新的特征选择及特征抽取方法。 ",MESS201808012
类比社交网络的进程故障检测方法研究, ,8,故障检测; 社交网络; 统计学习; 二分类;,"我们周围充满了各种网络;按照相似的内在机理,可以将它们分为物理网络和信息网络。对于具有明显物理特征的网络,我们可以运用物理常识解释其内部结构或节点的性质;而对于信息网络,我们往往需要结合一些先验知识去理解,社交网络正是这样一个例子。然而,对于那些并非具有显著物理或社交背景的网络,以往并没有明确的分析思路和方法。该文将尝试运用类似于分析社交网络的方法去分析电信CSB业务系统服务器集群上的进程网络;具体地预测进程网络中节点的崩溃(故障)状态。在这个特定的进程网络上,这种建模和分析思路得到了较为可信的结果;研究表明,进程节点的运行信息(如CPU和内存使用率)、进程间的通信情况以及进程节点在整个网络中的结构特征对于判断该节点的状态具有一定的指导价值,而上述特征在时间维度上的变化量同样反映了进程/端口的状态。 ",MESS201808013
面向复杂有权网络的社区发现方法研究,"谭红叶1:08402552|吴永科1:38513594|张虎1:08403299|刘全明1:09165839|李茹1,2:08453268",9,复杂网络; 社区发现; 有权网络;,"复杂网络中节点之间的连接强度会在很大程度上影响网络的社区结构,利用权重来刻画连接强度的差异性,并将其应用到社区发现研究中具有重要的意义。针对目前有权网络的社区发现方法存在的不足,该文结合节点的直接连边权重和基于共同邻居节点的连边权重,提出了一种改进的节点相关度度量准则。进一步基于这种改进的节点相关度度量准则和团体之间的聚集方法,构建了面向有权网络的社区发现模型。分别在有权值的科学家合作网络和全国列车网络数据集上进行了社区发现实验,结果表明了方法的有效性。 ",MESS201808014
传播源估计中有效观察点部署策略研究,"刘栋1,2:07254220|赵婧1:40032972|聂豪1:40032973",9,复杂网络; 传播源; 观察点;,"谣言或疾病的扩散均可模拟为传播源在网络中的传播,如何在网络中估计传播源位置是一项具有挑战性的任务。该任务往往根据部分观察点推断传播源的位置,故如何有效的选择观察点对准确定位传播源位置至关重要。该文分析了随机、度、聚类系数、特征向量、紧密度以及介数等观察点部署策略对传染源估计的影响。在实验中,采用SI传播模型和反向贪心算法估计传播源在三类合成网络和四个真实网络进行模拟仿真,实验结果表明采用特征向量的观察点部署策略更有利于提高传播源估计的精度。 ",MESS201808015
基于协同过滤Attention机制的情感分析模型,"赵冬梅1,2:37684273|李雅2:24080928|陶建华2:11607992|顾明亮1:27773998",7,情感分析; 协同过滤; LSTM; 注意力机制; SVD;,"该文主要研究在评论性数据中用户个性及产品信息对数据情感类别的影响。在影响数据情感类型的众多因素中,该文认为评价的主体即用户以及被评价的对象等信息对评论数据的情感至关重要。该文提出一种基于协同过滤Attention机制的情感分析方法(LSTM-CFA),使用协同过滤(CF)算法计算出用户兴趣分布矩阵,再将矩阵利用SVD分解后加入层次LSTM模型,作为模型注意力机制提取文档特征、实现情感分类。实验表明LSTMCFA方法能够高效提取用户个性与产品属性信息,显著提升了情感分类的准确率。 ",MESS201808016
面向商品评论的二元情感认知模型,陈放:31037364|王颗:40031760|梁爽:28085254|黄永峰:08227625,8,情感认知; 情感常识; 评价体系;,"该文提出了一种面向商品评论的二元情感认知模型。该模型由""二元情感常识库""、""评价体系知识库""和""情感分析引擎""三个主要模块组成。其特点体现为:(1)模型通过大规模评论文本学习领域先验知识,将其存储在知识库中,便于知识的修正和重用,体现了模型的认知能力;(2)模型不仅能够挖掘评论文本中出现的显式评价观点,还能借助领域知识进行情感推断,发现更高层次的用户情感。该文给出了构建""二元情感常识库""和""评价体系知识库""的相关算法,并介绍了""情感分析引擎""在观点挖掘和情感推断中的应用。在商品评论语料集上的实验验证了该模型的有效性。 ",MESS201808017
国家哲学社会科学成果文库,,1, ,"<正>书名:汉语核心词的历史与现状研究书号:978-7-100-15955-5作者:汪维辉著定价:298.00元开本:16开出版时间:2018年3月内容介绍:本书通过广泛调查历史文献和现代汉语方言资料,理清汉语100个核心词的历史演变线索及方言分布情况,为读者提供有关每个词的详细资料,并在充分占有材料、详尽准确描写的基础上,探讨核心词历时演变的客观规律。全书分为上、下两编。上编""总论"",概述汉语核心词研究的相 ",MESS201808018
基于门控卷积机制与层次注意力机制的多语义词向量计算方法,柳杨:39323283|吉立新:21514050|黄瑞阳:32951678|朱宇航:21554964|李星:29413083,11,多语义词向量; 层次注意力; 门控卷积;,"现有的将词映射为单一向量的方法没有考虑词的多义性,从而会引发歧义问题;映射为多个向量或高斯分布的方法虽然考虑了词的多义性,但或多或少没能有效利用词序、句法结构和词间距离等信息对词在某一固定语境中语义表达的影响。综合考虑以上存在的问题,该文提出了一种基于非残差块封装的门控卷积机制加以层次注意力机制的方法,分别在所选取语境窗口中词的子语义层、合成语义层获得非对称语境窗口下目标单词的合成语义向量以预测目标单词,并按此法在给定语料上学习得到多语义词向量的计算方法。小规模语料上用该方法得到的多语义词向量,在词类比任务的语义类比上相比于基线方法准确率最高可提升1.42%;在WordSim353、MC、RG、RW等计算单词相似度任务的数据集上相比于基线方法能够达到平均2.11的性能提升,最高可到5.47。在语言建模实验上,该方法的语言模型性能相比于其他预测目标单词的方法也有显著提升。 ",MESS201807001
基于CNN与双向LSTM的中文文本蕴含识别方法,谭咏梅1:06426460|刘姝雯1:38581365|吕学强2:10724564,9,中文文本蕴含; 卷积神经网络; 双向长短时记忆网络;,"为了避免基于传统机器学习的中文文本蕴含识别方法需要人工筛选大量特征以及使用多种自然语言处理工具造成的错误累计问题,该文提出了基于CNN与双向LSTM的中文文本蕴含识别方法。该方法使用CNN与双向LSTM分别对句子进行编码,自动提取相关特征,然后使用全连接层进行分类得到初步的识别结果,最后使用语义规则对网络识别结果进行修正,得到最终的蕴含识别结果。在2014年RITE-VAL评测任务的数据集上MacroF1结果为61.74%,超过评测第一名的结果61.51%。实验结果表明,该方法对于中文文本蕴含识别是有效的。 ",MESS201807002
中文笑话语料库的构建与应用,任璐1:39770370|杨亮1:14244075|徐琳宏2:29378611|樊小超1:39770371|刁宇峰1:25202941|林鸿飞1:06504899,10,人工智能; 中文笑话语料库; 语料标注; 笑话识别;,"笑话作为国家级非物质文化遗产,历史悠久,普遍存在于人们的日常生活中,是最贴近人们生活的艺术体裁之一,笑话的理解也是人工智能发展需要攻克的难题之一。该文构建的大规模中文笑话语料库为人工智能以及语言学研究提供了有利的资源支撑。该文首先归纳总结笑话语料库所依据的笑话相关理论基础,然后对语料库构建中语料标注、语料分析等工作做了详细的介绍,最后在语料库的基础上,分别将笑话与故事、微博、歇后语/谚语以及新闻四种体裁分别做了识别工作,验证了笑话简洁、具有一定的情节、富含情感等特征。同时通过与等长的负例构成的数据集进行笑话识别,验证了所提出特征的有效性。 ",MESS201807003
基于数据增强技术的神经机器翻译,蔡子龙:39251478|杨明明:39770372|熊德意:32622753,7,神经机器翻译; 数据增强技术; 泛化;,"神经机器翻译是目前机器翻译领域最热门的研究方法。和统计机器翻译相比,神经机器翻译在语料丰富的语种上可以取得非常好的结果,但是在资源比较稀缺的语种上表现一般。该文利用数据增强技术对资源贫乏语种的训练数据进行扩充,以此增强神经机器翻译的泛化能力。该文在藏汉、汉英两种语言对上进行了实验,当训练数据规模只有10万平行句对时,相较于基准系统,在两种语言对上均获得了4个BLEU值的提高。实验表明,数据增强技术可以有效地解决神经机器翻译因为训练数据太少而导致的泛化能力不足问题。 ",MESS201807004
基于数据并行的神经语言模型多卡训练分析,李垠桥:39770373|阿敏巴雅尔:39770374|肖桐:11698781|薄乐:39770375|朱靖波:06569435|张俐:06574957,7,数据并行; 神经语言模型; All-Reduce; 采样;,"数据并行训练神经语言模型,旨在不改变网络结构的同时,大幅度降低训练所带来的时间消耗。但由于多设备之间频繁的数据传输,使得整体加速效果并不理想。该文通过实验对比All-Reduce算法和基于采样的梯度更新策略在数据传输上的加速效果,使用了四块NVIDIA TITAN X(Pascal)GPU设备在循环神经语言模型上进行训练,两种方法分别可获得约25%和41%的速度提升。同时,该文还针对数据并行方法的适用性以及不同的硬件设备连接方式对传输速度的影响进行了讨论。 ",MESS201807005
蒙古文信息检索系统的设计与实现,温子潇:39770376|包飞龙:39770377|高光来:05981929|王勇和:39770378|苏向东:26374024,9,蒙古文; 网络爬虫; 信息检索系统;,"该文针对传统蒙古文与西里尔蒙古文设计开发了一个功能完备的信息检索系统。在网页抓取方面,采用MD5算法对爬虫进行了改进,提升了爬虫的速度。在预处理阶段,对蒙古文文档进行了编码转换、词缀切分转换等操作。在检索方面,使用向量空间模型实现了对蒙古文文档的检索。在该文系统中加入了西里尔蒙古文到传统蒙古文转换和更新统计等模块,最终搭建了一个可以达到应用要求的蒙古文信息检索系统。 ",MESS201807006
哈萨克语元音格局研究,"达吾勒·阿布都哈依尔1,2:23837636|努尔麦麦提·尤鲁瓦斯1,2:28479964|刘艳1:10239944",6,哈萨克语; 多音节词; 共振峰; 元音格局;,"由于哈萨克语构词法的特点,九个元音的声频特性在语音识别中具有重要的作用。该文采用实验语音学的基本理论和方法,研究了哈萨克语多音节词中的元音格局。针对从语音库中挑选的1 062个多音节词,分别对其词首、词腹和词尾音节中的元音共振峰频率值进行统计,并采用Joos方法详细地归纳和分析了哈萨克语词首、词腹和词尾音节元音格局以及存在的差异,绘制出了哈萨克语多音节词元音的共振峰模式。该项研究结果对哈萨克语的语音研究及应用具有较高的参考价值。 ",MESS201807007
藏语同形异音词的消歧方法研究,"拉巴顿珠1:30407992|欧珠1,2:11626402|祖漪清3:27645304|裴春宝1:21621296",9,藏语; 同形异音词; 读音消歧;,"随着藏语语音合成研究的深入,藏语同形异音词的读音问题成为影响合成系统自然度和可懂度的主要障碍。藏语同形异音词与汉语中多音词的性质有所不同,仅仅依靠词典不一定能解决问题。该文从藏语本身独有的语言规则和语音特点出发,依据《藏汉大词典》,在其所列出的常用藏语同形异音词的基础上,共收集整理了465个同形异音词,然后从372 320个句子文本中统计出了同形异音词在藏语文本中的出现频率及不同读音的使用频率,并深度辨析了藏语同形异音词的构词形式、分类以及在具体文本中出现的形式,最后结合实例提出了具体的消歧方法及实验结果,为语音合成系统的前端文本分析模块提供了有力依据。 ",MESS201807008
基于卷积降噪自编码器的藏文历史文献版面分析方法,"张西群1,2:38156146|马龙龙3:27055084|段立娟1,4:06297341|刘泽宇3:33315192|吴健3:09573880",8,藏文历史文献; 版面分析; 卷积降噪自编码器; 超像素;,"近年来,随着人们对历史和传统文化的保护和传承越来越重视,研究人员对历史文献数字化的兴趣也越来越高涨。版面分析是历史文献数字化的重要基础步骤,该文提出了一种基于卷积降噪自编码器的藏文历史文献版面分析方法。首先,将藏文历史文献图像进行超像素聚类获得超像素块;然后,利用卷积降噪自编码器提取超像素块的特征;最后,使用SVM分类器对藏文历史文献的超像素块进行分类预测,从而提取出藏文历史文献版面的各个部分。在藏文历史文献数据集上的实验表明,该方法能够对藏文历史文献的不同版面元素进行有效的分离。 ",MESS201807009
文本摘要的建构渗透度特征模型,"任立园1,2:39770379|谢振平1,2:07770504|刘渊1,2:07780067",8,文本摘要; 文句关键词; 知识网络; 渗透度;,"旨在实现从海量的文本数据中快速准确地获取关键信息。为探索新颖的摘要句特征因素,该文将文句中的关键词嵌入知识网络进行建模,并将文句映射至知识网络进行表达,进而提出文句的关键词建构渗透度特征模型,在摘要句判别中引入文句中关键词组的宽度和深度的渗透特性。结合最大熵建模分类方法,针对领域语料库进行不同特征的影响系数建模,实现了监督学习下摘要句的有效分类和自动提取。文中实验结果良好,表明了新特征模型的有效性和在领域语料库中的稳定性,且特征计算方法简洁,具有良好的综合实用性。 ",MESS201807010
生物医学文献中的蛋白质关系抽取研究,赵哲焕1:27030919|杨志豪2:06523490|孙聪2:38375636|林鸿飞2:06504899,9,关系词抽取; 蛋白质实体识别; 蛋白质关系抽取;,"蛋白质关系抽取研究对于生命科学各领域的研究具有广泛的应用价值。但是,基于机器学习的蛋白质关系抽取方法普遍停留在二元关系抽取,失去了丰富的关系类型信息,而基于规则的开放式信息抽取方法可以抽取完整的蛋白质关系(""蛋白质1,关系词,蛋白质2""),但是召回率较低。针对以上问题,该文提出了一种混合机器学习和规则方法的蛋白质关系抽取框架。该框架先利用机器学习方法完成命名实体识别和二元关系抽取,然后利用基于句法模板和词典匹配的方法抽取表示当前两个蛋白质间关系类型的关系词。该方法在AImed语料上取得了40.18%的F值,远高于基于规则的Stanford Open IE方法。 ",MESS201807011
融合K均值聚类和低秩约束的属性选择算法,杨常清:33020413,8,属性选择; 自表达方法; K均值聚类; 低秩约束; 稀疏学习;,"针对无监督属性选择算法无类别信息和未考虑属性低秩等问题,该文提出了一种融合K均值聚类和低秩约束的属性选择算法。算法在线性回归的模型框架中有效地嵌入自表达方法,同时利用K均值聚类产生伪类标签最大化类间距以更好地稀疏结构,并使用l2,p-范数代替传统的l2,1-范数,通过参数p来灵活调节结果的稀疏性,最后证明了该文算法具有执行线性判别分析的特点和收敛性。经实验验证,该文提出的属性算法与NFS算法、LDA算法、RFS算法、RSR算法相比分类准确率平均提高了17.04%、13.95%、3.6%和9.39%,分类准确率方差也是最小的,分类结果稳定。 ",MESS201807012
基于DQN的开放域多轮对话策略学习,宋皓宇:38732266|张伟男:23769189|刘挺:06994824,11,多轮对话; 对话策略; 强化学习;,"有效地进行多轮对话是开放域人机对话系统的主要目标之一。目前的神经网络对话生成模型在开放域多轮对话过程中存在着容易产生万能回复、很快陷入死循环的问题;而已有的多轮对话研究工作存在着没有考虑未来对话走向的问题。借鉴强化学习方法考虑全局的视角,该文利用深度强化学习算法DQN(deep Q-network),提出了使用深度价值网络对每一轮的候选句子进行评估,并选择未来收益最大的而非生成概率最大的句子作为回复的多轮对话策略学习方法。实验结果表明,该文提出的方法将多轮对话的平均对话轮数提高了两轮,同时在主观对比评价指标上获胜比例高出了45%。 ",MESS201807013
面向领域的高质量微博用户发现,"叶永君1,2:39770380|李鹏1,2:33053080|周美林1,2:39770382|万仪方1,2:39770384|王斌1,2:33053079",7,用户质量测量; 用户行为模型; 图排序算法;,"在微博系统中,寻找高质量微博用户进行关注是获取高质量信息的前提。该文研究高质量微博用户发现问题,即给定领域词查询,系统根据用户质量返回相关用户排序列表。将该问题分解成两个子问题:一是领域相关用户的检索问题,二是微博用户排序问题。针对用户检索问题,提出了基于用户标签的用户表示方法以及基于维基百科的查询—用户相似度匹配方法,该方法作为ESA(explicit semantic analysis)的一个扩展应用,结果具有良好的可解释性,实验表明基于维基百科的效果要优于基于其他资源的检索效果。针对用户排序问题,提出了基于图的迭代排序方法 UBRank,在计算用户质量时同时考虑用户发布消息的数量和消息的权威度,并且只选择含URL的消息来构建图,实验验证了该方法的高效性和优越性。 ",MESS201807014
在线技术社区的用户技能与兴趣发现,张东雷:39257860|林友芳:06327199|万怀宇:11653168|马语丹:39770386|陆金梁:39770387,12,在线技术社区; 用户画像; 用户技能; 用户兴趣;,"在线技术社区是技术爱好者或者从业者进行技术交流、咨询和分享的重要平台。社区运营者如果能够准确掌握每个用户的技能和兴趣,对用户进行画像,将有助于为用户提供精准的推荐和个性化服务,从而增加用户的黏性和社区的活跃度。考虑到社区用户既是内容的生产者(作者)又是内容的消费者(读者),生产者体现用户技能,消费者体现用户兴趣,从而提出了一种作者—读者—话题(author-reader-topic,ART)模型,同时对用户的技能和兴趣进行建模。该模型可以将文档的作者和读者关联起来,因而能够提升话题的聚集效果,产生更准确的作者话题分布和读者话题分布。该文基于CSDN技术社区的真实数据集进行了实验对比和分析,实验结果表明,该文提出的ART模型能够有效地发现用户的技能和兴趣,明显优于现有的各种话题模型。 ",MESS201807015
小说人物性格的文学智能分析:以《平凡的世界》为例,"吴育锋1,2,3:39770388|吴胜涛1,2:17603149|朱廷劭1:28661610|刘洪飞4:39770390|焦冬冬1:39770391",9,小说人物人格; 中文心理分析系统; 平凡的世界;,"以往小说人物心理分析主要是对人物性格的定性分析,易受研究者个人主观经验影响;而相比于描述繁杂的性格而言,更加稳定系统的人格能够更好地描述并传达小说人物心理。该文采用基于数据挖掘的文学智能分析方法,通过中文心理分析系统对《平凡的世界》人物对话进行处理,得到人物的大五人格预测分数;进而,考察文艺学文献、小说剧情对预测分数的验证情况,以确定这种方法的有效性。结果表明:年轻的孙少平和田晓霞开放性相对较强,而年长的孙少安和田润叶外向性较强;此外,孙少平和田润叶尽责性较强,孙少安和田晓霞宜人性较好,孙少安和孙少平情绪性较高。上述预测结果得到文献、剧情的支持,这说明文学智能分析小说人物人格是有效的,它为小说人物心理分析开辟出一条客观、体系化且智能化的道路。 ",MESS201807016
面向拓片信息的甲骨字网络构建与分析,"焦清局1,2,3:39433152|高峰1,2:06215330|金园园1:39770392|熊晶1,2:26043813|刘永革1,2,3:06230719",6,甲骨字; 拓片; 复杂网络; 构建; 分析;,"未识甲骨字的考释是甲骨文研究最重要的内容,也是历史学家和计算机学家研究甲骨文遇到的最大瓶颈。甲骨文研究积累的数据已体现出海量化和系统化。因此,该文以甲骨文拓片为基础数据,通过建模定义甲骨字之间的距离,进而构建甲骨字网络。在此网络之上,分析网络的度分布、局部连接比率、聚类系数、模块度等相关特性。结果表明:构建的甲骨字网络不仅能充分反映甲骨文系统的单音节词多和复音节词少的古文字特征,而且能捕捉甲骨文拓片的语义单元,并具有很强的模块特性。该文构建的网络及其特性可为历史学家和网络甲骨学家揭示未知甲骨字的语义提供新的数据和理论基础。 ",MESS201807017
国家社科基金后期资助项目成果,,1, ,"<正>书名:汉语否定表达的认知研究和逻辑分析书号:978-7-100-15769-8作者:袁毓林著定价:62.00元开本:16开出版时间:2018年3月内容介绍:本书从认知和功能语言学的角度,对汉语几种主要的否定表达的句法、语义和语用特点进行描写;着重用逻辑语义学的方法,分析显性否定表达和隐性否定表达的语义结构特点。还构建了语言使用者在获取复杂的否定表达的语义解释时,可能采用的自上而下的概率性的处理策略,从而展示了一种基于语言运用的汉语语法的研究范式。 ",MESS201807018
结合短语结构句法的语义角色标注,杨凤玲:38968030|周俏丽:25068859|蔡东风:24679274|季铎:25068860,11,语义角色标注; 短语结构句法分析; 剪枝; 子句抽取; 边界修正;,"该文提出一种结合短语结构句法的语义角色标注方法。结合短语结构句法对句子进行剪枝、子句抽取处理,然后,对处理过的句子进行语义角色分析并还原。最后,结合短语树对还原后的论元边界进行修正。其中,剪枝包括并列结构、插入语的剪枝,子句抽取针对不同形式的子句有不同的处理方式。边界修正主要是针对某些类型论元进行修正。该文分别在CoNLL2004与CoNLL2005评测语料中做了实验,在CoNLL2005Shared Task的test_wsj数据集上F值为88.25%,在CoNLL2004Shared Task的test数据集上F值为85.66%。实验结果表明,引入短语结构句法能有效地提升语义角色的识别效果。 ",MESS201806001
基于汉语国际教育教材语料的三音节名词型动态词分析,郭冬冬:38128587|宋继华:06364557|彭炜明:24186788|张引兵:39414490,7,动态词; 三音节名词; 结构模式; 国际汉语教学;,"国际汉语教学领域中存在大量的动态词。深入细致地研究分析国际汉语教材语料中真实出现的动态词,一方面有助于国际汉语教学的词汇研究与词汇教学;另一方面,对面向国际汉语教学的信息处理工作具有重要的促进作用。三音节名词是国际汉语教学中一种常见的词汇类型,在词汇教学中占有重要的位置,而其中三音节名词型动态词又占有较高的比重。该文首先介绍三音节名词型动态词结构模式的一种知识表示方法;然后通过标注一定规模的国际汉语教材语料,获取三音节名词型动态词的所有结构模式类型以及对应的动态词及词频信息,构建基于国际汉语教学的三音节名词型动态词结构模式知识库;最后在结构模式知识库的基础上对三音节名词型动态词进行分析。 ",MESS201806002
基于LSTM和N-gram的ESL文章的语法错误自动纠正方法,谭咏梅:06426460|杨一枭:35946792|杨林:25236358|刘姝雯:38581365,9,语法错误自动纠正; LSTM; N-gram投票策略; ESL语料;,"针对英语文章语法错误自动纠正(Grammatical Error Correction,GEC)问题中的冠词和介词错误,该文提出一种基于LSTM(Long Short-Term Memory,长短时记忆)的序列标注GEC方法;针对名词单复数错误、动词形式错误和主谓不一致错误,因其混淆集为开放集合,该文提出一种基于ESL(English as Second Lauguage)和新闻语料的N-gram投票策略的GEC方法。该文方法在2013年CoNLL的GEC数据上实验的整体F1值为33.87%,超过第一名UIUC的F1值31.20%。其中,冠词错误纠正的F1值为38.05%,超过UIUC冠词错误纠正的F1值33.40%,介词错误的纠正F1为28.89%,超过UIUC的介词错误纠正F1值7.22%。 ",MESS201806003
面向高考语文阅读理解的篇章标题选择研究,"关勇1:38479087|吕国英1:08401954|李茹1,2,3:08453268|郭少茹1:37313493|谭红叶1:08402552",9,高考语文; 阅读理解; 标题选择; 神经网络; 标题结构; 相关度矩阵;,"高考语文阅读理解篇章标题选择题要求机器根据对篇章内容的理解,从多个候选项中选取能够准确恰当的概括表达篇章内容的选项。标题往往是高度凝练且能准确表达文意、结构鲜明的词串。因此,如何对篇章内容进行归纳概括、对标题结构进行梳理和分析是解答篇章标题选择题的关键。针对该问题,提出了标题与篇章要点相关性分析模型。该模型通过分析标题与篇章要点的相关性,构建了基于标题和篇章要点的相关度矩阵。在此基础上融入标题结构特征,选取与篇章最相关的标题。在全国近10年高考真题和测试题上进行实验,验证了该方法的有效性。 ",MESS201806004
融合先验信息的蒙汉神经网络机器翻译模型,樊文婷:37906619|侯宏旭:08012191|王洪彬:37906618|武静:37906617|李金廷:37906616,8,重现神经网络; 未登录词; 词向量; 词性标注;,"神经网络机器翻译模型在蒙古文到汉文的翻译任务上取得了很好的效果。神经网络翻译模型仅利用双语语料获得词向量,而有限的双语语料规模却限制了词向量的表示。该文将先验信息融合到神经网络机器翻译中,首先将大规模单语语料训练得到的词向量作为翻译模型的初始词向量,同时在词向量中加入词性特征,从而缓解单词的语法歧义问题。其次,为了降低翻译模型解码器的计算复杂度以及模型的训练时间,通常会限制目标词典大小,这导致大量未登录词的出现。该文利用加入词性特征的词向量计算单词之间的相似度,将未登录词用目标词典中与之最相近的单词替换,以缓解未登录词问题。最终实验显示在蒙古文到汉文的翻译任务上将译文的BLEU值提高了2.68个BLEU点。 ",MESS201806005
基于统计的蒙汉机器翻译中词对齐方法研究,苏依拉:07987316|赵亚平:39185558|牛向华:39185557,8,词对齐; IBM模型; 词干词缀切分; 对数线性模型;,"蒙古语属于小语种,蒙古语到汉语机器翻译相关研究进展缓慢。所以,实现高质量的蒙汉机器翻译对我国少数民族地区信息化发展有着重要意义。其中,词语对齐对机器翻译质量起着至关重要的作用。该文提出了一种基于蒙古语切分的词干词缀为基本单位的蒙汉机器翻译词对齐方法。该方法利用词干词缀表和逆向最大匹配算法来实现蒙古语句子词干词缀的切分。实验结果表明对蒙古语进行词干词缀的切分能够显著提高对数线性词对齐模型的对齐质量。 ",MESS201806006
基于DCNNs-LSTM模型的维吾尔语突发事件识别研究,黎红1:38802617|禹龙2:09256058|田生伟1:09220503|吐尔根·依布拉音3:17705003|赵建国4:09252968,10,维吾尔语; 突发事件识别; 深度卷积神经网络; 长短期记忆网络; word embedding;,"结合对维吾尔语语言的特点分析,该文提出一种基于深度卷积神经网络(deep convolutional neural networks,DCNNs)联合长短期记忆网络(long-short term memory,LSTM)实现的维吾尔语文本突发事件识别方法。该方法提取突发事件包含六大特征块,并在特征集中引入富含词汇语义及上下文位置关系的Word Embedding,利用DCNNs对黏着性语言特征抽象化的学习能力抽取事件句中的高阶局部特征,以此作为LSTM网络的输入,利用其对于事件句中抽象含义序列关系的捕获特性获取全局特征,训练Softmax分类器完成维吾尔语突发事件的识别任务。该方法在维吾尔语突发事件识别中的准确率达到80.60%,召回率81.39%,F值80.99%。实验结果表明,与不同层数的DCNNs和独立的LSTM网络相比,DCNNs-LSTM模型更具备挖掘隐含上下文深层语义信息的能力,对Word Embedding特征项的引入有效地提高了模型识别性能。 ",MESS201806007
基于卷积神经网络的缅甸语分词方法,林颂凯:39585845|毛存礼:23238123|余正涛:05982358|郭剑毅:07895859|王红斌:21967787|张家富:39585846,10,分词; 缅甸语; 卷积神经网络; 巴克斯范式; 词向量;,"音节是缅甸语的最小构词单位。当前主流的基于统计的分词方法效果严重依赖于预先标注的训练样本集规模及人工方式选取特征的质量,然而,缅甸语属于稀缺资源语言,分词语料标注及特征选取面临较大困难。该文提出一种基于卷积神经网络的缅甸语分词方法,首先将缅甸语音节结构特征应用于缅甸语音节词向量特征分布式表示,然后基于卷积神经网络将音节及其上下文的特征进行融合,得到有效的特征表示,并通过深层网络的逐层特征优化自动学习到缅甸语分词的有效特征向量,最后利用softmax分类器来对构成缅甸语词汇的音节序列标记进行预测。实验结果表明,该方法取得了较好的效果。 ",MESS201806008
TP-AS:一种面向长文本的两阶段自动摘要方法,"王帅1:20241698|赵翔1,2:21059127|李博1:20652010|葛斌1,2:20267773|汤大权1,2:21019819",9,自动文本摘要; 自然语言处理; 抽取和生成; 循环神经网络;,"随着互联网上信息的爆炸式增长,如何有效提高知识获取效率变得尤为重要。文本自动摘要技术通过对信息的压缩和精炼,为知识的快速获取提供了很好的辅助手段。现有的文本自动摘要方法在处理长文本的过程中,存在准确率低的问题,无法达到令用户满意的性能效果。为此,该文提出一种新的两阶段的长文本自动摘要方法TP-AS,首先利用基于图模型的混合文本相似度计算方法进行关键句抽取,然后结合指针机制和注意力机制构建一种基于循环神经网络的编码器—解码器模型进行摘要生成。通过基于真实大规模金融领域长文本数据上的实验,验证了TP-AS方法的有效性,其自动摘要的准确性在ROUGE-1的指标下分别达到了36.6%(词)和33.9%(字符),明显优于现有其他方法。 ",MESS201806009
基于语义和句法依存特征的评论对象抽取研究,张志远:11071691|赵越:37280449,9,评价对象抽取; 条件随机场; 语义特征; 句法依存关系;,"评论对象抽取是情感分析的重要研究内容。基于语义词典,从评论对象的类别视角出发,运用语义相似度和相关度计算方法,该文提出用于评价对象抽取的七种新的语义特征。评价对象和评价词之间通常存在句法依存关系,并且评价词往往带有情感倾向,将句法依存分析和评价词识别结合,提出句法情感依存特征抽取方法,忽略无情感词和微情感词的句法依存关系,提高评价对象抽取的准确率。使用条件随机场模型,在SEMEVAL比赛的三个领域数据集上进行实验,新的语义特征和句法情感依存特征组合的F1分数比SEMEVAL比赛限制性系统最好成绩平均高3.78%,比非限制性系统最好成绩平均高2%,证明了所提特征的有效性。 ",MESS201806010
面向作文自动评分的优美句识别,"付瑞吉1,2:38228123|王栋1,2:39440125|王士进1,2:30628699|胡国平1,2:27814665|刘挺2,3:38228126",10,优美句识别; 深度神经网络; 作文自动评分;,"语言优美是学生写作能力中重要的一部分。该文提出一个面向作文自动评分的作文优美句识别任务,主要识别中学生中文作文中的优美句。相比传统文本分类任务,优美句识别更加难以用特征工程的方式解决。因此,该文提出一种基于卷积神经网络(CNN)和双向长短时记忆(BiLSTM)网络的混合神经网络结构进行优美句识别,并和CNN、BiLSTM网络进行了对比。实验证明,混合神经网络的准确率最高,达到89.23%,F1值与BiLSTM相当,达到75.39%。此外,该文将优美句子特征用于作文自动评分任务,可使计算机评分和人工评分的大分差比例下降21.41%。 ",MESS201806011
面向事件抽取的深度与主动联合学习方法,邱盈盈:37866727|洪宇:25038035|周文瑄:37885115|姚建民:13898051|朱巧明:09891804,9,事件抽取; 深度学习; 主动学习; 循环神经网络;,"事件抽取旨在从非结构化的文本中抽取出事件的信息,并以结构化的形式予以呈现。监督学习作为基础的事件抽取方法往往受制于训练语料规模小、类别分布不平衡和质量参差不齐的问题。同时,传统基于特征工程的事件抽取方法往往会产生错误传递的问题,且特征工程较为复杂。为此,该文提出了一种联合深度学习和主动学习的事件抽取方法。该方法将RNN模型对触发词分类的置信度融入在主动学习的查询函数中,以此在主动学习过程中提高语料标注效率,进而提高实验的最终性能。实验结果显示,这一联合学习方法能够辅助事件抽取性能的提升,但也显示,联合模式仍有较高的提升空间,有待进一步思考和探索。 ",MESS201806012
基于马尔科夫随机场的微博用户转发行为预测,王宁1:25872154|高光2:31687729|柴争义1:35198912,7,新浪微博; 转发预测; 能量优化; 逻辑回归;,"微博用户转发行为预测是微博社交网络消息扩散模型构建的基础,在图书阅读推广、舆情监控与市场营销等领域有着广泛的应用。为了提高用户转发行为预测的精度,该文在马尔科夫随机场框架下综合分析了用户属性与微博内容特征、用户转发行为约束等因素对用户转发行为的影响,并在逻辑回归模型的基础上构造了相应的能量函数对用户转发行为进行了全局性的预测。实验结果表明,微博用户转发行为不仅取决于用户属性、微博内容等特征,而且也受到与其相邻用户转发行为的约束。相对于传统算法该文算法可以更准确地对用户转发行为进行建模,因而可获得更好的预测结果。 ",MESS201806013
移动社交网络幂律分布特征及亲属关系判别,"张树森1:36626078|魏玉党1,2:39585848|梁循1:25202919|窦勇2:20514904|许媛1:35806261|梁天新1:29120811",10,社交网络; 幂律分布; 亲属关系;,"社交网络特征和用户关系是社交网络分析研究的重要内容。该文对移动社交网络中存在的幂律分布及用户亲属关系判别问题进行研究。在幂律分布的研究中,该文在度、连通子图规模及用户联系人数量的分布中找出存在的三个幂律分布,同时分析其中规律和结论,并与其他社交网络进行对比。在该文亲属关系判别研究中,通过提取用户通话行为的多种显著特征,采用GBDT(gradient boost decision tree)与LR(logistic regression)融合方法,提出一种用户亲属关系判别模型,并通过实验验证该模型能有效判别出用户间是否存在亲属关系,判别精确率达到81.01%。 ",MESS201806014
基于部首和音位的情感词汇表示模型,徐琳宏1:29378611|林鸿飞2:06504899|祁瑞华1:32639745|关菁华1:33955380,8,部首; 音位; 神经网络;,"文本情感分析是自然语言处理的热点问题之一,而词汇是情感分析的基础。汉字通过声音和形状表达意义,该文综合考虑词汇中每个字的部首和音位等信息,构建了一个情感词汇分类模型。在模型中,将词汇的字、部首和音位三种信息向量化,与原始词汇向量融合,生成新的情感词汇表示,最后采用前馈神经网络和卷积神经网络对情感词汇的极性进行分类。实验结果表明,三种细粒度特征都能有效地提高情感词汇的分类效果,并且该文在COAE评测的语料上验证了模型的有效性。 ",MESS201806015
基于语料库的古代汉语教材预期成效评估方法及应用,"邱冰1,2:22214348|皇甫伟2,3:29575869|朱庆之2:39585852",11,古代汉语; 词汇知识点; 语料库; 成效导向教学; 教材成效计算;,"古代汉语是中国语言文学专业的核心课程,然而现有教材编写在篇章选择、内容编排和知识点取舍上多基于主观经验,教学成效难以量化评估。该文基于先秦典型文献的词汇现象的频率、重要程度以及古今词义的差异,讨论了面向古代汉语教学的词汇知识点语料库的建设,提出了古代汉语教材词汇教学预期成效的计算方法,并以王力主编《古代汉语》和王硕编著《汉语古文读本》两种性质不同、文选编排顺序不同的教材作为个案,对比分析了两部教材的篇幅、知识点分布和学习曲线,从量化数据上佐证了学界对两种不同性质教材的定性认识,同时也证明所提出的教材预期成效评估方法的合理性。进一步讨论了文选的重新排序,获得了更加符合循序渐进教学过程的学习曲线。基于语料库的古代汉语教材预期成效评估方法不仅为教材评估提供了量化方法,也为成效导向教学在古代汉语课程的应用提供了探索性的思路和基础数据。 ",MESS201806016
中国语言文化典藏,,1, ,"<正>记录方言透视文化传承历史珍藏经典主编:曹志耘开本:16开定价:168.00元/卷《中国语言文化典藏》(澳门、潮州、杭州、衡山、怀集、怀集(标话)、江山、金华、井陉、连城、泸溪、清徐、寿县、苏州、濉溪、遂昌、藤县、屯溪、宜春、永丰)""中国语言文化典藏""丛书是教育部哲学社会科学研究重大课题攻关项目""中国方言文化典藏""的成果形式之一。主编是北京语言大学副校长曹志耘教授,副主编是王莉宁、刘晓海博士。所 ",MESS201806017
热烈祝贺倪光南院士获得全国“最美科技工作者”称号,,1, ,"<正>2018年6月14日,新闻联播报道由中宣部、科技部和中国科协联合主办的""最美科技工作者""评选结果揭晓,评选出张弥曼、多吉、倪光南、严纯华、邹学校、李贺军、李兴钢、蔚保国、秦川、王杜娟等10位先进典型,他们有的矢志不移自主创新,将核心技术牢牢掌握在自己手里;有的""板凳甘坐十年冷"",用科研成果赢得世界同行尊重;有的扎根基层一线,为扶贫攻坚和人民幸福付出毕生精力;有的投入社会公益,几十年如一日开 ",MESS201806018
中国中文信息学会网络空间大搜索专委会成立大会暨第一次全体委员会议在广州召开,,1, ,"<正>2018年6月19日,中国中文信息学会网络空间大搜索专委会成立大会暨第一次全体委员会议在广州白云国际会议中心顺利召开。会议应到委员46人,实到委员38人。中国中文信息学会理事长方滨兴院士,副理事长兼秘书长孙乐研究员,常务理事贾焰教授,美国伊利诺伊大学ACM/IEEE Fellow Philip S.Yu教授,京东集团副总裁裴健教授、华东师范大学林学民教授、复旦大学王晓阳教授和张彦春教授等出席,会议由 ",MESS201806019
中亚语言自然语言处理综述,"吐尔根·依布拉音1,2:17705003|卡哈尔江·阿比的热西提1,2:31758537|艾山·吾买尔1,2:10775068|买合木提·买买提1,2:22440290",14,土耳其语; 哈萨克语; 黏着语; 形态复杂语;,"该文对中亚地区属于同一个语族的土耳其语、哈萨克语等诸语言的自然语言处理现状进行了综述。首先分别回顾土耳其语、哈萨克语和其他中亚语言在词法分析、句法分析、命名实体识别、机器翻译方面的研究进展,随后讨论了与具体语言无关的黏着语词法分析方面的研究情况,最后指出国内外中亚诸语言处理自然语言领域中所面临的问题和挑战,并对未来的研究提出了建议。 ",MESS201805001
交互式问答的关系结构体系及标注,, , , ,MESS201805002
面向文本聚类的实体—动作关联模型研究,刘作国:34071691|陈笑蓉:06939837,9,文本表示模型; 实体—动作关联; 句型识别; 动作层次分解;,"该文提出面向文本聚类分析的实体—动作关联模型EARM,探讨汉语语义实体及其行为的描述方法。汉语属于非形态语言,语句没有时态及语态的变化,词类跟句法成分之间也不是简单的一一对应关系。该文提出一种句法成分识别机制,根据词汇类别特征及位置特征识别实体及动作。在句法成分识别的基础上展开句法分析,通过匹配句型特征建立实体—动作关联模型EARM,描述实体的行为及状态。对于嵌套句型等较为复杂的句型结构,需要在句法分析过程中实施动作层次分解,将复杂语句分解为简单的基本句型,以便于挖掘实体—动作关联。考虑到汉语语法比较灵活,语句成分缺省和倒装现象相对普遍,该文提出了倒装句的识别机制,通过匹配接近的句型进行实体移位,调整语序。论述了基于统计模型的EARM权重量化策略,借助语法树的最大公共子图量化文本的相似度并实施聚类,设计并开展了EARM实体—动作分析实验和EARM聚类实验。实验结果表明EARM的分析是准确有效的,聚类结果是合理的。 ",MESS201805003
短语结构树库向句式结构树库的自动转换研究,"张引兵1,2:39414490|宋继华1:06364557|彭炜明1:24186788|赵亚伟1:39414491|宋天宝1:37829928",11,转换方法; 树库; 短语结构; 句式结构;,"该文从短语结构和句式结构的区别与联系入手,设计了一种将短语结构自动转换为句式结构的算法。并以清华短语结构树库(TCT)为测试语料,实现了将大规模短语结构语料向句式结构语料的转换。最后,搭建了一套可扩展的可视化系统,用于不同句法结构语料的可视化查看。这一研究不仅实现了两种结构之间的初步转换,而且极大地丰富了汉语句本位图解树库的语料规模,并为汉语句本位图解树库的后续应用研究奠定了基础。 ",MESS201805004
基于CNN词根形态选择模型的改进蒙汉机器翻译研究,乌尼尔:36383307|苏依拉:07987316|刘婉婉:36383308|仁庆道尔吉:22393973,7,机器翻译; 蒙汉; CNN; 全局注意力; GRU;,"随着科学技术的发展,以循环神经网络为基础的机器翻译方法由于翻译质量更好而逐渐取代统计机器翻译方法,特别是在国际大语种之间的互译方面,RNN在对语料编码时能够提取更好的特征,这对翻译质量好坏至关重要。然而在蒙古语这类小语种的翻译方面,由于语料不足导致的数据稀疏和RNN模型训练梯度消失等问题,很难从语料中充分获取语义关系,因此该文提出一种基于卷积神经网络CNN(convolutional neural network)的蒙汉机器翻译方法,在对源语料编码时利用池化层获取语义关系,并根据蒙古语构词特点得到句子的语义信息,再通过融合全局注意力机制的GRU循环神经网络将编码过后的源语言解码为汉语。实验结果表明,该方法在翻译准确率和训练速度两方面均优于RNN基准机器翻译方法。 ",MESS201805005
基于循环神经网络的藏语语音识别声学模型,"黄晓辉1,2:09574191|李京1:09541748",7,循环神经网络; 藏语语音识别; 声学建模; 时域卷积;,"探索将循环神经网络和连接时序分类算法应用于藏语语音识别声学建模,实现端到端的模型训练。同时根据声学模型输入与输出的关系,通过在隐含层输出序列上引入时域卷积操作来对网络隐含层时域展开步数进行约简,从而有效提升模型的训练与解码效率。实验结果显示,与传统基于隐马尔可夫模型的声学建模方法相比,循环神经网络模型在藏语拉萨话音素识别任务上具有更好的识别性能,而引入时域卷积操作的循环神经网络声学模型在保持同等识别性能的情况下,拥有更高的训练和解码效率。 ",MESS201805006
基于栈式降噪自编码和词嵌入表示的维吾尔语零指代消解,秦越1:37906613|禹龙2:09256058|田生伟3:09220503|冯冠军4:09220102|吐尔根·依布拉音1:17705003|艾斯卡尔·艾木都拉1:17704444|赵建国4:09252968,9,维吾尔语; 零指代消解; 栈式降噪自编码; 词嵌入表示;,"针对维吾尔语零指代现象,提出采用栈式降噪自编码的深度学习机制进行维吾尔语零指代消解。首先由大规模无标注维吾尔语语料训练得到富含语义和句法信息的词嵌入表示,将其作为候选先行语和缺省零代词的语义特征;其次根据维吾尔语语言特点,抽取14项针对零指代消解任务的手工设计特征;然后融合word embedding特征和14项hand-crafted特征作为栈式降噪自编码的输入,最后经过无监督逐层贪婪的预训练和有监督的微调过程,使用softmax进行分类完成维吾尔语零指代消解任务。实验结果表明,与传统栈式自编码、浅层机器学习的支持向量机和人工神经网络相比,栈式降噪自编码的F值分别提高了4.450%、10.032%和8.140%,实验结果验证了该方法的有效性及栈式降噪自编码在任务中具备挖掘高层面鲁棒性语义特征的优势。 ",MESS201805007
基于深度信念网络的维吾尔语事件伴随关系识别,胡伟1:39356771|禹龙2:09256058|田生伟1:09220503|吐尔根·依布拉音3:17705003|冯冠军4:09220102|艾斯卡尔·艾木都拉3:17704444,9,伴随关系; 维吾尔语; 深度信念网络; 词向量; softmax分类器;,"维吾尔语事件伴随关系是维吾尔语语言中常见且重要的关系之一。结合对维吾尔语语言特点的研究,该文提出一种基于深度信念网络的维吾尔语事件伴随关系识别方法,根据维吾尔语语言特性和事件伴随关系的特点,抽取12项基于事件结构信息的特征;同时充分利用事件对所对应的两个触发词之间的语义信息,引入Word Embedding计算两个触发词之间的语义相似度。而后融合两类特征作为DBN模型的输入进行训练,最后将训练结果作为softmax分类器的输入实现维吾尔语事件伴随关系的识别。该方法用于维吾尔语事件伴随关系的识别准确率P为81.89%、召回率R为84.32%、F1值为82.48%。实验结果表明,与支持向量机方法相比,基于DBN模型的方法取得更好的识别效果。 ",MESS201805008
基于潜在语义分析的文本指纹提取方法,崔彤彤:39414492|崔荣一:09291242,6,文本指纹; 奇异值分解; 潜在语义分析; 随机超平面原理;,"网络化大数据时代的到来丰富了网络空间中的信息资源,然而由于数据资源类型的多样性及其增长的快速性,给网络空间的存储和信息资源的有效利用带来了压力和挑战。该文提出了一种基于潜在语义分析的文本指纹提取方法,该方法是对数据信息的一种压缩表示,是针对目前指纹提取方法语义缺失的一种改进。该方法主要通过奇异值分解获取原始文档的潜在语义特征,然后将原文档向量空间转换到与其对应的潜在语义空间,再根据随机超平面原理将该空间的文档转换成二进制数字指纹,最终用汉明距离来衡量指纹间的差异程度。实验以中国知网上的学术论文作为数据对象,通过对论文文本进行相似度实验和聚类实验对该文提出的方法进行实验验证。实验结果表明该方法能够较好地表征文档语义信息,进而验证了文本语义压缩表示的准确性和有效性。 ",MESS201805009
基于信任关系和词相关关系的冷启动用户词特征重建,"高亨德1:39415696|王智强1:25200586|李茹1,2,3:08453268",10,社交媒体; 词特征; 概率矩阵分解; 冷启动;,"文本是社交媒体用户的重要信息之一,从文本中获取用户的词特征是实现用户主题建模、兴趣挖掘及个性化推荐等任务的基础。然而社交媒体中存在许多用户(冷启动用户)只含有少量甚至缺乏文本信息,为此该文提出一种融合用户信任关系及词相关关系的词特征重建方法。该方法通过对用户信任关系矩阵、词相关关系矩阵和用户词特征矩阵进行联合概率矩阵分解来实现对冷启动用户的词特征重建。在新浪微博和Twitter的四组数据集上的实验结果表明,该文所提出的冷启动用户词特征重建算法能够取得较好的词特征重建结果。 ",MESS201805010
基于共指消解的实体搜索模型研究,熊玲:37885114|徐增壮:38779679|王潇斌:28130962|洪宇:25038035|朱巧明:05968617,8,共指消解; 伪相关反馈; 实体搜索;,"实体属性挖掘(slot filling,SF)旨在从大规模文档集中挖掘给定实体(称作查询)的特定属性信息。实体搜索是SF的重要组成部分,负责检索包含给定查询的文档(称为相关文档),供后续模块从中抽取属性信息。目前,SF领域关于实体搜索的研究较少,使用的基于布尔逻辑的检索模型忽略了实体查询的特点,仅使用查询的词形信息,受限于查询歧义性,检索结果准确率较低。针对这一问题,该文提出一种基于跨文档实体共指消解(cross document coreference resolution,CDCR)的实体搜索模型。该方法通过对召回率较高但准确率较低的候选结果进行CDCR,过滤不包含与给定实体共指实体的文档,提高检索结果的准确率。为了降低过滤造成的召回率损失,该文使用伪相关反馈方法扩充查询实体的描述信息。实验结果显示,相比于基准系统,该方法能有效提升检索结果,准确率和F1分别提升5.63%、2.56%。 ",MESS201805011
面向情感聚类的文本相似度计算方法研究,"李欣1:39414493|李旸2:29895353|王素格2,3:08454306",8,文本情感聚类; 文本相似度计算; 文本语义子空间;,"在文本情感分析时,使用无监督的聚类方法,可以有效节省人力和数据资源,但同时也面临聚类精度不高的问题。相似性是文本聚类的主要依据,该文从文本相似度计算的角度,针对情感聚类中文本—特征向量的高维和稀疏问题,以及对评论文本潜在情感因素的表示问题,提出一种基于子空间的文本语义相似度计算方法(RESS)。实验结果表明,基于RESS的文本相似度计算方法,有效解决了文本向量的高维问题,更好地表达了文本间情感相似性,并获得较好的聚类结果。 ",MESS201805012
基于主题模型的新疆暴恐舆情分析,"张绍武1,2:06536175|邵华1:06505876|林鸿飞1:06504899|杨亮1:14244075",9,动态主题模型; 层级式狄利克雷过程; 主题模型; 可视化;,"随着互联网的飞速发展,网络舆情引发的问题也越发突出。尤其是近年来发生的新疆暴恐事件,已成为公众关注的焦点。主题演化是网络舆情分析的重要内容之一,为了把握关于新疆的舆情动态,该文从主题热度变化、内容变化及关键词等多方面进行了研究。该文首先抓取了2013年1月到2015年12月互联网中关于新疆暴恐事件的新闻,并以此作为数据集建立了动态主题模型,实现对新闻的主题演化分析。该模型采用两次非负矩阵分解来生成主题,以层级式狄利克雷过程为对比实验,通过可视化分析与比较,总结出新疆暴恐事件的一些规律。 ",MESS201805013
基于语义的政策血缘网络演化机理研究,刘刚:06976186|傅玮萍:39414494|马莺歌:39414495,14,社保政策; 政策建模; 政策血缘网络; 结构演化;,"该文将行业政策形式化为一个由微观、中观和宏观政策血缘网络构成的复杂网络体系。分别通过改进的基于语义的政策词语相似度计算方法、依存句分析和基于向量空间模型的方法构建了微观、中观及宏观的政策血缘网络。在此基础上,该文对政策血缘网络进行了层次结构演化和碎片清理,构建了政策血缘森林并提出基于政策血缘森林的政策碎片化预防的方法。实验结果表明,该文所提出的方法能有效地解决政策碎片化等问题。 ",MESS201805014
基于特征融合的产科多标记辅助诊断研究,"马鸿超1,2:38128178|张坤丽1:10310465|赵悦淑3:09494412|昝红英1:09467924|庄雷1:09468875",9,中文产科电子病历; 数据清洗; 辅助诊断; 特征融合; 多标记分类;,"中文产科电子病历中蕴含着大量的医疗知识和健康信息,电子病历的信息抽取及辅助诊断对提高人口的生育健康水平具有重要意义。电子病历中,首次病程记录的入院诊断是根据主诉、辅助检查、查体等信息得出的。通常情况下诊断中包含正常诊断、病理诊断及并发症而非单一结果。因此,该文将辅助诊断问题转化为多标记分类任务。在对产科电子病历的首次病程记录进行数据清洗和结构化后,规范化诊断结论,将LDA所抽取的文本特征与病历中的数字特征采用向量拼接的方法融合为新的特征,再按诊断结果出现的频次不同形成不同的多标记集,根据首次病程中部分信息进行辅助诊断,采用RAkEL、MLkNN、CC和BP-MLL方法进行多标记分类。实验结果表明,采用融合特征的多标记分类方法,能够提升中文产科电子病历辅助诊断的效果。 ",MESS201805015
试题知识点预测:一种教研知识强化的卷积神经网络模型,"胡国平1:27814665|张丹1,2:32615860|苏喻1,3:35087594|刘青文1:38228119|李佳1:39185555|王瑞1:32487931",10,知识点; 卷积神经网络; 教研先验; 注意力机制;,"在各类在线学习系统中,为了给学生提供优质的学习服务,一个基础性的任务是试题知识点预测,即预测一道试题所考察的知识概念、能力等。在这个任务中,已有方法通常基于人工专家标注或者传统机器学习方法。然而,这些传统方法要么耗时耗力,要么仅关注试题资源的浅层特征,忽略了试题文本和知识点之间的深层语义关联。因此,这两类方法在实际应用中均受到了限制。为此,该文提出一种教研知识强化的卷积神经网络方法进行试题知识点预测。首先,结合教育学经验,定义和抽取试题的浅层特征。然后,利用一个卷积神经网络对试题的深层语义进行理解和表征。然后,考虑到教研先验与试题词句之间的关联,提出一种基于注意力机制的方法能够自动识别和计算不同教研先验对试题的重要性程度。最后,设计了一个融合知识点决策和试题语义约束的模型训练目标。该文在大规模数据上进行了充分的实验。实验结果表明,所提出的方法能够有效地进行试题知识点预测,具有很好的应用价值。 ",MESS201805016
第十五届全国自然语言处理青年学者研讨会在南京成功举行,,1, ,"<正>2018年5月4日至5日,第十五届全国自然语言处理青年学者研讨会(YSSNLP 2018会议)在南京召开。本次研讨会由中国中文信息学会主办,计算机软件新技术国家重点实验室(南京大学)承办。本次研讨会的主题为""关注学科交叉,增进产学交流"",旨在促进自然语言处理领域国内外学者间的学术互动,加强学术研究和产业发展的交流对话,共同促进整个自然语言处理领域的进步。本次研讨会由南京大 ",MESS201805017
图像的文本描述方法研究综述,马龙龙:27055084|韩先培:26496192|孙乐:10352504,12,图像的文本描述; 生成; 检索; 编码—解码;,"随着深度学习技术的兴起,自然语言处理与计算机视觉领域呈现相结合的趋势。作为融合视觉和语言的多模态研究任务,图像的文本描述可应用于基于文本内容的图像检索、网络图像分析等众多场景中,从而受到了研究界和企业界的广泛关注。图像的文本描述方法可归纳为三大类:基于生成的方法、基于检索的方法和基于编码—解码的方法。该文详细介绍了这三类方法各自具有代表性的工作,并进一步分析了各方法的优劣;然后对图像文本描述方法的相关数据集、评测标准和主要开源工具包进行了阐述;最后,分析了图像的文本描述中需要解决的关键技术问题。 ",MESS201804001
花园幽径句解码效果与反应时的关联性研究,"杜家利1,2:29594142|于屏方3:06841098",12,计算语言学; 花园幽径句; 非独立t检验;,"该文以126名中国大学生为测试样本,并采用非独立t检验为计算方法,讨论英语花园幽径句解码效果与解码反应时之间的关联性。花园幽径句是能引发行进错位的局部歧义句,大学生在歧义消解过程中易产生认知困惑。在其他条件不变的情况下,先后两次的语言实验将单样本花园幽径句的反应时从5s延长至10s,并进行了相应的t值计算。S1实验中,测定5s反应时和10s反应时的非独立t检验值为3.71,大于理论临界值并具有显著性差异。在S2-S100的实验中,分析发现材料的选择对实验结果有影响。总体而言,英语花园幽径句解码效果与解码反应时之间具有一定关联性,阅读时间的延长可以在一定程度上帮助学生更好地消解局部歧义。 ",MESS201804002
《文心雕龙》的篇章连接词研究,冯文贺1:36636463|郭海芳2:39225706|刘涛3:39225707,7,文心雕龙; 篇章结构; 连接词; 语义分析;,"标注《文心雕龙》的篇章结构,据此研究其连接词的显隐、语义及用法。研究发现:(1)隐式关系(78.1%)多于显式关系(21.9%),17类关系仅有四类(因果、转折、假设、目的)显多隐少;(2)各类关系的同义连接词种数与使用有差异,其中种数最多17(顺承),最少则无(总分、背景);(3)连接词(56种)单义为多(44),多义为少(12),义项最多为5,分布有差异。最后,个案分析同义连接词与多义连接词的用法,并与同时期著作连接词的使用进行了对比。 ",MESS201804003
向量模型和多源词汇分类体系相结合的词语相似性计算,梁泳诗:39223511|黄沛杰:24966316|岑洪杰:39223512|唐杰聪:39223513|王俊东:34071702,9,词语相似性; 向量模型; 词汇分类体系; 组合方法; 多源融合;,"现有的词语语义相似性计算主要包括基于向量模型以及基于词汇分类体系两类方法,但这两类方法都存在自身的缺点。向量模型所依赖的文本共现中的上下文信息不等同于真正意义上的语义,而词汇分类体系方法则存在构建代价大,并且在一定程度上还不够完善的问题。该文提出一种向量模型与多源词汇分类体系相结合的词语相似性计算方法,采用多源词汇分类体系的近义词关系以及向量模型得到的词向量,计算得到词语的向量表达,并探索了不同类型词汇分类体系提供的知识的选用和融合问题,弥补了单一词向量和单一词汇分类体系在词语相似性计算中的缺点。该文采用了NLPCC-ICCPOL 2016词语相似度评测比赛中的PKU 500数据集进行评测。在该数据集上,该文的方法取得了0.637的斯皮尔曼等级相关系数,比NLPCC-ICCPOL 2016词语相似度评测比赛第一名的方法的结果提高了23%。 ",MESS201804004
基于双向LSTM语义强化的主题建模,彭敏:10136641|杨绍雄:35196419|朱佳晖:33651013,10,双向LSTM; 语义强化; 主题模型;,"当前,双向LSTM神经网络等深度学习方法已经能有效地表达文本语义特征,为构建深层次的具有语义连贯性的主题模型提供了可能。但是,现有方法在文本的概率主题建模方面,提升的效果还比较有限。该文提出了一个基于双向LSTM语义强化的概率主题模型DGPU-LDA(double generalized polya Urn with LDA)。该模型一方面结合双向LSTM文档语义编码框架DS-Bi-LSTM(document semantic bi-directional LSTM)来实现文档宏观语义的嵌入表示,另一方面采用文档—主题和词汇—词汇双GPU(generalized polya Urn)语义强化机制以及LSTM来刻画参数推断过程中的吉布斯采样过程。在搜狗新闻数据集以及20新闻组数据集上的实验结果表明,相对于一些比较前沿的主题模型,DGPU-LDA模型在主题语义连贯性、文本分类准确率方面展现了一定的优势,同时该模型在文本语义特征表达方面的有效性也得到了证明。 ",MESS201804005
现代汉语形容词资源库的构建,"饶琪1,2:38526138|王厚峰1,2:06274413|汪梦翔1,2:29615765|李慧3:39223514",9,形容词; 联想; 知识库;,"形容词与名词、动词构成汉语实词的主体组成部分,在句法上表现出对""名词""的极度依赖,其核心功能是在概念层面上,在认知注意机制的调适作用下对名词的特征进行""评价""。该文主要叙述汉语形容词知识库构建的相关工作。首先是考察已有的形容词的收词情况,并结合语言演变中新产生的形容词,构建了一个较为全面的形容词词集;其次是详细阐述知识库的构建理念;再次是具体阐述知识库的特征描述体系;最后是对该知识库的应用场景进行展望。 ",MESS201804006
基于句式与句模对应规则的语义角色标注,何保荣:34916101|邱立坤:28907681|孙盼盼:39223515,7,句模; 句式; 语义角色标注; 标注规则;,"大规模语义角色标注语料库的构建可以为计算机理解自然语言的语义提供有用的训练数据。该文主要研究服务于语义角色标注语料库构建的语义角色标注规则。在人工语义角色标注的基础上,分析句式和句模的对应关系,并总结出一套基于句式的语义角色标注规则,在测试集上达到78.73%的正确率。基于上述规则,可以在构建语义角色标注语料库时完成自动标注的工作,标注人员在此基础上进行人工校对,可有效地减少工作量。 ",MESS201804007
基于概念层次网络的知识表示与本体建模,文亮:39223516|李娟:06361954|刘智颖:13895962|晋耀红:24682727,8,概念层次网络; 语义知识表示; 本体建模;,"知识表示是自然语言理解的重要基础。知识表示不统一、语义信息无法系统化利用是目前存在的亟待解决的问题。要解决这个问题,就要解决语义知识表示的问题。该文基于概念层次网络,描述了词语、句子和篇章层面的语义知识表示方法。基于文中描述的词汇层面的表示方法,构建了一个多语言本体知识库。该知识库的知识表示方法不仅可以为知识表示理论研究提供基础,还可以为自然语言处理相关领域的应用提供资源支持。 ",MESS201804008
基于子字单元的神经机器翻译未登录词翻译分析,韩冬:13969117|李军辉:09886805|熊德意:32622753|周国栋:13898054,7,神经机器翻译; BPE编码; 未登录词;,"神经机器翻译为机器翻译提供了一种全新的方法,在多对语言之间的翻译质量上,已超过了统计机器翻译,并逐渐成为当前机器翻译的主流方向。未登录词翻译是神经机器翻译的主要难点之一。为了消解未登录词,一种可行的方案是采用Byte Pair Encoding(BPE)方法。该方法在翻译前将原有的单词拆解为更小粒度的高频子字单元。该文主要探究BPE方法在中英神经机器翻译中的应用,分析BPE方法在多大程度上可以解决中英未登录词翻译缺失的问题。实验表明,与Baseline系统相比,BPE方法获得了1.02BLEU值的提升,对未登录词的翻译精准度达到了45%,与统计机器翻译系统翻译精准度相似。 ",MESS201804009
基于位置的知识图谱链接预测,张宁豫1:44257578|陈曦2:09325038|陈矫彦3:39225708|邓淑敏2:39225709|阮伟4:10280723|吴春明2:09387095|陈华钧2:09369118,8,位置特征; 知识图谱; 链接预测;,"链接预测是知识图谱的补全和分析的基础。由于位置相关的实体和关系本身拥有丰富的位置特征,该文提出了一种基于位置的知识图谱链接预测方法。该方法首先通过分析实体和关系的语义特征对关系进行分类,然后提出了一种基于位置的实体和关系位置特征和规则的挖掘方法;其次,通过挖掘出的实体位置特征和规则,对实体和关系的向量化方法预测结果进行约束,得到最终的结果。该文通过对WikiData、FB和WN数据集的实验,证明该方法针对基于位置的关系和实体链接预测拥有较好的效果。 ",MESS201804010
面向阅读理解的多对一中文文本蕴含问题研究,"陈千1:29259586|陈夏飞1:36440634|郭鑫1,2:27987630|王素格1:08454306",8,机器阅读理解; 中文文本蕴含识别; 多对一; 层级神经网络;,"机器阅读理解作为一种微阅读模式近年来在自动问答领域受到广泛关注,针对机器阅读理解中多对一的文本蕴含问题,该文首先构造了8 000级别的多句—单句中文文本蕴含语料M2OCTE,其次采用了层级神经网络模型,有效融合多个句子之间的语义信息,将多对一的蕴含对表达成统一的形式,实现端到端的输出。该方法在高考现代文阅读理解蕴含数据集上的准确率为58.92%,比将多句—单句的文本蕴含转换为单句—单句之后进行处理的准确率要高。同时也在英文数据集上进行了测试,实验结果验证了该方法的有效性。 ",MESS201804011
分层递阶的网络结构洞占据者挖掘及分析,"崔平平1,2:35506734|赵姝2,3:06141079|陈洁2,3:06134281|钱付兰2,3:06136578|张以文2,3:11581479|张燕平2,3:06139274",10,结构洞; 多粒度; 分层递阶网络; 社团划分;,"结构洞是在社会网络信息传播中占据重要位置的一类关键节点。据研究,5%的结构洞控制着50%的信息传播。学者们研究了单一粒度网络下结构洞的挖掘方法及分析,然而很多网络存在分层递阶的多粒度结构特性,对分层递阶网络的结构洞挖掘和分析具有现实意义。因此,该文提出了一种分层递阶网络的多粒度结构洞挖掘方法 HI-SH,并对不同粒度下的结构洞进行了分析。在该方法中,首先对网络进行多粒度社团划分,得到每一粒度下网络的社团;然后,根据两级信息传播理论,使用单一粒度下结构洞挖掘算法,挖掘每一粒度下top-k结构洞。在公用数据Topic16和真实数据上进行了实验,结果表明,网络的结构洞是动态变化的,单一粒度下的结构洞排名不能代表整个网络的结构洞排名。 ",MESS201804012
基于优化“未定义”类话语检测的话语领域分类,,9,话语领域分类; 未定义类; 两阶段法; 词向量; LSTM;,"""未定义""类话语在面向任务的对话语料中广泛存在,具有成分复杂,与其余""已定义""类话语边界模糊的特点,影响着话语领域的分类总体正确率。""未定义""类话语一旦错分,将会使用户对口语对话系统的功能有效性产生怀疑,导致大大降低用户体验。该文提出一种基于优化""未定义""类话语检测的领域分类方案,采用两阶段法完成口语话语的领域分类任务。首先,采用聚类方法将""已定义""类话语聚为几个大类,简化众多的""已定义""类话语独立存在时与""未定义""类话语之间的边界。进而利用分类模型对聚类后的""已定义""类话语大类以及""未定义""类话语进行领域分类,优化目标是""未定义""类话语的检测效率。最后,将第一阶段分类为""已定义""类的话语,在去除了绝大部分""未定义""类话语干扰的基础上进行再次分类。该文的分类模型采用了深度学习模型LSTM,并利用无标签微博数据训练词向量用于话语特征表达。在SMP 2017意图领域分类比赛的多任务语料上的评测结果表明,该方案在""未定义""类话语检测的F1值以及所有话语的领域分类总正确率上均有明显提升。 ",MESS201804013
基于深度学习的论文个性化推荐算法,王妍:22666715|唐杰:08180247,6,个性化推荐; 协同过滤; 词向量;,"该文基于学术搜索和数据挖掘平台Aminer向用户进行个性化推荐,提出了结合协同过滤推荐和基于内容推荐的混合模型,实验表明该算法可以有效解决新物品的推荐问题,即冷启动问题。其中在基于内容推荐的模型中,融合深度学习的方法,引进了词向量模型,将用户和论文映射到用词向量空间,并使用WMD(Word Mover Distance)计算相似度。实验表明,与其他基线模型相比该文提出的推荐模型在准确率上显著提高了4%。 ",MESS201804014
基于社交媒体的用户情绪建模与异常检测,"孙晓1:17392399|张陈1:39052159|任福继1,2:27168503",10,社交网络; 异常检测; 多元高斯分布; 联合概率密度;,"为了对新浪微博用户的异常情绪进行检测和分析,该文提出一种基于多元高斯模型和幂律分布的异常检测方法,根据联合概率密度值判断用户是否出现情绪异常。在实验部分,按照不同用户的异常检测准确率为83.49%,按照不同月份为87.84%。分布测试表明,单个用户的中性、快乐和悲伤情绪服从正态分布,而惊讶和愤怒情绪则不服从;群体发布的微博的情绪服从""幂律分布"",而单个用户则不服从。该文引入多元高斯模型来进行社交媒体的异常情绪的检测,通过联合概率密度值量化了异常情绪检测。当数据充足时,该方法可以检测用户或者某个社交平台每一周甚至每一天的异常情绪,这对个体异常情绪检测、网络舆情挖掘、大规模爆发事件预防以及公共安全监测有一定意义。 ",MESS201804015
基于主题模型的微博转发行为预测,郭亚:39223518|宫叶云:39223519|张奇:06708764|黄萱菁:06698167,7,微博转发预测; 主题模型; 社交网络;,"在全部微博内容中,由用户转发而产生的信息占有非常大的比例。同时,内容的转发也是微博中信息传播的主要途径。因此,用户的转发行为有着重要的研究价值,可应用于社交营销、微博检索、热点事件预测等领域中。该文中,我们通过分析所收集的大量真实的新浪微博数据,发现影响用户转发行为的一些因素:微博作者、用户兴趣以及微博热度。基于这些发现,该文提出了一种新颖的基于LDA模型的方法,综合利用以上3个特征预测用户转发行为。为了对该方法进行评价,我们利用收集的大量的微博数据及对应的社交网络结构模拟真实用户环境。实验表明,该方法的性能优于目前最好的方法,F值比其他基线方法高出35%—45%。 ",MESS201804016
儿童外语学习认知数据收集的在线游戏框架,马为之:38007171|张敏:08186086|张琛昱:39225671|刘奕群:08176974|马少平:08177513,8,语言认知; 儿童; 第二语言; 游戏性数据收集;,"近年来,人工智能技术飞速发展,不少工作试图从人类的认知发展过程中探索前进方向,语言学习认知的过程成为了重点关注的研究领域。已有的语言认知研究工作主要集中在学龄前儿童母语的词汇学习认知方面,依赖于WordBank(1)等大规模语料库。然而就我们所知,目前在第二语言学习方面研究不多,尚未有大规模的第二语言词汇学习数据,且传统的数据收集方法难以收集到大规模数据,这也一定程度上限制了对于第二语言学习的研究工作及母语与第二语言学习的比较。针对这一问题,该文面向学龄前儿童群体设计了基于游戏性原则的数据收集方法和研究框架,用于收集第二语言的语言学习情况和用户数据,以支撑相应研究工作的开展。目前,已经实现了针对学龄前儿童的第二语言为英语的词汇认知数据收集系统,正在进行在线的数据收集。 ",MESS201804017
“学生国学丛书新编”第一辑10种,,1, ,<正>王宁主编顾德希顾问面向莘莘学子普及国学经典涵养传统文化提升语文素养导读:名师指点阅读门径。注释:大家斟酌历代精注。选文:名家甄选名篇名文。目标:在阅读中走进中华优秀传统文化。 ,MESS201804018
论中国手语的分类词谓语,"姚登峰1,2,3:14346928|江铭虎2,3:08821580|张荣兴4:39026447|阿布都克力木·阿布力孜2,3:34071683",8,中国手语; 分类词谓语; 代名词;,"分类词谓语是手语中一种独特的语言现象。中国大陆学者对分类词谓语的研究刚开始涉足,尚未见到系统的研究报道。该文试图从语言学的角度对中国手语分类词谓语做了语义认知分析,首先结合Talmy的动态事件和代形词的分析,解释中国手语的分类词谓语现象,分析主体和背景的代形词如何形成以达到手语同时性和序列性要求,并由此确定主体代形词和背景代形词通常是由非运动的手形组成;另一方面也说明中国手语与汉语的相互影响,对""动作""和""位于""这两类的手语代形词做了较为详细的描述及分类。 ",MESS201803001
论羡余否定的形成机制及制约因素,陈秀清:30396045,8,羡余否定; 隐性否定词; 形成机制; 制约因素;,"该文采用定性研究和定量分析相结合的研究方法对羡余否定的形成机制和制约因素进行研究。认为羡余否定的形成机制是隐性否定意义上浮到句法层面,隐性否定词是羡余否定产生的基础。隐性否定词也对羡余否定的形成产生基础性的制约。根据意义来源不同,隐性否定词的否定强度并不一样,从而导致构成羡余否定的能力不一样。否定意义来自于断言的隐性否定词构成羡余否定的能力最弱,来自于衍推的最强,来自于预设的其次,来自于会话含义的再其次,这在数据统计上具有明显的表现,形成一个陡峭的曲线图。 ",MESS201803002
面向中文社交媒体语料的无监督新词识别研究,张婧:17303730|黄锴宇:37855545|梁晨:33095719|黄德根:06527360,10,未登录词识别; 社交媒体语料; 词向量; 无监督方法;,"该文结合词向量技术和传统统计量,提出了一种新的无监督新词识别方法。该方法利用传统统计量获得候选新词,然后采用多种策略训练得到词向量,利用词向量构建弱成词词串集合,并使用该集合从候选新词的内部构成和外部环境两个方面对其进行过滤。此外,该文人工标注了一万条微博的分词语料作为发展语料,用于分析传统统计量以及调整变量阈值。实验使用NLPCC2015面向微博的中文分词评测任务的训练语料作为最终的测试语料。实验表明,该文方法对二元新词进行识别的F值比基线系统提高了6.75%,比目前新词识别领域最佳方法之一Overlap Variety方法提高了4.9%。最终,在测试语料上对二元新词和三元新词识别的F值达到了56.2%。 ",MESS201803003
基于空间投影和关系路径的地理知识图谱表示学习,"段鹏飞1,2:10944693|王远3:08068851|熊盛武1,2:10155347|毛晶晶1:34518362",8,翻译模型; 地理知识图谱; 知识表示学习;,"近年来,类人智能技术和相关产品飞速发展,这在很大程度上得益于完备知识图谱的构建,特别是以地理为代表的基础教育知识图谱。传统的知识图谱采用网络知识组织形式进行表示,计算复杂度较高,而且三元组的知识表示形式不能有效地度量和利用实体间语义关联关系。该文构建了基于空间投影和关系路径的知识表示学习算法—PTransW(Path-based TransE and Considering Relation Type by Weight)模型,该模型结合空间投影和关系路径来对翻译模型进行扩展,并加入关系类型的语义信息进行改进。最后,在FB15K数据集和GEOGRAPHY数据集上训练并做链接预测实验。实验结果表明,PTransW模型对复杂关系的建模能力取得了较大地提升;对于规模较小的数据集,复杂度低的TransE和TransR模型将会训练得更充分;但是PTransE和PTransW模型由于利用了关系路径和反向关系中的语义信息,在关系预测方面有很大的优势。 ",MESS201803004
基于表示学习的开放域中文知识推理,姜天文:39026448|秦兵:06990821|刘挺:06994824,8,知识库表示学习; 知识推理; 开放域;,"知识库通常以网络的形式被组织起来,网络中每个节点代表实体,而每条连边则代表实体间的关系。为了利用这种网状知识库中的知识,往往需要设计专门的、复杂度较高的图算法。然而这些算法并不能很好适用于知识推理,尤其是随着知识库的知识规模不断扩大,基于网状结构知识库的推理很难较好地满足实时计算的需求。该文使用基于TransE模型的知识表示学习进行知识推理,包括对实体关系三元组中关系指示词以及尾实体的推理,其中关系指示词推理的实验取得了较好的结果,且推理过程无需设计复杂的算法,仅涉及向量的简单运算。另外,该文对原始TransE模型的代价函数进行改进,以更好地适用于开放域中文知识库表示学习。 ",MESS201803005
基于最长名词短语分治策略的神经机器翻译,张学强:38740201|蔡东风:24679274|叶娜:24679276|吴闯:37829920,8,神经机器翻译; 最长名词短语; 分治策略;,"神经机器翻译自兴起以来,不断给机器翻译领域带来振奋人心的消息。但神经机器翻译没有显式地利用语言学知识对句子结构进行分析,因此对结构复杂的长句翻译效果不佳。该文基于分治法的思想,识别并抽取句子中的最长名词短语,保留特殊标识或核心词,与其余部分组成句子框架。通过神经机器翻译系统分别翻译最长名词短语和句子框架,再将译文重新组合,缓解了神经机器翻译对句子长度敏感的问题。实验结果表明,该方法获得的译文与基线系统相比,BLEU分值提升了0.89。 ",MESS201803006
基于连词的维吾尔语情感词库扩展研究,刘若兰1:35412784|年梅1:10966512|玛尔哈巴·艾赛提2:35412785,6,维吾尔语; 情感词扩展; 连词; 程度副词; 极性判断;,"极性情感词是准确分析维吾尔文倾向性的基础资源。该文在前期构建的维吾尔语褒贬情感词典基础上进行网络情感词的自动扩展研究。首先分析维吾尔语情感表达的语言特征,总结了连词、程度副词与情感词的搭配规律,并基于此规律设计从情感语料库中获取候选情感词的算法,形成候选情感词库;最后再利用维吾尔语连词的特性,结合已创建的情感词典和维吾尔语反义词词典,以互联网作为超大规模语料库,设计基于搜索引擎的情感词极性判别算法,根据算法得分判别候选情感词的极性,再将其扩展到已构建的褒贬情感词库。实验结果表明,与扩展前的情感词库相比,使用互联网文本语料扩展后的情感词库后进行维吾尔语句子倾向性测评的准确率和召回率均有明显提高。 ",MESS201803007
基于共现词映射的中英韩跨语种文档相似度计算,刘娇:31307479|崔荣一:09291242|赵亚慧:10826481,9,跨语种文档相似度; 共现词; 潜在语义分析;,"该文采用中英韩跨语种文本数据研究不同语种文档间相似度的计算方法。首先,通过共现词映射将某语种空间中的文档向量表示成另一语种空间中的文档向量;其次,利用潜在语义分析补充了不同语言间一词多义现象造成的向量缺失;最后,在具有等价语义信息的同一语种空间中计算了两个文档之间的余弦相似度。该文工作避开了外部词典和知识库,利用中英韩三个语种的对齐语料库,建立了不同语种词汇间的对应关系。结果表明,共现词映射对计算不同语种文档之间的相似度具有较大影响,对同语义的不同语种文档(即译文)的检索准确率达到95%,验证了该方法的有效性。 ",MESS201803008
基于词向量的越汉跨语言事件检索研究,唐亮:33659786|席耀一:36173898|彭波:27052437|刘香伟:28029588|易绵竹:20301944,7,词向量; 跨语言检索; 关键词对齐; 语义特征向量;,"为了解决越汉跨语言事件检索中的查询翻译问题,该文提出了一种基于词向量的越汉跨语言事件检索方法。首先利用词向量构建事件关键词的汉语语义特征向量,然后计算越语的事件关键词的特征翻译向量,最后通过计算语义特征向量之间的相似度完成跨语言关键词对齐,从而实现查询关键词的自动翻译,进而完成跨语言事件检索。在构建的南海话题相关越汉语料库上进行的实验证明了该方法的有效性。 ",MESS201803009
汉—藏人名用字音译规则研究,龙从军1:11531165|豆格才让2:39026449|刘汇丹3:09573793,6,汉—藏人名; 人名音译; 音译原则;,"随着信息技术的发展,藏文在互联网上广泛使用,政府主办的报刊、杂志也逐渐有了网络版,大量的汉文材料被翻译成藏文。翻译者在音译汉文人名用字时,未能遵从统一的音译规范,导致同一人名存在多种音译形式。该文统计了五家藏文网站,发现一些公众人物的人名用字音译形式比较混乱,不但影响信息交流,而且不利于藏文自然语言处理。该文详细分析了音译混乱的原因,提出在汉—藏人名用字音译时,需要制定一一对应的音译原则;同时注重原则实践的可行性和一致性。翻译者在音译汉—藏人名用字时必须严格遵从音译原则;推行音译原则还需要依靠相关政府机构和部门。 ",MESS201803010
基于神经网络的体育新闻自动生成研究,李浥尘:39026450|胡珀:07625508|王丽君:24275994,7,神经网络模型; 直播脚本; 体育新闻; 新闻标题;,"面向体育比赛的大规模直播脚本快速及时地反映了比赛的实时进程,但依靠体育新闻记者来据此人工撰写新闻报道往往耗时费力。鉴于此,该文提出了一种自动生成体育直播脚本所对应的体育新闻的神经网络模型,该模型在一定程度上避免了传统模型过于依赖人工选择特征的局限性,同时还能综合考虑脚本中句子级局部信息与全局信息以及句子和新闻内容间的语义关联性,从而实现联合建模下的体育新闻生成。在公开数据集上的实验结果验证了该文所提方法的可行性和有效性。此外,还尝试了基于规则和模板来自动生成体育新闻的标题以突显新闻正文的关键内容。 ",MESS201803011
基于神经网络的片段级中文命名实体识别,王蕾:08113341|谢云:08083221|周俊生:08116958|顾彦慧:08080677|曲维光:08112756,8,深度学习; 神经网络; 片段级中文命名实体识别;,"命名实体识别是自然语言处理的一个重要基础任务。传统基于统计学习模型的命名实体识别方法严重依赖特征工程,特征设计需要大量人工参与和专家知识,而且已有的方法通常大多将中文命名实体识别任务看作一个字符序列标注问题,需要依赖局部字符标记区分实体边界。为了减弱系统对人工特征设计的依赖,避免字符序列化标注方法的不足,该文对基于神经网络的片段级中文命名实体识别方法进行探索研究。通过采用深度学习片段神经网络结构,实现特征的自动学习,并通过获取片段信息对片段整体分配标记,同时完成实体边界识别和分类。基于神经网络的片段级中文命名实体识别方法在MSRA数据集上对人名、地名和机构名识别的总体F1值达到了90.44%。 ",MESS201803012
基于双语URL匹配模式可信度的平行网页识别研究,"章成志1,2:13897453|马舒天1:39026452|揭春雨2:13898284|姚旭晨2,3:39026453",10,平行网页获取; 平行语料库; 双语URL匹配模式; 双语文本挖掘;,"平行语料是自然语言处理中一项重要的基础资源,在双语平行网页中大量存在。该文首先介绍双语URL匹配模式的可信度计算方法,然后提出基于局部可信度的双语平行网页识别算法,再依据匹配模式的全局可信度,提出两种优化方法:即利用全局可信度,救回因低于局部可信度阈值而被初始算法滤掉的匹配模式;通过全局可信度和网页检测方法,挖出深层网页。进一步,结合网站双语可信度、链接关系,侦测出种子网站周边更多较具可信度的双语网站。除了双语URL匹配模式自动识别,还利用搜索引擎,依据少数高可信度的匹配模式快速识别双语网页。为了提高以上五种方法识别候选双语网页对的准确率,计算了候选双语网页对的双语相似度,并设置阈值过滤非双语网页对。通过实验验证了所提方法的有效性。 ",MESS201803013
DRTE:面向基础教育的术语抽取方法,李思良:38562369|许斌:08184020|杨玉基:38562370,9,术语抽取; 术语定义; 术语关系;,"术语抽取从非结构化文本中自动抽取专业术语。该工作在中文分词、信息抽取、知识库构建中发挥着重要的作用。当前术语抽取方法很大程度上依赖于词的统计信息,由于基础教育学科中术语具有极强的长尾特性,导致基于统计的术语抽取方法很难抽取出处于尾端的术语。该文结合基础教育的学科特点,提出了DRTE:一种利用术语定义与术语关系挖掘,综合构词规则与边界检测的术语抽取方法。该文以初高中的数学课本为数据源进行术语抽取,实验结果表明我们的术语抽取方法 F1值达到82.7%,相比目前的方法提高了40.8%,能够有效地在中文基础教育领域进行自动化的术语抽取。 ",MESS201803014
基于多重增强图和主题分析的社交短文本检索方法,"刘德喜1,2:13897196|付淇1,3:39026455|韦亚雄1,2:39026456|万常选1,2:07848038|刘喜平1,2:07847937|钟敏娟1,2:11617711|邱家洪1,2:39026457",10,社交短文本检索; 多重增强图; LDA主题模型;,"社会网络平台上的社交短文本不同于网页或其他文本,它的特点是内容短、文本间存在转发评论等关系、话题复杂多样、与Web页面有链接关系、文本的作者间有关注关系等,现有的检索系统不能完全适应。该文提出一个基于多重增强图的社交短文本检索方法 SSTR,它利用多重增强图算法对通过Indri获得的初步检索结果实现再排序优化和去重。多重增强图算法是基于马尔科夫链理论设计出的图模型算法,社交短文本中蕴含的文本、作者、词语等不同层面的关系通过不同的图层及图中节点之间的边来建模。三个层面的关系相互增强,通过多次迭代运算,最终寻求多个层面间相互关系所处的稳定状态。多重增强图构建时,短文本的相似度计算基于主题分析结果,克服了传统余弦相似度计算时TF-IDF权重在短文本上的局限性。实验结果表明,与Indri、reRank-COS和reRank-LDA相比,基于多重增强图算法的SSTR排序的效果更好,适合初始检索结果相对较多的应用场合。 ",MESS201803015
基于Spark的大规模语义规则后向链推理系统,"顾荣1,2:30773840|王善永1:39026458|郭晨1:08037127|袁春风1,2:08045971|黄宜华1,2:08038125",15,语义推理; 后向链推理; 并行化;,"近年来,语义网数据快速增长,适合于处理静态小规模语义数据的前向链语义推理技术暴露出了需对数据进行频繁更新等问题。面对大规模动态语义网数据,对数据更新不敏感的后向链语义推理开始成为新的研究热点。后向链语义推理由查询目标驱动,在查询时根据规则集推理出查询结果。后向链语义推理具有推理过程复杂、规则扩展深度大等特点,在大规模语义数据上推理的效率和可扩展性上有一定的挑战。该文立足于已有的后向链推理技术,详细分析了语义推理规则集的特点,并结合当前主流的大数据处理平台Spark,设计了一套较为高效并且可扩展的大规模并行化语义规则后向链推理系统。该文的主要研究工作分为三个部分:(1)采用预计算本体数据闭包的方法,避免了本体模式在实时推理阶段的重复推理;(2)在后向链语义推理的逆向推理和查询阶段设计了优化措施,进一步提高了推理效率;(3)设计实现了一种基于Spark平台的大规模分布式RDFS/OWL后向链语义推理系统。实验数据显示,该文提出的RDFS/OWL后向链语义推理系统在合成数据集LUBM和真实数据集DBpedia上都表现出了良好的推理性能,在亿条三元组上的推理开销是几秒到几十秒,并且表现出了良好... ",MESS201803016
基于词语关联的散文阅读理解问题答案获取方法,"乔霈1:38469923|王素格1,2:08454306|陈鑫1:08400749|谭红叶1:08402552|陈千1:29259586|王元龙1:34932595",8,阅读理解; 问答题; LDA聚类; 词语关联;,"高考语文阅读理解问答题中的提问方式复杂多样,使用的词语语义抽象,而相关阅读材料的内容表达丰富和含蓄,造成问题中的词语与阅读材料中词语存在一定的语义鸿沟。为了解决这一问题,该文对词语关联进行相关研究。首先利用LDA主题聚类方法,将同一主题类的词语进行聚类,根据各类词语的词性、词频特征,筛选与主题相关联的词语,再利用Word2Vec的语义相似度计算,将每一个主题关联的词语扩展,获得与主题词语义关联的词语。最后,将所提出的方法应用于近12年北京高考题和模拟题的散文抽取类问答题解答中,实验结果表明该方法优于传统的词语扩展方法。 ",MESS201803017
中国语言文化典藏,,1, ,<正>记录方言透视文化传承历史珍藏经典主编:曹志耘开本:16开定价:168.00元/卷《中国语言文化典藏》(澳门、潮州、杭州、衡山、怀集、怀集(标话)、江山、金华、井陉、连城、泸溪、清徐、寿县、苏州、濉溪、遂昌、藤县、屯溪、宜春、永丰) ,MESS201803018
关于申报2018年中国中文信息学会科学技术奖——“钱伟长中文信息处理科学技术奖”的通知,,1, ,"<正>为调动我国从事中文信息处理技术研究的专家和学者的积极性,推动信息产业的发展,根据《钱伟长中文信息处理科学技术奖奖励条例》,以及《钱伟长中文信息处理科学技术奖奖励条例实施细则》,即将开展2018年度""钱伟长中文信息处理科学技术奖(中国中文信息学会科学技术奖)""评审奖励工作。自2006年 ",MESS201803019
英语学习者书面语法错误自动检测研究综述,刘磊1:09296596|梁茂成2:10548868,8,英语学习者书面语; 语法错误自动检测; 作文质量自动评测;,"英语学习者书面语法错误检测和修改系统可为作文自动评分提供参数,评测作文整体质量;也可用于计算机辅助英语教学,为学生提供书面纠错反馈,促进其二语写作能力的发展。该文概述了近十年来自然语言处理技术在英语学习者语法错误自动检测研究中的应用,首先介绍了基于大规模本族语和学习者语料库的三种数据驱动的系统设计方法,然后讨论了语误检测系统的评测标准,最后提出了提高现有系统准确率的一些建议。 ",MESS201801002
汉语“的”字短语认知神经机制的ERP研究,苏裴1:38833651|江铭虎1:08821580|白晨2:36972044,9,隐喻; N400; 认知; ERP;,"隐喻是我们日常生活中常见的语言现象,更是我们认知、理解、描述世界的重要方式。该文围绕汉语独有的隐喻形式,考察汉语NP+NP形式的""的""字短语隐喻的脑认知加工机制。通过有意义程度(plausibility)、熟悉度(familiarity)和比喻的程度(figurativeness)三个方面来对语料进行筛选和预处理。实验结果显示,隐喻组别激发了比本义组别更为明显的N400现象,统计分析结果显著,NP+NP""的""字短语句型中,隐喻和本义的认知有着不同的脑认知机制。本义的认知最容易,隐喻要比本义消耗更多认知资源,而假词消耗的认知资源最多。实验进一步说明,即使源域和靶域不同时出现,依旧可以激发大脑对隐喻的认知机制。 ",MESS201801003
汉语小句的俄语对应单位研究,杨毅1:42119910|冯文贺2:36636463,8,小句对齐; 篇章翻译; 汉语小句俄语对应单位;,"该文标注汉俄平行文本中汉语小句的俄语对应单位,并统计分析。首先,根据汉语小句切分对齐切分俄语,得到俄语对应单位;其次,对俄语对应单位进行语法标注;最后,基于标注语料,分析发现俄语对应单位。研究发现:(1)句子组成部分多(74.85%),句子少(25.15%);(2)单一述谓核心多(69.04%),无述谓核心次之(27.63%),多述谓核心少(3.33%);(3)单一述谓核心以简单谓语最多(31.84%),无述谓核心以动词短语最多(51.26%),多述谓核心以主从复合句最多(47.92%)。 ",MESS201801004
基于语言学特征向量和词嵌入向量的汉语动词事件类型预测,"刘洪超1:34227764|黄居仁1:23136240|侯仁魁1,2:38829597|李洪政3:30682057",8,事件类型; 汉语动词; 语言学特征; 词嵌入; 分类; 预测;,"该文主要介绍汉语动词事件类型的预测。事件类型是根据内部时间结构对汉语动词进行的重要分类,包括状态、活动、变化(完结和达成)。对汉语动词事件类型进行预测从理论上能够对以往语言学研究提出的特征进行验证,从应用上可以服务于机器翻译等任务。该文基于两种方式构建词向量进行汉语动词事件类型的预测,一种是根据语言学特征有监督地构建词向量,另一种是利用word2vec无监督地构建词嵌入向量。通过多元逻辑回归、支持向量机和人工神经网络分类器对汉语动词事件类型进行预测,最终实现了73.6%的总体准确率。 ",MESS201801005
基于知识库的汉语未登录词语义预测,"瞿健菊1,2:29230132|冯敏萱2:08753478",9,未登录词; 语义预测; 语言知识库; 构词; 知网;,"该文基于知识库的语素构词知识,采用了分阶段的算法自动预测未登录词的语素构词知识,以此实现对未登录词的语义预测。基本思路是通过语素义组合或语素义类组合的匹配,先预测语义层面的知识,再确定相应语素项,最终获得未登录词多层面的语素构词知识。该算法简单、直观、合理,在首素性类、首素义类、首素义、尾素性类、尾素义类、尾素义、构词方式这七项预测内容全部正确的标准下,实验结果的预测正确率为62.32%,召回率为61.72%。 ",MESS201801006
基于主题相似度的宏观篇章主次关系识别方法,,8,宏观篇章主次关系; 主题相似度; word2vec; LDA;,"篇章分析是自然语言处理领域的一个重要任务。分析篇章主次关系有助于理解篇章的结构和语义,并为自然语言处理的应用提供有力的支持。该文在微观篇章主次关系识别研究的基础上,重点研究宏观篇章主次关系,提出了一种基于word2vec和LDA的主题相似度的宏观篇章主次关系识别模型。基于word2vec的主题相似度和基于LDA的主题相似度在不同维度上计算语义相似度,两者在语义层面形成互补,因而增强了模型识别宏观篇章主次关系的能力。该模型在宏观汉语篇章树库(MCDTB)上实验的F1值达到79.9%,正确率达到81.82%,相较基准系统分别提升了1.7%和1.81%。 ",MESS201801007
面向多语料库的通用事件指代消解,陆震寰:38732229|孔芳:08865090|周国栋:13898054,8,卷积神经网络; 全局优化; 特征表示; 事件同指消解;,"事件同指消解对篇章理解、信息抽取意义重大。该文在事件抽取完成的基础上聚焦事件同指,给出了一个基于卷积神经网络的事件同指消解完整框架,针对实例分布不均衡问题给出了基于事件语义类别和时态信息的事件兼容性过滤策略。为了最大化适用不同的事件标注策略,提出了最小事件本身描述和事件间关系描述相结合的特征表示方法。针对基于事件对模型进行同指消解产生的局部最优问题,给出了一种全局优化的后处理方案。在KBP2015和ACE2005语料上的各类实验表明,上述三个解决方案均能有效解决问题,提升整个事件同指消解平台的性能。 ",MESS201801008
基于音系学模型的手语理解,"姚登峰1,2:14346928|江铭虎2:08821580|阿布都克力木·阿布力孜2:34071683|李晗静1:31844220|哈里旦木·阿布都克里木3:34071685",9,音韵参数; 手语; 深度学习; 音系学模型;,"该文试图模拟人脑处理手势信号的过程,设计了一个混合的深层神经网络模型来解决基于音系学模型的手语理解问题,即手语音韵信息到文本转换的问题。为此该文首先综合了手语语言学里同时性和序列性这两个观点的长处,提出了一个手语音系学的改进模型,并针对难点设计了基于音系学模型的手语理解算法。直接从语言学的音韵特征推断手语文本,相比从视觉特征推断出手语文本是一个很大的飞跃。实验验证了该认知计算技术的有效性,为实现类人智能奠定了技术基础。 ",MESS201801009
机器词典释义模版的建构和运用,"王恩旭1,2:37395833|袁毓林1:06263991",8,生成词库论; 释义模版; 多义词; 同义词; 新词;,"机器理解词主要借助于词典,但目前的词典释义还不准确,也不完备。对于这些问题,该文通过分析词的语义结构和建构词的释义模版来解决。通过分析词的语义结构,弄清词义中包含着哪些语义成分、语义关系,确定哪些是必有成分、必有关系,哪些是可有成分、可有关系。然后,结合实例讨论释义模版的建构过程、原则与方法。最后,通过释义模版,解决词典释义不完备、语义联系不明显、循环释义、新词释义等问题。 ",MESS201801010
中英文篇章依存树库构建与分析,, , , ,MESS201801011
由粗到精的哈萨克语短语结构句法分析研究,"梁金莲1,2,3:38833652|古丽拉·阿东别克1,2,3:22101463",6,句法分析; PCFG; 重排序;,"该文针对哈萨克语短语结构句法分两个阶段采用由粗到精的方法进行哈萨克语句法分析研究。第一阶段使用粗略的句法分析器生成20个最佳候选树;第二阶段采用感知机的方法训练,提取特征信息,并对第一阶段生成的20个最佳候选树进行重排序,最终解析结果是第一阶段产生的候选树的结果和重排序结果按照比例选取。该方法在两个阶段不仅可以获取到句子的结构信息,还可以提取到详细的特征信息,可以最大限度地对句子进行解析,获得了较好的句子解析结果,其句法分析正确率为71.4%。 ",MESS201801012
MHW蒙古文脱机手写数据库及其应用,范道尔吉1:08011551|高光来1:05981929|武慧娟2:08639734,7,蒙古文; 手写识别; 字库; HMM; LSTM;,"建立公开、权威的蒙古文手写数据库是研究和开发蒙古文手写识别系统的基础。该文在蒙古文编码、构词和语法的研究基础上,公开了一个蒙古文大词汇量脱机手写数据库MHW,其中训练集由5 000个单词构成,每个词采集了20个样本,共包含10万样本,测试集Ⅰ包含5 000样本,测试集Ⅱ包含14 085样本。该文利用蒙古文文字长度可变特征研究了自动错误检测算法,提高了字库的可靠性。在三种常用手写识别模型上评估了字库的性能,其中基于循环神经网络的模型表现出最佳性能,在字典受限条件下测试集Ⅰ的词错误率达到2.20%,测试集Ⅱ达到了5.55%。 ",MESS201801013
采用多尺度注意力机制的远程监督关系抽取,"蔡强1,2:06295600|郝佳云1,2:36748471|曹健1,2:25779088|李海生1,2:15593186",6,多尺度; 注意力机制; 远程监督模型; 关系抽取;,"针对目前大多数关系抽取模型中局部特征及全局特征利用不充分的缺点,该文提出一种采用多尺度注意力机制的远程监督关系抽取模型。在词语层面,通过在池化层构建权重矩阵来衡量词语与关系的相关程度,从而捕捉句子中重要的语义特征;在句子层面,采用注意力机制将预测关系与句子进行相关性比较,获得句子级别的重要信息。模型在NYT数据集上平均准确率达到78%,表明该模型能够有效地利用多尺度特征,并且提高远程关系抽取任务的准确率。 ",MESS201801014
面向专业文献知识实体类型的抽取和标注,"温雯1:24644962|伍思杰1:36294926|蔡瑞初1:26284587|郝志峰1,2:06748053",14,类型抽取; 类型标注; 知识实体; 多标签加权; 标签传播;,"知识实体的类型标注是专业文献的结构化管理和知识脉络挖掘中的一个重要问题。然而,由于知识实体具有专业性强、类型多样等特点,传统的实体抽取方法并不能很好地实现知识实体的类型标注。为了解决这一问题,该文从数据中发现并总结出知识实体类型的独有特性,根据这些特性首先提出一种基于启发式规则的类型抽取方法、实现部分知识实体的类型标注,进而通过多标签加权的标签传播方法实现对所有知识实体的类型标注。与传统方法相比,该方法能够从数据中获得最有可能的类型标签,在无需人工标注的情况下获得有效的知识实体类型标注。实验结果表明,所提出方法具有较好的灵活性,更适用于专业文献知识实体的类型标注。 ",MESS201801015
基于CNN-BLSTM-CRF模型的生物医学命名实体识别,李丽双:06521783|郭元凯:38829600,7,生物医学命名实体识别; LSTM; CNN;,"命名实体识别是自然语言处理任务的重要步骤。近年来,不依赖人工特征的神经网络在新闻等通用领域命名实体识别方面表现出了很好的性能。然而在生物医学领域,许多实验表明基于领域知识的人工特征对于神经网络模型的结果影响很大。因此,如何在不依赖人工特征的情况下获得较好的生物医学命名实体识别性能是有待解决的问题。该文提出一种基于CNN-BLSTM-CRF的神经网络模型。首先利用卷积神经网络(CNN)训练出单词的具有形态特征的字符级向量,并从大规模背景语料训练中得到具有语义特征信息的词向量,然后将二者进行组合作为输入,再构建适合生物医学命名实体识别的BLSTM-CRF深层神经网络模型。实验结果表明,不依赖任何人工特征,该文方法在BiocreativeⅡGM和JNLPBA2004生物医学语料上都达到了目前最好的结果,F-值分别为89.09%和74.40%。 ",MESS201801016
基于注意力机制的句子排序方法, ,8,句子排序; 注意力机制; 语义逻辑关系;,"句子排序是多文档自动摘要和答案融合任务的关键技术,其效果直接影响摘要或者答案融合结果的可读性。作为句子排序的重要依据,语义逻辑关系的准确度对于排序结果的可读性有很大影响。为此,该文提出了引入注意力机制的句子排序模型,以增强句子语义逻辑关系的捕获能力,进而获取句子的合理排序。实验结果表明,在句子排序任务中,引入注意力机制的句子排序模型明显优于基线方法。 ",MESS201801017
中文微博热点事件情感分布的原因分析,李泽魁1:31966558|李雪婷2:26630851|赵妍妍3:11639065,8,情感原因分析; 话题聚类; 话题纠正; 中文微博;,"微博作为新兴的社交媒体平台,越来越多的网民选择在微博上获取与分享自己感兴趣的信息。在微博日均千万级的大数据面前,分析网民对某一事件的观点与态度是一件非常有意义的工作。调研中发现,大众对单个事件的不同话题存在不同的情感分布。针对这一现象,该文提出了使用无监督学习的层次聚类排序方法和半监督学习的微博话题纠正算法两种方法,进行事件话题及其相关微博的挖掘。最后利用情感分析的相关技术,达到对相关微博进行情感分布统计及其原因分析的目的。通过在人工构建的数据集上测试,结果表明该方法能够准确分析事件情感分布的原因。 ",MESS201801018
基于多通道LSTM的不平衡情绪分类方法,殷昊:35705928|李寿山:27030929|贡正仙:09882510|周国栋:13898054,7,情绪分类; 不平衡分类; LSTM;,"情绪分类是自然语言处理问题中的重要研究问题之一。情绪分类旨在对文本包含的情绪进行自动分类,该任务是情感分析的一项基本任务。然而,已有的研究都假设各情绪类别的样本数量平衡,这与实际情况并不相符合。该文的研究主要面向不平衡数据的情绪分类任务。具体而言,该文提出了一种基于多通道LSTM神经网络的方法来解决不平衡情绪分类问题。首先,该方法使用欠采样方法获取多组平衡训练语料;其次,使用每一组训练语料学习一个LSTM模型;最后,通过融合多个LSTM模型,获得最终分类结果。实验结果表明该方法明显优于传统的不平衡分类方法。 ",MESS201801020
欢迎订阅《中文信息学报》,,1, ,"<正>《中文信息学报》(Journal of Chinese Information Processing)是全国一级学会-社团法人中国中文信息学会和中国科学院软件研究所联合主办的学术性刊物,创刊于1986年10月,现为月刊。由商务印书馆出版,为商务印书馆期刊方阵中的期刊之一,清华大学印刷厂印刷。《中文信息学报》是我国计算机、计算技术类中文核心期刊。主要刊登中文信息处理基础理论与应用技术方面的高水平学术论文,内容涵盖计算语言 ",MESS201801019
中国语言文化典藏,,1, ,"<正>丛书名:中国语言文化典藏书号:略定价:每卷168元开本:16开内容介绍:""中国语言文化典藏""丛书是教育部哲学社会科学研究重大课题攻关项目,教育部国家语委""中国语言资源保护工程""标志性成果,国家""十三五""出版规划项目、国家出版基金项目。该丛书在""语言文化""和""典藏""上精细打磨,""语言文化""是指用语言形式所表达的具有地方特色的文化现象,包 ",MESS201801021
汉语名词的隐喻知识表示及获取研究,"汪梦翔1,2:32278877|饶琪2:38526138|顾澄3:38526139|王厚峰2:06274413",9,中文信息处理; 隐喻计算; 模式识别; 惯用语;,"隐喻知识的表示和获取是进行隐喻计算的基础。该文把隐喻知识看作是本体和喻体的特征和属性之间的关联。主要通过惯用语导入和句法模式识别两种机制,来获取名词的隐喻知识。惯用语的隐喻比较固定和单一,从专门的词典释义中就能获取准确的隐喻特征和属性。而一般名词的隐喻知识比较复杂,该文主要依托语料库和搜索引擎,通过关键词和句法匹配来获取同一名词不同的隐喻特征及对应属性。该项工作的结果,对隐喻句隐喻意义的获取和名词语义属性特征的描述体系构建具有一定的价值。 ",MESS201706001
语言先验知识对神经网络模型自然语言处理任务的影响,贝超:38091242|胡珀:07625508,8,神经网络; 自然语言处理; 先验知识;,"随着互联网的发展及硬件的更新,神经网络模型被广泛应用于自然语言处理、图像识别等领域。目前,结合传统自然语言处理方法和神经网络模型正日益成为研究的热点。引入先验知识代表了传统方法的惯例,然而它们对基于神经网络模型的自然语言处理任务的影响尚不清楚。鉴于此,该文尝试探究语言层先验知识对基于神经网络模型的若干自然语言处理任务的影响。根据不同任务的特点,比较了不同先验知识和不同输入位置对不同神经网络模型的影响。通过大量的对比实验发现:先验知识并不是对所有任务都适用,在神经网络模型的合适位置加入合适的先验知识方可加快模型的收敛速度,提高相关任务的效果。 ",MESS201706003
基于词汇聚类方法的现代汉语分期与分期体系构建,饶高琦1:28523622|李宇明2:27454895,7,现代汉语; 分期; 词汇; 历史演变; 聚类;,"当前对现代汉语史的研究多借用政治-社会史的分期方式将现代汉语分为新文化运动至1949年、1950—1966年、1967—1976年和1977—至今四个时期,并在这一基础上开展了许多研究。语言尤其是书面语虽然与社会政治生活有密切联系,但语言系统有其自身的演化规律。从语言数据出发对语言进行分期是更加合适的选择。该文将语言的分期问题视作历时语料的分期问题,进而成为历时文本的聚类问题。该文工作基于历时报刊语料库遴选出的时间敏感程度较好的词汇。使用机器学习领域中广泛使用的K均值和期望最大算法进行聚类,以该部分词汇频率为特征对70年跨度(1945—2015)的历时报刊语料进行聚类,并在不同的聚类数量下绘制了具有层次性的词汇使用分期树。据此构建了过去70年现代汉语的词汇层次分期模型,揭示了改革开放的开始作为词汇使用变迁最重要分水岭的地位。 ",MESS201706004
基于多模型融合的汉语介词短语识别,刘彤:06530154|黄德根:06527360|张聪:14244109,8,简单名词短语; 分词融合; 分层嵌套结构; 双重错误校正系统;,"该文提出了一种多模型融合的介词短语识别方法,不仅能识别并列型介词短语,而且提高了嵌套型介词短语的识别精度。首先,利用简单名词短语识别模型识别出语料中的短语信息并进行融合,简化语料,降低介词短语内部复杂性;其次,用CRF模型识别嵌套的内层介词短语,即若存在嵌套则识别嵌套的内层,若无嵌套则识别该介词短语;最后,将初始语料中识别出来的内层介词短语进行分词融合并修改其特征信息,重新训练外层介词短语识别模型进行识别。在内外层介词短语自动识别后,利用双重错误校正系统对识别的介词短语进行校正。在2000年《人民日报》语料中的7 028个介词短语进行五倍交叉实验,结果表明,该方法识别的介词短语的正确率、召回率、F值分别为94.11%、94.02%、94.06%,比基于简单名词短语的介词短语识别方法(baseline)分别提高了1.09%、1.07%、1.08%,有效提高了介词短语识别的性能。 ",MESS201706005
基于外部记忆单元和语义角色知识的文本复述判别模型,李天时:38526140|李琦:06244787|王文辉:06270113|常宝宝:06253581,8,文本复述判别; 语义角色; 记忆单元; 循环神经网络;,"文本复述判别是一个重要的句子级语义理解应用。该文提出了一个轻量级的基于记忆单元的单层循环神经网络模型,并结合语义角色标注知识帮助进行英文文本复述判别。使用单层的循环网络模型减缓由于网络层数过多加重的梯度消失和梯度爆炸问题,易于训练;并且利用外部记忆单元和语义角色知识帮助存储两句话中不同层级的语义联系。该文模型在英文评测语料Microsoft Research Paraphrase Corpus测试集上F值为84.3%。实验表明,语义角色标注知识确实可以帮助文本复述判别,并且轻量级模型达到了与同类多层次网络模型相近的效果。 ",MESS201706006
基于神经网络纠正器的领域分词方法,吴佳林:38526141|唐晋韬:20581732|李莎莎:20431646|王挺:20633286,9,中文分词; 领域适应; 神经网络;,"提出了一种基于神经网络的中文分词方法,以提高分词系统向新领域迁移的适应性和灵活性。该文方法采用了对现有分词器分词结果进行纠正的思路。这种基于纠正的两阶段方法与分词模型解耦,避免了对源领域语料和分词器构建方式的依赖。然而现有的基于纠正的方法依赖于特征工程,无法自动适应不同领域。该文利用神经网络对纠正器进行建模,在无需手工设计特征的情况下即可实现领域适应。实验表明,与当前方法相比,该文方法在领域文本上具有更好的分词性能和鲁棒性,尤其在未登录词召回率方面提升显著。 ",MESS201706007
基于词分布式表征的汉语框架排歧模型,"张力文1:36382827|王瑞波1,2:13897708|李茹1,3,4:08453268|张晟1:36382826",8,汉语框架; 框架排歧; 分布式表征;,"框架排歧是根据句子中目标词的上下文语境,从框架库中为该目标词自动选择一个合适的框架。该任务在一定程度上解决了动词中一词多义的现象。该文基于词语及句子的分布式表征,提出了基于距离和基于词语相似度矩阵的框架排歧模型。与传统方法相比,该模型有效避免了人工选择特征,克服了特征空间维度过高、特征之间没有关联性等缺点,使框架排歧的准确率达到65.71%。并与当前最好的模型,进行显著性和一致性检验,进一步验证了词分布式表征对框架排歧任务的有效性。 ",MESS201706008
一种针对句法树的混合神经网络模型,"霍欢1,2:23576979|张薇1:09618889|刘亮1:26403314|李洋1:10846733",9,句法树; TreeLSTMs; TBCNNs; 并行性; 混合模型;,"在多数神经网络模型仍然将目光放在顺序结构上时,近期出现的两种基于句法树的模型TreeLSTMs和TBCNNs由于加入了结构信息而在多个自然语言处理任务上表现出色。考虑到TreeLSTMs因计算空间关联性使其训练效率不高,该文提出一种针对句法树的混合神经网络模型,借助TBCNNs的树卷积和池化方法实现了类似TreeLSTMs的计算,故将此模型命名为Quasi-TreeLSTMs。该文在依存树和支持树上分别构建了模型的两种版本Dependency Quasi-TreeLSTMs和Constituency Quasi-TreeLSTMs,实验结果表明,在情感分类和语义相似性两类任务上Quasi-TreeLSTMs表现优异。 ",MESS201706009
实体驱动的双向LSTM篇章连贯性建模,杜舒静:38526143|徐凡:31367729|王明文:08472511,8,实体; 篇章连贯性; 双向LSTM; 分布式表示;,"篇章连贯性建模是自然语言处理研究领域的一个基础问题。主流的篇章连贯性模型分为两大类,分别是基于实体网格的连贯性模型和基于神经网络的篇章连贯性模型。其中,基于实体网格的篇章连贯性模型需要进行特征提取,而基于深度学习的模型没有充分考虑篇章中句子间的实体链接对连贯性建模的重要作用。基于此,该文首先抽取篇章中相邻句子的实体信息,将其进行分布式表示,然后将此信息通过多种简单且有效的向量操作融合至句子级的双向LSTM深度学习模型之中。在汉语和英语篇章语料上的句子排序和中英文机器翻译连贯性检测两种任务上的实验表明该文提出的模型性能和现有模型相比有所提升,尤其在中文上有显著提升。 ",MESS201706010
汉语日常会话的对话行为分析标注研究,周强:08836151,8,会话分析; 对话行为标注; 话题线索;,"对话行为分析是进行更深入的对话理解模型探索的合适切入点。该文综合前人研究成果,设计了一套针对汉语日常会话的对话行为标注体系。引入主客观阐述和正反向反应子类,加强对话行为依存对和连贯修辞对的结构描述,同时引入话题线索分析机制,有效组织会话中的话题变化趋势。基于500个日常会话片段进行的对话行为标注实验中显示出了90%左右的双人独立标注宏一致率,表明目前的对话行为标记集设计具有良好的可操作性,可以适应汉语日常会话的行为功能模式描述需求。 ",MESS201706012
对外汉语教学领域可比语料库的构建及应用研究——以“把”字句的句法语义标注及应用研究为例,谭晓平:38526144,10,可比语料库; 对外汉语教学; “把”字句;,"该文构建了一个规模为11万字的,包含自然语料、对外汉语教材语料和汉语中介语语料的小型""把""字句可比语料库,制订了""把""字的句法语义标注框架,对语料库中1 556个""把""字句进行了句法语义标注,开发了检索界面,探讨了可比语料库在""把""字句教学与研究中的应用。数据显示:汉语教材中表示具体空间转移、描述动作的方式和次数、信息转移、致使类的""把""字句偏多,但表示抽象空间转移、判断或认同类的""把""字句偏少。学习者对于结果类""把""字句掌握较好;教材中S+把+N+V+状态补语、S+把+N1+V+N2等五种结构形式的""把""字句偏多,但S+把+N1+V为+N2、S+把+N1+V到+N2等六种结构形式的""把""字句偏少。学习者须依次加强S+把+N+V+趋向补语、S+把+N1+V到+N2等17种结构形式的""把""字句的学习。研究认为汉语可比语料库可为对外汉语教材研究、教材编排、二语习得研究、课堂教学提供数据支持与语料基础。 ",MESS201706013
融合概念对齐信息的中文AMR语料库的构建,"李斌1:08075606|闻媛1:36638639|宋丽1:36382828|卜丽君1:36638640|曲维光2,3:08112756|薛念文4:36638641",10,抽象语义表示; 语义图; 句子语义; 语言知识库;,"作为一种新的句子语义表示方法,抽象语义表示(AMR)将一个句子抽象为单根有向无环图,目前已经建立了较大规模的英文语料库。然而,句子中的词语和AMR图的概念对齐信息缺失,使得自动分析效果和语料标注质量受到影响,同时中文尚无较大规模的AMR语料库。该文介绍了中文AMR语料库的构建工作,针对汉语特点调整了AMR的标注体系,增加对复句关系的标注,提出了融合概念对齐的一体化标注方案,解决了中英文输入法频繁切换的问题,增加了错别字纠正和未标注词高亮功能,提高了标注效率。然后,从CTB中选取了6 923句进行人工标注,形成中文AMR语料库,统计得到图和环的比例分别为48%和1%,以及利用对齐信息才能获取的非投影句的比例32%,为中文AMR的理论和自动分析研究奠定基础。 ",MESS201706014
藏汉神经网络机器翻译研究,"李亚超1,2:27243481|熊德意2:32622753|张民2:31758527|江静1:28750005|马宁1:09136899|殷建民3:23062859",7,藏语; 神经网络机器翻译; 注意力机制; 循环神经网络; 迁移学习;,"神经网络机器翻译是最近几年提出的机器翻译方法,在多数语言对上逐渐超过了统计机器翻译方法,成为当前机器翻译研究前沿热点。该文在藏汉语对上进行了基于注意力的神经网络机器翻译的实验,并采用迁移学习方法缓解藏汉平行语料数量不足问题。实验结果显示,该文提出的迁移学习方法简单有效,相比短语统计机器翻译方法,提高了三个BLEU值。从译文分析中可以看出藏汉神经网络机器翻译的译文比较流畅,远距离调序能力较强,同时也存在过度翻译、翻译不充分、翻译忠实度较低等神经网络机器翻译的共同不足之处。 ",MESS201706015
CRF与规则相结合的维吾尔文地名识别研究,"买合木提·买买提1,2:22440290|卡哈尔江·阿比的热西提1,2:31758537|艾山·吾买尔1,2:10775068|吐尔根·依布拉音1,2:17705003|王路路1,2:35686939",9,命名实体; 维吾尔文; 地名; 条件随机场; 词向量;,"该文通过维吾尔文地名的分析研究,提出了一种基于条件随机场和规则的维吾尔文地名识别方法。根据维吾尔文地名黏着性、音译等特点,针对维吾尔文地名识别任务,在词汇和词性特征基础之上,引入音节、词向量获取的相似单词、常用地名词典、地名特征词、地名词缀等特征进行实验,结果表明这些特征对识别性能有较大的影响。通过对错误识别结果分析,该文提出了基于规则的后处理,进一步提高了识别性能,准确率达到94.68%,召回率达到89.52%,F值达到92.03%。 ",MESS201706017
基于分写增强字符向量和LSTM-CRF的朝鲜语自动分写方法,"金国哲1,2:30001967|崔荣一1:09291242",6,朝鲜语; 自动分写; 分写增强字符向量; LSTM-CRF;,"朝鲜语自动分写问题类似于中文分词问题,属于朝鲜语自然语言处理中的基本问题。首先,针对传统的朝鲜语自动分写方法中依赖人工特征的问题,该文提出一种朝鲜语分写增强字符向量训练模型KWSE,用于获取包含语义及分写倾向性信息的字符向量。其次,将朝鲜语分写增强字符向量与LSTM-CRF模型结合,完成朝鲜语自动分写任务。实验结果表明该方法的单词级分写F1值为92.86%,优于其他方法。 ",MESS201706018
基于双语主题和因子图模型的汉语-越南语双语事件关联分析,唐莫鸣:38526145|朱明玮:38526146|余正涛:05982358|唐培丽:38526147|高盛祥:07892541,8,汉越双语新闻事件; 事件关联; 多语言文本;,"随着""一带一路""国家战略实施,我国与越南的交流与合作日益密切,及时掌握两国新闻事件动态意义重大。该文针对汉越双语新闻事件关联分析所面临的跨语言关联问题,研究汉越双语新闻事件关联分析方法。汉越双语新闻事件分析其实质是多语言多文本的理解问题。其主要难点是要解决多语言多文本下的新闻事件理解问题。该文提出了基于因子图模型的局部密切度传播算法。首先使用双语主题概率模型,从双语文档中获得双语主题及主题概率分布,然后基于新闻事件的文本相似度构建事件因子图模型,在因子图上对相互关联的事件使用局部密切度传播算法计算某一主题下所有相互关联的事件间的影响力。最后得到不同主题下事件间的影响力拓扑图。实验结果表明该方法相比相似度计算和词语共现的方法取得了不错效果。 ",MESS201706019
问答中的问句意图识别和约束条件分析,孙鑫:26105827|王厚峰:06274413,8,长短期记忆网络; 条件随机场; 注意力机制;,"意图识别和约束条件分析是口语理解(SLU)中的两个重要过程。前者是分类问题,判断话语意图;后者可以看作序列标注问题,给关键信息标特定标签。该文提出了一种LSTM联合模型,同时结合了CRF和注意力机制。在ID问题上,将所有词语输出层向量的加权和用于分类;在SF问题上,考虑标签之间的转移,计算标签序列在全局的可能性。在中文数据集和ATIS英文数据集上的实验验证了该文所提方法的有效性。 ",MESS201706020
深度学习中汉语字向量和词向量结合方式探究,李伟康:38526148|李炜:06264443|吴云芳:06270718,7,字向量; 词向量; 深度学习; 问答系统;,"该文旨在探究深度学习中汉语字向量和词向量的有效结合方式。我们在以词作为基础语义单元和以字作为基础语义单元这两个方向进行探究,实验了字、词信息多种浅层结合方式和深层结合方式。为了验证该文提出的结合方式的有效性,我们改进了一种compare-aggregate模型,并在基于文档的问答系统上进行了实验。实验结果表明,有效的汉语字向量和词向量的结合方式超越了单独的字向量和词向量,提升了基于文档的问答系统的性能,使其结果与目前最好的结果可媲美。 ",MESS201706021
基于双向LSTM和两阶段方法的触发词识别,何馨宇:38526149|李丽双:06521783,8,触发词识别; 两阶段方法; 双向LSTM; 依存词向量;,"生物事件抽取是生物文本挖掘领域的一个重要分支,而触发词识别作为事件抽取的重要子过程,已经吸引了众多的关注。现有的触发词识别方法多为浅层的一阶段方法,训练代价较大,且需要丰富的领域知识抽取大量特征,人工成本较高。因此,该文提出了一种基于两阶段和双向LSTM神经网络的触发词识别方法。首先,将触发词识别分为识别和分类两个阶段,有效地缓解了训练过程中存在的类不平衡问题;其次,在两个阶段中均采用目前性能较好的双向LSTM神经网络来完成二分类任务和多分类任务,避免了浅层机器学习方法抽取人工特征时的代价。此外,利用PubMed数据库下载大规模语料训练带有依存关系的词向量,获得了更加丰富的语义信息,从而有效地提高了触发词的识别性能。该文方法在生物事件抽取通用语料MLEE上已获得目前最好抽取性能,F值为78.46%。 ",MESS201706022
一种话题敏感的抽取式多文档摘要方法,应文豪:36646384|李素建:06264429|穗志方:06268960,7,文本自动摘要; 卷积神经网络; 排序学习;,"抽取式摘要的核心问题在于合理地建模句子,正确地判断句子重要性。该文提出一种计算句子话题重要性的方法,通过分析句子与话题的语义关系,判断句子是否描述话题的重要信息。针对自动摘要任务缺乏参考摘要作为训练数据的问题,该文提出一种基于排序学习的半监督训练框架,利用大规模未标注新闻语料训练模型。在DUC2004多文档摘要任务上的实验结果表明,该文提出的话题重要性特征能够作为传统启发式特征的有效补充,改进摘要质量。 ",MESS201706023
基于多模态神经网络的图像中文摘要生成方法,"刘泽宇1,2:33315192|马龙龙1:27055084|吴健1:09573880|孙乐1:10352504",10,图像中文摘要; 多模态处理; 神经网络;,"图像的自然语言描述(image captioning)是一个融合计算机视觉、自然语言处理和机器学习的跨领域课题。它作为多模态处理的关键技术,近年来取得了显著成果。当前研究大多针对图像生成英文摘要,而对于中文摘要的生成方法研究较少。该文提出了一种基于多模态神经网络的图像中文摘要生成方法。该方法由编码器和解码器组成,编码器基于卷积神经网络,包括单标签视觉特征提取网络和多标签关键词特征预测网络,解码器基于长短时记忆网络,由多模态摘要生成网络构成。在解码过程中,该文针对长短时记忆网络的特点提出了四种多模态摘要生成方法 CNIC-X、CNIC-H、CNIC-C和CNIC-HC。在中文摘要数据集Flickr8k-CN上实验,结果表明该文提出的方法优于现有的中文摘要生成模型。 ",MESS201706024
基于汉语框架语义网的篇章关系识别,"李国臣1,2:08407515|张雅星1:38527894|李茹1,3,4:08453268",9,篇章关系; 汉语框架语义网; 篇章单元; 核心目标词;,"篇章关系识别是篇章分析中一项具有挑战性的子任务。传统的篇章关系分析主要是用篇章的局部特征对篇章关系进行分析,但是局部特征无法直接诠释篇章单元的外部语义关系,因此该文基于汉语框架语义网识别篇章关系,在框架语义层面对篇章单元进行分析。该文主要利用汉语框架语义网中的目标词,对篇章单元进行分析,从而识别出篇章关系。实验结果表明,核心目标词能更完整地表达篇章单元的核心语义,对篇章关系的识别有较好的效果。 ",MESS201706026
基于优化样本分布抽样集成学习的半监督文本分类方法研究,"徐禹洪1,2:34071703|黄沛杰1:24966316",10,文本分类; 半监督学习; 集成学习; 样本抽样策略;,"针对现有文本分类方法在即时性文本信息上面临的挑战,考虑到即时性文本信息具有已标注数据规模小的特点,为了提高半监督学习的分类性能,该文提出一种基于优化样本分布抽样集成学习的半监督文本分类方法。首先,通过运用一种新的样本抽样的优化策略,获取多个新的子分类器训练集,以增加训练集之间的多样性和减少噪声的扩散范围,从而提高分类器的总体泛化能力;然后,采用基于置信度相乘的投票机制对预测结果进行集成,对未标注数据进行标注;最后,选取适量的数据来更新训练模型。实验结果表明,该方法在长文本和短文本上都取得了优于研究进展方法的分类性能。 ",MESS201706027
基于整数线性规划的商家属性抽取研究,"孙庆英1,2:37558014|王中卿1:23843509|朱巧明1:05968617|周国栋1:13898054",7,商家属性; 属性抽取; 整数线性规划; 最大熵;,"商家属性是指商家本身具备的一些属性,比如就餐环境、停车位等。商家属性对于用户决策有很大的帮助,比如用户开车去就餐,就会关心饭店是否提供停车位。该文提出了一种新的基于整数线性规划的商家属性抽取模型,用来自动地从评论文本中抽取商家属性。首先使用最大熵分类器从用户发表的评论中抽取单个商家属性,然后利用整数线性规划模型,通过添加不同属性之间的关联条件,对整个模型进行协同优化学习。实验证明该方法能够有效地抽取商家属性。 ",MESS201706028
面向中国学生的英语书面语动词形式错误自动检查——基于链语法的研究,陈功1:11039747|梁茂成2:10548868,9,语法检查; 动词形式错误; 型式语法; 链语法;,"该研究以型式语法为理论基础,通过链语法形式化语法体系对动词型式进行了形式化,并对链语法动词词典进行了重构,旨在构建一个更好的面向中国学生的英语书面语动词形式错误检查系统。测试结果显示,重构后链语法词典的查错性能和句法分析能力得到提高。对错句检查的召回率比原词典提高了4.5%,准确率提高了15.7%;对本族者正确分析句子的准确率提高了12.2%。研究表明,该研究所基于的语言学理论(动词型式语法)和形式模型(链语法)可以较好地适用于中国学生书面英语动词形式错误检查系统的构建。 ",MESS201706029
基于局部密度的无监督作文跑题检测方法,"李霞1,2:06840132|温启帆2:38526151",9,作文跑题检测; 主题词抽取; 切题度; 阈值选取;,"针对现有的无监督作文跑题检测方法中,使用作文内容向量表示作文存在非主题词噪声所导致的相似度不准确问题,该文提出一种基于作文主题词抽取和局部密度阈值选择的无监督作文跑题检测方法。首先使用LDA主题生成模型挖掘待测作文的主题词,并使用分布式表示向量寻找与题目词项语义相似的词,作为对作文题目的主题词扩展,在此基础上使用提出的切题度计算方法计算待测作文的切题度,并使用所提出的基于作文集切题度局部密度的阈值抽取方法动态选取切题阈值,进而实现一种无需训练集和主题无关的无监督作文跑题检测方法。在以英语为母语的学习者和以汉语为母语的学习者所写的8个作文集共9 381篇作文上的实验结果表明,该文提出的作文跑题检测方法能有效识别跑题作文,加入拼写检查预处理后,平均F1值为79.64%,单个作文题目下F1值最好为96.1%。 ",MESS201706030
面向高考阅读理解鉴赏题语言风格判别方法,"陈鑫1:08400749|王素格1,2:08454306|李德玉1,2:08401294|谭红叶1,2:08402552|陈千1,2:29259586|王元龙1,2:34932595",9,层次分类; 语言风格; 阅读理解; 鉴赏题;,"语言风格是高考阅读理解中的重要考察内容,然而不同考察方式所需的分类层次不尽相同,该文将语言风格鉴赏转化为层次分类问题。在类别标签指导下,利用图分割算法,获取与特定类别相对应的原始簇。基于原始簇,利用层次聚类获取语言风格类别层次结构,之后结合层次结构训练SVM层次分类器。在解答语言风格鉴赏题过程中,依据阅读理解题干确定所需分类层次,利用SVM层次分类器完成对阅读材料语言风格判别,最后结合知识库生成语言风格鉴赏题答案。实验结果表明,基于层次结构的语言风格判别方法,可以为高考鉴赏类考题的解答提供技术支撑。 ",MESS201706031
第十三届全国机器翻译研讨会在大连成功举办,,1, ,"<正>2017年9月27-29日,第十三届全国机器翻译研讨会(CWMT 2017)在大连顺利举办,会议由中国中文信息学会主办,大连理工大学承办。中国中文信息学会理事长方滨兴院士,大连理工大学电子信息与电气工程学部党委书记张晓华分别致欢迎辞。大会开幕式由组委会主席、大连理工大学教授 ",MESS201706033
中国中文信息学会2017学术年会暨理事会在深圳成功召开,,1, ,"<正>2017年11月25—26日,中国中文信息学会2017学术年会暨理事会在深圳隆重举行,会上邀请了五位国内外专家做学术报告,并对学会2017年开展的技术评测工作进行了回顾,来自中文信息处理领域的专家学者300余人参加了本次会议。大会开幕式由中国中文信息学会副理事长兼秘书长、中国科学院软件研究所孙乐研究员主持,中国中文信 ",MESS201706034
第十六届全国计算语言学学术会议(CCL-2017)在南京成功召开,,1, ,"<正>2017年10月13日至15日,""第十六届全国计算语言学学术会议""与""第五届基于自然标注大数据的自然语言处理国际学术研讨会""在南京师范大学成功举行。会议由中国中文信息学会主办,南京师范大学承办,组织单位为清华大学智能技术与系统国家重点实验室。会议的大会主席由中国科学院计算技术研究所 ",MESS201706035
第三届中国健康信息处理大会(CHIP 2017)在深圳成功召开,,1, ,"<正>2017年11月23—24日,由中国中文信息学会医疗健康与生物信息处理专业委员会主办,哈尔滨工业大学(深圳)承办的第三届中国健康信息处理大会(CHIP 2017)在深圳大梅沙隆重举行。会议首先分别邀请了国内三位健康医疗领域杰出的青年学者开设前沿讲习班和四位生物医学信息学领域杰出的青年学者开设青年论坛。随后邀请了三名国 ",MESS201706036
中文信息学报(双月刊) 2017年 第31卷 总目次,,14, , ,MESS201706037
商务印书馆新书目录,,1, , ,MESS201706038
基于物性结构的无向型名词语义构词研究——以汉语同义类语素双音节合成词为例,刘璐:25403938|亢世勇:10882043,9,语义构词; 物性结构; 转喻; 隐喻; 隐转喻;,"该文首先介绍了鲁东大学进行的语义构词研究,说明了""无向型名词""的所指;进一步运用物性结构理论,分析语素义转指的六种类型,并提出结合转喻、隐喻、转隐喻理论共同解释""无向型名词""词义构成的研究方法;根据两个语素义如何通过转喻或隐喻转化为词义,将无向型词语分为八类。根据物性结构理论,具体分析无向型词语的语素义体现了哪种物性角色,语素义与词义是什么关系,语素义是基于相关性发生转喻还是基于相似性发生隐喻。最后总结了语素义整合转化为词义的特点,八种类型中前项—后项转喻(包含整体转喻)、前项—后项隐喻(包含整体隐喻)数量最多,符合人类普遍认知规律。 ",MESS201704001
词语序差的分布特点与文本间词汇异同,"刘锐1,2:09196676|孙碧泽3:35535611|龙云飞4:34205750|王珊2:36383214",6,序差; 双尾分布; 主题内容; 文体风格;,"该文在已有关于""频级""""频序""研究的基础上,结合两种不同类型的语料,采用词汇计量分析方法,考察词语的""序差""所具有的分布特点。该研究发现,对于两种文本的共有词集,词的序差呈对称分布,且集中分布于中位数附近,存在离群值序差。这一特点在序差图上表现为""中段平直,双尾翘曲""的""双尾分布""形态。根据词语序差的分布规律,可以将文本共有词划分为""中段""""下尾""""上尾""三个层次。""中段""词语反映两个文本的共性特征,""下尾""及""上尾""词语反映两个文本的差异性特征,这些特征具有反映文本的主题内容和文体风格的语言学意义。 ",MESS201705003
基于规则的汉语疑问词“什么”的语义识别模型构建,牛长伟1:33768862|程邦雄2:07589393,7,什么; 语义识别模型; 词义排歧;,"汉语疑问词具有多义性,至少有三种通用解读:疑问解读、存在解读(虚指)和全称解读(任指)。该文从汉语疑问词的词义排歧角度出发,通过总结汉语疑问词三种解读所处的句法环境的共同特征,确立其在复杂句法环境中的强势解读,进而构建一个基于规则的汉语疑问词的语义识别模型,为制订词义排歧决策表提供依据。该文以词义最多的疑问词""什么""为例,尝试通过这一思路,来构建基于规则的""什么""的语义识别模型和词义排歧决策表,并通过实验来验证,然后将其改进。 ",MESS201705004
基于概念知识树的双宾短语分析,"林子琦1,2:32789351|倪晚成1:45687235|赵美静1:29201483|杨一平1:11176182",12,双宾短语; 概念知识树; 语法分析; 语义表达模型;,"双宾短语是一种特殊的语言现象,为了使计算机能够理解并处理双宾短语,该文从语法和语义两个层面对双宾短语进行了分析,基于概念知识树知识表示模型建立了双宾短语的语义表达模型;并提出一种双宾短语分析算法,实现了从双宾短语到其语义表达模型的自动转换。双宾短语分析算法采用自顶向下和自底向上相结合的方法,自顶向下用于对双宾短语的语法成分进行划分,获得构成双宾短语的双宾动词成分、间接宾语成分和直接宾语成分;自底向上用于使用基于概念知识树的短语分析推理算法对双宾短语中的这三种成分分别进行分析,获得对应的语义表达;最后,利用三种成分的语义分析结果构建双宾短语完整的语义表达。该文从权威文献和语法词典中选取了122个双宾动词,对这些双宾动词构成的209个短语进行了分析,分析的正确率为90.43%,证明了该文提出的双宾短语分析算法和语义表达模型的有效性。 ",MESS201705005
基于句本位图解树库的汉语句式实例获取,"朱淑琴1,2:37829929|彭炜明1:24186788|宋继华1:06364557|郭冬冬1:38128587",8,句本位图解树库; 句式结构; 句式实例获取;,"为了将中文树库更好地服务于国际汉语教学,考虑到语法教学中句式框架的整体性,该文引入基于句式结构的句本位图解树库,深入分析其结构特征,并基于句式结构的分层抽取思路,提取了蕴含在每个标注句中的句式实例,构建了汉语句式实例库,具体分为基础句式实例库和复杂句式实例库两部分。该项工作使得小规模标注树库可以获取较大规模的句式实例库,为句本位图解树库在国际汉语教学中的应用提供了一种有效的数据解决方案。 ",MESS201705006
基于CFN的汉语篇章连贯性研究,"吕国英1:08401954|苏娜1:34417201|李茹1,2:08453268|王智强1:25200586",10,框架; 篇章单元; 篇章结构; 篇章关系; kappa值;,"篇章连贯性研究是篇章分析领域的重要课题之一。基于Chinese FrameNet(CFN),该文构建了汉语篇章连贯性描述体系,该描述体系研究了框架语义与篇章单元的关系,探讨了篇章如何通过框架与框架之间的语义关系实现篇章的连贯,为篇章连贯提供了合适的描写机制和计算基础。从《人民日报》选取了160篇文章进行标注实践,在篇章结构和篇章关系两方面均取得了大于0.8的kappa值,验证了描述体系具有较高的人工标注一致性,可作为进一步进行大规模篇章标注语料构建的依据。 ",MESS201705007
译文语序的领域性思考:一种融合主题信息的领域自适应调序模型,刘梦眙:38128588|姚亮:08849993|洪宇:25038035|刘昊:32925637|姚建民:13898051,9,统计机器翻译; 领域适应性; 调序模型; 主题模型;,"领域自适应研究的目标是建立一种动态调整翻译模型,使翻译模型对目标领域的语言特征具备较强的学习和处理能力,借以保证翻译系统在不同领域获得平衡可靠的翻译能力。现有翻译模型的自适应研究已经取得显著进展,但调序过程的领域适应性研究相对较少。在该文前期工作中通过对大规模源语言和目标语言的真实互译样本统计发现,在语义等价的短语级互译对子中,36.17%的样本在不同领域中的语序存在显著差异。针对这一问题,该文从主题角度出发,探索不同主题分布下的短语调序差异,提出一种融合主题信息的领域自适应调序模型。实验结果显示,嵌入调序适应性模型的翻译系统取得了较为明显的性能优势。 ",MESS201705008
基于语料库的藏语语音合成单元选择算法,才让卓玛:11447913|才智杰:08166533,5,语音合成; 单元选择; 基本构件; 组合构件;,"在基于语料库的语音合成方法中,语音合成单元选择的优劣直接影响合成语音的自然度和流畅性。该文针对藏语言文字的特点,提出以基本构件、组合构件、字、词及句单元相融合的混合单元语音合成策略,并提出了藏语语音合成混合单元选择算法。主观评价与客观评测数据表明该策略与算法有效和合理,各类合成单元在开放语料上的覆盖率与语音合成效果均达到预期的目标。 ",MESS201705009
基于部件组合的联机手写“藏文—梵文”样本生成,王维兰1:09120056|卢小宝2:38128589|蔡正琦1:09119483|沈文韬1:36144329|付吉1:36144330|才科扎西1:11621850,10,联机手写; 藏文—梵文; 字符集; 部件组合; 样本生成;,"""藏文—梵文""包括500多个现代藏文、6 000多个梵音藏文,在文字识别领域属于大类别的字符集,所以联机手写样本采集是庞大而复杂的工程。鉴于此,提供了一种基于部件组合的""藏文—梵文""手写样本生成方法,主要包括:(1)确定""藏文—梵文""字符集和部件集;(2)获取""藏文—梵文""字丁的部件位置信息;(3)采集联机手写""藏文—梵文""部件的样本;(4)生成联机手写""藏文—梵文""字符集样本库。该文为联机手写""藏文—梵文""识别的研究提供字符训练样本库和测试样本库,提高了手写梵音藏文样本采集效率,解决了样本数量及多样性问题,降低了样本采集成本,为进一步联机手写梵音藏文识别的研究与系统开发奠定了基础。 ",MESS201705010
基于字素分割的蒙古文手写识别研究,范道尔吉1:08011551|高光来1:05981929|武彗娟2:38128590,7,蒙古文; 字素; HMM; 手写识别;,"隐马尔科夫模型(HMM)对序列数据有很强的建模能力,在语音和手写识别中都得到了广泛的应用。利用HMM研究蒙古文手写识别,首先需要解决的问题是手写文字的序列化。从蒙古文的构词和书写特点看,蒙古文由多个字素从上到下串联构成。选择字素集合和词的字素分割是手写识别的基础,也是影响识别效果的关键因素。该文根据蒙古文音节和编码知识确定了蒙古文字母集合,共包括1 171个字母。通过相关性处理、HMM排序筛选等手段得到长字素集合,共包括378个字素。对长字素经过人工分解,获得了50个短字素。最后利用两层映射给出了词转字素序列的算法。为了验证长短字素在手写识别中的效果,我们在HTK(hidden Markov model toolkit)环境下利用小规模字库实现了手写识别系统,实验结果表明短字素比长字素有更好的性能。文中给出的字素集合和词转字素序列的算法为后续基于HMM的蒙古文手写识别研究奠定了基础。 ",MESS201705011
齐普夫定律对朝鲜语适用性的测定,崔荣一:09291242|赵雪:25111789,5,朝鲜语信息处理; 齐普夫定律; 文字频率; 最小二乘法;,"该文目的在于验证齐普夫定律对朝鲜语的适用性。首先统计了朝鲜语大规模语料中的文字及字母两种语言单位的频率分布,然后利用最小二乘法对文字频率分布曲线进行了拟合,最后计算了文字字频齐普夫定律的参数估计值。实验结果表明,朝鲜语的文字和字母的频率与频级关系都近似符合齐普夫定律,验证了齐普夫定律对朝鲜语的适用性,这对朝鲜语的信息处理与研究具有重要的现实意义。 ",MESS201705012
蒙古语固定短语识别算法的设计与实现,斯·劳格劳:07995395,7,蒙古语; 固定短语识别; 有限状态自动机;,"固定短语的自动识别和标注是进行蒙古语文本处理的基础和前提条件。词类标注、短语标注、句法分析、语义分类及语义角色标注等基础研究和机器翻译、文本校对等应用系统的开发均以正确标注固定短语的文本为处理对象。该文在""蒙古语固定短语语法信息词典""的基础上采用基于有限状态自动机和规则的方法设计实现了固定短语识别和标注算法。经实验,其识别率已达到90%以上,在处理中,词均用时与基于字符串匹配的算法相比提高较多,达到0.005 0ms。 ",MESS201705013
维吾尔语名词短语待消解项识别,陶豆豆1:38128591|禹龙2:09256058|田生伟1:09220503|赵建国3:09252968|吐尔根·依布拉音4:17705003|艾斯卡尔·艾木都拉1:17704444,8,待消解项识别; 维吾尔语; 非负约束算法; 栈式自编码; 支持向量机;,"针对维吾尔语名词短语待消解项识别任务,该文提出一种利用栈式非负约束自编码器(Stacked Nonnegative Constrained Autoencoder,SNCAE)完成基于语义特征的待消解项识别方法。为了提高自动编码器隐藏层激活度的稀疏性和重构数据的质量,利用NCAE非负约束算法,为连接权值施加非负性约束。通过分析维吾尔语名词短语语言指代现象,提取出15个特征,利用SNCAE提取出深层语义特征,引入Softmax分类器,进而完成待消解项识别任务。该方法在维吾尔语名词短语待消解项识别中,正例准确率和负例准确率分别比SVM高出8.259%和4.158%,比栈式自编码(SAE)高出1.884%和1.590%,表明基于SNCAE的维吾尔语名词短语待消解项识别方法比SVM和SAE更适合维吾尔文的待消解项识别任务。 ",MESS201705014
基于语义串特征提取及融合评价的维吾尔文文本聚类,吐尔地·托合提:17704504|维尼拉·木沙江:17704505|艾斯卡尔·艾木都拉:17704444,9,维吾尔文; 语义串抽取; 特征评价及选取; 向量空间模型; K_means;,"该文研究一种改进的n元递增算法来抽取文本中表达关键信息的语义串,然后用多特征融合的评价方法为每一个文本选取最重要的语义串,并用这些语义串作为特征表示文本。通过K_means聚类分析的实验结果表明,以语义串作为特征可以构造比单词特征集更紧凑的文本模型,不仅可以大大降低特征空间的维度,对于提高聚类算法性能也是非常有效的。 ",MESS201705016
维吾尔文初中数学教材词干分析研究,"艾孜尔古丽1:26177339|艾孜海尔江1,2:32674441|玉素甫·艾白都拉1:22251454|祖力克尔江1,2:34722235|米尔夏提3:09255275",6,现代维吾尔语; 词干; 分析; 方法;,"该文将初中数学维吾尔文教材作为研究对象,根据维吾尔语的特点和统计学原理理论,从计算语言学角度调查初中数学维吾尔文教材用词干情况。该文主要研究维吾尔语词干、教材概貌、数据处理技术相关概念及其算法及现代维吾尔语语料处理工具,获取教材中词干基本情况、新增词干、初中数学教材高频词干,开展了初中数学维吾尔文教材词干调查,为维吾尔语研究、维吾尔文数学教学与教材编纂等提供参考依据,从而更加积极有效地促进维吾尔语语言本身研究及其信息处理的发展。 ",MESS201705017
基于弱监督和半自动方法的中文关系抽取数据集构建,马超义:38128592|徐蔚然:06420468,6,关系抽取; 数据集; 弱监督; 半自动;,"关系抽取是信息抽取中的一项基础任务,对信息检索、问答系统、知识图谱等有非常重要的意义。现有的关系抽取数据集存在包含类别太少、句子标注困难、不易扩展等缺陷,且只有英文数据集,不能很好地解决中文关系抽取任务。该文采用弱监督和半自动的方法,构建了一份中文关系抽取数据集,弥补了上述不足。首先借助维基百科抽取出丰富的关系对,从百度搜索返回结果及搜狗新闻语料中抽取包含实体对的句子,完成弱监督句子抽取过程。将句子放入RNN关系抽取系统进行打分,选取标注价值高的句子提交人工标注,对标注结果进行处理,最终得到中文关系抽取数据集。 ",MESS201705018
基于特征加权的新闻主题句抽取,万国:36400512|张桂平:24679273|白宇:24679275|朱耀辉:36153140,7,特征加权; 重合度; 关联度; 加权二部图;,"根据新闻文本的特点,分别对新闻标题与正文进行分析,该文提出了一种针对新闻文本的特征加权的主题句抽取方法。首先对新闻主题句在文本中的分布情况进行分析,选取了位置特征;然后根据新闻标题对于新闻主旨的提示作用,选取了标题句子重合度与关联度的特征,且在关联度特征中将基于加权二部图的最大匹配算法融入其中;最后依据句子的得分排名,进行主题句抽取。实验显示,利用该方法进行主题句抽取的P@1为75.9%,P@3达到92.4%。 ",MESS201705019
任意网页的主题信息抽取研究,"张儒清1,2:34652122|郭岩1:09559534|刘悦1:09639001|俞晓明1:09560060|程学旗1:09559496",11,任意网页; 主题信息; 网页分类; 实用价值;,"目前大部分的网页信息抽取方法都局限于某一类网页的提取,并没有进一步深入到适用于任意网页的抽取。针对这一问题,该文提出了一种基于融合机制的任意网页主题信息抽取框架,特点是通过""模板库匹配—基于模板抽取—网页分类—全自动抽取""四个步骤实现对模板无关的全自动抽取算法和基于模板的抽取算法的融合。实验显示,这种融合机制能促进抽取准确率的有效提高,从而最终建立起一个适用于任意网页的、具有实用价值的信息抽取框架。 ",MESS201705020
基于TF-IDF和余弦相似度的文本分类方法,"武永亮1,2:38128593|赵书良1,2:07149329|李长镜1,2:38128594|魏娜娣3:30889854|王子晏4:38128595",8,文本分类; 大数据; TF-IDF; 余弦相似度; 类别关键词;,"文本分类是文本处理的基本任务。大数据处理时代的到来致使文本分类问题面临着新的挑战。研究者已经针对不同情况提出多种文本分类算法,如KNN、朴素贝叶斯、支持向量机及一系列改进算法。这些算法的性能取决于固定数据集,不具有自学习功能。该文提出一种新的文本分类方法,包括三个步骤:基于TF-IDF方法提取类别关键词;通过类别关键词和待分类文本关键词的相似性进行文本分类;在分类过程中更新类别关键词改进分类器性能。仿真实验结果表明,本文提出方法的准确度较目前常用方法有较大提高,在实验数据集上分类准确度达到90%,当文本数据量较大时,分类准确度可达到95%。算法初次使用时,需要一定的训练样本和训练时间,但分类时间可下降到其他算法的十分之一。该方法具有自学习模块,在分类过程中,可以根据分类经验自动更新类别关键词,保证分类器准确率,具有很强的现实应用性。 ",MESS201705021
基于深度神经网络的搜索引擎点击模型构建,谢晓晖:11159353|王超:08237752|刘奕群:08176974|张敏:08186086|马少平:08177513,10,异质化结果; 深度神经网络; 点击模型;,"随着富媒体展现形式被越来越多地引入搜索交互界面,搜索引擎的结果页面呈异质化和二维模块展现形式,这对传统的点击预测模型提出了巨大的挑战。针对这一情况,我们对实际搜索引擎结果页面的多模态结果进行了分析,构建了一个结合深度神经网络和点击模型的框架,该框架既包含了神经网络的特性,又利用了点击模型的预测能力。我们希望利用这个框架挖掘出多模态信息与文本信息之间的相关性,使之具有描述异质化结果和二维模块展示形式的能力。实验表明,我们的框架相较于传统的点击模型在点击预测性能上有显著提升,但由于搜索引擎的多模态结果内容复杂,仅利用多模态结果的底层特征,即使使用深度神经网络,从中能够挖据出的语义相关性较弱。 ",MESS201705022
基于上下文的深度语义句子检索模型,"范意兴1,2:33384077|郭嘉丰1:14336892|兰艳艳1:30526869|徐君1:10348528|程学旗1:09559496",7,信息检索; 文本匹配; 循环神经网络;,"传统的信息检索的研究多集中在文档级的检索场景中,然而,句子级的检索在如移动应用以及信息需求更加明确的检索场景下具有非常重要的意义。在句子级的检索场景下,我们认为句子的上下文能够提供更加丰富的语义信息来支撑句子与查询的匹配,基于此,该文提出了一个基于句子上下文的深度语义句子检索模型(contextaware deep sentence matching model,CDSMM)。具体的,我们使用双向循环神经网络来建模句子内部以及句子上下文的语义信息,基于句子和查询的语义信息得到它们的匹配程度,在WebAP句子检索数据集上的实验表明,我们的模型性能显著地优于其他的方法,并取得了目前最好的效果。 ",MESS201705023
基于阈值的快速启动Top-k查询处理算法,"江宇1,2:29605903|宋省身2:36597898|杨岳湘3:21126670|姜琨4:36597897",8,Top-k查询处理; 阈值计算; 倒排索引;,"Top-k查询是搜索引擎领域广泛应用的技术之一,该算法从海量数据中返回最符合用户需求的前k个结果,在执行时能避免对大部分无关文档的打分处理。Top-k查询虽然极大提升了查询性能,但其存在的慢启动问题并未得到有效解决。为此,该文首先提取倒排索引的静态Top-k信息,再动态计算针对具体查询词项的初始阈值,在此基础上,结合MaxScore和WAND算法,提出了快速启动的Top-k查询处理算法。实验结果表明,该方法能够有效解决上述问题,具有良好的性能。 ",MESS201705024
基于双语信息的问题分类方法研究,徐健:10753555|张栋:09891027|李寿山:27030929|王红玲:08848649,7,问答系统; 问题分类; LSTM;,"问题分类是问答系统研究的一项基本任务。先前的研究仅仅是在单语语料上训练得到问题分类模型,存在语料不足和问题文本较短的问题。为了解决这些问题,该文提出了融合双语语料的双通道LSTM问题分类方法。首先,利用翻译语料分别扩充中文和英文语料;其次,将两种语言语料中的样本都分别用问题文本和翻译文本表示;最后,提出了双通道LSTM分类方法用于充分利用这两组特征,构建问题分类器。实验结果表明,该文提出的方法能有效提高问题分类的性能。 ",MESS201705025
一种级联式微博情感分类器的构建方法,张仰森1:15552896|孙旷怡2:29576728|杜翠兰2:13575022|王建1:38128596|佟玲玲2:29597833,7,微博; 情感词典; 基准词; 朴素贝叶斯模型; 级联式分类器;,"该文从统计学方法与机器学习的分类思想出发,对中文微博文本的情感类别进行研究。针对微博文本的特点,提出了一种级联式微博情感分类器模型,该模型首先构建基于情感词典和新浪表情符号词典的微博情感初级分类模型;然后根据基准词构建基于类别倾向相似度的二级分类模型,对初级模型未能确定情感类别的微博进行再次分类,并对初级模型的词典进行更新;最后采用朴素贝叶斯分类器构建三级分类模型,对以上还未确定情感类别的微博进行三级分类。通过与NLPCC2014微博情感分类评测参赛结果进行比较,说明了所提方法的有效性。 ",MESS201705026
基于迭代回归树模型的跨平台长尾商品购买行为预测,"白婷1,2:38128597|文继荣1,2:09750702|赵鑫1,2:32936762|杨伯华1,2:38128598",9,长尾商品; 电子商务; 社交媒体; 购买行为预测;,"长尾商品是指单种商品销量较低,但是由于种类繁多,形成的累计销售总量较大,能够增加企业盈利空间的商品。在电子商务网站中,用户信息量较少且购买长尾商品数量较少、数据稀疏,因此对用户购买长尾商品的行为预测具有一定的挑战性。该文提出预测用户购买长尾商品的比例,研究单一用户购买长尾商品的整体偏好程度。利用社交媒体网站上海量的文本信息和丰富的用户个人信息,提取用户的个人属性、文本语义、关注关系、活跃时间等多个种类的特征;采用改进的迭代回归树模型MART(Multiple Additive Regression Tree),对用户购买长尾商品的行为进行预测分析;分别选取京东商城和新浪微博作为电子商务网站和社交媒体网站,使用真实数据构建回归预测实验,得到了一些有意义的发现。该文从社交媒体网站抽取用户特征,对于预测用户购买长尾商品的行为给出一个新颖的思路,可以更好地理解用户个性化需求,挖掘长尾市场潜在的经济价值,改进电子商务网站的服务。 ",MESS201705027
面向社交网络的潜在药物不良反应发现,赵明珍:33405430|林鸿飞:06504899|徐博:23769215|郝辉辉:33522150,9,社交网络; 药物不良反应; 信息熵; Word2vec; Skip-gram;,"随着互联网的发展,社交网络中积累了大量的医疗健康领域的文本数据。该文利用基于信息熵的方法,从健康社交网络中的用药者评论数据中识别药物的潜在不良反应;同时,对于潜在药物不良反应,该文提出了基于Word2vec和Skip-gram模型的蛋白质关联紧密度函数,尽最大努力发现药物引起其""潜在""不良反应的证据链。实验证明,该方法用来寻求潜在药物不良反应证据链是有效的。 ",MESS201705029
基于WMD距离与近邻传播的新闻评论聚类,"官赛萍1,2:38128599|靳小龙1,2:26681578|徐学可1,2:28861560|伍大勇1,2:29729449|贾岩涛1,2:29294835|王元卓1,2:24307899|刘悦1,2:09639001",12,新闻评论聚类; 强化权重向量; 去背景化; Word Mover’s Distance; 近邻传播;,"随着新闻网站的快速发展,网络新闻和评论数据激增,给人们带来了大量有价值的信息。新闻让人们了解发生在国内外的时事,而评论则体现了人们对事件的观点和看法,这对舆情分析和新闻评论推荐等应用很重要。然而,新闻评论数据又多又杂,而且通常比较简短,因此难以快速直观地从中发现评论者的关注点所在。为此,该文提出一种面向新闻评论的聚类方法 EWMD-AP,用以自动挖掘社会大众对事件的关注点。该方法利用强化了权重向量的Word Mover’s Distance(WMD)计算评论之间的距离,进而用Affinity Propagation(AP)对评论进行聚类,从杂乱的新闻评论中得到关注点簇及其代表性评论。特别地,该文提出利用强化权重向量替代传统WMD中的词频权重向量。而强化权重由三部分组成,包括结合词性特征与文本表达特征的词重要度系数、新闻正文作为评论背景的去背景化系数和TFIDF系数。在24个新闻评论数据集上的对比实验表明,EWMD-AP相比Kmeans和Mean Shift等传统聚类算法以及Density Peaks等当前最新算法都具有更好的新闻评论聚类效果。 ",MESS201705030
基于用户隐性反馈行为的下一个购物篮推荐,李裕礞:28541698|练绪宝:35318029|徐博:23769215|王健:06522915|林鸿飞:06504899,8,下一个购物篮推荐; 隐性反馈; 时序行为; 卷积神经网络;,"下一个购物篮推荐是当前电子商务领域中极其重要的一项任务,传统的下一个购物篮推荐方法主要分为时序推荐模型和总体推荐模型。这些方法对点击、收藏、加入购物车等用户的隐性反馈行为利用得不够,并且没有考虑用户行为偏好的时间敏感性。该文提出了一种基于用户隐性反馈行为的下一个购物篮推荐方法,将用户行为按照一定的时间窗口进行划分,对于每个窗口从多个维度抽取用户对商品的时序偏好特征,运用深度学习领域的卷积神经网络模型进行分类器训练。在真实数据集中的实验结果表明,与传统的线性模型和树模型等分类器相比,该文提出的卷积神经网络框架具有较强的特征萃取能力和泛化能力,提高了推荐系统的用户满意度。 ",MESS201705031
庆祝商务印书馆创立120周年,,1, ,"<正>陈平语言学文选出版时间:2017年7月《汉语的形式、意义与功能》ISBN:978-7-100-13980-9《引进·结合·创新——现代语言学理论与中国语言学研究》ISBN:978-7-100-13981-6《语言与中国的现代化进程》ISBN:978-7-100-13982-3《汉语的形式、意义与功能》本书围绕汉语的形式、意义与功能三者关系展开,研究对象是汉语句法、语义、语用和话语分析中具有重大影响的研究课题,包括汉语句子组织的基本格局、话题结构、同指称相关的哲学、逻辑、语法、语义、语用和话语问题、时间结构、话语组织、 ",MESS201705032
全国知识图谱与语义计算大会(CCKS 2017)在四川成都隆重召开,,1, ,"<正>2017年8月26-29日,全国知识图谱与语义计算大会(CCKS 2017)在四川成都隆重召开。本次会议由中国中文信息学会语言与知识计算专业委员会主办,西华大学承办。大会分为讲习班和主会两个主要环节,其中讲习班暨中国中文信息学会《前沿技术讲习班》ATT第七期的主题是知识图谱。本次大会吸引了来自全国学术界、产业界从事知识图谱相关研究的500多人参加,会议探讨了知识图谱领域的新发现、新技术和新应用,旨在向社会公众介绍知识图谱与语义计算领域的发展趋势和创新成果,进一步推动我国语言与知识计算领域的发展。 ",MESS201705033
第六届全国社会媒体处理大会(SMP 2017)在北京隆重召开,,1, ,"<正>2017年9月14-17日,第六届全国社会媒体处理大会(SMP 2017)在北京隆重召开。本次会议由中国中文信息学会社会媒体处理专业委员会主办,中国科学院计算技术研究所承办。本次大会吸引了来自学术界、产业界和新闻界从事社会媒体处理研究或关注社会媒体发展的800多人参加。大会包括4个讲习班专题、8个大会特邀报告、8个论坛、2个技术评测报告和4场论文报告会,内容丰富,精彩纷呈。大会秉承学科交叉、兼容并蓄的发展理念,探讨了社会媒体处理领域的新发现、新技术和新应 ",MESS201705034
基于Web of Science的社会化媒体环境下社区发现研究综述,方倩:26146313|窦永香:09039039|王帮金:31163996,8,社会化媒体; 社区发现; 科学知识图谱; Web of Science;,"社会化媒体是一种新型在线媒体,发现并研究其中的社区有利于揭示社会化媒体环境下信息传播与共享的特点和规律。该文基于Web of Science检索得到的文献数据,使用CiteSpace、SATI、UCINET等科学知识图谱软件,从共被引文献、关键词及突现词等角度构建了社会化媒体环境下有关社区发现的科学知识图谱,并对该领域的研究现状、知识演进过程、研究热点和研究前沿进行了可视化分析。 ",MESS201703001
大数据时代的计算政治学研究,"杨阳1,2:17303211|林鸿飞1:06504899|杨亮1:14244075|任巨伟1:28913382",8,计算政治学; 计算社会科学; 大数据; 研究方法;,"政治学研究一直是社会科学领域的热点研究方向。政治理论、比较政治、公共政策和国际政治等,这些经典的政治学研究课题吸引了大批的政治学学者。从传统政治学研究中的道德哲学和法理主义,到行为主义政治学研究中的科学方法论和定量分析,再到一些自然科学工作者开始涉足政治学领域,政治学的研究方法一直在发展与演变。该文在对传统政治学研究的方法进行简要总结的基础上,针对互联网时代,""大数据""驱动下的政治学研究,阐述了计算政治学的起源、定义及其主要的研究内容和方法,论述了目前研究的热点政治倾向性及政治观点识别、冲突观点检测、选举预测和分析可视化的研究进展。 ",MESS201703002
网络语言中构式的形成机制初探,"黄思思1:10548224|詹卫东1,2:06264050",8,网络语言; 构式; 构式化; 语言演化;,"构式指整体意义无法从其组成部分简单加合出来的语言单位。该文以网络语言中的构式为考察对象,分析了网络语言中构式的浮现、扩散和固化的过程。网络语言中构式的浮现主要有语境赋义和错配成型两种机制。构式的扩散则可分为同范畴扩容和跨范畴变异两种情况。构式的固化程度可以通过能产性、图式性和组合性三个维度进行衡量。最后该文总结了网络语言中构式化的三个特点。 ",MESS201703003
基于词语关系的词向量模型,蒋振超:32481647|李丽双:06521783|黄德根:06527360,7,词表示; 词嵌入; 词向量; 神经网络; 关系模型;,"词向量能够以向量的形式表示词的意义,近来许多自然语言处理应用中已经融入词向量,将其作为额外特征或者直接输入以提升系统性能。然而,目前的词向量训练模型大多基于浅层的文本信息,没有充分挖掘深层的依存关系。词的词义体现在该词与其他词产生的关系中,而词语关系包含关联单位、关系类型和关系方向三个属性,因此,该文提出了一种新的基于神经网络的词向量训练模型,它具有三个顶层,分别对应关系的三个属性,更合理地利用词语关系对词向量进行训练,借助大规模未标记文本,利用依存关系和上下文关系来训练词向量。将训练得到的词向量在类比任务和蛋白质关系抽取任务上进行评价,以验证关系模型的有效性。实验表明,与skipgram模型和CBOW模型相比,由关系模型训练得到的词向量能够更准确地表达词语的语义信息。 ",MESS201703004
基于汉字固有属性的中文字向量方法研究,胡浩:29126397|李平:22414454|陈凯琪:36294955,9,短文本; 中文字向量; 深度学习;,"中文短文本在如今高速发展的互联网应用中变得日趋重要,如何从海量短文本消息中挖掘出有价值的信息,已成为当前中文自然语言处理中非常重要且具有挑战性的课题。然而,采用传统的长文本处理方法进行分析往往得不到很好的效果,其根本原因在于中文短文本消息的语法及其语义的稀疏性。基于此,该文提出一种基于汉字笔画属性的中文字向量表示方法,并结合深度学习对短文本消息进行相似性计算。该方法结合中文汉字的构词和拼音属性,将中文汉字映射为一个仅32维的空间向量,最后使用卷积神经网络进行语义提取并进行相似性计算。实验结果表明,与现有的短文本相似性计算方法相比,该方法在算法性能及准确率上均有较大的提高。 ",MESS201703005
面向隐喻识别的词语抽象性度量,贾玉祥1:10308738|昝红英1:09467924|范明1:09485307|俞士汶2:06272028|王治敏3:11255396,7,隐喻识别; 词语抽象性; 跨语言知识迁移;,"隐喻通常借助具体的概念来表达抽象的概念。如果能判断出文本中词语所指的概念是具体还是抽象的,即度量出词语的抽象程度,那么这将为隐喻的机器识别提供重要的依据。该文提出基于跨语言知识迁移的汉语词语抽象性度量方法,把英语中的词语抽象性知识迁移到汉语中来。提出基于词语抽象性知识的隐喻识别方法,并详细分析了词语抽象性与隐喻之间的关系。实验表明,知识迁移是可行的,基于抽象性知识的隐喻识别有较高的准确率,可以有效提高从真实文本中抽取隐喻的效率。 ",MESS201703006
情感词发现与极性权重自动计算算法研究,"张华平1,2:24480556|李恒训3:28813353|李清敏4:37340875",7,情感词; 情感权重; 情感程度判别; 情感词典;,"随着互联网电子商务和各种社交网络应用的快速发展,产生了大量的用户评价信息。为满足快速整理这些评价信息的需求,情感倾向性分析应运而生。情感词典是各类情感倾向性识别算法的基础,收集一部全面且权重合理的情感词典,往往可以简单快速而有效地解决情感分析问题。但情感词典规模有限,而网络上新的情感词层出不穷,语言使用不规范,人工整理耗时耗力。已有的情感词收集方法较复杂,且领域性强,收集的情感词可扩展性差。本文提出一种自动挖掘潜在情感词并计算其极性权重的算法,该算法与应用领域无关,具有良好的扩展性。该方法利用共现特性,基于朴素贝叶斯公式能检测出未知的情感词,并根据其情感权重值的大小判断其情感极性,可有效地扩展情感词典,将已有的情感词典进一步量化。在理论研究的基础上,本文分别针对京东、豆瓣及大众点评网三组评论语料做了实验,其结果的准确率都基本在90%以上,验证了该方法的有效性和实用性,为情感倾向性分析提供了知识库基础。 ",MESS201703007
面向社会媒体的开放领域新词发现,"张华平1,2:24480556|商建云3:06346952",7,社会媒体; 新词发现; 条件随机场;,"随着互联网的发展,社会媒体已经逐渐发展成为信息交流的重要载体。该文针对社会媒体文本的领域分布广、口语化程度高等特征,提出一种面向社会媒体的开放领域新词发现算法。此算法所有步骤均为线性时间复杂度,并且在分析过程中有效降低了内存的使用,从而能够实时处理社会媒体所产生的大规模数据。在6.6GB社会媒体文本语料中的新词发现准确率达到了87.2%,在普通计算机上新词发现速度可达2.6 MB/s。与传统算法相比,该算法在社会媒体领域的大规模语料中速度及精度上均有较好的效果。 ",MESS201703008
用于文本分类的局部化双向长短时记忆,"万圣贤1,2:31367734|兰艳艳1:30526869|郭嘉丰1:14336892|徐君1:10348528|庞亮1,2:36815829|程学旗1:09559496",7,文本分类; 深度学习; 长短时记忆; 卷积;,"近年来,深度学习越来越广泛地应用于自然语言处理领域,人们提出了诸如循环神经网络(RNN)等模型来构建文本表达并解决文本分类等任务。长短时记忆(long short term memory,LSTM)是一种具有特别神经元结构的RNN。LSTM的输入是句子的单词序列,模型对单词序列进行扫描并最终得到整个句子的表达。然而,常用的做法是只把LSTM在扫描完整个句子时得到的表达输入到分类器中,而忽略了扫描过程中生成的中间表达。这种做法不能高效地提取一些局部的文本特征,而这些特征往往对决定文档的类别非常重要。为了解决这个问题,该文提出局部化双向LSTM模型,包括MaxBiLSTM和ConvBiLSTM。MaxBiLSTM直接对双向LSTM的中间表达进行max pooling。ConvBiLSTM对双向LSTM的中间表达先卷积再进行max pooling。在两个公开的文本分类数据集上进行了实验。结果表明,局部化双向LSTM尤其是ConvBiLSTM相对于LSTM有明显的效果提升,并取得了目前的最优结果。 ",MESS201703009
基于内涵模糊概念格的汽车评价知识发现方法研究,"李旸1:29895353|郭晓敏1:23669609|王素格1,2:08454306|梁吉业1,2:08408575",8,汽车评价; 知识发现; 模糊形式概念分析; 内涵模糊概念; 模糊概念格;,"为了有效利用汽车评论数据,参照已建立的汽车评价本体,从文本中抽取评价搭配对,提出基于五元组的对象评价度量,从而获取汽车评价模糊形式背景。在模糊形式背景中,定义了内涵模糊概念和内涵模糊概念格。设计了模糊形式背景和内涵模糊概念格构建算法,并以实例对如何基于内涵模糊概念格进行知识发现予以讨论。 ",MESS201703010
中文模糊限制信息范围语料库的研究与构建,周惠巍1:13896094|杨欢1:29895357|徐俊利1:37337812|张静2:17320983|亢世勇2:10882043,9,中文模糊限制信息范围; 标注规则; 语料库;,"模糊限制语用于表示不确定性的观点。由模糊限制语所引导的信息为模糊限制信息,开展中文模糊限制信息检测研究,对事实信息抽取意义重大。模糊限制信息检测包含模糊限制性句子识别和模糊限制信息范围检测两个子任务。中文模糊限制信息范围语料库的缺乏,影响了中文模糊限制信息检测的研究。该文研究制定了基于短语结构的中文模糊限制信息范围标注规则,构建了中文模糊限制信息范围语料库。最后对标注的语料库进行了统计和分析。该文语料库的构建为中文模糊限制信息检测研究提供了资源支持。 ",MESS201703011
汉英篇章结构平行语料库的对齐标注评估,"冯文贺1,2:36636463|李艳翠3:23391989|任函1:36636466|周国栋4:13898054",8,篇章结构; 平行语料库; 对齐标注; 结构对齐; 对齐评估;,"汉英篇章结构平行语料库是为汉英翻译文本标注对齐篇章结构信息的语料库,对齐标注是其核心工作,基本原则是""结构对齐、关系对齐""。该文基于所开发的对齐标注平台,进行人工对齐标注实验,提出切分对齐、结构对齐、关系对齐、连接词对齐、关系角色与中心对齐等对齐标注任务的评估方法,并给出评估分析。实验表明,对齐标注是构建汉英篇章结构平行语料库的合理、有效工作方式。 ",MESS201703012
基于CRF模型的网络新闻主题线索发掘研究,"徐静1,2:10375385|杨小平1:09751479",7,主题线索; 条件随机场; 线索链;,"为了准确挖掘出同一主题的大量网络新闻的线索发展脉络,该文提出了一种基于条件随机场模型的网络新闻主题线索发掘方法。首先,根据新闻主题线索句的识别规则提取出相关特征,并应用到条件随机场模型中提取出主题线索句;然后,按照时间顺序构建原始线索链;最后,对语义相近的原始线索链进行合并处理,获得最终的新闻主题发展脉络。实验结果表明,该方法在主题线索句识别上有较好的效果,最终得到的主题线索脉络能够较清晰地展现新闻发展趋势。 ",MESS201703013
基于特征驱动的微博话题检测方法,"贺敏1:31560377|刘玮1,2:15034678|刘悦1:09639001|王丽宏2:28474623|白硕1:09596143|程学旗1:09559496",9,话题检测; 微博; 关键特征; 逻辑回归; 聚类;,"该文针对微博数据稀疏、内容关系难以计算的特点,提出了一种基于特征驱动的微博话题检测方法。提取有意义串作为微博动态特征,根据微博的结构关系计算特征的作者影响力和文档影响力,与内容统计特性共同构成特征的属性组,采用逻辑回归对特征建模,基于属性组对特征二元分类得到话题关键特征,将关键特征之间的互信息作为距离度量,改进最近邻聚类方法对关键特征聚类产生话题。微博数据实验表明,该方法有效提高了微博话题检测的准确率和召回率。 ",MESS201703014
在线评论质量有用特征识别:基于GBDT特征贡献度方法,"王洪伟1:08965813|孟园1,2:32265223",9,GBDT; 评论质量; 特征贡献度; 信息采纳模型; 递归特征消除;,"面对海量的在线评论,有用特征识别有助于消费者选择高质量的评论,为合理决策提供支持。该文基于信息采纳模型理论,在数码相机和手机数据集上提取了四类影响评论质量的有用特征集合,以logistic岭回归和基本decision tree模型作为基准模型,并结合递归特征消除(RFE)降维方法,比较检验了GBDT模型对评论质量分类和特征降维上的表现,揭示了各特征项对评论质量分类结果的""贡献度"",进而识别关键特征。实验结果表明,基于GBDT模型对评论质量分类效果较好,评论发表时间、评论者排名、关键特征数量、评论字数是影响评论质量的关键特征。 ",MESS201703015
基于领域的影响力最大化与病毒营销,刘泉:14370677|张铭:06276534,7,影响力最大化; 领域发现; 领域影响力;,"近年来随着新浪微博、人人网等社交网络新媒体的涌现,线上影响力传播得到了越来越多企业和研究机构的关注。如何在给定资源的约束下实现最大的传播范围(影响力最大化问题),对病毒营销等市场战略的有效开展有着重要意义。如果能充分利用社交网络上的异质性信息来更准确地定位用户所属的领域,进而基于领域实现影响力最大化,将对从整体角度出发的传统研究和片面的结构或内容角度的研究形成很好的补充。该文同时利用新浪微博上用户之间的社交关系和微博内容的话题两个维度的信息将用户划分为不同的领域;进而提出了一种基于贪心和动态规划混合的改良算法实现基于领域的影响力最大化。实验表明该文的领域影响力模型较好优化了传统影响力最大化的时间消耗,同时拥有相近的精度。 ",MESS201703016
基于LDA主题模型的分布式信息检索集合选择方法,何旭峰1:30928953|陈岭1:10276766|陈根才1:09370161|钱坤1:10590707|吴勇2:29301770|王敬昌2:25362626,9,集合选择; 分布式信息检索; LDA;,"该文针对分布式信息检索时不同集合对最终检索结果贡献度有差异的现象,提出一种基于LDA主题模型的集合选择方法。该方法首先使用基于查询的采样方法获取各集合描述信息;其次,通过建立LDA主题模型计算查询与文档的主题相关度;再次,用基于关键词相关度与主题相关度相结合的方法估计查询与样本集中文档的综合相关度,进而估计查询与各集合的相关度;最后,选择相关度最高的M个集合进行检索。实验部分采用Rm、P@n和MAP作为评价指标,对集合选择方法的性能进行了验证。实验结果表明该方法能更准确的定位到包含相关文档多的集合,提高了检索结果的召回率和准确率。 ",MESS201703017
基于矩阵分解的个性化推荐系统研究,张时俊:37337815|王永恒:24156189,7,矩阵分解; 个性化推荐系统; 社交网络; 用户建模;,"随着社交网络的快速发展,用户在使用社交应用时会产生大量有价值的数据。通过对社交网络进行数据挖掘,发现隐藏在数据中关联用户与物品之间的偏好关系。然后对用户建模分析,选择合适的推荐引擎进行个性化物品推荐,这是一个非常有价值的研究方向。该文重点研究矩阵分解算法对处理大规模用户与物品评分矩阵的推荐效果,为了提高推荐的准确度展开了对用户社交关系和隐性反馈的研究,在组合预测模型中加入社交关系、人口统计学信息配置项、用户的消费记录等隐因子项,通过实验验证了扩展之后的混合预测模型在RMSE值上比SVD算法降低了0.259 475,在推荐性能有较大幅度的提高。 ",MESS201703018
基于依存句法分析的复合事实型问句分解方法,刘雄:25417570|张宇:06997645|张伟男:23769189|刘挺:06994824,7,问句分解; 复合事实型问句; 问句理解; 问答系统; 自然语言处理;,"问答系统一直以来都是自然语言处理领域的研究热点之一,然而现有问答系统技术对复合事实型问句的处理效果并不完美。为了增强问答系统理解复合事实型问句的能力,该文提出了一种针对复合事实型问句的分解方法:使用基于树核的支持向量机对问句的分解类别进行识别,进而使用基于依存句法分析的方法生成分解结果。实验结果显示,在我们所构建的高质量问句分解语料库中,我们的方法对问句分解类别进行了准确的识别,同时也可以较好地生成嵌套型问句的子问句。 ",MESS201703019
一种融合用户主题兴趣与用户行为的文档推荐方法,张桂平:24679273|翟顺龙:36400558|王裴岩:24679272,9,用户模型; 主题兴趣; 用户行为; 文档推荐;,"针对单一角度描述用户兴趣存在片面性的问题,该文提出一种融合用户主题兴趣和用户行为的文档推荐方法。一方面从主题兴趣的角度,构建反映用户主题兴趣的主题向量用户模型;另一方面从用户行为的角度,构建反映用户行为兴趣的打分矩阵用户模型。然后,基于上述用户模型提出了两种文档推荐方法,并采用线性加权的方式融合这两种方法,从而实现对用户主题兴趣与用户行为的融合。实验结果表明,该方法的推荐结果好于协同过滤推荐方法和基于内容的推荐方法。 ",MESS201703020
基于规则和统计相结合的西里尔蒙古文到传统蒙古文转换方法,飞龙:23670720|高光来:05981929|王洪伟:33922789|路敏:36582081,7,西里尔蒙古文; 传统蒙古文; 转换; 规则; 联合序列模型;,"西里尔蒙古文与传统蒙古文分别是蒙古国与中国使用的蒙古文,西里尔蒙古文到传统蒙古文的转换工作不仅给两国同胞的交流带来更多的便利,而且对蒙古族的科学、文化和教育发展具有重要意义。本文结合规则与统计模型的优点,研究了西里尔蒙古文到传统蒙古文的转换方法。本文首先采用基于规则的方法对西里尔蒙古文集内词进行转换,其次对集外词的转换采用了基于联合序列模型的方法,并采用N-gram语言模型解决了一个西里尔蒙古文单词对应多个传统蒙古文单词的问题。实验结果表明,该系统单词转换错误率低至4.12%,基本达到了实用要求。 ",MESS201703021
基于多特征的藏文微博情感倾向性分析,江涛:23407964|袁斌:34433057|于洪志:09120080|加羊吉:24688520,7,藏文微博; 混合文本; 情感倾向; 情感词; 词性序列;,"中英文微博大都以单一语种来表述,而将近80%的藏文微博都是以藏汉混合文本形式呈现,若只针对藏文内容或中文内容进行情感倾向性分析会造成情感信息丢失,无法达到较好效果。根据藏文微博的表述特点,该文提出了基于多特征的情感倾向性分析算法,算法使用情感词、词性序列、句式信息和表情符号作为特征,并针对藏文微博常出现中文表述的情况,将中文的情感信息也作为特征进行情感计算,利用双语情感特征有效提高了情感倾向性分析的效果。实验显示,该方法对纯藏文表述的微博情感倾向性分析正确率可达到79.8%,针对藏汉双语表述的微博在加入中文情感词、中文标点符号等特征后,正确率能够达到82.8%。 ",MESS201703022
基于情感词向量的微博情感分类,"杜慧1,2:32481680|徐学可1:28861560|伍大勇1:29729449|刘悦1:09639001|余智华1:09560057|程学旗1:09559496",7,情感分析; 情感分类; 词向量; 机器学习;,"该文提出了一种基于情感词向量的情感分类方法。词向量采用连续实数域上的固定维数向量来表示词汇,能够表达词汇丰富的语义信息。词向量的学习方法,如word2vec,能从大规模语料中通过上下文信息挖掘出潜藏的词语间语义关联。本文在从语料中学习得到的蕴含语义信息的词向量基础上,对其进行情感调整,得到同时考虑语义和情感倾向的词向量。对于一篇输入文本,基于情感词向量建立文本的特征表示,采用机器学习的方法对文本进行情感分类。该方法与基于词、N-gram及原始word2vec词向量构建文本表示的方法相比,情感分类准确率更高、性能和稳定性更好。 ",MESS201703023
一种基于情感依存元组的简单句情感判别方法,"周文1,2:31033476|欧阳纯萍1:26808225|阳小华1:08033226|刘志明1:08025798|张书卿1:32144888|饶婕1:13897413",7,情感依存元组; 情感倾向性; 依存语法; 句法分析;,"基于依存句法""动词配价""原理与组块的概念,提出以情感依存元组(EDT)作为中文情感表达的基本单位。它以句中能承载情感的几类实词作为中心词,修饰词依附于中心词,程度词和否定词依附于中心词和修饰词。该文对句子进行句法分析,在句法树和依赖关系中按规则提取情感依存元组,建立简单句情感依存元组判别模型计算情感倾向性。针对COAE2014评测公布的网络新闻语料,将该方法分别与有监督分类算法(KNN、SVM)和半监督算法(K-means)进行实验对比。结果表明,基于EDT的情感分类性能与有监督的机器学习算法相当,远高于半监督的聚类算法。 ",MESS201703024
基于深度模型的社会新闻对用户情感影响挖掘,"孙晓1:17392399|高飞1:07064074|任福继1,2:27168503",8,深度信念网络; 限制玻尔兹曼机; 情感影响; 社会新闻;,"该文研究了社会新闻中影响读者情感的深层特征。使用三种文本特征选择方法,分别从一元词、二元词和主题粒度下提取文本浅层特征,使用支持向量机模型选择三种粒度下最优浅层特征并且进行分类,得到最优宏平均F1值分别为60.5%、62.1%、63.3%。引入深度信念网络模型,使用三种粒度下最优浅层特征作为输入,进一步训练和抽象得到深层特征,实验中使用深度为3的深度信念网络模型进行训练与分类,最优宏平均F1值分别为61.4%、63.5%、66.1%。实验结果表明,深层特征比浅层特征具有更多的文本语义信息,可以更好地判断社会新闻对公众情绪影响。 ",MESS201703025
基于弱监督预训练深度模型的微博情感分析,"万圣贤1,2:31367734|兰艳艳1,2:30526869|郭嘉丰1,2:14336892|程学旗1,2:09559496",7,情感分析; 深度学习; 弱监督; 预训练-微调整;,"微博情感分析对于商业事务和政治选举等应用非常重要。传统的做法主要基于浅层机器学习模型,对人工提取的特征有较大的依赖,而微博情感特征往往难以提取。深度学习可以自动学习层次化的特征,并被用于解决情感分析问题。随着新的深度学习技术的提出,人们发现只要提供足够多的监督数据,就能训练出好的深度模型。然而,在微博情感分析中,通常监督数据都非常少。微博中广泛存在着弱监督数据。该文提出基于弱监督数据的""预训练—微调整""训练框架(distant pretrain-finetune),使用弱监督数据对深度模型进行预训练,然后使用监督数据进行微调整。这种做法的好处是可以利用弱监督数据学习到一个初始的模型,然后利用监督数据来进一步改善模型并克服弱监督数据存在的一些问题。我们在新浪微博数据上进行的实验表明,这种做法可以在监督数据较少的情况下使用深度学习,并取得比浅层模型更好的效果。 ",MESS201703026
新浪微博谣言检测研究,祖坤琳:33544319|赵铭伟:06523974|郭凯:26594830|林鸿飞:06504899,7,新浪微博; 谣言检测; SVM; 情感计算;,"社会网络信息的可信度问题近年来受到了相当大的关注。谣言的散播可能造成社会恐慌,引发信任危机。在国内,新浪微博用户量的快速增长,使其成为了谣言传播的温床。及时清理在新浪微博中传播的谣言,对于社会的和谐发展有着现实的意义。该文以新浪微博为背景,将谣言检测任务作为分类问题,首次提出将微博评论的情感倾向作为谣言检测分类器的一项特征。实验结果表明,引入评论的评论情感倾向特征后,使得谣言检测的分类结果得到了可观的提升。 ",MESS201703027
基于桥系数的分裂社区检测算法研究,冀庆斌:32932207|康茜:32932206|李德玉:08401294|王素格:08454306,8,社区检测; 分裂算法; 桥系数;,"研究社区结构有助于揭示网络结构和功能之间的关系,而社区检测是社区结构研究的基础和核心。该文定义了一种聚集度桥系数,将其应用到社区检测中,设计出一种分裂社区检测方法,包括分裂和合并两个算法。分裂算法使用桥系数识别社区间边,通过迭代删除社区间边分解网络,从而发现网络中的社区结构;合并算法根据社区连接强度合并社区,可以揭示社区结构中的分层嵌套的现象。在六个社会网络数据集上的实验表明,本文算法可以有效的将网络分裂为有意义的社区,并且准确性接近或超过经典的社区检测算法。 ",MESS201703028
基于最小割图分割的社区发现算法,王亚珅:34826313|黄河燕:23136252|冯冲:24549647,10,社区发现; 模块度; 最小割图分割;,"该文证明了模块度最大化问题可以被转换成为原网络上的最小割图分割问题,并且基于该证明提出了一种高效的社区发现算法。同时,该文创新性地将模块度理论与当今比较流行的统计推理模型相结合:首先,这些统计推理模型被转化为模块度最大化问题中的零模型;其次,统计推理模型中的目标函数被修改并应用于本文的最优化算法中。实验结果显示,无论是在真实世界网络还是在人工生成网络中,该文提出的算法均具有高效和稳定的发现社区的能力。 ",MESS201703029
东亚太平洋语言的基本词及与印欧语的对应,,1, ,"<正>《东亚太平洋语言的基本词及与印欧语的对应》书号:978-7-100-11955-9定价:85元开本:16开本书有50篇分别讨论意义相关词项的文章,以说明东亚太平洋的语言和印欧语基本词的词源关系。一部积多年之功研究东亚太平洋语言与印欧语词源关系的力作。 ",MESS201703030
商务印书馆2016年度语言学出版基金评选揭晓,,1, ,"<正>2017年3月14日,商务印书馆举行2016年度语言学出版基金评议会。经评议委员会专家评议并投票,王芳的《重叠功能模式的类型学研究》和吴波的《江淮官话音韵研究》入选基金资助项目。该基金设立于2002年,由商务印书馆斥资100万元,用于资助国内语言学著作的出版。每年评选一次,这次为第15届。凡获基金资助的著作,均列入商务印书馆""中国语言学文库""出版。 ",MESS201703031
中国中文信息学会2017年分支机构工作研讨会在京召开,,1, ,"<正>中国中文信息学会2017年分支机构工作研讨会于2017年3月29日在北京中国科学院软件研究所召开。学会理事长方滨兴院士、名誉理事长李生教授出席会议,来自学会分支机构的主任、秘书长和学会工作人员等23人参加了本次会议。会议由学会副理事长兼秘书长孙乐研究员主持。会上首先明确了中国科协的改革精神,对分支机构今后的工作指明了方向。会议主要讨论分支机构的管理条例,包括组建流程、分支机构人员组成、分支机构撤销、分支机构标识等内容。各工作委员会和专业委 ",MESS201703032
《中文信息学报》期刊网站及公众号上线通知,,1, ,"<正>为适应当前学术期刊电子化和标准化建设的需要,更好地服务读者,促进科技成果的交流与分享。《中文信息学报》在线投审稿系统现已正式上线,并开通了微信公众号,在PC端和移动端同时提供服务,原投稿邮箱(jcip@iscas.ac.cn)不再接受邮箱投稿,只做联系使用。《中文信息学报》期刊网站荟萃自本刊创刊以来的全部文献,是一个集信息发布、远程稿件处理、网刊发 ",MESS201703033
汉语介词短语自动识别研究综述,李洪政:30682057|晋耀红:24682727,10,介词短语; 识别; 规则; 统计;,"作为一种重要的短语类型,介词短语在汉语中分布广泛,正确识别汉语介词短语对自然语言处理领域的很多任务和应用都有重要的作用和意义。该文对近些年与识别汉语介词短语有关的研究做了梳理,从研究对象、实验评价标准和具体研究方法等几个方面比较详细地介绍了相关工作,最后归纳了汉语介词短语识别研究中表现出来的一些特点,并对未来研究的发展提出了几点建议。 ",MESS201702001
现代汉语隐喻式双音节名名复合词研究——基于生成词库理论,赵青青1:36977249|宋作艳2:25019866,7,名名复合词; 隐喻; 生成词库; 物性角色; 语义类;,"该文基于生成词库理论中的物性结构和语义类框架,对现代汉语双音节隐喻式名名复合词进了语义信息标注。在此基础上,我们对这些复合词进行了定量与定性分析,即考察了复合词在隐喻过程中涉及的物性角色、探索语义类对隐喻涉及物性角色的影响、以及语素语义类与复合词整体语义类之间的相关性。研究结果显示:形式角色是隐喻式名名复合词中最常涉及的物性角色;自然类在发生隐喻时较多涉及构成角色,而人造类则较多涉及功用角色。并且,构词语素的语义类对复合词整体的语义类具有一定的预测性。 ",MESS201702002
面向文本信息处理的汉语句子和小句,"宋柔1,2:34071693|葛诗利1:24597890|尚英2:06428017|卢达威2:30152896",8,汉语篇章处理; 句子; 小句; 广义话题结构; 话题自足句;,"小句和句子分别是篇章信息处理的基本单位和复合单位。但是汉语中,这两个概念至今未有公认的适用于语言信息处理的界定,这种状况阻碍了汉语信息处理的发展。该文将汉语的句子大致界定为自足的广义话题结构,把小句界定为基于广义话题结构的话题自足句,并提出了这样界定的语言学依据和认知依据。 ",MESS201702003
基于HITS算法的双语句对挖掘优化方法,刘昊:32925637|洪宇:25038035|姚亮:08849993|刘乐:32925638|姚建民:13898051|周国栋:13898054,11,统计机器翻译; 特定领域机器翻译; 特定领域双语网站; 权威性;,"识别和定位特定领域双语网站,是基于Web自动构建特定领域双语语料库的关键。然而,特定领域双语网站之间的句对质量往往差异较大。相对于原有基于句对文本特征识别过滤质量较差句对的方法。该文从句对的来源(即特定领域双语网站)出发,依据领域权威性高的网站往往蕴含高质量平行句对这一假设,提出一种基于HITS算法的双语句对挖掘优化方法。该方法通过网站之间的链接信息建立有向图模型,利用HITS算法度量网站的权威性,在此基础上,仅从权威性高的网站中抽取双语句对,用于训练特定领域机器翻译系统。该文以教育领域为目标,验证""领域权威性高的网站蕴含高质量句对""假设的可行性。实验结果表明,利用该文所提方法挖掘双语句对训练的翻译系统,相比于基准系统,其平均性能提升0.44个BLEU值。此外,针对HITS算法存在的""主题偏离""问题,该文提出基于GHITS的改进算法。结果显示,基于GHITS算法改进的机器翻译系统,其性能继续提升0.40个BLEU值。 ",MESS201702004
基于特征加权重叠度的中文实体协同消歧方法,线岩团:23245672|余正涛:05982358|洪旭东:30038174|张磊:10631974|郭剑毅:07895859,6,实体消歧; 实体链接; 加权重叠度; 近邻传播聚类;,"该文针对中文实体消歧中的特征项部分匹配和协同消歧问题,提出基于特征加权重叠度的中文实体协同消歧方法。该方法利用实体指称上下文中多种特征的加权重叠度计算实体指称相似度,针对实体链接与消歧聚类约束,分类定义实体指称相似度计算方法,构建待消歧实体相似度矩阵,采用近邻传播聚类算法实现中文实体协同链接与消歧。基于CLP-2012评测数据的实验表明,提出的方法取得了较好的消歧效果,准确率、召回率和F值分别达到了84.01%、87.75%和85.65%。 ",MESS201702006
利用句法信息改进交互式机器翻译,张亚鹏:32885850|叶娜:24679276|蔡东风:24679274,7,交互式机器翻译; 子树信息; 译文前缀;,"在很多领域中,全自动机器翻译的译文质量还无法达到令人满意的程度。要想获得正确无误的译文,往往需要翻译人员对自动翻译系统的输出进行后处理。在交互式机器翻译的框架内,翻译系统和译员协同工作,译员确认系统提供的译文中的最长正确前缀,系统据此对译文后缀进行预测,共同完成翻译任务。该文利用基于短语的翻译模型,建立了交互式机器翻译系统,并结合交互式机器翻译的特点,利用句法层面的子树信息来指导翻译假设的扩展。实验表明,该方法可以有效地减少人机交互次数。 ",MESS201702007
基于网络搜索的英汉人名翻译,刘颖:08230768|曹项:35580709,6,人名翻译; 音译相似度; 规则; 翻译概率;,"该文利用搜索引擎从网络中挖掘英语人名的中文翻译。该方法综合利用翻译辅助词、英中人名共现规则、音译相似度和翻译概率。首先,利用搜索引擎从互联网上搜索英文人名的中文翻译候选。把汉语人名标注结果、翻译辅助词、英中人名共现规则和英文人名的发音音节长度结合起来提取翻译候选词。翻译辅助词有助于搜索与英文人名更相关的信息,英中人名共现规则和发音音节长度进一步缩小英文人名的翻译范围,使得英文人名的翻译搜索符合人名共现规律和发音规律。然后,根据音译相似度和翻译概率对候选词进行排序。人名翻译的绝大部分是根据发音翻译过来的,音译相似度是帮助判断两个词在发音上的相似性。翻译概率从统计上判断两个词互为翻译的可能性。实验结果表明,翻译辅助词、规则、音译相似度和翻译概率都有助于提高人名翻译的正确率。 ",MESS201702008
基于基频的朝鲜语方言辨识方法的研究,刘双君:30877949|金小峰:09291671|崔荣一:09291242,7,方言辨识; 语种辨识; 基频特征; 移位差分系数; 支持向量机;,"该文提出了一种基于基音频率特征的中国朝鲜族语言、韩国朝鲜语和朝鲜朝鲜语方言的自动辨识方法。首先,选择具有良好区分度的基频移位差分系数作为三个方言的特征参数;其次,设计和采用了分层支持向量机分类器,并进一步引入投票法确定最佳的分类结果。实验结果表明该文提取的特征参数具有良好的区分性和较强的稳定性,该文提出的方言辨识方法比传统的移位差分倒谱系数特征方法识别率高,可以有效解决朝鲜朝鲜语、韩国朝鲜语和中国朝鲜族语言的方言辨识问题。 ",MESS201702009
基于大规模网络语料的藏文音节拼写错误统计与分析,刘汇丹:09573793|洪锦玲:26179693|诺明花:15570459|吴健:09573880,10,藏文拼写检查; 拼写检查; 语料; 统计; 藏文信息处理; 中文信息处理;,"针对从互联网获取的一份包含19万藏文网页,总计427万句、9 328万音节字的藏文文本语料,该文按照预定的规则对其中的藏文音节拼写错误情况进行了统计与分析。数据显示,在语料中出现的共计20 743个藏文音节中,含有拼写错误的音节共有9 700个,占藏文音节总数的46.762 8%,错误音节在语料中共出现27 427次,仅占0.030 8%,说明这份语料的文本质量是相当高的。文中还详细统计了各种不同表现形式的错误音节所占比重,并分析了导致拼写错误的四个主要原因:一是输入了多余的元音符号;二是音节点或句尾空格缺失;三是同一字丁/字符存在多种表达形式;四是错误地使用了相似字符。 ",MESS201702010
融合无监督特征的藏文分词方法研究,李亚超:27243481|加羊吉:24688520|江静:28750005|何向真:09119510|于洪志:09120080,6,藏文; 分词; 序列标注;,"藏文分词是藏文信息处理的基础性关键问题,目前基于序列标注的藏文分词方法大都采用音节位置特征和类别特征等。该文从无标注语料中抽取边界熵特征、邻接变化数特征、无监督间隔标注等无监督特征,并将之融合到基于序列标注的分词系统中。从实验结果可以看出,与基线藏文分词系统相比,分词F值提高了0.97%,并且未登录词识别结果也有较大的提高。说明,该文从无标注数据中提取出的无监督特征较为有效,和有监督的分词模型融合到一起显著提高了基线分词系统的效果。 ",MESS201702011
一种面向突发事件的文本语料自动标注方法,刘炜:08480650|王旭:09543375|张雨嘉:33434548|刘宗田:05974886,10,突发事件; 语料库; 自动标注;,"事件语料库是研究语义Web中事件知识的抽取、表示、推理和挖掘的基础和关键技术之一。该文以事件作为文本知识单元,在LTP分析的基础上,用序列模式挖掘算法PrefixSpan从现有的小规模语料库中挖掘事件要素的词性规则等,用同义词词林(扩展版)对触发词表进行了扩充,结合自定义的事件要素词典,采用多遍过滤、逐遍完善的思想提出一种针对大规模突发事件语料库构建的自动标注方法,在实验部分不仅与人工标注做了对比,同时与Stanford CoreNLP NER进行了对比,实验效果理想。 ",MESS201702012
融合全局词语边界特征的中文命名实体识别方法,"刘冰洋1,2:31156616|伍大勇1:29729449|刘欣然3:10628857|程学旗1:09559496",6,命名实体识别; 字序列标注; 全局特征; 词语边界特征;,"目前在中文命名实体识别的任务中经常采用有监督的字序列标注模型。我们在实际应用中发现,基于字序列标注模型的中文命名实体识别模型对于词语边界的识别错误是影响识别效果的主要因素之一,边界错误平均占错误结果中的47.5%。该文通过在平均感知机模型中引入全局的词语边界特征,使得人名、地名、机构名识别的F值平均提升了0.04并降低了边界错误占错误结果的比例。 ",MESS201702013
基于宏特征融合的文本分类,王丹丹1:36977250|陈清财2:30526870|王晓龙2:06993266|汤步洲2:17503829,7,文本分类; 有监督宏特征抽取; 无监督宏特征抽取; 特征融合;,"宏特征(即文档级特征)抽取方法是文本分类中一类典型的特征抽取方法,可以分为有监督宏特征抽取和无监督宏特征抽取。这两类宏特征抽取方法均能提高文本分类的性能。但是,同时使用两类宏特征的情况还没有被研究。该文研究了有监督宏特征和无监督宏特征融合对文本分类性能的影响。具体来讲,研究了两种有监督宏特征抽取方法,与三种无监督宏特征抽取方法,即K-means、LDA和DBN,相互融合的情况。在两个公开语料库Reuters-21578和20-Newsgroup以及一个自动构建的语料库上的对比实验表明,有监督和无监督宏特征之间的融合比单独使用有监督或者无监督宏特征的方式对文本分类更加有效。 ",MESS201702014
中文文学作品中的社会网络抽取与分析,"赵京胜1,2:36977251|张丽2:24733412|朱巧明1:05968617|周国栋1:13898054",9,文学作品; 社会网络; 自然语言处理;,"应用自然语言处理技术和复杂网络技术,可以对中文文学作品中内含的社会网络进行抽取和分析。该文以《三国演义》为例,抽取了其中的社会网络,节点是作品中的人物,边是人物之间的联系,边的权重为各章回中的人物共现次数。借助背景知识和互联网构建了角色库辅助网络建模。对构建出来的社会网络进行分析,包括节点度分布、中心性、聚类特征等。结果表明,中文文学作品中的角色分布具有明显的小世界性、有限幂律分布特征和社区特性,同时也有多面性和多元性。 ",MESS201702015
微博客蕴含交通事件信息抽取的自动标注方法,"仇培元1,2:30264955|张恒才1:27622616|余丽1,2:32045070|陆锋1:09607498",10,微博客; 信息抽取; 交通事件; 条件随机场; 支撑向量机;,"微博客文本蕴含丰富的实时交通事件信息,能够为现有交通信息采集手段提供补充。然而,当前事件抽取方法缺少对地理实体关系的判断过程,对涉及多个地理实体及关系表达的地理空间要素抽取效果不佳,难以准确识别交通事件信息的位置描述。该文提出一种自动标注方法,将地理实体关系识别引入事件抽取过程来解决这一问题。该方法利用条件随机场模型实现交通事件角色标注,利用支撑向量机模型实现角色关系与要素关系标注,完成了交通事件信息空间要素识别。以新浪微博为数据源开展的实验分析表明,该文所提出的微博客蕴含交通事件抽取方法,正确率和召回率均达到90%,优于现有的基于模式匹配的抽取方法。 ",MESS201702016
利用框架语义知识优化事件抽取,陈亚东:24880537|洪宇:25038035|王潇斌:28130962|杨雪蓉:28523621|姚建民:13898051|朱巧明:09891804,9,事件抽取; 信息抽取; 框架语义;,"事件抽取旨在把含有事件信息的非结构化文本以结构化的形式予以呈现。现有的基于监督学习的事件抽取方法往往受限于数据稀疏和分布不平衡问题,具有较低的召回率。针对这一问题,该文提出一种利用框架语义优化事件抽取的方法,引入框架类型作为泛化特征,在此基础上进行框架类型和事件类型的映射,然后结合框架类型识别模型和事件类型识别模型进行协作判定,以此优化事件抽取的召回性能。实验结果显示,针对触发词(事件类型)识别任务,相较于仅使用事件类型识别模型,该文提出的框架语义辅助的事件类型识别模型能够提高抽取召回率6.44%(5.74%),提高F值1.45%(0.83%)。 ",MESS201702017
面向信息内容安全的文本过滤模型研究,刘梅彦:11412123|黄改娟:15551287,7,文本信息过滤; 不良文本; 语义分析; 依存句法分析;,"该文设计了一种面向信息内容安全的不良文本信息过滤模型。该模型采用主题信息过滤和倾向性过滤两级过滤模式,以语句为基本处理单元,采用依存句法获取语句的语义框架,结合基于知网的词汇褒贬倾向性判别,识别文本中的不良信息并予以过滤。实验表明,该模型能够较好地提高文本过滤效率和准确率。 ",MESS201702018
基于用户回答顺序的社区问答答案质量预测研究,徐安滢1:36977252|吉宗诚2:33357901|王斌3:33053079,7,答案质量预测; 排序学习; 社区问答; 回答顺序;,"近年来,随着互联网的普及和知识爆炸性的增长,社区问答网站积累了大量的用户和内容,同时也产生了大量的低质量文本,极大地影响了用户检索满意答案的效率,因此如何提升答案质量预测的性能十分重要。目前,社区问答答案质量预测方面的研究大都是使用点方式(pointwise)来实现分类模型,但由于问题的难度不同,对答案的要求也有所差异,使用点方式会忽略掉部分答案的特点,所以该文使用点对方式(pairwise)来预测答案质量。另外,已有的研究工作表明,社区问答中同一问题下的答案数量特征对答案质量预测没有效果,甚至有冗余作用。对于时间差也有相同的结论,即不能提升预测性能。该文提出了一种将上述两者结合在一起的新特征,实验结果表明,该特征能显著提高社区问答答案质量预测的性能。 ",MESS201702019
新浪微博隐式组织发现,刘程:36977253|沙灜:33015039|姜波:36977254|郭莉:32902263,8,社交网络; 隐式组织; 机器学习算法;,"社交网络中往往同时存在多种类型的账号,如正常个体用户、水军、僵尸粉、蓝V组织等。我们把其行为呈现为组织特性的个体账号,定义为隐式组织。隐式组织通常背后有相应的组织团队负责账号的运营,因此其行为模式呈现为组织的行为模式,有别于个体账号。隐式组织的有效发现对于社交网络中舆情传播趋势分析、广告推荐等都有重要的意义。该文以新浪微博数据为例,在数据采集系统基础上,共人工标注了583个账号,提取了22个特征,使用朴素贝叶斯和决策树算法,实现了对隐式组织的有效识别,其准确率达86.4%,并分析得出了特征的重要程度排序。实验证明了社交网络中存在隐式组织,其行为特征是可以识别的。 ",MESS201702020
结合信任度与社会网络关系分析的微博推荐方法研究,"李慧1,2:07636922|马小平2:09610495|施珺1:07649647|仲兆满1:27149673|蔡虹1,3:07636856",8,信任度; 社会网络; 矩阵分解; 微博; LDA;,"随着微博网络的盛行,越来越多的微博信息困扰用户无法快速定位自己感兴趣的博文。为了解决微博信息过载问题,信息过滤、推荐和搜索等技术被应用于微博研究中。该文提出了一个综合信任模型、社会网络关系分析的综合推荐模型,应用LDA主题模型及矩阵分解技术推断微博的主题分布和用户的兴趣取向,实现微博的个性化推荐。通过实验验证,该方法能十分有效地解决个性化博文推荐问题。 ",MESS201702021
一种融合个性化与多样性的人物标签推荐方法,"颛悦1,2:29498770|熊锦华1,2:09596985|程学旗1,2:09559496",9,人物标签推荐; 多样性推荐; 标签冗余; 标签质量;,"针对人物标签推荐中多样性及推荐标签质量问题,该文提出了一种融合个性化与多样性的人物标签推荐方法。该方法使用主题模型对用户关注对象建模,通过聚类分析把具有相似言论的对象划分到同一类簇;然后对每个类簇的标签进行冗余处理,并选取代表性标签;最后对不同类簇中的标签融合排序,以获取Top-K个标签推荐给用户。实验结果表明,与已有推荐方法相比,该方法在反映用户兴趣爱好的同时,能显著提高标签推荐质量和推荐结果的多样性。 ",MESS201702022
一种基于领域本体的稿件—审阅人相关度度量方法,"肖刘明镜1:31878016|周志2:31878015|邹小军2:27278521|胡俊峰1,2:06243608",6,审阅人指派; 相似度计算; 领域本体; 信息检索;,"随着稿件数量的不断增长,审阅人指派越来越成为会议组织者、期刊编辑和基金委员会的一项费时费力的工作,计算机辅助审阅人指派研究也由此得到了更多的关注。稿件—审阅人相关度度量是该研究中的一个重点问题。该文设计了一种基于领域本体的稿件—审阅人相关度度量方法。该方法由文档关键词提取、领域本体的自动构建及基于网络流模型的稿件—审阅人相关度计算等部分组成。初步实验表明,该方法在国家自然科学基金申请书申请代码分配的任务中取得较好表现,优于单纯基于关键词字串相似度的方法。 ",MESS201702023
基于情感常识的微博事件公众情感趋势预测,任巨伟:28913382|杨亮:14244075|吴晓芳:27135988|林原:23136279|林鸿飞:06504899,10,微博; 情感分析; 语义扩充; 情感常识; 公众情感趋势;,"微博日益成为一个巨大而复杂的互联网舆论平台。分析微博中特定话题的情感趋势对于了解网络舆情、分析产品销量趋势显得尤为重要。该文使用微博进行真实事件公众情感趋势预测:首先,考虑到微博特征稀疏、上下文缺失的特性,借助词语上下位语义关系对其进行语义扩充;其次,使用语义特征和情感常识知识构造双层分类方法进行情感分析;最后,对特定事件在连续时间段内的微博使用时序情感分析方法进行公众情感趋势预测。实验证明,该情感分析方法准确率相对于传统分类方法有明显的提高,在此基础上的情感趋势预测符合事件的真实发展状况。 ",MESS201702024
基于无指导学习的微博评论分析方法,徐帅帅:36977258|戴新宇:08061509|黄书剑:11520226|陈家骏:08035597,8,微博评论; 价值性; 无指导学习; 评论过滤;,"该文以一种有效的方法寻找出有价值的微博评论,这对于读者更高效地阅读评论,为舆情分析、文本挖掘等任务提供支持,均具有重要的应用价值。针对微博及其评论文本短小、内容发散等特点,该文提出一种基于无指导学习的微博评论分析方法,该方法通过互联网搜索引擎扩展微博文本,基于相关性计算自动构造正负训练用例,生成特定的某条微博评论分类模型,通过该模型对评论的价值性进行评估。实验结果表明,该方法能够比较好地识别出评论的价值。 ",MESS201702025
大规模情感词典的构建及其在情感分类中的应用,赵妍妍1:11639065|秦兵2:06990821|石秋慧2:32150309|刘挺2:06994824,7,情感词典; 情感分析; 情感分类; 微博;,"以微博为代表的社会媒体的飞速发展为情感分析方向带来巨大的资源,同时也对情感分析算法的性能提出了更大的挑战。其中,现有的情感词典尤其是中文情感词典规模不足是影响情感分析性能的一个重要因素。为此,该文基于海量的微博数据,使用简单的文本统计算法,构建了一个十万词语/词组的大规模情感词典。我们以情感分析的基础任务——情感分类为例,将大规模情感词典作为特征用于该任务上,实验结果表明大规模词典有助于情感分类性能的提高。 ",MESS201702026
基于情感分析和LDA主题模型的协同过滤推荐算法,彭敏:10136641|席俊杰:36977259|代心媛:35424593|何炎祥:10133728,10,推荐系统; 协同过滤; LDA; 情感分析;,"协同过滤推荐算法通常基于物品或用户的相似度来实现个性化推荐,但是数据的稀疏性往往导致推荐精度不理想。大多数传统推荐算法仅考虑用户对物品的总体评分,而忽略了评论文本中用户对物品各个属性面的偏好。该文提出一种基于情感分析的推荐算法SACF(reviews sentiment analysis for collaborative filtering),该算法在经典的协同过滤推荐算法的基础上,考虑评论文本对相似度计算的影响。SACF算法利用LDA主题模型挖掘物品潜在的K个属性面,通过用户在各个属性面上的情感偏好计算用户相似度,从而构建推荐模型。基于京东网上评论数据集的实验结果表明,SACF算法不但可以有效地改善传统协同过滤推荐算法中数据稀疏性的问题,而且提高了推荐系统的精度。 ",MESS201702027
基于评论主题分析的评分预测方法研究,马春平:33224971|陈文亮:33224970,8,推荐系统; 评分预测; 词向量; 用户评论;,"推荐系统(recommender system)广泛应用于电子商务网站。目前流行的基于协同过滤的推荐算法利用用户的历史评分来预测用户对物品的喜好程度。随着互联网的发展,如今的电子商务网站越来越注重与用户的交互,于是产生了大量的用户生成内容(user generated content),如评论、地理位置、好友关系等。相对评分来说,用户对物品的评论从用户或者物品的各个角度具体表达了用户的观点。利用这些信息更有助于挖掘用户的喜好。该文提出一种基于词向量的方法挖掘用户评论信息,并结合协同过滤的方法设计新的推荐算法,来改善评分预测的效果。实验结果表明,该算法较大程度上提高了评分预测精度。 ",MESS201702028
自由表述口语语音评测后验概率估计改进方法,"许苏魁1:35597988|戴礼荣1:09539044|魏思2:28360400|刘庆峰1,2:09575724|高前勇2:30696586",8,自由表述口语; 语音评测; 后验概率; 深度神经网络; RNN语言模型;,"该文研究了两种用于改善深度神经网络声学建模框架下自由表述口语语音评测任务后验概率估计的方法:1)使用RNN语言模型对一遍解码N-best候选做语言模型得分重估计来获得更准确的识别结果以重新估计后验概率;2)借鉴多语种神经网络训练框架,提出将方言数据聚类状态加入解码神经网络输出节点,在后验概率估计中引入方言似然度得分以评估方言程度的新方法。实验表明,这两种方法估计出的后验概率与人工分相关度分别绝对提升了3.5%和1.0%,两种方法融合后相关度绝对提升4.9%;对于一个真实的评测任务,结合该文改进的后验概率评分特征,总体评分相关度绝对提升2.2%。 ",MESS201702029
多语种文本图像中的文字语种辨识方法的研究,朴明姬:10775519|崔荣一:09291242,6,文种辨识; 主成分分析; 相对熵; 欧式距离; 文字分割;,"本文针对汉字、朝鲜文字和英文单词混合的文本图像提出了基于主成分分析技术以文字为单位进行文种辨识的方法。首先,通过主成分分析方法构造特征空间,并且把分割的文字映射到此空间得到重构图像;其次,计算原图像和重构图像的水平和垂直方向直方图的相对熵;最后,根据原图像和重构图像之间的欧式距离和相对熵来判别文字语种。实验表明,本文提出的方法在没有分割错误的情况下,能获得99.78%的识别准确率,有效地解决了在汉、朝、英三种文字混合构成的文档图像中文种辨识问题。 ",MESS201702030
中国语言生活皮书,,1, ,"<正>由国家语言文字工作委员会组编并发布,包括""绿皮书""""黄皮书""四个子系列,""白皮书""""蓝皮书""实时记录当年中国语言文字事业发展情况以及中国和世界语言政策、语言规划、语言状况和热点事件,及时提供反映语言生活的调查报告和相关数据。旨在服务国家社会需求,研究现实语言问题,保护和开发语言资源,引导社会语言生活和谐发展。 ",MESS201702031
"方滨兴院士当选中国中文信息学会第八届理事会理事长,李生教授担任名誉理事长",,1, ,"<正>2016年12月23-24日,中国中文信息学会第八次全国会员代表大会暨学会成立35周年学术会议在北京中国科技会堂隆重举行,大会通过无记名等额投票方式选举产生了中国中文信息学会第八届理事会全体成员、常务理事会全体成员以及学会领导班子成员。中国电子信息产业集团方滨兴院士当选中国中文信息学会第八届理事会理事长,北京理工大学黄河燕教授、北京语言大学李宇明教授、科大讯飞刘庆峰董事长、 ",MESS201702032
“2017年院士候选人推选初审会”在中科院软件所顺利召开,,1, ,"<正>2017年2月17日,由中国中文信息学会、中国计算机学会和中国通信学会联合举办的2017年院士候选人推选初审会在中科院软件所顺利召开。院士推选专家委员会组长由中国中文信息学会理事长方滨兴院士担任,副组长由中国计算机学会理事长高文院士担任,出席会议的专家还有:沈昌祥院士、刘尚合院士、林惠民院士、陈鲸院士、陈志杰院士、段宝岩院士、赵沁平院士、谭铁牛院士、梅宏院士、费爱国院士、樊邦奎院 ",MESS201702033
基于问题与答案联合表示学习的半监督问题分类方法,张栋:09891027|李寿山:27030929|王晶晶:08846650,7,问题分类; 联合表示; 半监督;,"问题分类旨在对问题的类型进行自动分类,该任务是问答系统研究的一项基本任务。该文提出了一种基于问题和答案联合表示学习的问题分类方法。该方法的特色在于利用问题及其答案作为共同的上下文环境,学习词的分布式表示,从而充分利用未标注样本中问题和答案隐含的分类信息。具体而言,首先,我们引入神经网络语言模型,利用问题与答案联合学习词向量表示,增加问题词向量的信息量;其次,加入大量未标注的问题与答案样本参与词向量学习,进一步增强问题词向量表示能力;最后,将已标注的问题样本以词向量形式表示作为训练样本,采用卷积神经网络建立问题分类模型。实验结果表明,该文提出的基于半监督问题分类方法能够充分利用词向量表示和大量未标注样本来提升性能,明显优于其他基准半监督分类方法。 ",MESS201701001
面向阅读理解复杂问题的句子融合,"谭红叶1,2:08402552|赵红红1:30989216|李茹1,2:08453268",9,阅读理解; 复杂问题; 句子融合; 文本生成;,"阅读理解是目前NLP领域的一个研究热点。阅读理解中好的复杂问题解答策略不仅要进行答案句的抽取,还要对答案句进行融合、生成相应的答案,但是目前的研究大多集中在前者。该文针对复杂问题解答中的句子融合进行研究,提出了一种兼顾句子重要信息、问题关联度与句子流畅度的句子融合方法。该方法的主要思想为:首先,基于句子拆分和词重要度选择待融合部分;然后,基于词对齐进行句子相同信息的合并;最后,利用基于依存关系、二元语言模型及词重要度的整数线性规划优化生成句子。在历年高考阅读理解数据集上的测试结果表明,该方法取得了82.62%的F值,同时更好地保证了结果的可读性及信息量。 ",MESS201701002
基于事件元素无向图的查询扩展方法,叶雷:36636449|高盛祥:07892541|余正涛:05982358|秦广顺:35840953|洪旭东:30038174,7,新闻事件; 查询扩展; 事件元素; 事件元素无向图;,"借助新闻事件元素之间的关联特性,提出了基于事件元素无向图的查询扩展方法,利用新闻事件元素之间的关联关系进行查询扩展提升新闻事件检索效果。首先分析候选事件文档与查询项的关系,确定待扩展的元素;然后利用事件元素之间的关联关系构建无向图,通过事件向量空间计算边的权重;最后,利用无向图节点权重模型计算事件元素权重,依据权重进行事件元素扩展。在新闻事件查询扩展方面进行了对比试验,结果表明该文提出的查询扩展方法取得了较好的效果。 ",MESS201701003
基于文档发散度的作文跑题检测,"陈志鹏1,2:34071696|陈文亮1,2:33224970",8,跑题检测; 文档发散度; 文本相似度;,"作文跑题检测是作文自动评分系统的重要模块。传统的作文跑题检测一般计算文章内容相关性作为得分,并将其与某一固定阈值进行对比,从而判断文章是否跑题。但是实际上文章得分高低与题目有直接关系,发散性题目和非发散性题目的文章得分有明显差异,所以很难用一个固定阈值来判断所有文章。该文提出一种作文跑题检测方法,基于文档发散度的作文跑题检测方法。该方法的创新之处在于研究文章集合发散度的概念,建立发散度与跑题阈值的关系模型,对于不同的题目动态选取不同的跑题阈值。该文构建了一套跑题检测系统,并在一个真实的数据集中进行测试。实验结果表明基于文档发散度的作文跑题检测系统能有效识别跑题作文。 ",MESS201701004
利用词表示和深层神经网络抽取蛋白质关系,李丽双:06521783|蒋振超:32481647|万佳:36636450|黄德根:06527360,10,蛋白质关系抽取; 词表示; 深层神经网络;,"蛋白质关系抽取是生物医学信息抽取领域的重要分支。目前研究中,基于特征和核函数方法的蛋白质关系抽取已被充分研究,并且达到了很高的F-值,通过改进特征和核函数进一步优化实例表示变得十分困难。该文结合词表示和深层神经网络,提出了一种实例表示模型。该模型能够充分利用词表示的语义表示能力和深层神经网络的表示优化能力;同时引入主成分分析和特征选择进行特征优化,并且通过比较多种传统的分类器,寻找适合蛋白质关系抽取的分类器。该方法在AIMed语料、BioInfer语料和HPRD50语料上的F-值分别取得了70.5%、82.2%和80.0%,在蛋白质关系抽取任务上达到了目前最好的抽取水平。 ",MESS201701005
汉语词汇测试自动命题研究,胡韧奋:24106271,9,二语教学; 词汇测试; 自动命题;,"为了提升汉语词汇测试的命题效率,该文从汉语语言特性和二语教学需求出发,对词语听力、多空词语选择、词语排序和单空词语选择四种词汇测试题型进行自动命题尝试,以满足不同语言信息、不同难度的词汇知识考查。在词语特征的提取上,构建了一个覆盖词音、词形、词义、语法、搭配、偏误各层次信息的词汇知识库,在句子特征的提取上,实现了语法项目自动识别、句子难度分析等算法,为自动命题中的题干句、目标词和干扰项选择提供依据。通过词句选择和语块合成等步骤,生成四种题型共计7 263道词汇测试题。人工测试数据显示,词汇测试自动命题的初步尝试取得了较好的效果,约58%的试题被评价为完全合理,经人工简单调整,试题接受率达到75.7%。 ",MESS201701006
英汉《小王子》抽象语义图结构的对比分析,李斌1:08075606|闻媛1:36638639|卜丽君1:36638640|曲维光2:08112756|薛念文3:33909442,9,抽象语义表示; 语义图; 英汉对比; 自然语言处理;,"AMR(抽象语义表示)是国际上一种新的句子语义表示方法,有着接近于中间语言的表示能力,其研发者已经建立了英文《小王子》等AMR语料库。AMR与以往的句法语义表示方法的最大不同在于两个方面,首先采用图结构来表示句子的语义;其次允许添加原句之外的概念节点来表示隐含的语义。该文针对汉语特点,在制定中文AMR标注规范的基础上,标注完成了中文版《小王子》的AMR语料库,标注一致性的Smatch值为0.83。统计结果显示,英汉双语含图结构句子具有很高的相关性,且含有图的句子比例高达40%左右,额外添加的概念节点则存在较大差异。最后讨论了AMR在汉语句子语义表示以及跨语言对比方面的优势。 ",MESS201701007
基于点关联测度矩阵分解的中英跨语言词嵌入方法,"于东1,2:26514992|赵艳2:25718152|韦林煊2:36636451|荀恩东1,2:06433984",9,点关联测度; 词嵌入; 跨语言; 矩阵分解;,"研究基于矩阵分解的词嵌入方法,提出统一的描述模型,并应用于中英跨语言词嵌入问题。以双语对齐语料为知识源,提出跨语言关联词计算方法和两种点关联测度的计算方法:跨语言共现计数和跨语言点互信息。分别设计目标函数学习中英跨语言词嵌入。从目标函数、语料数据、向量维数等角度进行实验,结果表明,在中英跨语言文档分类中以前者作为点关联测度最高得到87.04%的准确率;在中英跨语言词义相似度计算中,后者作为点关联测度得到更好的性能,同时在英—英词义相似度计算中的性能略高于主流的英语词嵌入。 ",MESS201701008
利用源域结构的粒迁移学习及词性标注应用,"孙世昶1,2:14012855|林鸿飞1:06504899|孟佳娜2:33259452|刘洪波3:22174757",9,迁移学习; 粒计算; 区间信息粒; 词性标注;,"迁移学习在一定程度上减轻了目标域的数据稀疏问题对泛化能力的影响,然而泛化能力的提高仍然受到负迁移等问题的影响。为了解决负迁移问题,该文提出使用源域结构的文本语料的信息粒化方法,用区间信息粒表示出源域数据集的结构对数据集中统计量的影响。然后提出区间二型模糊隐马尔可夫模型(Interval Type-2fuzzy Hidden Markov Model,IHMM)以处理区间信息粒。给出了IHMM的构建方法和去模糊化方法。在文本的词性标注任务中进行了多个实验,可以证实利用源域结构信息的粒迁移学习方法避免了负迁移,提高了模型的泛化能力。 ",MESS201701009
基于BCC的离合词离析形式自动识别研究,臧娇娇:35208672|荀恩东:06433984,10,离合词; BCC; 离析形式; 自动识别;,"该文从中文信息处理角度对动宾型离合词自动识别进行研究。通过分析离合词在实际语料中的使用特点以及离合词离析成分在大规模语料库中的表现形式,从离合词内部入手,形式化地表示离合词的离析形式,总结自动识别的规则,设计基于规则的自动识别算法。经过优化后,该算法在20亿字的语料中达到了91.6%的正确率。离合词语素构词能力强,分词与词性标注错误,规则的不完整性,语料本身的错误,以及人工标注的疏漏等是影响实验结论的主要因素。 ",MESS201701010
基于规则的“把”字句语义角色标注,何保荣:34916101|邱立坤:28907681|徐德宽:07962449,10,把字句; 语义角色标注; 句模;,"""把""字句是现代汉语中一种重要的特殊句式,该文尝试用基于知识库的规则方法对把字句进行语义角色自动标注。首先,我们从《人民日报》语义角色标注语料库中收集把字句例句,形成一个覆盖范围较广的把字句例句库;之后,对例句库中把字句的句法和语义构成规律进行手工标注,标注内容包括谓语动词的配价类型、把字句谓语结构类型、把字句句模类型等。在上述标注的基础上,对把字句的句模构成规律进行分析,总结出若干条语义角色标注规则;最后,在测试数据上对前述规则进行验证,语义角色标注的最终正确率为98.61%,这一结果说明该文所提出的规则在把字句语义角色标注上是有效的。 ",MESS201701011
基于语义构词的汉语词语语义相似度计算,"康司辰1,2:36636922|刘扬3,2:06269306",9,词语语义相似度计算; 语义构词; 词义知识表示; 语素概念;,"汉语词语语义相似度计算,在中文信息处理的多种应用中扮演至关重要的角色。基于汉语字本位的思想,我们采用词类、构词结构、语素义等汉语语义构词知识,以""语素概念""为基础,计算汉语词语语义相似度。这种词义知识表示简单、直观、易于拓展,计算模型简洁、易懂,采用了尽可能少的特征和参数。实验表明,该文方法在典型""取样词对""上的表现突出,其数值更符合人类的感性认知,且在全局数据上也表现出了合理的分布规律。 ",MESS201701012
藏汉跨语言话题模型构建及对齐方法研究,"孙媛1,2:31992289|赵倩1,2:35733306",10,藏汉跨语言; 话题抽取; LDA; 话题对齐;,"如何获取藏文话题在其他语种中的相关信息,对于促进少数民族地区的社会管理科学化水平、维护民族团结和国家统一、构建和谐社会具有重要意义。目前大多数研究集中在英汉跨语言信息处理方面,针对藏汉跨语言研究较少。如何根据藏语、汉语的特点,并结合目前藏语信息处理的研究现状,实现藏汉多角度的社会网络关系关联,同步发现关注话题并进行数据比较,是迫切需要解决的问题。该文在藏汉可比语料的基础上,利用词向量对文本词语进行语义扩展,进而构建LDA话题模型,并利用Gibbs sampling进行模型参数的估计,抽取出藏语和汉语话题。在LDA话题模型生成的文档-话题分布的基础上,提出一种基于余弦相似度、欧氏距离、Hellinger距离和KL距离四种相似度算法的投票方法,来实现藏汉话题的对齐。 ",MESS201701013
基于词向量的藏文词性标注方法研究,"郑亚楠1:28979767|珠杰1,2:10216645",6,词向量; 藏文; 词性标注;,"藏文词性标注是藏文信息处理的基础,在藏文文本分类、自动检索、机器翻译等领域有广泛的应用。该文针对藏文语料匮乏,人工标注费时费力等问题,提出一种基于词向量模型的词性标注方法和相应算法,该方法首先利用词向量的语义近似计算功能,扩展标注词典;其次结合语义近似计算和标注词典,完成词性标注。实验结果表明,该方法能够快速有效地扩大了标注词典规模,并能取得较好的标注结果。 ",MESS201701014
蒙古文原始语料统计建模研究,白双成:24771929,8,蒙古文原始文本; 统计建模; 读音错误; 字形错误; 智能输入;,"蒙古文字符编码与字形之间的多对多复杂转换关系及录入不规范等众多原因导致原始语料存在严重的拼写多样化现象和字形拼写错误,成为大数据处理瓶颈。该文以蒙古文输入法为例,利用大词库和形码生成器,将原本基于读音正确的词晶格最佳路径搜索问题转换为基于形码词晶格路径搜索问题,很好地解决了原始文本统计建模问题。实验结果证明,该方法及字形归并的模型优化方法可显著提高输入效率,对所有蒙古文""音词转换""和""形词转换""研究都有广泛的参考价值。 ",MESS201701015
基于语法的维吾尔语情感词汇自动获取,玛尔哈巴·艾赛提:35412785|艾孜尔古丽:26177339|玉素甫·艾白都拉:22251454,8,"情感词汇,维吾尔语; 语法; 自动获取;","情感词汇的获取是文本倾向性分析的基础。为了解决人工识别方法低效的不足,并为维吾尔语情感词的研究及情感词词典的创建提供一些可供选择的方法和思路,该文首先分析了维吾尔语情感词汇在上下文中表现的特征,并结合维吾尔语本身的语法特征,建立了扩展的维吾尔语新增特征模型,与词频逆文档频率(TF-IDF)算法相结合,实现了维吾尔语情感词汇的识别。实验结果指出该特征模型有效地提高了情感词汇的识别率。 ",MESS201701016
基于多策略的维吾尔文网页识别方法,"阿力木·木拉提1,2,3:34417210|艾孜尔古丽4:26177339|杨雅婷1,2:24687213|李晓1,2:09602585",7,维吾尔文; 网页识别; N-Gram方法; 常用词; 向量空间模型;,"经过对大量维吾尔文网站的调查与分析,该文从多语种混合网页中针对维吾尔文网页识别进行了研究,这对维吾尔语信息处理工作起着关键作用。首先该文探讨了维吾尔文不规范网页的字符编码转换规则及原理,以此对不规范维吾尔文字符进行了相应的处理,之后介绍了基于修改的N-Gram方法和基于维吾尔语常用词特征向量的两种方法,其中后者融合了维吾尔文常用候选词语料库及向量空间模型(Vector Space Model)。使用三种不同类型的维吾尔文网页文本作为本研究的数据集,在此基础上验证了该文提出的网页识别方法,以及采用不同的方法进行了网页识别的实验。实验结果表明,基于N-Gram的方法对正文较长的新闻或论坛网页的识别性能最佳,反而基于常用词特征向量的方法对短文本的网页识别性能优越N-Gram。所提方法对维吾尔文网页识别的整体性能达到90%以上,并验证了这两种方法的有效性。 ",MESS201701017
知识图谱中实体相似度计算研究,李阳:27305552|高大启:07520370,8,实体相似度; 监督学习; 分类模型; 集成学习;,"实体相似度的计算有诸多应用,例如,电商平台的相似商品推荐,医疗疗效分析中的相似病人组等。在知识图谱的实体相似度计算中,给出了每个实体的属性值,并对部分实体进行相似度的标注,要求能得到其他实体之间的相似度。该文把该问题归结为监督学习问题,提出一种通用的实体相似度计算方法,通过清洗噪声数据,对数值、列表以及文本等不同数据类型进行预处理,使用SVM,Logistic回归等分类模型、Random Forest等集成学习模型以及排序学习模型进行建模,得到了较好的结果。 ",MESS201701018
基于Dropout正则化的汉语框架语义角色识别,, , , ,MESS201701019
基于神经网络的语义选择限制知识自动获取,贾玉祥:10308738|许鸿飞:36382830|昝红英:09467924,7,语义选择限制; 词汇知识获取; 神经网络; 伪消歧;,"语义选择限制刻画谓语对论元的语义选择倾向,对自然语言的句法语义分析有重要作用,语义选择限制知识的自动获取也成为一个重要的研究课题。鉴于神经网络模型在自然语言处理的很多任务中都有出色的表现,该文提出基于神经网络的语义选择限制知识获取模型,设计了引入预训练词向量的单隐层前馈网络和两层maxout网络。在汉语和英语的伪消歧实验中神经网络模型取得了较好的效果,优于基于隐含狄利克雷分配的模型。 ",MESS201701020
一种针对短文本的主题情感混合模型,谢珺:08893125|郝洁:35693571|苏婧琼:35693572|邹雪君:36636455|李思宇:36636456,7,主题情感混合模型; 情感分类; BTM;,"主题情感混合模型可以同时提取语料的主题信息和情感倾向。针对短文本特征稀疏的问题,主题情感联合分析方法较少的问题,该文提出了BJSTM模型(Biterm Joint Sentiment Topic Model),在BTM模型(Biterm Topic Model)的基础上,增加情感层的设置,从而形成""情感-主题-词汇""的三层贝叶斯模型。对每个双词的情感和主题进行采样,从而对整个语料的词共现关系建模,一定程度上克服了短文本的稀疏性。实验表明,BJSTM模型在无监督情感分类和主题提取方面都有不错的表现。 ",MESS201701021
基于深度表示学习和高斯过程迁移学习的情感分析方法,吴冬茵1:36636457|桂林1:30330029|陈钊2:36636458|徐睿峰1:07001926,8,情感分析; 深度表示学习; 高斯过程; 迁移学习;,"情感分析是自然语言处理领域的重要研究问题。现有方法往往难以克服样本偏置与领域依赖问题,严重制约了情感分析的发展和应用。为此,该文提出了一种基于深度表示学习和高斯过程知识迁移学习的情感分析方法。该方法首先利用深度神经网络获得文本样本的分布式表示,而后基于深度高斯过程,从辅助数据中迁移与测试集数据分布相符的高质量样例扩充训练数据集用于分类器训练,以此提高文本情感分类系统性能。在COAE2014文本情感分类数据集上进行的实验结果显示,该文提出的方法可以有效提高文本情感分类性能,同时可以有效缓解训练数据的样本偏置以及领域依赖问题的影响。 ",MESS201701022
词典与机器学习方法相结合的维吾尔语文本情感分析,"热西旦木·吐尔洪太1,2:36636459|吾守尔·斯拉木1:17705001|伊尔夏提·吐尔贡1:36636461",8,维吾尔文; 情感词典; 情感分析; 机器学习;,"随着互联网整体水平的提高,大量基于维吾尔文的网络信息不断建立,引起了对不同领域的信息进行情感倾向性分析的迫切需要。该文考虑到维吾尔文没有足够的情感训练语料和完整的情感词典,结合机器学习方法和词典方法的优点,构建一个分类器模型LCUSCM(Lexicon-based and Corpus-based Uyghur Text Sentiment Classification Model),先用自己构建的维吾尔文情感词典对语料进行高质量的情感分类,分类过程中对词典进行递归扩充,再根据每条句子的情感得分,从词典分类的结果中选择一部分语料来训练一个分类器并改进第一步的分类结果。此方法的正确率比单独使用机器学习方法提高了9.13%,比词典方法提高了1.82%。 ",MESS201701023
基于语言现象的文本蕴涵识别,"任函1,2:36636466|冯文贺1,2:36636463|刘茂福2,3:10135689|万菁4:36636928",8,文本蕴涵识别; 语言现象; 随机森林;,"该文提出一种基于语言现象的文本蕴涵识别方法,该方法建立了一个语言现象识别和整体推理判断的联合分类模型,目的是对两个高度相关的任务进行统一学习,避免管道模型的错误传播问题并提升系统精度。针对语言现象识别,设计了22个专用特征和20个通用特征;为提高随机森林的泛化能力,提出一种基于特征选择的随机森林生成算法。实验结果表明,基于随机森林的联合分类模型能够有效识别语言现象和总体蕴涵关系。 ",MESS201701024
基于稀疏主成分分析的非正式语词的心理-人格特征研究,钟毓:36636462|费定舟:09012342,13,文本分析; 稀疏主成分分析; 非正式语词;,"针对社会媒体中非正式文本的数据分析经常出现的稀疏数据矩阵,在应用文本分析工具的基础上使用稀疏主成分分析这一特征,降维分析方法分析现实情况下聊天文本中非正式语词表现的认知语用特征、描述非正式语词与人格的关系。使用短文本主题模型、心理距离问卷、大五人格问卷测量人格和背景变量,使用计算机文本分析工具对被试提供的即时聊天文本内的语词计频,使用简体中文版语词查询与字词计数字典和认知语用学对稀疏主成分分析后非正式语词维度进行特征表征。在非正式语词降维上,稀疏主成分分析比主成分分析在因子载荷数上更稳定,在累积方差解释率上也相对更优（24.54%>23.40%）;降维所得的6因子中""主观评价""与宜人性正相关(r0.05=.16,p=.03<0.05),""随意社交""与宜人性负相关(r0.05=-.16,p=.03<0.05),""认知愉悦""与性别显著正相关(r0.05=.43,p=.00<0.001)。使用稀疏主成分分析对非正式语词的降维效果较好,并且比较简体中文版语词查询与字词计数字典的非正式语词维度和降维后所得非... ",MESS201701025
基于偏向相似性的自然语言关联和聚类研究,陈振宁1:33574265|陈振宇2:06703030,8,不对称性; 条件概率; 关联; 聚类;,"聚类按关联进行分类,关联和聚类分析的基础是相似性计算。通常相似性是指绝对相似性,具有对称性。但自然语言研究中发现大部分规律都是偏向的,具有不对称性,需要用偏向的思路来考察不对称的关联和聚类策略:以类似条件概率的概率蕴涵指标来描写特征间的不对称关联,并在此基础上定义优势关系、紧密关系、控制中心、中途岛等关联特性;基于偏向相似性的聚类策略,从而能更好地处理语言本体研究中的""假性孤立点""、数据稀疏问题和家族象似性类型的聚类。 ",MESS201701026
《世说新语》的篇章连接词,"冯文贺1,2:36636463|郭海芳2:36636464|李玉静3:36636465|任函1:36636466",9,《世说新语》; 篇章结构; 连接词; 语义分析;,"该文标注《世说新语》的篇章结构,据此研究其连接词的显隐、语义及用法。研究发现:1)隐式关系(3 346,81.4%)多于显式关系(786,18.6%),17类关系仅有三类(假设,选择,让步)显多隐少;2)各类关系的同义连接词种数与使用有差异,其中种数最多36(顺承),最少则无(总分,背景);3)连接词(90种)单义为多(55),多义为少(35),义项最多为八种(""乃""),分布也有差异。对比发现,《世说新语》与同时期《文心雕龙》的连接词使用有一定差异。 ",MESS201701027
汉语二语教学领域词义标注语料库的研究及构建,王敬:06364425|杨丽姣:06366403|蒋宏飞:36636467|苏靖杰:34417198|付静玲:36636468,9,汉语二语教学; 语料库; 多义词标注;,"词汇教学在汉语二语教学领域占有极为重要的地位,其中多义词又是词汇教学的重点和难点。该研究通过分析三部经典领域词表,选取了1 181个重点多义词,以《现代汉语词典(第6版)》为标注体系,制定了适合实际标注的多义词标注规范和形式,在197册经典汉语二语教材上进行了多义词词义标注,构建了一个规模约350万字的面向汉语二语教学领域的词义标注语料库,并在此基础上对1 811个多义词、4 323个多义词义项进行了计量统计,分析了多义词不同词义的出现情况及其分布规律。为了更好地服务于汉语二语教学,开发了语料库检索系统,设计并实现了多义词义项的查询功能。 ",MESS201701028
从短语到构式:构式知识库建设的若干理论问题探析,詹卫东:06264050,9,构式; 知识库; 组合性; 非递归性;,"构式语法(construction grammar)在汉语语法学界已引起持续关注,但在自然语言处理领域,将构式语法理论应用到计算机自动句法语义分析中的研究还很少见。该文提出构建现代汉语构式知识库的语言工程任务,讨论了构式与传统语法单位的关系、构式的形式表示、构式的内部小类及主要特征等。 ",MESS201701029
书讯,,1, ,"<正>两岸语言文字调查与语文生活作者:李宇明开本:32开书号:978-7-100-12829-2定价:45.00元本书是首届""两岸语言文字调查研究与语文生活""研讨会论文集。全书秉持""求同化异、便利应用""的宗旨,关注两岸的现实语言生活,围绕""两岸语言文字传承与中华文化传播""""两岸语言文字合作研究、机制建设及展望""两个专题,对语音、文字、词汇、语 ",MESS201701030
中国中文信息学会第八次全国会员代表大会暨学会成立35周年学术会议在京成功举办,,1, ,"<正>2016年12月23—24日,中国中文信息学会第八次全国会员代表大会暨学会成立35周年学术会议在北京中国科技会堂隆重举行,会上颁发了""钱伟长中文信息处理科学技术奖"",中国中文信息学会""终身成就奖"",""青年创新奖"",以及中国中文信息学会""优秀博士学位论文奖""。同时在本次会议也发布了2016年《中文信息处理发展报告》。会议邀请了五位专家进行了学术报告。来自中国科协、教育部国家语委等部委领导、学会支撑单 ",MESS201701031
借重于人工知识库的词和义项的向量表示:以HowNet为例,"孙茂松1,2:08823738|陈新雄1:36387475",7,词向量; 义项向量; 义原向量; HowNet; 神经网络语言模型;,"该文旨在以HowNet为例,探讨在表示学习模型中引入人工知识库的必要性和有效性。目前词向量多是通过构造神经网络模型,在大规模语料库上无监督训练得到,但这种框架面临两个问题:一是低频词的词向量质量难以保证;二是多义词的义项向量无法获得。该文提出了融合HowNet和大规模语料库的义原向量学习神经网络模型,并以义原向量为桥梁,自动得到义项向量及完善词向量。初步的实验结果表明该模型能有效提升在词相似度和词义消歧任务上的性能,有助于低频词和多义词的处理。作者指出,借重于人工知识库的神经网络语言模型应该成为今后一段时期自然语言处理的研究重点之一。 ",MESS201606001
语义角色映射为句法成分的词汇语义制约规律及特点,亢世勇:10882043|张晨:34628264,8,词汇语义; 语义角色; 句法成分;,"该文以联接理论、事件结构理论为指导,进行词汇语义类、语义角色、句法成分对应关系的研究。选择人教社中小学语文课文语料,标注语义角色、句法成分及中心词的词汇语义类。在标注语料库的基础上,统计分析了词汇语义类与语义角色的对应关系,重点分析各语义类语义角色映射为句法成分的规律,并进一步总结了各词汇语义类的语义角色与句法成分的对应的特点。尽管词汇语义类、语义角色、句法成分之间存在错综复杂的关系,但还是有规律的,可以为计算机句法分析提供一些依据。 ",MESS201606002
细粒度与可视化的“比”字句分析模型及计算应用,朴敏浚:35809304|袁毓林:06263991,11,“比”字句; 语义要素; 比较关系; 细粒度; 可视化; 知识本体;,"针对现有五元组比较句语义要素框架的缺陷,该文引进了提升语义分辨率的七元组语义要素分类模板。在此基础上建立了一个可视化的""比""字句结构分析模型,用以总结出比较对象之间的三种对应模式,并确立了判定""不对称比较""的形式标准。该文的可视化分析模型可以明确阐述""比""字句内部的多重述谓结构,有助于获取容易被忽略或认错的隐含成分及比较关系。而且,它立足于谓词逻辑的基础形式,所以与OWL本体语言相兼容。作为模型的应用实践,该文还建设了小规模知识本体(ontology),演示了""比""字句语义要素的自动识别过程。 ",MESS201606003
汉语未登录词的词义知识表示及语义预测,"田元贺1,2:36382819|刘扬2,3:06269306",9,未登录词; 词义知识表示; 语义预测; 语义构词;,"在此前的汉语未登录词语义预测中,构词相关的知识一直被当做预测的手段,而没有被视为一种有价值的知识表示方式,该文在""语素概念""基础上,深入考察汉语的语义构词知识,给出未登录词的""多层面""的词义知识表示方案。针对该方案,该文采用贝叶斯网络方法,构建面向汉语未登录词的自动语义构词分析模型,该模型能有效预测未登录词的""多层面""的词义知识。这种词义知识表示简单、直观、易于拓展,实验表明对汉语未登录词的语义预测具有重要的价值,可以满足不同层次的应用需求。 ",MESS201606004
基于声调核参数及DNN建模的韵律边界检测研究,林举:34683081|解焱陆:27065196|张劲松:23592433|张微:36382820,6,韵律边界建模; 声调核; 深度神经网络;,"韵律边界对言语表达的自然度和可理解度有着重要作用。韵律建模也是语音合成、语音理解中的重要方面。该文从相邻声调的相互作用角度出发,提出基于深度神经网络(DNN)及声调核声学特征的汉语韵律边界检测方法。该方法首先采用声调核部分的声学特征来计算边界检测相关参数。然后,利用深度神经网络进行建模。作为对比,实验中采用了以整个音节的声学特征为输入特征的基线系统。结果表明,只使用调核部分声学特征的系统优于使用整个音节的系统,韵律边界检测正确率相对提高了4%,这表明该文提出的汉语韵律边界检测方法的有效性。 ",MESS201606005
面向深层语义表示的否定义表达规律探析,邱立坤:28907681|黄焜:36382821|何保荣:34916101|亢世勇:10882043,9,现代汉语; 深层语义表达; 否定词;,"否定义是深层语义表示中的一个重要组成部分。该文基于语料库的方法对现代汉语中的否定表达形式及其使用规律进行深入分析。首先,系统地收集否定表达形式,将之分为显性否定词、隐性否定词、否定结构三类,并讨论否定表达形式的非否定用法。其次,对否定表达形式的使用规律进行归纳与总结,涉及单动核结构、情态成分、述补结构、动词性并列结构、连谓结构、兼语结构等,重点分析多动核结构中否定对命题义的影响,并总结在深层语义标注框架下否定义的标注规则。最后,基于多领域句法树库考察否定表达形式的领域分布差异。 ",MESS201606006
基于70年报刊语料的现代汉语历时稳态词抽取与考察,饶高琦1:28523622|李宇明2:27454895,10,稳态词; 历时语料库; 语言监测;,"该文基于70年跨度的历时报刊语料库,使用九种统计方法计算了词语历年的使用情况,并通过对稳定性、覆盖度和时间区分性能的考察筛选获得了规模为3 013词的历时稳态词候选词集。该词集中动词与名词各占约三分之一(其余为形容词、副词与虚词),平均词长约1.7字,前密后疏地分布于历时语料库总频序表的前7 609位,覆盖了总语料的近九成。该部分词语中包含大量构造句子结构的核心词语。它们塑造了稳态词在词长和词类上的特性。稳态词的提取可以加深对语言生活底层与基础词汇的认识,对汉语教学、中文信息处理和语言规划都具有重要意义。 ",MESS201606007
CRFs融合语义信息的英语功能名词短语识别,马建军1:06530781|裴家欢2:36382822|黄德根2:06527360,8,功能名词短语; 名词短语识别; 条件随机域模型; 语义信息;,"名词短语识别在句法分析中有着重要的作用,而英汉机器翻译的瓶颈之一就是名词短语的歧义消解问题。研究英语功能名词短语的自动识别,则将名词短语的结构消歧问题转化成名词短语的识别问题。基于名词短语在小句中的语法功能来确定名词短语的边界,选择商务领域语料,采用了细化词性标注集和条件随机域模型结合语义信息的方法,识别了名词短语的边界和句法功能。在预处理基于宾州树库细化了词性标注集,条件随机域模型中加入语义特征主要用来识别状语类的名词短语。实验结果表明,结合金标准词性实验的F值达到了89.04%,改进词性标注集有助于提高名词短语的识别,比使用宾州树库标注集提高了2.21%。将功能名词短语识别信息应用到NiuTrans统计机器翻译系统,英汉翻译质量略有提高。 ",MESS201606008
限定领域口语对话系统中的商品属性抽取,叶大枢:36382823|黄沛杰:24966316|邓振鹏:36382824|黄强:30821750,8,商品属性抽取; 词向量; 卷积神经网络; 特征表达; 口语对话系统;,"按功能或问题域划分,商品属性抽取(product feature mining)在限定领域的对话系统中属于口语语言理解(spoken language understanding,SLU)的范畴。商品属性抽取任务只关注自然文本中描述商品属性的特定部分,它是细粒度观点抽取(fine-grained opinion mining)的一个重要的子任务。现有的商品属性抽取技术主要建立在商品的评论语料上,该文以手机导购对话系统为背景,将商品属性抽取应用到整个对话过程中,增强对话系统应答的针对性。使用基于CBOW(continuous bag of words)语言模型的word2vector(W2V)对词汇的语义层面建模,提出一个针对口语对话的指数型变长静态窗口特征表达框架,捕捉不同距离词语组合的重要特征,使用卷积神经网络(convolutional neural network,CNN)结合词汇的语义和上下文层面对口语对话语料中的商品属性进行抽取。词嵌入模型给出了当前词和所给定的属性类别是否存在相关性的证据,而所提出的特征表达框架则是为了解决一词多义的问题。实验结果表明,该方法取得了优于研究进... ",MESS201606009
基于DNN的汉语框架识别研究,"赵红燕1,2:36382825|李茹1,3:08453268|张晟1:36382826|张力文1:36382827",9,汉语框架; 框架识别; 深度神经网络; 分布式表征;,"框架识别是语义角色标注的基本任务,它是根据目标词激起的语义场景,为其分配一个合适的语义框架。目前框架识别的研究主要是基于统计机器学习方法,把它看作多分类问题,框架识别的性能主要依赖于人工选择的特征。然而,人工选择特征的有效性和完备性无法保证。深度神经网络自动学习特征的能力,为我们提供了新思路。该文探索了利用深度神经网络自动学习目标词上下文特征,建立了一种新的通用的框架识别模型,在汉语框架网和《人民日报》2003年3月新闻语料上分别取得了79.64%和78.58%的准确率,实验证明该模型具有较好的泛化能力。 ",MESS201606010
基于分布式表示和多特征融合的知识库三元组分类,安波:32720108|韩先培:26496192|孙乐:10352504|吴健:09573880,7,知识库; 深度学习; 三元组分类;,"三元组分类是知识库补全及关系抽取的重要技术。当前主流的三元组分类方法通常基于TransE来构建知识库实体和关系的分布式表示。然而,TransE方法仅仅适用于处理1对1类型的关系,无法很好的处理1对多、多对1及多对多类型的关系。针对上述问题,该文在分布式表示的基础上,提出了一种特征融合的方法—TCSF,通过综合利用三元组的距离、关系的先验概率及实体与关系上下文的拟合度进行三元组分类。在四种公开的数据集(WN11、WN18、FB13、FB15K)上的测试结果显示,TCSF在三元组分类上的效果超过现有的state-of-theart模型。 ",MESS201606011
基于认知属性库的原型范畴研究,李斌1:08075606|宋丽1:36382828|银思琪1:36173996|曲维光2:08112756|王萌3:11695873,10,认知属性; 原型范畴; 语义分类; 语义计算;,"原型范畴是认知科学研究中的重要理论,使用属性来区分范畴中心成员及边缘成员有着较强的解释力,但该理论一直缺乏基于频率信息的属性数据支撑。该文借助认知属性库的23万条数据,对原型理论研究中经常讨论的""鸟""、""水果""、""交通工具""等范畴的典型成员和非典型成员进行分析验证。认知属性库的数据显示,在汉语中,""鸟""的典型成员是""麻雀""、""燕子""等,和""鸟""具有较多的共同属性;而""企鹅""、""鸵鸟""则只共享了""鸟""很少的属性,且缺少关键的属性""飞""。大体上验证了原型理论的观点。同时,我们也发现""小鸟""的属性特别丰富,具有典型成员的特性。在进一步观察了""水果""和""交通工具""两个范畴后,我们探讨了范畴的跨类现象,进而从数学模型上区分了树结构的层次分类体系和图结构的范畴化体系。 ",MESS201606012
中国英语学习者花园幽径句错位效应强度研究:计算语言学视角,"杜家利1,2:29594142|于屏方3:06841098",17,计算语言学; 花园幽径句; 行进错位; 认知过载; 斯坦福解析器;,"该文借助126名英语专业大二学生对100个花园幽径句和对照句的限时理解实验,讨论了中国英语学习者在解读花园幽径句过程中产生的错位效应,测算了效应强度,并与stanford parser的自动翻译进行了人机对比研究。花园幽径现象是一种有意识的受控行为。其编码和解码具有行进错位和认知过载现象,并能反映人类复杂的心理认知活动。实验证明:在划分的引导词类错位、宾语辖域错位、嵌套错位和兼类错位四类中,错位效应呈现非对称性,其中兼类错位频数最高,错位效应强度也最大。在人机对照中,机器的程序解码错位和学习者认知解码错位不具有完全联动性和绝对共时性。 ",MESS201606013
双语者加工汉语母语语义时对英语的ERP激活效应的研究,"杨思琴1,2:36383213|江铭虎1,2:08821580",9,ERP; 语义; 反应时间; N400;,"本研究采用ERP实验,以被试的反应时间、错误率和脑电成分N400为参考因素,探索高级双语者在加工第一语言时是否自动检索第二语言。结果显示,内隐的英语首发音条件引起的效应没有体现在反应时间上。在ERP实验结果中,被试在判断语义相关的词语时,大脑语言区域的N400在词语英译首发音一致与否的情况下差异不显著;而判断语义无关的词语时,N400在该条件下显著。实验结果分析表明,高级双语者在深度加工第一语言时,大脑可能无意识地检索第二语言。 ",MESS201606014
基于语义角色标注的汉语句子相似度算法,田堃:36382829|柯永红:35817146|穗志方:06268960,7,语义角色标注; 词语相似度; 知网; 词向量; 标注句型匹配;,"在语义角色标注过程中,经常需要检索相似的已标注语料,以便进行参考和分析。现有方法未能充分利用动词及其支配的成分信息,无法满足语义角色标注的相似句检索需求。基于此,本文提出一种新的汉语句子相似度计算方法。该方法基于已标注好语义角色的语料资源,以动词为分析核心,通过语义角色分析、标注句型的相似匹配、标注句型间相似度计算等步骤来实现句子语义的相似度量。为达到更好的实验效果,论文还综合比较了基于知网、词向量等多种计算词语相似度的算法,通过分析与实验对比,将实验效果最好的算法应用到句子相似度计算的研究中。实验结果显示,基于语义角色标注的句子相似度计算方法相对传统方法获得了更好的测试结果。 ",MESS201606015
网络用语词典的构建及问题分析,昝红英1:09467924|许鸿飞1:36382830|张坤丽1:10310465|穗志方2:06268960,7,网络用语; 词典构建; 标注;,"随着互联网应用的快速发展,网络用语的使用越来越普遍,网络新词层出不穷。网络文本中大量的网络用语,对基于自然语言处理的情感分析、产品推荐、问答系统等应用带来了一定的挑战,而收集并构建网络用语词典及相关语料则是解决此类问题的突破点。该文以微博语料为出发点,综合多类网络资源,收集并整理了较为全面的网络用语词典及相关语料。同时,对网络用语词典构建中遇到的问题进行了分析和总结,并对其潜在应用进行了初步的探讨。 ",MESS201606016
谈话节目语料库的构建与会话结构分析,王珊:36383214|刘锐:36383215,7,谈话节目; 会话结构; 组合模式;,"口语语料库的建设是口语研究的基础工作,该文选择具有代表性的交谈式谈话节目《锵锵三人行》和对谈式谈话节目《鲁豫有约》作为语料,建立了一个小型的谈话节目语料库,并构建了包含五大类16小类的会话结构标注体系,对语料进行了会话结构的标注。统计得到打断结构309例,插入结构141例,重复结构111例,问答结构653/589例,阻碍—修正结构51/21例,反映了会话结构在数量上的不均衡分布,节目的形式、性质以及交际任务是会话结构分布的主要影响因素。会话结构组合具有模式性,该文使用Trigram方法对其组合情况进行了分析,发现语料中的高频组合是问答毗邻对,此外有大量的非毗邻性组合。会话结构组合模式不但反映出谈话节目的风格特点,还有助于分析会话中的功能性模块、会话策略的形成,进而更加深入地了解会话的运作机制。 ",MESS201606017
基于远监督的语义知识资源扩展研究,卢达威1:34227763|王星友2:36382831|袁毓林1:06263991,9,资源扩展; 远监督; 语义知识资源;,"语义知识资源蕴含了深刻的语言学理论,是语言学知识和语言工程的重要接口。该文以形容词句法语义词典为研究对象,探索对语义知识资源自动扩展的方法。该文的目标是利用大规模语料库,扩展原有词典的词表及其对应的句法格式。具体方法是根据词的句法格式将词典的词分类,将待扩展的新词通过分类器映射到原有词典的词中,以此把词典扩展问题转化为多类分类问题。依据的原理是词典词和待扩展新词在大规模语料中句法结构的相似性。该文通过远监督的方法构造训练数据,避免大量的人工标注。训练过程结合了浅层机器学习方法和深度神经网络,取得了有意义的成果。实验结果显示,深度神经网络能够习得句法结构信息,有效提升匹配的准确率。 ",MESS201606018
基于伪文档的伪相关反馈方法,闫蓉:10588313|高光来:05981929,9,伪相关反馈; 伪文档; 主题分析; 隐含主题;,"传统的伪相关反馈(Pseudo Relevance Feedback,PRF)方法通常是以文档作为扩展源单元提取扩展词,提取粒度过大造成扩展源质量下降,使得检索结果鲁棒性差。该文研究利用主题分析技术,尝试将文本语义内容作为扩展源单元,缓解扩展源质量不高的问题。提出并实现了对文本集中各文档内容的伪文档描述,通过对其进行隐式多样化处理,实现了从更细微的文本内容角度出发提取扩展词。通过在真实NTCIR8中文语料的检索结果表明,该方法可以有效地提升伪相关反馈的检索性能。 ",MESS201606019
基于框架语义的高考语文阅读理解答案句抽取,"李国臣1,2:08407515|刘姝林1:36382832|杨陟卓1:32467421|李茹1,3:08453268|张虎1:08403299|钱揖丽1:09166197",9,高考语文; 阅读理解; 框架语义; 答案句抽取; 流形排序;,"高考语文阅读理解问答相对普通阅读理解问答难度更大,问句抽象表述的理解需要更深层的语言分析技术,答案候选句抽取更注重与问句的关联分析,答案候选句排序更注重答案句之间的语义相关性。为此,该文提出借助框架语义匹配和框架语义关系抽取答案候选句,在排序时引入流形排序模型,通过答案句之间的框架语义相关度将排序分数进行传播,最终选取分数较高的Top-4作为答案句。在北京近12年高考语文阅读理解问答题上的准确率与召回率分别达到了53.65%与79.06%。 ",MESS201606020
基于文本语义离散度的自动作文评分关键技术研究,王耀华1:36383216|李舟军1:05979723|何跃鹰2:25062726|巢文涵1:22036030|周建设3:08708177,9,作文评分; 语义离散度; 神经网络;,"该文尝试从文本语义离散度的角度去提升自动作文评分的效果,提出了两种文本语义离散度的表示方法,并给出了数学化的计算公式。基于现有的LDA模型、段落向量、词向量等具体方法,提取出四种表征文本语义离散度的实例,应用于自动作文评分。该文从统计学角度将文本语义离散度向量化,从去中心化的角度将文本语义离散度矩阵化,并使用多元线性回归、卷积神经网络和循环神经网络三种方法进行对比实验。实验结果表明,在50篇作文的验证集上,在加入文本语义离散度特征后,预测分数与真实分数之间均方根误差最大降低10.99%,皮尔逊相关系数最高提升2.7倍。该表示方法通用性强,没有语种限制,可以扩展到任何语言。 ",MESS201606021
限定领域口语对话系统中超出领域话语的对话行为识别,,9,对话行为识别; 超出领域话语; 随机森林; 词向量; 口语对话系统;,"由于领域外话语具有内容短小、表达多样性、开放性及口语化等特点,限定领域口语对话系统中超出领域话语的对话行为识别是一个挑战。该文提出了一种结合外部无标签微博数据的随机森林对话行为识别方法。该文采用的微博数据无需根据应用领域特点专门收集和挑选,又与口语对话同样具有口语化和表达多样性的特点,其训练得到的词向量在超出领域话语出现超出词汇表字词时提供了有效的相似性扩展度量。随机森林模型具有较好的泛化能力,适合训练数据有限的分类任务。中文特定领域的口语对话语料库测试表明,该文提出的超出领域话语的对话行为识别方法取得了优于最大熵、卷积神经网络等短文本分类研究进展中的方法的效果。 ",MESS201606022
汉维时间数字和量词的识别与翻译研究,"阿依古丽·哈力克1,2:36382840|艾山·吾买尔1,2:10775068|吐尔根·伊布拉音1,2:22675986|卡哈尔江·阿比的热西提1,2:31758537|买合木提·买买提1,2:22440290",11,时间数字; 无歧义量词; 有歧义量词; 翻译规则; 翻译模板;,"统计机器翻译对时间、数字、量词的泛化能力较弱,为了提高汉维机器翻译系统对时间、数字和量词短语的翻译性能,该文利用双语语料库挖掘并提取汉语时间、数字、量词表达与翻译模式,实现了基于模板的时间、数字、无歧义量词翻译方法及基于上下文的有歧义量词翻译方法。时间、数字、无歧义量词、有歧义量词的翻译F值达到了93.23%、90.15%、96.55%、87.58%,实验证明,该方法具有简单高效的优点。 ",MESS201606023
融合被动和可能态模型的日汉统计机器翻译,王楠:06320374|徐金安:25200603|明芳:36382841|陈钰枫:33219873|张玉洁:10874141,7,被动态; 可能态; 统计机器翻译; 最大熵模型;,"日语中谓词语态有不同的词尾变形,其中被动态和可能态具有相同的词尾变化,在统计机器翻译中难以对其正确区分及翻译。因此,该文提出一种利用最大熵模型有效地对日语可能态和被动态进行分类,然后把日语的可能态和被动态特征有效地融合到对数线性模型中改进翻译模型的方法,以提高可能态和被动态翻译规则选择的准确性。实验结果表明,该方法可以有效提升日语可能态和被动态句子的翻译质量,在大规模日汉语料上,最高翻译BLEU值能够由41.50提高到42.01,并在人工评测中,翻译结果的整体可理解度得到了2.71%的提升。 ",MESS201606024
基于条件随机场的评价对象缺省项识别,"唐文武1:34395377|过弋1,2:23802815|徐永斌1:34395378|方旭1:36382842",7,条件随机场; 评价对象; 缺省识别; 序列标注;,"在电商网站评论文本中,评价对象和评价属性的缺省识别对文本情感分析具有重要地作用。针对电商网站评论文本中评价对象和评价属性缺省问题,该文提出了一种基于条件随机场的评价对象缺省项识别方法。首先利用情感词典识别观点句,将缺省项识别问题转换成序列标注问题,综合词法特征和依存句法特征,使用条件随机场模型进行训练,并在测试集上对待识别的观点句进行序列标注,通过标注结果判定缺省项的位置。实验结果表明,该方法具有较高的准确率和召回率,验证了该方法的有效性。 ",MESS201606025
基于多特征融合的混合神经网络模型讽刺语用判别,"孙晓1:17392399|何家劲1:36383217|任福继1,2:27168503",9,讽刺; 神经网络; 多特征融合; 情感分析;,"在社交媒体中,存在大量的反讽和讽刺等语言现象,这些语言现象往往表征了一定的情感倾向性。然而这些特殊的语言现象所表达的语义倾向性,通常与其浅层字面含义相去甚远,因此加大了社交媒体中文本情感分析的难度。鉴于此,该文主要研究中文社交媒体中的讽刺语用识别任务,构建了一个覆盖反讽、讽刺两种语言现象的语料库。基于此挖掘反讽和讽刺的语言特点,该文通过对比一些有效领域特征,验证了在反讽和讽刺文本的识别中,其结构和语义等深层语义特征的重要性。同时,该文提出了一种有效的多特征融合的混合神经网络判别模型,融合了卷积神经网络与LSTM序列神经网络模型,通过深层模型学习深层语义特征和深层结构特征,该模型获得了较好的识别精度,优于传统的单一的神经网络模型和BOW(Bag-of-Words)模型。 ",MESS201606026
藏文复合句的依存句法分析,华却才让:17628476|赵海兴:08819558,6,句法分析; 依存句法; 藏文分句; 藏文复合句;,"为解决藏文复合句引起的依存句法分析性能下降的主要问题,该文提出了一种基于判别式的藏文复合句切分标注方法,先根据藏文固有的虚词语法结构和连词特征,将复合句子切分标注为句法分析的基本单元,然后将句法分析之后的各个部分依据主分句关系进行合并,生成复合句的完整分析结果。实验结果表明该方法在一定程度上降低了藏文复合句依存句法分析的复杂度,最终句法分析的准确率达到88.72%。 ",MESS201606027
基于蒙古语名词语义网的同形词歧义消除研究,哈斯1:08644535|布音其其格2:36382843,6,蒙古文; 名词语义网; 同形词; 歧义消除;,"蒙古文同形词歧义消除问题是蒙古文信息处理的难点之一。该文提出了基于蒙古语名词语义网的同形词歧义消除方法,设计实现了同形词歧义消除算法,最后给出了语料库中同形词歧义消除实验的设计过程及结果分析。 ",MESS201606028
商务印书馆新书目录,,1, , ,MESS201606029
中文信息学报(双月刊)2016年第30卷总目次,,14, , ,MESS201606030
欢迎订阅2017年度《中文信息学报》,,1, ,"<正>《中文信息学报》(Journal of Chinese Information Pro-cessing)是全国一级学会-社团法人中国中文信息学会和中国科学院软件研究所联合主办的学术性刊物,创刊于1986年10月,现为双月刊。2007年改版为大16开,每期126页,由商务印书馆出版,成为商务印书馆期刊方阵中的期刊之一,清华大学印刷厂印刷。《中文信息学报》是我国计算机、计算技术类中文核心期刊。主要刊登中文信息处理基础理论与应用技术方面的高水平 ",MESS201606031
借重于人工知识库的词和义项的向量表示:以HowNet为例,"孙茂松1,2:08823738|陈新雄1:36387475",7,词向量; 义项向量; 义原向量; HowNet; 神经网络语言模型;,"该文旨在以HowNet为例,探讨在表示学习模型中引入人工知识库的必要性和有效性。目前词向量多是通过构造神经网络模型,在大规模语料库上无监督训练得到,但这种框架面临两个问题:一是低频词的词向量质量难以保证;二是多义词的义项向量无法获得。该文提出了融合HowNet和大规模语料库的义原向量学习神经网络模型,并以义原向量为桥梁,自动得到义项向量及完善词向量。初步的实验结果表明该模型能有效提升在词相似度和词义消歧任务上的性能,有助于低频词和多义词的处理。作者指出,借重于人工知识库的神经网络语言模型应该成为今后一段时期自然语言处理的研究重点之一。 ",MESS201606001
在线社交网络中的新兴话题检测技术综述,"笱程成1,2:35952838|杜攀1:25200622|刘悦1:09639001|程学旗1:09559496",10,新兴话题; 话题检测; 信息传播; 社交网络;,"新兴话题检测是社交网络研究的热点问题之一。在线社交网络特别是微博的开放性,给话题的流行和爆发提供了前所未有的便利条件。新兴话题是即将流行或爆发的话题,往往伴随着重大的事件或新闻的发生,会产生重大的社会影响,如何在早期识别此类话题,是新兴话题检测研究的主要内容。该文回顾了近年来在新兴话题检测方面的主要进展,分析了新兴话题检测领域面临的挑战,阐述了相关的概念、方法和理论,重点从内容突发特征和信息传播模型两个方面对影响新兴话题检测的方法进行了分析和讨论,并对新兴话题检测的前景做了展望。 ",MESS201605002
情感词典构建综述,梅莉莉:35502006|黄河燕:23136252|周新宇:34873784|毛先领:33078440,9,情感分析; 情感词典; 评测; 语料; 综述;,"文本情感分析是近年来迅速兴起的一个研究课题,具有显著的研究价值和应用价值。情感词典的构建在情感分析任务中发挥着越来越重要的影响力。该文对情感词典构建的研究进展进行了总结。首先重点介绍了情感词典构建的研究现状,将其归纳为四种方法,即基于启发式规则的方法、基于图的方法、基于词对齐模型的方法以及基于表示学习的方法,并对每种方法进行介绍和分析;然后对一些常见的语料库、词典资源以及评测组织进行介绍;最后,对情感词典的构建进行了总结,并对发展趋势进行了展望。 ",MESS201605003
面向短文本情感分类的特征拓扑聚合模型,"胡杨1:32929441|冯旭鹏2:32929442|黄青松1,3:07895919|付晓东1:11502836|刘骊1:08529056|刘利军1:10537962",8,短文本; 情感分类; 特征关联度; 强联通分量; 拓扑聚合;,"由于短文本极稀疏性和特征分散的特点,短文本的情感分类效果总是不及篇章文本的情感分类,针对此问题,该文提出面向短文本情感分类的特征拓扑聚合模型。模型首先从特征点互信息,情感指向相似度,主题归属差异值三个维度整合计算情感特征的关联度,然后根据特征关联度建立拓扑聚合图模型,通过在图上求解强联通分量聚合高关联度情感特征,从大量未标注语料中提取相似特征对训练集特征进行补充,同时降低训练空间维度。实验将模型应用于短文本情感分类,与基准算法对比能提高分类准确率和召回率分别达0.03和0.027。验证了模型在缓解短文本极稀疏性和特征分散问题上的效果。 ",MESS201605004
基于统计的新浪微博动态传播规律研究,王怡:35975759|梁循:25202919|周小平:09752355,11,新浪微博; 线性关联密度; 关键节点; 传播模式;,"社交网络是一个庞大的新型复杂系统,用户和信息常用作研究网络静态结构和动态传播过程的典型对象,它们的结构特点和传播规律处处体现出社会网络复杂的特点。该文利用新浪微博约三万名用户及其发信息的数据,从上述两方面进行了研究。首先基于统计,本文发现了新浪微博网络的紧密程度较弱,并实证了关注网络的关联密度是线性的。其次,通过研究单条微博的传播过程的用户影响曲线,我们发现10%的用户能影响其他的90%。第三,该文从时间和转发结构两方面对微博的传播模型进行了归纳。相关的结论能够为后续模型建立、舆情监控等提供支持。 ",MESS201605005
基于地域特征和异构社交关系的事件推荐算法研究,"乔治1,2:32402509|周川2,3:33235093|纪现才3:35975760|曹亚男3:32902264|郭莉3:32902263",10,事件推荐; 基于事件的社交网络; 用户行为倾向; 协从过滤; 地域特征; 异构社交关系;,"近几年,在基于事件的社交网络(EBSNs)服务中,为便于增强用户体验,事件推荐任务一直被广泛研究。本文基于对EBSN中用户行为数据的详细分析,提出了一种新型的融合多种数据特征的潜在因子模型。该模型综合考虑EBSN中两种新型的数据特征:异构的社交关系特征(线上社交关系+线下社交关系)和用户参与行为的地域性特征。基于真实的Meetup数据集,实验结果表明我们的算法在解决事件推荐问题时比传统的算法有更好的性能。 ",MESS201605006
预测信息传播中的转发选择,王永庆:35976935|沈华伟:23136281|程学旗:09559496,9,信息传播; 转发选择; 影响力; 易感性;,"在信息传播中,用户在重复接收同一信息的情况下其转发行为会具有一定的倾向性。对这种转发的倾向性建模是影响力分析、传播动力学、社会推荐等一系列信息传播相关应用研究领域中的一个关键问题。本文假设用户的转发选择行为主要由用户间的人际影响力决定。人际影响力的大小由信息传播者的影响力和信息接收者的易感性共同作用。本文从真实的信息传播记录中推断出用户隐式的影响力和易感性,进而提出了一种转发选择模型。该模型能够有效解决目前方法存在的对转发选择行为建模不充分和模型泛化能力差的问题。本文选取典型的转发选择建模方法作为比较,将所提的转发选择模型在新浪微博数据上进行对比验证。实验表明,本文所提的模型在两种评价指标上均取得更好效果,证明了所提模型的有效性。 ",MESS201605008
一种基于增广网络的快速微博社区检测算法,蒋盛益1:06844554|杨博泓1:30590866|姚娟娜1:35975761|吴美玲2:35975762|张钰莎3:43072524,8,微博; 社区检测; 模块度; 主成分分析; 增广网络; 主题社区;,"微博是当前最流行的在线社交媒体之一,有效地检测出微博用户的社区结构,能够帮助人们理解微博社交网络的结构和用户的行为特征,从而为用户提供个性化的服务。然而,现有社区检测算法大多只考虑社交网络节点之间的直接链接关系,忽略节点自身的内容特征。针对此问题,提出一种基于增广网络的快速微博社区检测算法。该算法通过融合社交网络的链接信息以及用户在微博上所发布的博文内容信息构建增广网络,然后以模块度为目标函数快速挖掘增广网络中的主题社区。通过真实微博社交网络的实验表明,提出的算法能够高效地检测出社交网络的主题社区。 ",MESS201605009
基于概率交易模型的线下百货推荐,"王鹏飞1,2:35975763|郭嘉丰1:14336892|兰艳艳1:30526869|晏小辉1:35975764|程学旗1:09559496",7,PTM; 概率交易模型; 品牌共现;,"该文提出了一种新颖的概率交易模型PTM,针对线下百货进行个性化的推荐。传统的推荐模型,如K-近邻算法、矩阵分解等,或者仅利用局部的数据,使得模型面临线下数据极大的稀疏性挑战,或者忽略百货数据中的交易维度,使得模型损失了同一交易中多商品共现的强相关信息,最终导致它们在面对线下百货推荐问题时性能低下。针对以上的问题,本模型从交易的维度出发,建模交易记录中的共现模式,并利用全局的交易数据来学习商品的相关分量,在此基础上推断出用户的兴趣分布,实现个性化的推荐。在真实的线下百货交易数据上的实验结果表明,该模型能够极大地提高线下百货领域个性化推荐的准确性。 ",MESS201605010
基于路径与深度的同义词词林词语相似度计算,陈宏朝:06885081|李飞:22700423|朱新华:06888229|马润聪:35841995,9,同义词词林; 路径; 深度; 分支间距; 最近公共父结点;,"该文提出了一种基于路径与深度的同义词词林词语语义相似度计算方法。该方法通过两个词语义项之间的最短路径以及它们的最近公共父结点在层次树中的深度计算出两个词语义项的相似度。在处理两个词语义项的最短路径与其最近公共父结点的深度时,为提高路径与深度计算的合理性,为分类树中不同层之间的边赋予不同的权值,同时通过两个义项在其最近公共父结点中的分支间距动态调节词语义项间的最短路径,从而平衡两个词语的相似度。该方法修正了目前相关算法只能得出几个固定的相似度值,所有最近公共父结点处于同一层次的义项对之间的相似度都相同的不合理现象,使词语语义相似度的计算结果更为合理。实验表明,该方法对MC30词对的相似度计算值与人工判定值相比,取得了0.856的皮尔逊相关系数,该结果高于目前大多数词语相似度算法与MC30的相关度。 ",MESS201605011
基于高斯词长特征的中文分词方法,张义:09036504|李治江:09016430,5,高斯词长; 条件随机场; 中文分词; 自然语言处理;,"中文分词是中文信息处理的基础,在语音合成、中外文翻译、中文检索、文本摘要等方面均有重要应用。在中文分词的任务中,存在的主要问题在于可用有效特征较少,分词准确率较低,如何有效的获取和使用分词特征是关键。该文从中文文本生成的过程出发,基于词长噪声的高斯分布特性,提出利用上下文的词长特征作为分词特征。实验表明,在封闭测试中,采用条件随机场模型,使用该特征对现有的实验结果有提高作用。 ",MESS201605013
基于Markov逻辑网的虚假评论识别方法,行娟娟:17664194,7,Markov逻辑网; 虚假评论; 权重学习; 自适应聚类;,"为解决虚假评论识别的问题,该文提出一种基于Markov逻辑网的虚假评论识别方法。首先,对虚假评论内容和评论者行为的特点进行分析,选取评论内容特征和评论者行为特征;然后,根据特征定义一阶逻辑谓词和逻辑公式,并介绍了权重学习和推理的过程;最后,进行了对比实验,结果表明该方法的虚假评论识别取得了较好的效果。 ",MESS201605014
基于属性主题分割的评论短文本词向量构建优化算法,李志宇:31829552|梁循:25202919|周小平:09752355,11,在线评论; 短文本; 词向量; 相似度计算;,"从词向量的训练模式入手,研究了基于语料语句分割(BWP)算法,分隔符分割(BSP)算法以及属性主题分割(BTP)算法三种分割情况下的词向量训练结果的优劣。研究发现,由于评论短文本的自身特征,传统的无分割(NP)训练方法,在词向量训练结果的准确率和相似度等方面与BWP算法、BSP算法以及BTP算法具有明显的差异。通过对0.7亿条评论短文本进行词向量构建实验对比后发现,该文所提出的BTP算法在同义词(属性词)测试任务上获得的结果是最佳的,因此BTP算法对于优化评论短文本词向量的训练,评论短文本属性词的抽取以及情感倾向分析等在内的,以词向量为基础的应用研究工作具有较为重要的实践意义。同时,该文在超大规模评论语料集上构建的词向量(开源)对于其他商品评论文本分析的应用任务具有较好可用性。 ",MESS201605015
基于训练样本集扩展的隐式篇章关系分类,朱珊珊:32017553|洪宇:25038035|丁思远:33952665|严为绒:30700879|姚建民:13898051|朱巧明:09891804,10,隐式篇章关系; 语义向量; 训练样本集扩展; 篇章分析;,"隐式篇章关系分类主要任务是在显式关联线索缺失的情况下,自动检测特定论元之间的语义关系类别。前人研究显示,语言学特征能够有效辅助隐式篇章关系的分类。目前,主流检测方法由于缺少足够的已标注隐式训练样本,导致分类器无法准确学习各种分类特征,分类精确率仅约为40%。针对这一问题,该文提出一种基于训练样本集扩展的隐式篇章关系分类方法。该方法首先借助论元向量,以原始训练样本集为种子实例,从外部数据资源中挖掘与其在语义以及关系上一致的""平行训练样本集"";然后将""平行训练样本集""加入原始训练样本集中,形成扩展的训练样本集;最后基于扩展的训练样本集,实现隐式篇章关系的分类。该文在宾州篇章树库(Penn Discourse Treebank,PDTB)上对扩展的训练样本集进行评测,结果显示,相较于原始训练样本集,使用扩展的训练样本集的实验系统整体性能提升8.41%,在四种篇章关系类别上的平均性能提升5.42%。与现有主流分类方法性能对比,识别精确率提升6.36%。 ",MESS201605016
基于语义和图的文本聚类算法研究,蒋旦:33543252|周文乐:31718964|朱明:10337125,8,文本聚类; 完全子图; 语义相似度; 词向量;,"传统的文本聚类往往采用词包模型构建文本向量,忽略了词语间丰富的语义信息。而基于中心划分的聚类算法,容易将概念相关的自然簇强制分开,不能很好地发现人们感兴趣的话题。该文针对传统文本聚类算法的缺点,提出一种基于语义和完全子图的短文本聚类算法,通过对目前主流的三大语义模型进行了实验和对比,选择了一种较为先进的语义模型,基于该语义模型进行了聚类实验,发现新算法能较好地挖掘句子的语义信息且较传统的K-means有更高的聚类纯度。 ",MESS201605017
基于全局优化的中文事件时序关系推理方法,"郑新1,2:32144889|李培峰1,2:09886822|朱巧明1,2:05968617",7,事件; 时序关系; 推理;,"近年来,越来越多的研究关注事件时序关系,但大多数工作集中于提高事件关系分类器的性能,忽略了分类器错误所造成的事件关系间不一致的问题。该文利用了一个全局优化的推理模型来解决这一问题,将事件时序关系全局优化看成整数线性规划问题,使用了自反性、传递性、同指性、时序连接词、事件类型对等多个约束条件。实验结果表明,该文的全局推理方法与分类器相比,F1值提高了3.56%。 ",MESS201605018
产品评论中领域情感词典的构建,郗亚辉:07075773,9,情感分析; 领域情感词典; 上下文约束; 基于约束的标签传播算法;,"领域情感词典是情感分析最重要的基础。由于产品评论的数量巨大、领域众多,如何自动构建领域情感词典已经成为近年来的一个研究热点。该文提出了一个两阶段的领域情感词典构建算法。第一阶段,利用情感词间的点互信息和上下文约束,使用基于约束的标签传播算法构造基本情感词典;第二阶段,根据情感冲突的频率来识别领域相关情感词,并根据其上下文约束以及修饰的特征完善领域情感词典。实验结果表明,该方法在实际产品评论数据集上取得了较好的效果。 ",MESS201605019
基于翻译模型和语言模型相融合的双语句对选择方法,姚亮:08849993|洪宇:25038035|刘昊:32925637|刘乐:32925638|姚建民:13898051,8,双语句对选择; 生成式建模; 翻译模型; 语言模型; 权重调节;,"双语句对选择方法旨在从大规模通用领域双语语料库中,自动抽取与待翻译文本领域相关性较高的句对,以缓解特定领域翻译模型训练语料不足的问题。区别于原有基于语言模型的双语句对选择方法,该文从句对生成式建模的角度出发,提出一种基于翻译模型和语言模型相融合的双语句对选择方法。该方法能够有效评价双语句对的领域相关性及互译性。实验结果显示,利用该文所提方法选择双语句对训练所得翻译系统,相比于基准系统,在测试集上性能提升3.5个BLEU值;此外,针对不同句对质量评价特征之间的权重调节问题,该文提出一种基于句对重排序的特征权重自动优化方法。基于该方法的机器翻译系统性能继续提升0.68个BLEU值。 ",MESS201605020
二分图顶点配对模型下的英汉句子对齐研究,严灿勋:20288395,7,句子对齐; 双语词典; 平行文本; 二分图; 顶点配对; 顶点对;,"英汉平行文本句子对齐可以视为一个二分图顶点配对模型。利用完全基于英汉词典的双语句子相关性评价函数,能够对二分图的""顶点对""进行加权。该文提出的顶点配对句子对齐方法首先获取二分图全局最大权重顶点配对作为临时锚点;在此基础上,根据句子先后顺序,局部最大权重顶点配对和英汉句长比的值域范围,纠正临时锚点中的错误,补充锚点序列未覆盖的合法顶点对,同时划分句对,实现句子对齐处理。在对比实验中该句子对齐方法优于Champollion句子对齐系统。从实验对比结果和实践效果看,该句子对齐方法可行。 ",MESS201605022
异源语料融合研究,"吕学强1:10724564|仵永栩1,2:35074495|周强2:08836151|刘殷1,2:34683574",9,语料建设; 语料融合; 词类映射; 词性消歧;,"语料资源与自然语言处理领域的各项研究息息相关,具有很大的应用价值。由于不同的研究机构对于语料标注的规则和标记的类型不尽相同,使得不同的语料库很难组合为一个更大的语料库来进行使用。针对该问题,该文从不同标注库及词类映射层面考虑,对其产生的词性歧义问题进行了研究,提出了一种将异源语料融合到一种体系下的方法,对词类信息进行映射和消歧,并进行了实验验证,融合后的词性信息准确率可达87%,实验结果表明该方法具有一定的有效性和可扩展性。 ",MESS201605023
基于查询性能预测的鲁棒检索排序研究,"薛源海1,2,3:31835373|俞晓明1,2:09560060|刘悦1,2:09639001|关峰1,2,3:31835374|程学旗1,2:09559496",8,查询性能预测; 排序学习; 鲁棒检索排序;,"信息检索技术致力于从海量的信息资源中为用户获取所需的信息。相较于传统的简单模型,近些年来的大量研究工作在提升了检索结果平均质量的同时,往往忽略了鲁棒性的问题,即造成了很多查询的性能下降,导致用户满意度的显著下降。本文提出了一种基于排序学习的查询性能预测方法,针对每一个查询,对多种模型得到的检索结果列表进行预测,将其中预测性能最优的检索结果列表展示给用户。在LETOR的三个标准数据集OHSUMED、MQ2008和MSLR-WEB10K上的一系列对比实验表明,在以经典的BM25模型作为基准的情况下,与当前最好的检索模型之一LambdaMART相比,该方法在提升了检索结果平均质量的同时,显著地减少了性能下降的查询的数量,具备较好的鲁棒性。 ",MESS201605024
一种半监督的中文垃圾微博过滤方法,姚子瑜:35975765|屠守中:33118167|黄民烈:08227571|朱小燕:08187758,11,垃圾微博过滤; 半监督学习; EM算法; 朴素贝叶斯;,"微博作为目前国内外最活跃的信息分享平台之一,其中却充斥着大量的垃圾内容。因此,如何从给定话题的微博数据中,过滤掉与话题不相关的垃圾微博、保留话题相关微博,成为迫切需要解决的问题。该文提出了一种半监督的中文微博过滤方法,基于朴素贝叶斯分类模型和最大期望算法,实现了利用少量标注数据的垃圾微博过滤算法,其优势是仅仅利用少量标注数据就可以获得较为理想的过滤性能。分别对十个话题140 000余条新浪微博数据进行过滤,该文提出的模型准确度和F值优于朴素贝叶斯和支持向量机模型。 ",MESS201605025
一种基于云模型的文摘单元选取方法研究,陈劲光:11431418,9,云模型; 自动文摘; 不确定性;,"该文提出了一种基于云模型的文摘单元选取方法,利用云模型,全面考虑文摘单元的随机性和模糊性,提高面向查询的多文档自动文摘系统的性能。首先计算文摘单元和查询条件的相关性,将文摘单元和各个查询词的相关度看成云滴,通过对云的不确定性的计算,找出与查询条件真正意义相关的文摘单元;随后利用文档集合重要度对查询相关的结果进行修正,将文摘句和其他各文摘句的相似度看成云滴,利用云的数字特征计算句子重要度,找出能够概括尽可能多的文档集合内容的句子,避免片面地只从某一个方面回答查询问题。为了证明文摘单元选取方法的有效性,在英文大规模公开语料上进行了实验,并参加了国际自动文摘公开评测,取得了较好的成绩。 ",MESS201605026
一种基于神经网络模型的句子排序方法,康世泽:35386764|马宏:21334685|黄瑞阳:32951678,8,句子排序; 多文本摘要; 神经网络模型; 马尔科夫随机游走模型;,"句子排序是多文本摘要中的重要问题,合理地对句子进行排序对于摘要的可读性和连贯性具有重要意义。该文首先利用神经网络模型融合了五种前人已经提出过的标准来决定任意两个句子之间的连接强度,这五种标准分别是时间、概率、主题相似性、预设以及继承。其次,该文提出了一种基于马尔科夫随机游走模型的句子排序方法,该方法利用所有句子之间的连接强度共同决定句子的最终排序。最终,该文同时使用人工和半自动方法对句子排序的质量进行评价,实验结果表明该文所提出方法的句子排序质量与基准算法相比具有明显提高。 ",MESS201605027
藏文国际音标(拉萨音)自动转换研究,"龙从军1,2:31758532|刘汇丹1:09573793|吴健1:09573880",7,藏语; 国际音标; 自动转换; 分词;,"该文旨在实现从藏文文本到国际音标的自动转换,在一定程度上解决获取较大规模的藏文国际音标标注文本的问题。在国际音标转换系统中,采用了基于规则和统计融合的方法,实现了文语语音词自动切分;利用辅音、元音和声调对应规则表实现了藏语音节的国际音标自动转换;利用声调变化规则、辅音和元音变化规则实现了基于语音词的声调变调、辅音和元音的变化。从自动标注的结果来看,达到了实用效果。 ",MESS201605028
基于笔画曲率特征的笔迹鉴别方法,"李庆武1,2:07178603|马云鹏1:31013657|周妍1,2:21770298|周亮基1:32435324",6,笔迹鉴别; 数学形态学; 笔画圆重构; 笔画曲率; 夹角相似性;,"现有的手写汉字脱机笔迹鉴别方法存在只能针对特定字符或需要大量样本字符等问题,为此提出一种基于笔画曲率特征的笔迹鉴别方法。首先运用数学形态学对采集的笔迹图像进行预处理,在横、竖、撇、捺四个方向提取具有代表性的笔画骨架,然后对笔画骨架进行圆的重构,提取四个方向笔画圆的曲率作为特征值组成笔迹特征矩,根据待鉴别的笔迹特征矩与数据库中笔迹特征矩向量夹角相似性度量结果对样本做出判断。实验结果表明该文方法对于待鉴别样本字符的内容没有要求,样本字符数量要求低、应用范围广、鲁棒性强。 ",MESS201605029
商务印书馆新近推出《全球华语大词典》,,1, ,"<正>主编:李宇明书号:978-7-100-12229-0定价:298.00元《全球华语大词典》是《全球华语词典》的升级版,是一部反映世界主要华语区当代华语词汇面貌的大型语文辞书。主要收录全球华人使用的华语词语,包括中国大陆(内地)、中国香港、中国澳门、中国台湾、新加坡、马来西亚以及亚洲其他地区和北美、欧洲等地的华语词语,共收录华语词语约 ",MESS201605030
第十五届全国计算语言学学术会议在鲁东大学成功召开,,1, ,"<正>""第十五届全国计算语言学学术会议""与""第四届基于自然标注大数据的自然语言处理国际学术研讨会""于2016年10月14日至16日在鲁东大学成功举行。会议主办单位为中国中文信息学会,组织单位为清华大学智能技术与系统国家重点实验室,承办单位为鲁东大学。会议的大会主席由清华大学张钹院士和哈尔滨工业大学李生教授担任,计算语言学会议程序委员会主席由清华大学孙茂松教授 ",MESS201605031
欢迎订阅2017年度《中文信息学报》,,1, ,"<正>《中文信息学报》(Journal of Chinese Information Pro-cessing)是全国一级学会-社团法人中国中文信息学会和中国科学院软件研究所联合主办的学术性刊物,创刊于1986年10月,现为双月刊。2007年改版为大16开,每期126页,由商务印书馆出版,成为商务印书馆期刊方阵中的期刊之一,清华大学印刷厂印刷。《中文信息学报》是我国计算机、计算技术类中文核心期刊。主要刊登中文信息处理基础理论与应用技术方面的高水平 ",MESS201605032
篇章关系分析研究综述,严为绒:30700879|徐扬:08867922|朱珊珊:32017553|洪宇:25038035|姚建民:13898051|朱巧明:05968617,11,篇章关系; 篇章修辞结构; RSTDT; PDTB; CDTB;,"篇章关系研究,旨在推断同一篇章内相邻或跨度在一定范围内的文本片段之间的语义连接关系。语义连接关系对篇章内容理解和结构分析都具有重要作用,成为目前篇章分析领域的重点研究内容。该文针对三个中英文篇章关系研究领域的语料库:基于修辞结构理论的篇章树库(Rhetorical Structure Theory Discourse Treebank,RSTDT)、宾州篇章树库(Penn Discourse Treebank,PDTB)和哈尔滨工业大学中文篇章关系语料库(HIT Chinese Discourse Treebank,HIT-CDTB),主要介绍篇章关系分析理论的语料资源与研究背景、标注与评测体系以及国内外研究现状。此外,总结相关工作,指出目前篇章关系,尤其是隐式篇章关系研究的主要难题。 ",MESS201604001
汉语“比”字句关键要素的常规序列模式探索,朴敏浚1:35809304|李强2:08480529|袁毓林1:06263991,9,“比”字句; 关键要素; 关联规则; 序列模式; 分布规律;,"表达""差比""义的""比""字句,是比较句的主要句型,也是比较句关键要素抽取研究中不可回避的主要课题。该句型的关键要素(SUB、BI、OBJ、ITM、DIM、RES、EXT)在语义上互相交织,在表层句法上可以实现为多种多样的序列模式。该文面向中文""比""字句关键要素抽取这个目标,对于表示""差比""义的460多个""比""字句文本进行了七种关键要素的标注。在此基础上,利用Apriori和PrefixSpan算法找出这些要素的关联规则及其序列模式,并归纳出六种""比""字句关键要素的分布规律。此外,该文还进一步说明了产生这六种模式规则的动因,为""比""字句特征选取和处理提供了重要的语言学理论依据。 ",MESS201604002
基于马尔科夫逻辑网的中文专利最大名词短语识别,蔡东风:24679274|赵奇猛:30813178|饶齐:32622764|王裴岩:24679272,8,最大名词短语; 马尔科夫逻辑网; 中文专利;,"缺少标注语料和难以识别动词和名词类是阻碍中文专利最大名词短语识别的主要问题。针对上述问题,该文提出了一种基于马尔科夫逻辑网的中文最大名词短语识别方法。该方法避免对开放类的名词短语的识别,而将主要精力放在了相对封闭的分隔符的识别上,利用句子自身特征、领域迁移特征以及双语对齐特征来识别最大名词短语的边界。结果说明,双语信息较好地促进了动词、介词、连词等MNP边界的识别。MNP识别的F值可达83.27%。 ",MESS201604003
基于知网与词林的词语语义相似度计算,朱新华:06888229|马润聪:35841995|孙柳:32024244|陈宏朝:06885081,8,语义相似度; 知网; 同义词词林; 语义距离;,"该文提出了一种综合知网与同义词词林的词语语义相似度计算方法。知网部分根据义原层次结构的特征,采用了顶部平缓而底部陡峭的曲线单调递减的边权重策略,改进了现有的义原相似度算法;词林部分采用以词语距离为主要因素、分支节点数和分支间隔为微调节参数的方法,改进了现有的词林词语相似度算法。然后再根据词语的分布情况,采用综合考虑知网与同义词林的动态加权策略计算出最终的词语语义相似度。该方法充分利用了词语在知网与词林中的语义信息,极大地扩充了可计算词语的范围,同时也提高了词语相似度计算的准确率。 ",MESS201604004
专利中基于语义角色的术语相似度计算方法,姜利雪:32881832|季铎:25068860|蔡东风:24679274,7,术语; 内部语义角色; 共享最近邻; 术语相似度; 专利文本;,"术语是由一个到多个单词按照某种语义角色组合而成的,传统的基于统计的相似度计算方法,将术语看作一个基本单元来进行计算,忽略了术语内部的语义角色,且对于上下文信息不丰富的术语,无法利用统计的方法取得理想的效果;基于语义资源的相似度计算方法,所涵盖的词语有限,因此不包含在语义资源中的术语便无法计算相似度。针对这些问题,该文针对专利提出了基于语义角色的术语相似度计算方法,该方法弥补了传统方法的不足。该文对术语内部的单词进行语义角色标注,通过共享最近邻方法计算单词的相似度,然后根据不同的语义角色,利用单词相似度来计算术语相似度。实验表明,该方法与传统方法相比,取得了较好的效果。 ",MESS201604005
一种基于主动学习的框架元素标注,"屠寒非1:35842585|李茹1,2:08453268|王智强1:25200586|周铁峰1:35842586",12,主动学习; 框架元素标注; 条件随机场; 不确定性度量;,"框架元素标注是中文FrameNet众多任务中亟待解决的一个问题,目前仍主要采用有监督的机器学习方法,即依赖大规模人工标注的例句作为训练语料。但例句标注又是一件费时费力的工作,所以为了降低人工标注的代价,该文将主动学习应用到框架元素标注中,优先选择训练模型预测最不准的例句交由人工标注。该文以条件随机场为标注模型,并提出了进行样本选择时所依赖的准则。实验表明,一方面,与随机选择样本进行标注相比,当使用相同数量的例句训练模型时,主动学习使框架元素标注的性能最高提升4.83%;另一方面,主动学习使框架元素标注达到同等F值时只需更少的标注例句,人工标注量最高可减少30%。 ",MESS201604006
基于复杂网络理论的汉语复句关系词搭配网的统计特征研究,胡泉1:07627062|谢芳2:17545671|李源3:07646009|刘延申1:07641511,10,汉语复句关系词搭配; 复杂网络; 平均路径长度; 聚集系数; 度分布;,"汉语复句关系词是汉语复句在语表形式上的标记,是复句中标识关系的重要构件,在现代汉语复句研究领域起着关键作用。汉语复句关系词的搭配是指在汉语语篇中两个或两个以上的复句关系词形成的句法共现形式,它不仅影响着分句的语义,而且影响着复句层次关系的划分。该文利用复杂网络的理论,基于已获取的470个复句关系词构建了一个""现代汉语复句关系词搭配网络""。通过对该网络中的平均路径长度、聚集系数和度分布等特征的统计,用来发现汉语复句关系词之间的搭配能力和搭配强度,这些结果能够帮助复句层次关系和复句逻辑语义的自动识别。 ",MESS201604007
基于WordNet的中泰文跨语言文本相似度计算,"石杰1,2:07896533|周兰江1,2:07894197|线岩团1,2:23245672|余正涛1,2:05982358",6,WordNet; 中间层语言; 跨语言文本相似度;,"文本相似度在信息检索、文本挖掘、抄袭检测等领域有着广泛的应用。目前,大多数研究都只是针对同一种语言的文本相似度计算,关于跨语言文本相似度计算的研究则很少,不同语言之间的差异使得跨语言文本相似度计算很困难,针对这种情况,该文提出一种基于WordNet的中泰文跨语言文本相似度的计算方法。首先对中泰文本进行预处理和特征选择,然后利用语义词典WordNet将中泰文本转换成中间层语言,最后在中间层上计算中泰文本的相似度。实验结果表明,该方法准确率达到82%。 ",MESS201604008
一种基于复杂网络的短文本语义相似度计算,詹志建:29075166|杨小平:09751479,11,复杂网络; 综合特征值; 短文本; 语义相似度;,"将传统的文本相似度量方法直接移植到短文本时,由于短文本内容简短的特性会导致数据稀疏而造成计算结果出现偏差。该文通过使用复杂网络表征短文本,提出了一种新的短文本相似度量方法。该方法首先对短文本进行预处理,然后对短文本建立复杂网络模型,计算短文本词语的复杂网络特征值,再借助外部工具计算短文本词语之间的语义相似度,然后结合短文本语义相似度定义计算短文本之间的相似度。最后在基准数据集上进行聚类实验,验证本文提出的短文本相似度计算方法在基于F-度量值标准上,优于传统的TF-IDF方法和另一种基于词项语义相似度的计算方法。 ",MESS201604009
基于PDTB体系的隐式篇章关系识别,李生:26803240|孔芳:08865090|周国栋:13898054,9,篇章处理; 隐式篇章关系; 宾州篇章树库;,"识别隐式篇章关系是篇章分析领域中非常有挑战的一个任务。该文基于PDTB语料提出一个隐式篇章分析识别方法,使用传统的特征如动词,极性和句法推导规则等,系统分析了它们对隐式篇章分析的影响。我们利用全部标注数据构建多个分类器并使用加法规则融合分类结果,此外还通过前向特征选择算法确定各分类任务最优的特征集。实验结果表明该方法能显著提升隐式篇章分析的性能。 ",MESS201604010
基于中心理论和话语结构的交互式问答文本指代消解,李映:08865211|孔芳:08865090,8,指代消解; 交互式问答; 中心理论; 话语结构;,"与传统新闻文本相比,交互式问答中蕴含着更为丰富的语言现象。在传统的针对新闻文本的指代消解方案的基础上,融入了交互式问答特有的特征集,给出了一个适于交互式问答文本的指代消解方案。具体而言,基于浅层语义角色分析的结果进行话语结构的识别,根据识别出的话语结构进行话语中心及中心跳转的识别。将获取到的话语中心及跳转信息组织成交互式文本特有的特征集,使用交互式问答领域广泛使用的TREC2004和TREC2007的评测语料进行指代消解的实验,结果表明给出的方案能大大提高交互式问答文本中指代消解的性能,系统F值提高了3.2%。 ",MESS201604011
藏文字形结构分布研究,"才智杰1:08166533|才让卓玛1,2:11447913",8,中文信息处理; 字形结构; 独体字; 合体字; 频度统计;,"字是语言文字的基本组成单位,字形结构统计研究是自然语言处理的基础,为字属性分析、输入法设计、排序、语音合成和字符信息熵研究等提供理论依据。该文通过分析藏文字形结构的特征,对藏文字的字形结构分成独体字和合体字,合体字按其构件的结构位和所含构件数进行分类。设计了藏文字形结构统计系统模型和算法,从约含8 500万藏文字的450M语料中对藏文字形结构进行统计,建立了藏文字形结构分布统计表,并对统计结果进行了分析。 ",MESS201604012
基于拓扑特征的纳西东巴文象形文字输入方法研究,"王海燕1:23824515|王红军1,2:06405765|徐小力2:06407828",4,纳西; 东巴; 象形文字; 输入方法;,"纳西东巴文字是一种比甲骨文还要原始的图画象形文字,该文针对大量纳西经典古籍资料需要录入、整理、分析的需要,设计一种普通用户即可使用的基于拓扑特征的输入方法。首先针对纳西东巴象形文字的1 561个基本字形的五个拓扑特征-块数、孔数、端点数、三叉点数和四叉点数进行了统计和分析,然后基于Java程序结合TTF字库文件进行了测试,证明了该方法可行。统计结果表明,50%以上的纳西东巴象形文字通过这五个特征可以唯一识别,80%以上的东巴文字通过该方法识别时重复数不高于4,人工输入、识别的效率较高,为纳西东巴象形文字的输入方法提供一种新的思路。 ",MESS201604014
基于层叠条件随机场的高棉语分词及词性标注方法,潘华山:45671676|严馨:07900010|周枫:08529670|余正涛:15380715|郭剑毅:07895859,7,高棉语; 层叠条件随机场; 分词; 词性标注;,"针对高棉语分词及词性标注问题,提出一种基于层叠条件随机场模型的自动分词及词性标注方法。该方法由三层条件随机场模型构成:第一层是分词模型,该模型以字符簇为粒度,结合上下文信息与高棉语的构词特点构建特征模板,实现对高棉语句子的自动分词;第二层是分词结果修正模型,该模型以词语为粒度,结合上下文信息与高棉语中命名实体的构成特点构建特征模板,实现对第一层分词结果的修正;第三层是词性标注模型,该模型以词语为粒度,结合上下文信息与高棉语丰富的词缀信息构建特征模板,实现对高棉语句子中的词语进行自动标注词性。基于该模型进行开放测试实验,最终准确率为95.44%,结果表明该方法能有效解决高棉语的分词和词性标注问题。 ",MESS201604015
机器译文自动评价中基于IHMM的近义词匹配方法研究,李茂西:29475622|徐凡:31367729|王明文:08472511,7,机器译文自动评价; 近义词匹配; 间接隐马尔可夫模型; 单语句子词对齐; 相关性;,"机器译文的自动评价推动着机器翻译技术的快速发展与应用,在其研究中的一个关键问题是如何自动的识别并匹配机器译文与人工参考译文之间的近义词。该文探索以源语言句子作为桥梁,利用间接隐马尔可夫模型(IHMM)来对齐机器译文与人工参考译文,匹配两者之间的近义词,提高自动评价方法与人工评价方法的相关性。在LDC2006T04语料和WMT数据集上的实验结果表明,该方法与人工评价的系统级别相关性和句子级别相关性不仅一致的优于在机器翻译中广泛使用的BLEU、NIST和TER方法,而且优于使用词根信息和同义词典进行近义词匹配的METEOR方法。 ",MESS201604017
基于多特征融合和图匹配的维汉句子对齐,"倪耀群1,2,3:25202890|许洪波1:10348532|程学旗1:09559496",10,句子对齐; 人名、地名翻译; 多特征融合; 二部图最佳匹配;,"维吾尔语新闻网页与对应的中文翻译网页在内容上往往并非完全可比,主要表现为双语句子序列的错位甚至部分句子缺失,这给维汉句子对齐造成了困难。此外,作为新闻要素的人名地名很多是未登录词,这进一步增加了维汉句子对齐的难度。为了提高维汉词汇的匹配概率,作者自动提取中文人名、地名并翻译为维吾尔译名,构造双语名称映射表并加入维汉双语词典。然后用维文句中词典词对应的中文译词在中文句中进行串匹配,以避免中文分词错误,累计所有匹配词对得到双语句对的词汇互译率。最后融合数字、标点、长度特征计算双语句对的相似度。在所有双语句子相似度构成的矩阵上,使用图匹配算法寻找维汉平行句对,在900个句对上最高达到95.67%的维汉对齐准确率。 ",MESS201604018
基于词重要性的信息检索图模型,王明文:08472511|洪欢:29895355|江爱文:26498557|左家莉:07871349,8,词项重要性; 词项图; 检索模型; TI-IDF;,"在信息检索建模中,确定索引词项在文档中的重要性是一项重要内容。以词袋(bag-of-word)的形式表示文档来建立检索模型的方法中大多是基于词项独立性假设,用TF和IDF的函数来计算词项的重要性,并未考虑词项之间的关系。该文采用基于词项图(graph-of-word)的文档表示形式来捕获词项间的依赖关系,提出了一种新的基于词重要性的信息检索图模型TI-IDF。根据词项图得到文档中词项的共现矩阵和词项间的概率转移矩阵,通过马尔科夫链计算方法来确定词项在文档中的重要性(Term Importance,TI),并以此替代索引过程中传统的词项频率TF。该模型具有更好的鲁棒性,我们在国际公开数据集上与传统的检索模型进行了比较。实验结果表明,该文提出的模型都要优于BM25,且在大多数情况下优于BM25的扩展模型、TW-IDF等模型。 ",MESS201604019
基于Tri-training与噪声过滤的弱监督关系抽取, ,9,关系抽取; 弱监督学习; Tri-training; 数据编辑;,"弱监督关系抽取利用已有关系实体对从文本集中自动获取训练数据,有效解决了训练数据不足的问题。针对弱监督训练数据存在噪声、特征不足和不平衡,导致关系抽取性能不高的问题,文中提出NF-Tri-training(Tritraining with Noise Filtering)弱监督关系抽取算法。它利用欠采样解决样本不平衡问题,基于Tri-training从未标注数据中迭代学习新的样本,提高分类器的泛化能力,采用数据编辑技术识别并移除初始训练数据和每次迭代产生的错标样本。在互动百科采集数据集上实验结果表明NF-Tri-training算法能够有效提升关系分类器的性能。 ",MESS201604020
产品评论挖掘中特征同义词的识别,郗亚辉:07075773,9,产品评论挖掘; 产品特征同义词; 相似度; 约束层次聚类算法;,"随着电子商务的飞速发展,电子商务网站上的各种产品评论数量也在飞速增长。如何从Web中大量存在的产品评论中挖掘出对消费者和生产厂商都有价值的信息,已经成为一个非常重要的研究领域。在产品评论中,用户往往会用不同的词语描述同一产品特征。识别这些产品特征同义词才能更好地进行观点汇总。该文经过对产品评论的分析,抽取了must-link和can-not-link两类约束,并使用约束层次聚类算法识别产品特征同义词。同时,比较了几种不同产品特征相似度计算方法的结果。实验结果表明,该文的方法在实际产品评论数据集上取得了较好的效果。 ",MESS201604021
基于CRFs和领域本体的中文微博评价对象抽取研究,"丁晟春1,2:08092475|吴婧婵媛1:35842587|李霄1:28752674",8,CRFs模型; 本体; 特征选择; 评价对象抽取; 信息抽取;,"微博情感分析是对微博内容进行细粒度的挖掘,有着重要的研究价值。微博评价对象的抽取是微博情感分析研究的关键问题之一。为了提高中文微博评价对象抽取的准确率,该文在中文微博特征分析和微博评论本体构建研究的基础上,尝试从词、词性、情感词以及本体四个方面进行特征选择,采用CRFs模型对评价对象进行抽取。该文将提出的方法运用到COAE2014测评的Task5评价对象抽取任务中,宏平均准确率达到61.20%,在所有测评队伍中居第一。实验结果表明,将本体特征引入到CRFs模型中,能够有效地提高评价对象抽取的准确率。 ",MESS201604023
一种基于事件本体的文本事件要素提取方法,刘炜:08480650|刘菲京:30186677|王东:09543298|刘宗田:05974886,9,事件本体; 事件要素; 事件要素推理;,"在事件信息的抽取中,事件要素的提取是一个难点。现有的事件要素抽取主要是基于机器学习的方法,这类方法容易受到语料稀疏性的影响。该文提出一种基于事件本体的事件要素提取方法,该方法将事件要素推理分为两步:一、通过事件要素词和事件指示词的位置关系来初步填充要素值,并将得出的置信度较高的事件作为种子事件;二、利用第一步得出的种子事件,查询事件本体中的事件类约束和基于事件非分类关系的推理规则,并对要素进行推理,进一步对事件要素进行填充和修正。实验结果表明,该方法能较好地提升事件要素提取的准确度。 ",MESS201604024
融合多种特征的实体链接技术研究,陈玉博1:29895348|何世柱1:35841997|刘康1:13898613|赵军1:10891784|吕学强2:10724564,8,实体消歧; 实体链接; 排序学习;,"实体消歧是自然语言理解的重要研究内容,旨在解决文本信息中普遍存在的命名实体歧义问题,在信息抽取、知识工程和语义网络等领域有广泛的应用价值。实体链接是实体消歧的一种重要方法,该方法将具有歧义的实体指称项链接到给定的知识库中从而实现实体歧义的消除[1]。传统的实体链接方法主要利用上下文的词语匹配等表层特征,缺乏深层语义信息,针对这一问题,该文提出的实体链接方法利用了多种特征,从不同的维度捕获语义信息。为了更好地融合各个维度的特征,该文利用了基于排序学习框架的实体链接方法,与传统的方法相比,节省了人工对大量的模型参数选择和调节的工作,与基于分类的方法相比,能更好地利用到候选之间的关系信息。在TAC-KBP-2009的实体链接评测数据上的实验表明,该文提出的特征和方法表现出良好的性能,在评测指标上高出参赛队伍最好水平2.21%,达到84.38%。 ",MESS201604025
融合显性和隐性特征的中文微博情感分析,陈铁明:09404143|缪茹一:32907990|王小号:10797906,9,表情符号; 情感词典; 语义; 频繁项集; 聚类;,"微博情感分析是研究社交网络舆情的一项关键技术。微博表情符号和情感词汇等是一类直观显性的情感特征,而微博的内容语义则可视为隐性特征,且对情感判定往往具有决定性作用,因此本文提出将两类特征因素融合的微博情感分析方法。首先构建情感分析词典、网络用语词典以及表情符号库,定义微博频繁特征词集,再根据频繁特征词集,利用最大频繁项集获得微博初始情感簇;针对初始簇间存在文本重叠情况,提出基于短文本扩展语义隶属度的簇间重叠消减算法,获得完全分离的初始簇;最后根据簇语义相似度矩阵,给出一种凝聚式情感聚类方法。利用NLPCC2013评测所提供的训练语料进行情感分类实验,说明了分析该文方法的性能优势,并以2014年3月8日马航事件微博数据为例,给出了利用微博情感分析公众随事态发展的情感变化,说明了该文方法的实用效果。 ",MESS201604026
中文微博情感词提取:N-Gram为特征的分类方法,刘德喜1:13897196|聂建云2:07985895|张晶3:07566560|刘晓华2:35842165|万常选1:07848038|廖国琼1:23417932,14,情感词提取; 中文微博; 分类方法; N-Gram特征;,"情感词典是文本情感分析的基础资源,但采用手工方式构建工作量大,且覆盖有限。一种可行的途径是从新情感词传播的重要媒介-微博数据-中自动抽取情感词。该文以COAE 2014评测任务3提供的中文微博数据为统计对象,发现传统的基于共现的方法,如点互信息等,对中文微博数据中的新情感词发现是无效的。为此,设计一组基于上下文词汇的分类特征,即N-Gram特征,以刻画情感词的用词环境和用词模式,并以已知情感词为训练数据训练分类器,对候选情感词进行分类。实验结果表明,该方法较传统基于共现的方法要好。实验还发现,与英语不同的是,中文情感词通常会以名词词性出现,而基于共现的方法无法有效地区分该类情感词,这是造成其失效的主要原因,而该文提出的分类特征能解决这一问题。 ",MESS201604027
基于隐马尔可夫模型的主观句识别,"刘培玉1,2:30224816|荀静2:31317940|费绍栋2:29361292|朱振方3:30224817",7,隐马尔可夫模型; 特征标注; 主观句识别;,"文本情感倾向分析是意见挖掘和情感文摘中的一个重要环节,而在情感倾向分析中涉及到的是主观性文本,这就需要进行主客观文本分类。当前的主客观文本分类方法主要是基于特征词典的概率统计方法,并没有考虑特征之间的语法与语义关系。针对该问题,该文提出一种基于隐马尔可夫模型(HMM)的主观句识别方法。该方法首先从训练语料中抽取具有明显分类效果的七类主客观特征,然后每个句子应用HMM进行特征角色类别标注,并依据标注的结果计算句子的权重,最终识别主观句。该方法在第六届中文倾向性分析评测任务中能够有效地识别主观句。 ",MESS201604028
在线游戏用户的流失预测:基于不平衡数据的采样方法比较和分析,吴悦昕:32936763|赵鑫:29227474|过岩巍:31343806|闫宏飞:06276313,10,在线游戏; 流失预测; 不平衡数据; 采样法;,"流失用户预测问题在很多领域都是研究重点。目前主流的流失用户预测方法是使用分类法,即把用户是否会流失看作一个二分类问题来处理。该文提出了一个基于二分类问题解决的在线游戏流失用户预测方法。此方法除了总结了一些对在线游戏而言比较重要的可以用于流失预测的特征之外,也考虑到流失用户相对稀少的问题,在流失用户预测问题中引入了不平衡数据分类的思想。该文主要在流失预测中结合使用了基于采样法的不平衡数据处理策略,并对现有主要的几种采样算法进行了对比实验和分析。 ",MESS201604029
首届语言与智能技术高峰论坛在京隆重召开,,1, ,"<正>8月28日,首届语言与智能技术高峰论坛(Language&Intelligence Summit)在北京隆重召开。本次会议由中国中文信息学会和中国计算机学会联合主办。本次大会吸引了来自全国学术界、产业界从事语言与智能相关研究的500余人参加,共同探讨语言与智能领域的新发展和新技术。本届高峰论坛,旨在向社会公 ",MESS201604030
第十二届全国机器翻译研讨会(CWMT 2016)在乌鲁木齐圆满落幕,,1, ,"<正>8月25日,由中国中文信息学会主办,中国科学院新疆理化技术研究所承办的第十二届全国机器翻译研讨会在新疆乌鲁木齐开幕。来自国内外49家高校、研究机构、相关企业的代表共襄盛举,分享各自最新的研究成果,并讨论机器翻译的发展趋势。本次研讨会由苏州大学张民教授担任大会主席,哈尔滨工业大学杨沐昀副教授担任程序委员会主席,中科 ",MESS201604031
全国知识图谱与语义计算大会(CCKS 2016)在北京隆重召开,,1, ,"<正>2016年9月19—22日,全国知识图谱与语义计算大会(CCKS 2016)在北京西郊宾馆隆重召开。本次会议由中国中文信息学会语言与知识计算专业委员会主办。大会分为讲习班和主会两个主要部分,本次讲习班暨中国中文信息学会《前沿技术讲习班》ATT第三期的主题是知识图谱专题。本次大会吸引了来自全国学术界、产业界从事知识图谱相关研究的400多人参 ",MESS201604032
书讯,,1, ,"<正>自然语言交流的计算机模型作者:Roland Hausser译者:冯秋香书号:978-7-100-11518-6定价:56.00元出版日期:2016年3月本书第一部分是对人工智能主体的高层次描述,人们可以用自己熟悉的语言和这个人工智能主体自由交流。 ",MESS201604033
计算语义合成性综述,王超超:32622752|熊德意:32622753,8,语义合成; 自然语言处理; 分布式方法; 深度学习;,"随着自然语言处理技术的飞速发展,单纯在语法层上的研究已经不能解决目前的问题,语义层的研究逐渐成为热点。计算语义合成性作为语义学的关键部分,受到了诸多研究人员的关注。计算语义合成性的研究方法可以分为两大类:语言学方法和分布式方法。该文详细介绍了它们各自具有代表性的工作,着重阐述了近年来使用广泛的深度学习方法在计算语义合成性研究中的应用,并对这两种方法进行了比较;然后对计算语义合成性在情感分析以及机器翻译中的应用做了细致分析;最后,展望了计算语义合成性未来的研究趋势。 ",MESS201603001
汉语篇章中零形式的识别与消解,"武娟1:24619617|李茹1,2:08453268|王智强1:25200586",7,汉语框架网; 零形式识别; 零形式消解;,"传统的语义角色标注只能为句中显式表达的句法论元分配语义角色,但是忽略了一些隐式的语义成分,即零形式。该文基于汉语框架语义研究了零形式的识别及消解。在识别阶段,首先使用规则方法进行零形式检测,然后运用筛选过滤的策略去除部分错误识别的零形式;在消解阶段,将篇章中显式表达的框架元素填充项作为零形式的候选先行语,提出结合框架元素语义类型与框架关系的消解方法。在构建的164篇中文语料上进行实验,与其他方法相比,该方法能获得更好的结果。 ",MESS201603002
汉语冒号标注与自动识别方法研究,谷晶晶:31568599|周国栋:13898054,7,汉语冒号分类; 最大熵; 篇章分析;,"随着对篇章分析研究的逐步加深,标点符号研究成为了篇章分析与消歧的一个重要切入点。有效识别标点符号在句子中的作用,将有助于句法分析、篇章分析以及其他自然语言处理技术的发展。该文主要任务是实现汉语冒号的人工标注与自动识别,其中自动识别采取了规则法和基于统计的最大熵法。基于规则的方法比较简单且易于实现,最大熵方法把规则融入到统计之中,在实验结果中具有更好的识别效果。 ",MESS201603003
基于轻语义λ-演算的汉语陈述句灵活语序研究,刘冬宁:06744607|邓春国:31827383|滕少华:06751236|张巍:06750117|梁路:24687206,7,Lambek演算; λ-演算; 中文陈述句; 灵活语序; 语义;,"目前,自然语言处理已经从句法、语法层面走向轻语义层面。对于汉语陈述句的处理,传统的方法是采用Lambek演算来进行处理。但是传统的Lambek演算无法处理汉语中的灵活语序问题,而现有的方法,如加入模态词、新连接词等,又因为其进一步使得本已是NP-hard的Lambek演算时间复杂度变大,并不适合当前的计算机处理。基于此,该文提出了λ-Lambek演算,即采用Lambek演算来对汉语陈述句进行句法演算,并通过Curry-Howard对应理论与λ-演算来对汉语陈述句进行轻语义模型的构建。λ-Lambek演算不仅能够对汉语陈述句进行轻语义演算,而且还能对汉语陈述句灵活语序进行处理。 ",MESS201603004
汉语析句的形式化问题,"彭炜明1,2:30613113|宋继华2:06364557|王宁3:06365544",7,析句方法; 形式化; 汉语句式; 句本位语法;,"该文讨论了形式化析句的基本概念,从语言和言语、描写和解释、层次和线性、短语和句式、词法和句法等多个语言学视角梳理了汉语析句中的形式化问题,并介绍了在句本位语法图解析句形式化中总结的若干经验、原则和待解决问题。 ",MESS201603005
一种基于维基百科的中文词语相关度学习算法,黄岚:31397218|杜友福:06469495,10,词语相关度; 维基百科; 中文信息处理; 回归; 链接结构;,"词语相关程度计算是语义计算的基础。维基百科是目前最大、更新最快的在线开放式百科全书,涵盖概念广,概念解释详细,蕴含了大量概念间关联关系,为语义计算提供了丰富的背景知识。然而,中文维基百科中存在严重的数据稀疏问题,降低了中文词语相关度计算方法的有效性。针对这一问题,该文利用机器学习技术,提出一种新的基于多种维基资源的词语相关度学习算法。在三个标准数据集上的实验结果验证了新算法的有效性,在已知最好结果的基础上提升了20%—40%。 ",MESS201603006
基于子词的历史典籍术语对齐方法,车超1:32097134|郑晓军2:35580708,6,子词; 术语对齐; 最大熵模型; 音译特征;,"由于历史典籍术语存在普遍的多义性且缺少古汉语分词算法,使用基于双语平行语料的对齐方法来自动获取典籍术语翻译对困难重重。针对上述问题,该文提出一种基于子词的最大熵模型来进行典籍术语对齐。该方法结合两种统计信息抽取频繁在一起出现的字作为子词,使用子词对典籍进行分词,解决了缺少古汉语分词算法的问题。针对典籍术语的多义性,根据典籍术语的音译模式制定音译特征函数,并结合其他特征使用最大熵模型来确定术语的翻译。在《史记》双语平行语料上的实验表明,使用子词的方法远远优于未使用子词的方法,而结合三种特征的最大熵模型能有效的提高术语对齐的准确率。 ",MESS201603007
基于熵模型的英汉人名对齐,刘颖:08230768|曹项:35580709,8,人名对齐; 熵模型; 音译相似度; 最小编辑距离; 词典;,"该文使用熵模型来对中英文双语语料进行人名对齐。熵模型综合利用双语人名词典、双语姓氏词典、词汇对齐概率、中英文人名的共现特征、基于最小编辑距离的音译相似度和基于语音匹配的音译相似度。实验结果表明,基于熵模型的中英文人名对齐在大规模语料库的实验中达到了较好的人名对齐正确率和召回率。我们分析了人名对齐存在的主要错误,并针对主要错误给出了可能的解决方案。 ",MESS201603008
拉丁化维吾尔文字特征及其基于规则的正规化,赛牙热·依马木1:25709285|于斯音·于苏普2:30871649|阿不都萨拉木·达吾提3:31411376,8,维吾尔语; 拉丁化维吾尔文; 正规化; 规则库; 最小编辑距离; 文字转写;,"结合网络上流通的拉丁化维吾尔文字特征,以拉丁化维吾尔文单词作为研究单位,首先,通过大规模文本语料库建立了固定词库、词首字母序列库、词尾字母序列库以及特殊词库等正规化规则库。然后,利用维吾尔单词中的字母序列结构特征和相邻字母上下文信息进行了拉丁化维吾尔文的正规化,同时引用最小编辑距离的方法进一步提高了正规化正确率,并用Visual C#编程工具实现了基于规则的拉丁化维吾尔文的正规化算法。最后,给出了实验结果,并分析了结果不佳的原因及相应的对策。 ",MESS201603009
哈萨克语IT领域术语识别研究与实现,木合亚提·尼亚孜别克1:23837637|古力沙吾利·塔里甫2:21736545,6,哈萨克语; IT术语; 术语管理平台; 最大熵模型;,"该文阐述了基于统计方法进行哈萨克语IT领域术语识别的研究,并在已有的训练语料基础之上,采用最大熵模型进行标注识别和结合人工方式对错误识别结果进行后处理的分析实验,阐述了该平台的研究和设计思路,系统的总体框架、基本结构、功能模块以及实现方法等相关的问题。实验结果显示该方法识别哈萨克语IT领域术语是有效的,封闭测试结果达到了82.6%。 ",MESS201603010
基于小字符集藏文拉丁转写系统的设计与实现,陈小莹1:33833235|艾金勇2:33833236,5,藏文; 拉丁转写; 小字符集; 占位辅音;,"随着藏语语言信息技术的迅速发展,藏文拉丁转写成为迫切需要解决的重要课题之一。该文在前人有关藏文拉丁转写研究的基础上,设计并实现了基于小字符集方案的藏文拉丁转写系统。文章通过对小字符集编码方案的特征分析,同时根据藏文正字法知识,提出了基于小字符集编码的藏文拉丁转写算法,并对具体算法策略进行了分析和说明,最后在Windows平台进行了程序的实现。藏文拉丁转写方案的设计与实现,可以解决藏文多编码系统之间的兼容性问题。 ",MESS201603012
说话人自适应技术在维吾尔语语音识别中的应用研究,努尔麦麦提·尤鲁瓦斯:28479964|张力文:31758534|吾守尔·斯拉木:17705001,6,维吾尔语; 语音识别; 说话人自适应; MLLR; MAP;,"该文针对维吾尔语说话人之间的发音差异会在一定程度上影响维吾尔语语音识别系统的性能这一情况研究了说话人自适应技术,将目前较为常用的MLLR和MAP以及MLLR和MAP相结合的自适应方法应用于维吾尔语连续语音识别的声学模型训练中,并用这三种方法自适应后的声学模型分别在测试集上进行识别实验。实验结果表明MLLR、MAP以及MAP+MLLR自适应方法使基线识别系统的单词错误识别率分别降低了0.6%、2.34%和2.57%。 ",MESS201603013
关于朝鲜文信息技术标准化,玄龙云1:35585040|崔荣一2:09291242,5,朝鲜语信息处理; 信息技术标准; ISO国际标准;,"信息技术标准是我国普及应用信息技术、弘扬民族文化、取得市场主动性的关键。该文分析了朝鲜语信息技术标准化国内外现状,论述了朝鲜语信息处理的必要性,并提出信息技术标准化工作的具体建议。该文认为统一的中国少数民族文字信息技术基础标准体系亟待完善,朝鲜语的信息技术标准化对我国朝鲜族文化的传承与发展具有深远意义,对形成系统、完整的中华语言文字信息处理统一平台、扩大国际影响、维护国家统一而言是不可或缺的工作。 ",MESS201603015
基于条件随机场的维吾尔文组块分析,艾山·吾买尔:10775068|吐尔根·依布拉音:17705003|卡哈尔江·阿比的热西提:31758537|早克热·卡德尔:22045086|买合木提·买买提:22440290|亚森·艾则孜:35580710,6,条件随机场; 维吾尔; 组块分析;,"该文对维吾尔语树库标注体系进行分析,根据组块划分原则,在短语标记集的基础上制定了维吾尔语组块标记集,从已完成标注的3 000句语料库构建组块库。根据维文语言的特点,在英汉组块识别特征基础上,增加了词干、词缀、同义词标记等特征。该文中的性能评价指标采用了国际通用的准确率,召回率和F值,3 000个标注句子作为训练和测试语料库用,实验采用了交叉验证法,训练和测试语料库的比例分别为9∶1,8∶2,2∶1,召回率分别为80.34%,76.87%,66.76%。实验表明,语料库规模对模型性能影响较大。 ",MESS201603016
基于音节划分及短语表优化的英汉人名音译研究,王丹丹:06522854|黄德根:06527360|高扬:22157949,7,英汉人名音译; 音节划分; 短语表优化; C-value;,"把英汉人名音译问题转换为以音节为基本单位的翻译问题,将连续的音节组合看作短语,引入一种基于短语的统计机器翻译方法,实现英汉人名的音译。首先,针对现有音节划分方法存在的问题,提出一种改进的音节划分方法;其次,该文提出去除低频词法及基于C-value方法对短语表进行优化,解决了训练语料偏小导致短语表中出现杂质信息的问题;之后,融入了汉语人名中首字(词)及尾字(词)的位置特征,改善了生成的音译候选中汉字选取的不合理性;最后,提出了两阶段音节划分方法,缓解了音节划分粒度过大导致的音译错误。与基准方法相比,其音译准确率ACC由63.78%提高到67.56%。 ",MESS201603017
基于神经网络的统计机器翻译的预调序模型,杨南1:31474742|李沐2:14788529,8,统计机器翻译; 预调序; 神经网络;,"长距离调序是统计机器翻译的一个主要挑战。之前的研究工作表明预调序是解决这个问题的一个可能的途径。在该工作中,我们沿着预调序这个研究方向,将神经网络建模结合到线性排序的框架之下,提出了一个基于神经网络的预调序模型。这个的预调序模型能够利用从海量未标注数据中抽取的句法和语意信息,从而更好的对不同语言之间的语序差异进行预测。我们在中文到英文以及日文到英文的机器翻译任务上进行了实验,实验结果表明了该方法的有效性。 ",MESS201603018
中文专利文献术语自动识别研究,杨双龙1:35580711|吕学强1:10724564|李卓1:28564014|徐丽萍2:26095266,8,术语自动识别; 专利文献; 信息抽取; 文本挖掘;,"中文专利文献中含有大量领域术语,对这些术语进行自动识别是信息抽取、文本挖掘等领域的重要任务。该文提出了基于专利文献标题的术语词性规则自动生成方法以及针对候选术语排序的TermRank算法。该方法首先从大量的中文专利文献标题中自动生成词性规则;然后利用生成的词性规则对中文专利文献正文部分进行规则匹配获得候选术语表;再利用提出的TermRank排序算法对候选术语表排序,最终得到术语列表。通过在9 725篇中文专利文献数据上实验,证实了该方法的有效性。 ",MESS201603019
中医针灸领域术语自动抽取研究,"孙水华1,2:33053082|黄德根1:06527360|牛萍1:06505729",7,中医针灸领域术语; 术语种子集迭代算法; 术语过滤规则;,"针对中医针灸领域术语的构成特点,该文建立了一种基于规则的领域术语抽取算法模型,该模型首先对中医针灸领域术语种子集进行有限次的迭代,生成中医针灸领域术语构件集;然后,以术语构件集为领域词典,采用最大向前匹配算法对中文针灸医学文献中的句子进行切分,并抽取候选术语;最后,利用语言规则对候选术语进行过滤处理,筛选出中医针灸领域专业术语。分别以关键字集和中医词典为种子集进行实验,开式测试的F值分别达到76.96%和35.59%。 ",MESS201603020
一种交互式事件常识知识的获取方法,"曹聪1,2,3:29590851|曹存根1:10348278|臧良军3:35580714|王石1:23246662",9,常识知识获取; 事件常识; 交互过程;,"赋予机器常识知识是使机器具有真正智能的必备条件之一,而获得这些常识一直是人工智能研究的一个重要课题。该文提出了一种通过交互的方式来引导知识贡献者给出关于事件的常识知识的方法。方法获取过程是一个机器与贡献者的交互过程:机器动态地生成问题,对知识贡献者进行提问;知识贡献者通过回答问题给出常识知识。交互过程通过包含提示信息的提问问题对知识贡献者进行提示,运用七种类型问题层层递进地引导知识贡献者思考,以此唤醒他们大脑中的常识知识;通过动态变化的问题改善知识贡献者贡献常识知识过程的趣味性。同时,该文还引入可接受性和有效性两个定量标准评价提问问题,用于进一步改善交互过程。实验结果表明,知识贡献者运用此方法给出的知识量增加了451.61%,同时知识的正确率也达到了92.5%。 ",MESS201603021
基于频繁依存子树模式的中心词提取方法研究,田卫东:07061932|虞勇勇:28029163,10,中心词; 依存关系树; 条件随机场; 频繁子树模式;,"条件随机场模型通过抓取问句中心词各方面统计特征来进行中心词标注,但未能充分利用中心词特征间存在的深层统计关系。该文利用中文问句的依存关系树结构,通过挖掘问句依存关系树所蕴藏的中心词各维度特征之间的统计概率关系,为正确提取中心词提供依据,通过挖掘频繁依存子树模式以生成相应统计规则模式,使用条件随机场模型进行中心词初始标注,使用频繁依存子树模式统计规则进行中心词标注校正等。该文方法属于典型的客观方法,建立在严格的统计语料基础上,标注的稳定性、适应性和鲁棒性较好。实验结果表明,该文方法将条件随机场模型的中心词标注准确率提高约3%。 ",MESS201603022
中文微博故事线生成方法,"李培1:17439057|翁伟2:14411643|林琛1,3:25047882",9,微博故事线; 最小权重支配集; 有向斯坦纳树;,"新浪微博、腾讯微博等微博平台已经成为国内重要的网络媒体。随着海量的实时信息在微博上分享和传播,为每个用户提供更多方便,展现一目了然的实事资讯的任务已经迫在眉睫。这就需要在微博中理出重大事件的发展进程。该文中,我们将利用最小权重支配集和有向斯坦纳树在给定查询的微博数据集上生成故事线。该文的工作由三部分组成:第一部分是在Lucene检索出来的结果集上构建多视点图;其次,通过在图中寻找最小权重支配集来选出具有代表性的微博;最后,通过求解有向斯坦纳树问题来平滑地连接这些已挑选的微博,形成故事线。在实际数据集上的实验验证了该文提出系统的高效性和有效性。 ",MESS201603023
基于三维坐标的模糊量化情感分类方法,林明明1:30024589|邱云飞1:07922846|邵良杉2:07933392,11,微博情感; 模糊量化; 情感分类; 模糊情感; 三维坐标;,"针对微博情感分类问题,构造了基于三维坐标的模糊量化情感分类算法,通过将情感模糊量化,对微博进行多情感分类。首先对情感模糊处理,将情感分为六大类,根据六大类,定义并计算句子的模糊情感;其次将情感量化处理,根据情感类别构造三维坐标模型,将模糊情感值作为句子的坐标,通过坐标将句子映射到三维坐标模型中,使其量化;最后通过模糊量化处理后,根据与坐标轴的夹角判断句子最终的情感分类。通过实验,对三个作者的微博进行模糊量化处理,对其情感分类,实验结果的F值达到85%以上,同时与三种经典算法进行对比实验,准确率有了明显的提高。 ",MESS201603024
基于短文本隐含语义特征的文本蕴涵识别,张晗:09035175|盛雅琦:32989918|吕晨:27030890|姬东鸿:09004523,9,文本蕴涵; 隐含语义特征; 短文本; 支持向量机;,"该文采用基于短文本隐含空间语义特征改进文本蕴涵识别,该方法通过构造句子的隐含变量模型,并融合基于该模型的句子之间相似度特征,和词汇重叠度、N元语法重叠度、余弦相似度等字符串特征,以及带标记和未标记的子树重叠度句法特征一起利用SVM进行分类。基于该分类算法,我们对RTE-8任务进行了测试,实验表明短文本的隐含语义特征可有效改进文本蕴涵关系识别。 ",MESS201603025
一种长短期兴趣结合的个性化检索模型,王晓春:21857998|李生:06989058|杨沐昀:06996935|赵铁军:06997742,6,个性化信息检索; 长期兴趣; 短期兴趣;,"个性化信息检索针对用户个人兴趣优化文档排序,被认为是改善用户检索体验的一种有效途径。为提高个性化检索模型的检索性能,该文提出了一种将用户的长短期兴趣结合的通用方法,利用用户长期兴趣和短期兴趣对查询模型进行改进。大规模真实搜索日志数据上的实验结果显示,利用长短期兴趣能够获得准确表达信息需求的查询模型,相对于传统的个性化检索模型取得了更好的效果。 ",MESS201603027
一种基于事实知识的实体相关度计算方法,孙叔琦1:25480598|孙珂2:35580715|赵世奇2:25202879|李生1:06989058|王海峰2:24956332|杨沐昀1:06996935,9,实体相关度; 实体—属性—属性值(SPO)记录; 用户需求; 面向实体的搜索;,"在近来出现的面向实体的搜索服务中,准确地预测实体间的相关程度是至关重要的。该文提出了一种基于实体的事实知识,即利用""实体—属性—属性值""(SPO)记录进行实体相关度计算的方法。该文通过基于属性和属性值的两步概率估计,将实体表示为一个属性值词的概率分布列,并通过比对两个实体共享的属性值词汇得出二者的相关度。实验表明,在用于面向实体搜索的相关实体排序问题上,该文方法达到了80.9%的平均top-5准确率,优于词袋方法和基于查询日志共现的方法。此外,该文通过定量分析,考察了不同领域的用户需求特性对实体相关度计算结果的影响。 ",MESS201603028
一种基于用户互动话题的微博推荐算法,"鲁骁1,2:33809729|李鹏3:33053080|王斌3:33053079|李应博1:35580718|房婧1:35580719",9,互动关系; 互动话题; 社会化推荐; 协同过滤; 微博推荐;,"随着社交网络的发展,微博逐渐成为人们获取信息的重要来源。然而随着用户的增多,微博中的信息过载问题也越来越严重,如何快速准确地为用户推荐感兴趣的微博已经成为研究的热点。与传统的推荐技术不同,微博中的用户具有天然的社交关系,这为推荐算法提供了额外的用户信息,因此,融合了用户社交关系的社会化推荐方法日益受到重视。但是,现有的方法大多只利用了固定的用户社交关系或简单的互动行为,事实上,用户互动行为的出发点必然是用户与好友的共同兴趣,具有明显的话题相关性。该文从话题层面来分析用户的互动关系,提出了度量互动关系在话题上强弱度的方法,通过有效地融合互动关系的话题特征,最终提出了改进的微博推荐模型IBCF。实验结果表明,与现有的社会化推荐方法相比,该文提出的新方法在MAP和NDCG等指标上取得了更好的推荐效果,而且为推荐结果提供了更明确的可解释性。 ",MESS201603029
汉语谓词组合范畴语法词库的自动构建研究,周强:08836151,8,组合范畴语法; 汉语谓词词库; 多资源融合;,"谓词词库是深层语法模型分析和理解的核心资源。近年来的常规方法是人工构建或从标注语料库中自动获取,标注规模和信息容量的扩大受制于巨大的人工投入量和标注库体系设计。该文提出了一种多资源融合自动构建汉语谓词组合范畴语法(CCG)词库的新方法。从知网、北大语法信息词典和大规模事件句式实例中提取汉语谓词的不同句法语义分布特征,融合形成CCG原型范畴表示,将它们指派给各资源信息完全重合的谓词形成核心词库。然后通过自动分类和隶属度分析相结合方法对其他谓词的CCG范畴进行预测,并对两者结果进行融合得到扩展词库,最终合并形成包含约15,000个词条的汉语谓词CCG词库。通过在随机均匀抽样的1000个谓词上通过多人独立标注形成的标准测试库上进行不同角度的性能分析实验,表明该词库的预期准确率达到了96.3%。 ",MESS201603030
基于数据场和全局序列比对的大规模中文关联数据模型,王汀:33220068|徐天晟:24954494|冀付军:30457587,9,语义网; 关联数据; 本体映射; 同义词词林; 相似度计算;,"目前关联数据的研究工作主要集中在实例级别上展开,而在模式级别(Schema-Level)上的关联数据构建则易被忽视。本体映射是解决本体异构问题的重要途径和手段,同时,本体映射也可视为模式级别关联数据构建的典型情景。特别是在中文知识库方面,中文知识是关联数据网中的重要组成部分,但现有的中文本体映射系统在面对大规模本体映射任务时,显得效率较低且可用性不高,目前仍缺乏针对中文大规模本体映射的相关系统。为了解决在模式级别上的中文大规模关联数据构建问题,提出了一种新的基于数据场和序列比对思想的大规模中文关联数据构建模型。首先,基于改进的融合概念相似度和相异度的拟核力场势函数对大规模中文本体映射规模进行约简和压缩;其次,通过引入序列比对算法,对组合概念进行相似度的度量;最后,将本系统与相似度计算相关典型算法进行比较,表明其具备一定的可用性和较高的总体性能。 ",MESS201603031
中文文本的事件时空信息标注,张春菊1:32113635|张雪英2:10993040|王曙2:32113636|廖建平2:35580720|陈晓丹2:29992765,10,中文文本; 时空信息; 事件; 标注体系; 标注语料库;,"基于文本数据源的地理空间信息解析研究侧重于地名实体、空间关系等空间语义角色的标注和抽取,忽略了丰富的时间信息、主题事件信息及其时空一体化信息。该文通过分析中文文本中事件信息描述的语言特点和事件的时空语义特征,基于地名实体和空间关系标注研究成果,制定了中文文本的事件时空信息标注体系和标注模式,并以GATE(General Architecture for Text Engineering)为标注平台,以网页文本为数据源,构建了事件时空信息标注语料库。研究成果为中文文本中地理信息的语义解析提供标准化的训练和测试数据。 ",MESS201603032
热烈祝贺我学会推荐代表胡郁获“中国优秀青年科技人才”奖,,1, ,"<正>2016年6月2日,首届全国杰出科技人才奖和中国优秀青年科技人才奖在人民大会堂举行隆重颁奖仪式,""全国杰出科技人才""奖和""中国优秀青年科技人才""奖颁奖,10位高层次科技领军人才和10位优秀青年科学家分获奖项。我学会推荐的胡郁获""中国优秀青年科技人才""奖。2015年,经中共中央批准,中国科技协会在""全国优秀科技工作者""奖中增设""全国杰出科技人才""子奖项,在""中国青年科技奖""中增设""中国优秀青年科技人才""子奖项。 ",MESS201603011
热烈祝贺学会两位副理事长孙茂松、刘庆峰当选中国科协第九届全国委员会委员,,1, ,"<正>2016年6月2日,中国科协第九次全国代表大会闭幕。经中国科协九大代表资格审查委员会认真审查,本次大会产生正式代表1 300余名,九届全国委员会委员候选人380余名。九届常委会按照学科分布合理、老中青相结合、广泛代表性原则,注意吸收新兴科技领域杰出科技工作者代表,注意提高基层一线科技工作者比例,努力形成一个深化改革、团结奋进、开拓创新的中国科协新的领导层。 ",MESS201603014
万钢当选中国科协新一届主席韩启德担任名誉主席,,1, ,"<正>中国科学技术协会第九次全国代表大会闭幕会议于2016年6月3日下午在人民大会堂举行,会议宣布中国科协九届全委会主席、副主席、常委名单。经九届一次全国委员会选举,万钢当选为中国科协九届全委会主席,马伟明等18人当选为副主席。当天的会议还宣布授予韩启德为中国科协名誉主席的称号。韩启德是中国科协八届全委会主席。 ",MESS201603026
书讯,,1, ,"<正>""三礼""名物词研究作者:刘兴均等书号:978-7-100-11958-0定价:315.00元出版日期:2016年3月本书借鉴当代词汇学、语义学和语言学的前沿理论和研究成果,借助前人注疏以及《说文》等小学专书,结合出土实物和简帛文献,发掘""三礼""名物词的词源义,归纳其命名理据。在 ",MESS201603033
汉语概念复合块的自动分析,"仵永栩1,2:35074495|吕学强1:10724564|周强2:08836151|关晓炟1,2:30806488",11,句法分析; 块识别; 概念复合块; 移进-归约分析;,"为解决句法分析任务中的块边界识别和块内结构分析问题,该文基于概念复合块描述体系进行了块分析探索。通过概念复合块与以往的基本块和功能块描述体系的对比分析,深入挖掘了概念复合块自动分析的主要难点所在,提出了一种基于""移进-归约""模型的汉语概念复合块自动分析方法。在从清华句法树库TCT中自动提取的概念复合块标注库上,多层次、多角度对概念复合块自动分析性能进行了纵向与横向评估,初步实验结果证明了该分析方法对简单概念复合块分析的有效性,为后续进行更复杂的概念复合块的句法语义分析研究打下了很好的基础。 ",MESS201602001
融合分词隐层特征的汉语基本块识别,"李国臣1,2:08407515|刘展鹏1:35074498|王瑞波3:13897708|李济洪3:08401319",6,分布表征; 汉语基本块识别; 神经网络模型; 隐层特征; 整句似然函数;,"该文以字为基本标注单位,构建了一种汉语基本块识别的神经网络学习模型。模型联合分词任务的神经网络学习模型与基本块识别任务模型,将分词任务模型中学习得到的隐层特征融入基本块识别的模型中,两模型相互交替优化学习模型参数,并实现了以整句似然函数(而非单字似然函数)作为优化目标的算法。实验结果表明:1)以整句似然函数为优化目标的基本块识别的F值比单字似然情形要高出1.33%,特别是在多字块识别中,其召回率比单字似然情形要高出4.68%;2)融合分词任务模型中的隐层特征的汉语基本块识别模型的结果比不做融合的模型要高出2.17%,说明融合分词隐层特征的交替联合学习方法是有效的。 ",MESS201602002
基于PDTB的自动显式篇章分析器,李生:26803240|孔芳:08865090|周国栋:13898054,8,篇章处理; 条件随机场; 宾州篇章树库;,"自动篇章处理是自然语言处理中非常有挑战的一个任务,对自然语言处理的其他任务,如问答系统,自动文摘以及篇章生成都有重要的作用。近年来,大规模篇章语料PDTB的出现为篇章研究提供了一个公共的平台。该文在PDTB语料之上提出了一个完整的基于条件随机场模型的显式篇章分析平台,该平台包含连接词识别、篇章关系分类和关系论元提取三个子任务。给出了在PDTB上各模块的实验结果,并针对错误传播问题,给出了完整平台的性能及详细分析。 ",MESS201602003
一种基于特征映射的中文专家消歧方法,"潘霄1,2:31888689|余正涛1,2:05982358|郭剑毅1,2:07895859|毛存礼1,2:23238123|杨秀贞1:31960835",6,中文专家消歧; 属性特征; 特征映射; 模糊聚类;,"针对中文专家页面特点,以及用于消歧的基准专家页面中信息涵盖不全的问题,该文提出一种基于特征映射的中文专家消歧方法。首先,采用条件随机场模型,从基准专家页面和待消歧页面中提取出所定义的12维人物属性特征,并利用最大熵分类模型,结合已有消歧结果训练出各属性特征的权重;然后,针对某个专家的基准页面,计算待消歧页面与该页面的相似度,根据设定的阈值判断该页面是否单独成类,若不是单独成类,则利用特征映射,扩充该页面的属性特征,结合模糊聚类方法,得到与该页面为一类的页面。在""自然语言处理""及""机器学习""领域进行中文专家消歧实验,结果表明提出的方法能有效对中文专家页面进行消歧。 ",MESS201602004
一种策略融合的跨语言文本情感倾向判别方法,"张鹏1:08403344|王素格1,2:08454306|李德玉1,2:08401294",9,跨语言; 倾向分类; 多策略融合;,"随着互联网的迅速发展,网络资源呈现领域开放性和语言多样性的特点。而语言多样性将造成网络信息交流上的障碍,整合多语言数据资源让用户快速了解其他语言信息具有重要的应用价值和现实意义。该文结合跨语言情感倾向判别的特点,提出策略融合的跨语言文本情感倾向判别框架。通过跨语言一致文本和跨语言混合概念空间的文本两种策略,构建基于双语协同文本情感倾向判别框架和基于跨语言特征混合文本情感倾向判别框架。在两种判别框架的基础上,融合两种框架判别结果,给出文本整体情感倾向性。实验表明,该文提出的融合策略在跨语言文本情感倾向判别上是有效的。 ",MESS201602006
基于多分类器投票集成的半监督情感分类方法研究,黄伟:09594553|范磊:08517811,10,情感分类; 集成学习; 半监督学习;,"情感分类是目前自然语言处理领域的一个具有挑战性的研究热点,该文主要研究基于半监督的文本情感分类问题。传统基于Co-training的半监督情感分类方法要求文本具备大量有用的属性集,其训练过程是线性时间的计算复杂度并且不适用于非平衡语料。该文提出了一种基于多分类器投票集成的半监督情感分类方法,通过选取不同的训练集、特征参数和分类方法构建了一组有差异的子分类器,每轮通过简单投票挑选出置信度最高的样本使训练集扩大一倍并更新训练模型。该方法使得子分类器可共享有用的属性集,具有对数时间复杂度并且可用于非平衡语料。实验结果表明我们的方法在不同语种、不同领域、不同规模大小,平衡和非平衡语料的情感分类中均具有良好效果。 ",MESS201602007
基于因果模型的主题热度计算与预测方法,"杜慧1,2:32481680|郭岩1:09559534|范意兴1,2:33384077|张瑾1:22101466|余智华1:09560057|程学旗1:09559496",6,主题热度; 因果模型; 面板数据; 热度预测; 多峰高斯曲线;,"网络是目前最重要的信息传播渠道,其自由性和丰富性使得信息迅速传播。挖掘网络中的热点主题对政府政策的制定、企业经营决策的调整可以提供强有力的支持,并能够满足网民对热点主题的关注需求。主题数量的庞大使得主题热度值的计算尤为重要,该文分析热度的形成原因,基于因果模型并采用面板数据,给出一种较为客观可行的主题热度计算模型。该模型使用易于获取的数据进行计算,给出较为客观的热度度量,进而便于不同主题、不同日期间的热度对比。在此基础上,通过对热度变化规律的考察,提出一种基于多峰高斯曲线拟合热度变化进行主题热度预测的思路。 ",MESS201602008
社交网络用户标签预测研究,刘列:33316056|邢千里:33316055|刘奕群:08176974|张敏:08186086|马少平:08177513,8,社交网络; 用户行为分析; 标签预测;,"随着社交网站的流行以及用户的大规模增加,社交网络用户行为分析已经成为社交网站进行网站维护、性能优化和系统升级的重要基础,也是网络知识挖掘和信息检索的重要研究领域。为了更好地理解社交网络用户添加个人标签的行为特征,该文基于大约263万个微博用户的真实数据,对用户标签的分布进行了研究和分析。我们主要考察了用户标签的宏观分布特征,以及用户标签与关注对象的标签分布之间的联系,发现微博用户给自己添加标签时,在开始阶段倾向于使用反映个性的标签,之后会出于从众心理而选用大众化标签。我们将研究发现运用到基于关注关系的标签预测算法中,结果证实相关分析对于社交网站的标签推荐等课题具有一定的参考意义。 ",MESS201602009
一种融合地理位置信息的协同过滤推荐算法,鲁骁1:35077461|王书鑫2:33809727|王斌3:33053079|鲁凯4:35077462,10,推荐系统; 协同过滤; 地理位置信息; 邻居模型; 隐参数模型;,"目前,基于用户消费数据构建的推荐系统在电子商务领域发挥着越来越大的作用,而在这些数据中,商家本身具有的地理位置信息忠实地记录了用户的消费痕迹,能够有效反映出用户在地理位置维度上的个人偏好信息,从而对推荐系统具有非常重要的意义。现有工作一般只利用了用户对地点的评价以及地点之间的距离,无法反映出不同地点之间的关联关系,以及用户在不同地点中的偏好权重问题。该文从地理区域划分的角度出发,研究了用户在区域范围内的消费兴趣偏好,以及不同粒度级别的区域划分方法对推荐模型的影响,探索了在推荐过程中有效融合地域信息的方法,考虑了包括地区的全局性影响、用户对地区的偏好等,结合这些因素提出了融合地理位置信息的推荐模型LGE、LGN及LRSVD。通过在Yelp数据集上的实验表明,这些模型相比于传统的推荐算法能够有效提高预测效果。 ",MESS201602010
利用社交网络的影响力骨架探索信息传播,黄俊铭:35074500|沈华伟:23136281|程学旗:09559496,9,信息传播; 社交网络; 影响力骨架;,"理解社交网络上的信息传播机制,通常包括对拓扑结构的分析和对用户行为的分析。由于社交网络上连边的强度具有异质性,只有一部分连边对于信息传播有实质作用,构成隐藏在社交网络中的影响力骨架。对影响力骨架的拓扑研究可帮助我们获得比直接研究社交网络拓扑结构更深入的认识。我们从连边正负性和个体节点角色分化入手,探讨了微观层面连边和节点在信息传播中的作用,进而从宏观层面分析信息传播所依赖的影响力骨架的连通性和扩散效率,发现信息传播具有一定程度的脆弱性,且其传播效率低于对社交网络本身研究的预期。 ",MESS201602011
基于在线社会网络的用户影响力研究,许丹青:25200640|刘奕群:08176974|张敏:08186086|马少平:08177513,7,社会影响力; 小世界属性; 信息扩散; 社会网络;,"对大规模的在线社会网络图结构进行了较为系统的分析,结果表明社会网络的入度、出度、发文数等基本符合幂律分布。社会网络的小世界属性也使得强连通关系呈现""纺锤体""形状。该文从用户的阅读概率角度引入用户的发文行为、浏览行为与标签社区小世界属性等对用户的社会影响力模型进行建模。实验结果显示PTIM模型融合了发文行为与小世界属性等特性,在最具影响力用户节点、用户粉丝数、认证用户数与人工标注的相对用户影响力大小等指标上均表现出稳定的性能。 ",MESS201602012
基于用户相似性传递的跨平台交叉推荐算法,"李超1,2:06563644|周涛1,2:06549836|黄俊铭3:35074500|程学旗3:09559496|沈华伟3:23136281",9,个性化推荐系统; 协同过滤; 多源数据; 稀疏性; 冷启动;,"个性化推荐系统在电子商务领域中的广泛应用带来了巨大的经济效益和良好的用户体验。由于用户数据往往分布在多个不同的网站,单个网站的推荐系统受制于数据稀疏性的限制,难以获得准确的推荐效果。该文提出了一种基于传递相似性的交叉推荐系统算法,可以利用多个网站平台数据计算不同网站中的用户的相似度,从而很大程度上克服了推荐系统中的数据稀疏性以及冷启动问题。结果显示,该交叉推荐算法与传统的针对单个数据集的推荐算法相比,推荐的精确性有一至两倍的提高。 ",MESS201602013
一种支持混合语言的并行查询纠错方法,"颛悦1,2:29498770|熊锦华1:09596985|马宏远3:35074502|程舒杨1:29695138|程学旗1:09559496",8,查询纠错; 词典树; 语言模型; 并行纠错;,"中文信息检索系统中的查询语句包含中文字、拼音、英文等多种形式,而有些查询语句过长,不利于纠错处理。现有的查询纠错方法不能很好的解决中文检索系统中的混合语言与中文长查询的问题。为了解决上述两个问题,该文提出了一种支持混合语言的并行纠错方法。该方法通过对混合语言统一编码,建立统一编码语言模型和异构字符词典树,并根据语言特点制定相应的编辑规则对查询词语进行统一处理,其中,针对中文长查询,提出双向并行的纠错模型。为了并行处理查询语句,我们在字符词典树和语言模型的基础上提出了逆向字符词典树和逆向语言模型的概念。模型中使用的训练语料库是从用户查询日志、网页点击日志、网页链接信息等文件中提取的高质量文本。实验表明,与单向查询纠错相比,支持混合语言的并行纠错方法在准确率上提升了9%,召回率降低了3%,在速度上提升了40%左右。 ",MESS201602014
结合句子级别检索的信息检索模型,左家莉:07871349|王明文:08472511|吴水秀:07878314|万剑怡:07869967,7,"信息检索模型; 句子级别检索,句子相关度;","查询词之间的距离较为接近的文档,相关的可能性更大,将这种距离信息用于信息检索模型的构造可有效提高检索的性能。然而直接估计查询词在文档中的距离需要大量的训练文本,且计算复杂度高。该文提出了一种结合句子级别检索的信息检索模型,将文档分为若干个窗口,通过计算句子和查询的相关度考察查询词在给定窗口中的共现性,该方法可增大那些查询词彼此靠近的文档的相关度,从而使得检索模型可返回更为相关的文档。标准数据集上的实验结果表明所提出的模型可以取得较好的性能。 ",MESS201602015
查询会话中带时间因子的隐式负反馈研究,"陈振宏1,2:33765671|俞晓明1:09560060|刘悦1:09639001|程学旗1:09559496",8,查询会话; 隐式负反馈; 时间因子; 排序;,"隐式相关反馈常被用于提升检索系统的性能,目前大部分工作集中在研究隐式正反馈。该文同时考虑隐式正负反馈,将查询会话中被点击网页前的未被点击网页作为隐式负反馈信息,通过引入时间因子,估计用户在未被点击网页的标题和摘要上的停留时间,推断隐式负反馈与用户兴趣和行为的关系,达到优化检索结果的目的。在TREC Session 2011和2012数据集上的实验,验证了该文提出的带时间因子的隐式正负反馈算法TIPNF的有效性。 ",MESS201602016
基于内容和用户行为的查询聚类,程舒杨:29695138|熊锦华:09596985|公帅:26332838|程学旗:09559496,7,查询聚类; 多意图查询; 搜索意图;,"现有方法没有有效利用查询文本特征、点击行为和session信息来挖掘用户的搜索意图,获取的查询特征对于多意图查询在不同意图下的区分度不足,对于多意图查询的相关查询聚类效果不佳。针对以上问题,该文提出了基于查询图信息的GPLSI模型,并利用该模型学习所得的查询特征进行查询聚类。基于查询图信息的GPLSI模型利用查询的词语、点击和session共现现象,从查询的文本特征、点击行为和session信息等多个方面来模拟查询意图的产生和表现,学习查询在不同搜索意图上的概率分布。最后,实验结果验证了基于查询图信息的PLSI模型用于查询相似度计算和多意图查询聚类中的有效性。 ",MESS201602017
基于用户偏好与语言模型的个性化引文推荐,刘亚宁:30803081|严睿:29558002|闫宏飞:06276313,8,引文推荐; 个性化;,"根据引文上下文,自动为科研人员推荐备引用的论文列表具有很大的实用价值和研究意义。在科研人员写作时,一个为引用符自动推荐引文的系统,会为科研人员节省大量的时间。对于引文推荐问题,过去的工作均主要把注意力集中到基于内容的研究上。该文认为引文推荐,不能只根据内容进行通用推荐,还需要根据不同研究者的偏好进行个性化推荐。该文利用用户的发表及引用历史,结合语言模型,构建出一个个性化引文推荐模型——PCR模型。在结合用户引用倾向性与内容相关性后,与传统的基于内容的语言模型相比,PCR模型在recall@10上获得了71.01%的性能提升,在MAP上获得了70.23%的性能提升。 ",MESS201602018
基于视觉显著计算的图像语义检索方法,柳伟1:15272588|陈旭2:35074503|梁永生1:09711295,6,随机漫步; 图像分析; 标签; 网络标注;,"网络标签已经开始广泛地用于图像内容的标注和分享,由于图像本身的差异和人们对图像的不同理解,对图像语义检索提出了新的挑战。该文首先引入视觉显著模型,突出图像的显著信息;然后提取视觉显著特征,建立图像内容的相似关系;最后基于随机漫步模型平衡图像内容及网络标签间的关系。实验表明该文提出的方法能够有效地实现图像的语义理解并用于图像检索。 ",MESS201602019
基于本体和语义文法的上下文相关问答,"王东升1,2:14204564|王石3:23246662|王卫民1:26180385|刘亮亮1:11068955|符建辉3:25121025",12,本体; 语义文法; 上下文; 问答;,"在问答系统中,用户的提问通常不是孤立的,而是使用连续的多个相关的问题来获取信息,用户在与这样的系统进行交互时,才会感觉更自然。在已构建的非上下文相关问答系统的基础上,该文提出了一种可以处理上下文相关问题的方法并开发了系统OSG-IQAs。方法首先识别当前问题是否是一个从问题(follow-up),并判别其与前面问题的具体的相关类别,然后根据相关类别,利用话语结构中的信息对当前的follow-up问题进行重构,并提交到非上下文相关问答系统中。最后,将方法在两个不同规模的领域进行测试,并与相关系统或方法进行比较,测试结果表明,该方法具有较好的可扩展性。在总体测试中,该方法比基线系统获得了更好地效果,同时利用手工将所有上下文相关问题进行上下文消解,系统与此也进行了比较,并获得了相近的性能。 ",MESS201602021
利用维基百科实体增强基于图的多文档摘要,陈维政:33805143|严睿:29558002|闫宏飞:06276313|李晓明:06245325,7,多文档摘要; 维基实体; 基于图;,"针对基于图的多文档摘要,该文提出了一种在图排序中结合维基百科实体信息增强摘要质量的方法。首先抽取文档集合中高频实体的维基词条内容作为该文档集合的背景知识,然后采用PageRank算法对文档集合中的句子进行排序,之后采用改进的DivRank算法对文档集合和背景知识中的句子一起排序,最后根据两次排序结果的线性组合确定文档句子的最终排序以进行摘要句的选取。在DUC2005数据集上的评测结果表明该方法可以有效利用维基百科知识增强摘要的质量。 ",MESS201602022
基于迁移学习的蛋白质交互关系抽取,李丽双:06521783|郭瑞:26871419|黄德根:06527360|周惠巍:13896094,8,蛋白质交互关系抽取; 迁移学习; 负迁移;,"作为生物医学信息抽取领域的重要分支,蛋白质交互关系(Protein-Protein Interaction,PPI)抽取具有重要的研究意义。目前的研究大多采用统计机器学习方法,需要大规模标注语料进行训练。训练语料过少,会降低关系抽取系统的性能,而人工标注语料需要耗费巨大的成本。该文采用迁移学习的方法,用大量已标注的源领域(其它领域)语料来辅助少量标注的目标领域语料(本领域)进行蛋白质交互关系抽取。但是,不同领域的数据分布存在差异,容易导致负迁移,该文借助实例的相对分布来调整权重,避免了负迁移的发生。在公共语料库AIMed上实验,两种迁移学习方法获得了明显优于基准算法的性能;同样方法在语料库IEPA上实验时,TrAdaboost算法发生了负迁移,而改进的DisTrAdaboost算法仍保持良好迁移效果。 ",MESS201602023
一个半监督的中文事件抽取方法,徐霞1:09890447|李培峰2:09886822|朱巧明2:09891804,7,事件抽取; 自举; 文档相关度; 语义相似度;,"半监督或无监督的事件抽取方法在目前依旧是一个具有挑战性的课题。针对中文本身在表述中存在的固有特点,该文提出一种基于双视图的事件抽取自举学习方法。该方法以少量种子为基础,从文档相关度与语义相似度两个视图出发,进行交互过滤筛选,不断抽取新的有效事件模板,为事件抽取服务。在ACE2005中文语料上的测试表明,和现有方法相比,该方法可以有效地提高中文信息事件抽取系统的性能。 ",MESS201602024
基于领域知识抽样的深网资源采集方法,"林海伦1,2:27442311|熊锦华1:09596985|王博3:24253186|程学旗1:09559496",7,深网; 置信度; 抽样; 领域知识;,"深网资源是指隐藏在HTML表单后端的Web数据库资源,这些资源主要通过表单查询的方式访问。然而,目前的网页采集技术由于采用页面超链接的方式采集资源,所以无法有效覆盖这些资源,为此,该文提出了一种基于领域知识抽样的深网资源采集方法,该方法首先利用开源目录服务创建领域属性集合,接着基于置信度函数对属性进行赋值,然后利用领域属性集合选择查询接口并生成查询接口赋值集合,最后基于贪心选择策略选择置信度最高的查询接口赋值生成查询实例进行深网采集。实验表明,该方法能够有效地实现深网资源的采集。 ",MESS201602025
FPC:大规模网页的快速增量聚类,"余钧1,2:28913386|郭岩1:09559534|张凯1:10348575|刘林3:26522729|刘悦1:09639001|俞晓明1:09560060|程学旗1:09559496",7,DOM树分层向量; 网页簇中心; 局部敏感哈希; 快速增量聚类;,"面向结构相似的网页聚类是网络数据挖掘的一项重要技术。传统的网页聚类没有给出网页簇中心的表示方式,在计算点簇间和簇簇间相似度时需要计算多个点对的相似度,这种聚类算法一般比使用簇中心的聚类算法慢,难以满足大规模快速增量聚类的需求。针对此问题,该文提出一种快速增量网页聚类方法FPC(Fast Page Clustering)。在该方法中,先提出一种新的计算网页相似度的方法,其计算速度是简单树匹配算法的500倍;给出一种网页簇中心的表示方式,在此基础上使用Kmeans算法的一个变种MKmeans(Merge-Kmeans)进行聚类,在聚类算法层面上提高效率;使用局部敏感哈希技术,从数量庞大的网页类集中快速找出最相似的类,在增量合并层面上提高效率。 ",MESS201602026
文本聚类的重构策略研究,陈笑蓉:06939837|刘作国:34071691,7,文本聚类; 聚簇重构; 邻近域规则; 高斯加权;,"该文提出面向文本距离并独立于聚类过程的聚类重构策略。提出邻近域的概念并阐述了邻近域规则,设计了高斯加权邻近域算法。利用高斯函数根据样本与聚簇中心的距离为样本赋权,计算聚簇间距。基于邻近域权重对文本聚类的结果实施重构。使用拆分算子拆分稀疏聚簇并调整异常样本;使用合并算子合并相似聚簇。实验显示聚簇重构机制能够有效地提高聚类的准确率及召回率,增加聚簇密度,使得形成的聚类结果更加合理。 ",MESS201602027
Wikipedia跨语言链接发现中的锚文本译项选择,郑剑夕:30148825|白宇:24679275|郭程:30148824|张桂平:24679273,7,Wikipedia; 跨语言链接发现; 锚文本; 译项选择; 逐点互信息;,"Wikipedia跨语言链接发现主要研究从源语言Wikipedia文章中自动识别与主题相关的锚文本,并为锚文本推荐一组相关的目标语言链接。该研究涉及三个关键问题:锚文本识别、锚文本翻译和目标链接发现。在锚文本翻译中,一个锚文本可能存在多个目标译项,如果其译项选择有误,将会直接影响目标链接发现中的链接推荐的准确性。为此,该文提出了一种基于上下文的锚文本译项选择方法,使用基于逐点互信息投票的方式确定锚文本的译项。对中英文Wikipedia中的人名、术语以及缩略语的译项选择进行测试,实验表明该方法取得了较好的效果。 ",MESS201602028
藏文字符的向量模型及构件特征分析,"才智杰1:08166533|才让卓玛1,2:11447913",5,中文信息处理; 向量模型; 稀疏域模型; 构件;,"藏文字属性分析是藏文信息处理的一项基础性工作,对藏文信息处理的研究和藏语文教学具有重要的参考价值及指导意义。藏文字是一种特殊的拼音文字,由1~7个基本构件横向和纵向拼接而成。因而藏文字符的属性包括其组成的构件及其构件的位置特征,以及藏文字的使用频度、结构、字长等属性特征。该文通过分析藏文字的结构,分别建立了藏文字及藏文字符串的向量模型VMTT、VMTS和藏文字符串的稀疏域模型SLM,并在向量模型和稀疏域模型上研究了藏文字符的构件特征。 ",MESS201602029
面向维吾尔语关键词检索的等宽切词算法和基于清浊音结构的切词算法实现与对比分析, ,6,维吾尔语; 敏感词检索; 切词; 广播新闻;,"该文提出了面向维吾尔语关键词检索的两种切词算法,并给出MATLAB实现的算法代码及详细说明;在同等条件下对两种算法的切词效果和关键词识别效率进行对比分析;提出两种算法的优化方法和构想。 ",MESS201602030
汉蒙机器翻译中译文动词后处理研究,王斯日古楞1:07999500|王春荣1:26547528|斯琴图2:08644763|阿荣1:07998199|玉霞1:07999576,4,蒙古文动词; 汉蒙机器翻译; 后处理; 错误词形;,"蒙古文的形态变化非常丰富,在动词词类上该特点更为明显。我们对蒙古文的动词自动生成方法进行了系统的研究。该文利用生成的蒙古语动词库,给出了对基于层次短语的汉蒙统计机器翻译译文中句尾错误词形动词进行纠正处理的方法。实验表明,该方法可以提高汉蒙机器翻译的性能和流利度。 ",MESS201602031
2016中国中文信息学会战略研讨会在海口成功召开,,1, ,"<正>当前已经进入以互联网和大数据为主要标志的海量信息时代。计算机和互联网技术的快速发展对中文信息处理技术提出了许多新的挑战。继2010、2012、2014年学会战略研讨会之后,2016年5月5-6日,中国中文信息学会在海口成功举办了2016中国中文信息学会战略研讨会,承办单位海南师范大学。本次会议邀请了来自University of Illi- ",MESS201602005
知识图谱与问答系统前沿技术研讨会暨清华大学“计算未来”博士生论坛顺利召开,,1, ,"<正>2016年4月17日,知识图谱与问答系统前沿技术研讨会暨清华大学""计算未来""博士生论坛在FIT大楼多功能报告厅召开。本次研讨会由中国中文信息学会语言与知识计算专业委员会、中国中文信息学会青年工作委员会青工委和清华大学计算机科学与技术系联合举办。研讨会由清华大学李涓子教授、中科院自动化所刘康博士和清华大学刘知远博士担任主席,博士生论坛由林衍凯同学担任主席。 ",MESS201602020
书讯,,1, ,"<正>汉语多功能语法形式的语义地图研究·世界语言类型学新方法""语义地图模型""运用于汉语语法研究的阶段性成果·作者:李小凡张敏郭锐等开本:16开书号:978-7-100-10859-1定价:78.00元本书介绍了语义地图模型的理论、发展史和操作方法,展示了运用语义地图模型研究汉语语法的最新成果。 ",MESS201602032
面向问答社区的答案摘要方法研究综述,"刘秉权1:06988938|徐振1:24268059|刘峰1:06989485|刘铭1:22077849|孙承杰1:06996605|王晓龙1,2:06993266",8,答案摘要; 问答社区; 问句分类; 文本语义相似度;,"社区问答系统(Community-Based Question Answering Portal,CQA)的兴起,不仅为用户提供了信息获取与知识分享的平台,同时也积累了大量的问答资源。近年来对于问答社区中的问题匹配、专家发现、用户满意度分析、答案质量评价等方面的研究也逐渐加深,特别是答案质量研究已经从通过答案质量评价改善用户体验,逐步过渡到使用答案摘要提升答案质量。该文阐述了答案摘要对于社区问答系统中问答对资源再利用的重要意义,概括了答案摘要的主要任务,分析了答案摘要和多文档自动文摘的异同点,对答案摘要国内外的研究现状进行了概述,并且总结了答案摘要中需要进一步解决的关键技术问题。 ",MESS201601001
一种短正文网页的正文自动化抽取方法,"郗家贞1,2:32363763|郭岩1:09559534|黎强1,2:34743839|赵岭1:30315620|刘悦1:09639001|俞晓明1:09560060|程学旗1:09559496",8,短正文; 正文抽取;,"随着互联网的发展,网页形式日趋多变。短正文网页日益增多,传统的网页正文自动化抽取方式对短正文网页抽取效果较差。针对以上问题,该文提出一种单记录(新闻、博客等)、短正文网页的正文自动化抽取方法,在该方法中,首先利用短正文网页分类算法对网页进行分类,然后针对短正文网页,使用基于页面深度以及文本密度的正文抽取算法抽取正文。 ",MESS201601002
基于同义扩展的在线百科中实体属性抽取,"刘倩1,2:29729450|刘冰洋1,2:31156616|贺敏3:30399340|伍大勇1:29729449|刘悦1:09639001|程学旗1:09559496",9,实体属性; 同义属性; 命名实体; 信息抽取词;,"实体属性抽取是信息抽取、知识库构建等任务的重要基础。该文提出了一种利用在线百科获取实体属性的方法,该方法首先通过在线百科的结构特征和领域独立的抽取模式捕获可能的属性短语,然后根据同义扩展获取尽可能多的属性表述形式,并同时得到对应实体类别的同义属性集合。实验表明,该方法在保证属性抽取准确率不变的情况下,获得了比仅使用频率的方法覆盖范围更广的实体属性集合。 ",MESS201601003
基于多核融合的中文领域实体关系抽取,"郭剑毅1,2:07895859|陈鹏1:07895375|余正涛1,2:05982358|线岩团1,2:23245672|毛存礼1,2:23238123|赵君1:26288662",6,关系抽取; 径向基核函数; 卷积核函数; 多核融合;,"针对传统径向基核函数的训练矩阵中所有元素都十分接近零而不利于分类的问题,该文提出了一种融合了改进的径向基核函数及其他核函数的多核融合中文领域实体关系抽取方法。利用径向基核函数的数学特性,提出一种改进的训练矩阵,使训练矩阵中的向量离散化,并以此改进的径向基核函数融合多项式核函数及卷积树核函数,通过枚举的方式寻找最优的复合核函数参数,并以上述多核融合方法与支持向量机结合进行中文领域实体关系抽取。在旅游领域的语料上测试,相对于单一核方法及传统多核融合方法,关系抽取性能得到提高。 ",MESS201601004
基于SAO的专利结构化相似度计算方法,杜玉锋:32648285|季铎:25068860|姜利雪:32881832|张桂平:24679273,6,数据挖掘; 专利相似度; Subject-Action-Object(SAO)技术; 实体抽取工具; OLLIE;,"该文提出了一种基于subject-action-object(SAO)的专利结构化相似度计算方法。传统的基于关键词的定量分析方法没有考虑专利自身的结构特点,忽略了对专利间内在关系的计算,该文弥补了传统的基于关键词的定量方法的不足。在SAO结构抽取过程中,将最新的实体抽取工具OLLIE引入到专利领域,得到了比传统SAO抽取工具更好的抽取结果。和传统的SAO方法相比,对Action元组进行了大量分析,通过重复大量实验,确定了Action元组的结构特征。最后,通过实验验证,将vector space module(VSM)模型和SAO结构进行融合,得到了比仅仅通过VSM模型进行相似度计算更好的结果。 ",MESS201601005
基于混合模型的生物事件触发词检测,李浩瑞:33076682|王健:06522915|林鸿飞:06504899|杨志豪:06523490|张益嘉:24031139,7,触发词; 生物事件; 歧义; 丰富特征; 组合学习器;,"语义歧义增加了生物事件触发词检测的难度,为了解决语义歧义带来的困难,提高生物事件触发词检测的性能,该文提出了一种基于丰富特征和组合不同类型学习器的混合模型。该方法通过组合支持向量机(SVM)分类器和随机森林(Random Forest)分类器,利用丰富的特征进行触发词检测,从而为每一个待检测词分配一个事件类型,达到检测触发词的目的。实验是在BioNLP2009共享任务提供的数据集上进行的,实验结果表明该方法有效可行。 ",MESS201601006
基于LDA模型的论坛热点话题识别和追踪,徐佳俊:33010418|杨飏:29155381|姚天昉:08576605|付中阳:34746184,7,论坛; 话题模型; 趋势分析; 话题追踪; LDA;,"在当今处于信息数量爆炸式增长的互联网时代,如何分析海量文本中的信息并从而提取出所蕴含的有利用价值的部分,是一个值得关注的问题。然而论坛语料作为网络语料,其结构和内容较一般语料相比更为复杂,文本也更加短小。该文提出的方法利用LDA模型对语料集进行建模,将话题从中抽取出来,根据生成的话题空间找到相应的话题支持文档,计算文档支持率作为话题强度;将话题强度反映在时间轴上,得到话题的强度趋势;通过在不同时间段上对语料重新建模,并结合全局话题,得到话题的内容演化路径。实验结果说明,上述方法是合理和有效的。 ",MESS201601007
一种无指导的子主题挖掘方法,郭程:30148824|白宇:24679275|郑剑夕:30148825|蔡东风:24679274,6,子主题挖掘; 查询意图; 潜在主题;,"为了解决用户查询经常存在表意模糊或歧义性等问题,明确用户的查询意图,该文提出了一种无指导的子主题挖掘方法。该方法首先在检索结果文档集中利用ATF×PDF模型挖掘候选主题词;其次,为保证子主题的多样性,该文基于HowNet语义相似度方法对候选主题词进行了层次聚类分析,进而得到潜在主题;最后,利用LCS算法生成多样性子主题。实验结果显示,系统平均D#-nDCG@10达到0.573,结果说明该方法在明确查询主题表意方面取得了较好效果。 ",MESS201601008
基于多层Markov网络的信息检索模型,廖亚男1:29895356|王明文1:08472511|左家莉1:07871349|吴根秀2:00114473|甘丽新3:28803348,7,信息检索; 多层Markov网络; 查询扩展; 团;,"随着信息检索技术的不断发展,挖掘更加有效的信息来提高检索精度成为研究热点,已有的研究表明在检索过程中有效地融合各种信息将得到更好的检索效果。对一个具体查询而言,可以充分利用与已有查询的相关性、词语相关性和文档相关性等信息进行查询扩展和重构。基于这种思路,该文分别构造查询网络、词网络和文档网络,提出了多层Markov网络的信息检索模型,模型可以融合词间关系、文档间关系和查询间关系,为了有效降低计算量,给出了基于团计算模型。在标准数据集上的实验表明该文的模型能够有效融合三类信息,并较大幅度地提高检索效果。 ",MESS201601009
基于时空局部性的层次化查询结果缓存机制,"朱亚东1,2:28368038|郭嘉丰1:14336892|兰艳艳1:30526869|程学旗1:09559496",9,页面缓存; 标识符缓存; 启发式预取;,"查询结果缓存可以对查询结果的文档标识符集合或者实际的返回页面进行缓存,以提高用户查询的响应速度,相应的缓存形式可以分别称之为标识符缓存或页面缓存。对于固定大小的内存,标识符缓存可以获得更高的命中率,而页面缓存可以达到更高的响应速度。该文根据用户查询访问的时间局部性和空间局部性,提出了一种新颖的基于时空局部性的层次化结果缓存机制。首先,该机制将固定大小的结果缓存划分为两层:页面缓存和标识符缓存。对于用户提交的查询,该机制会首先使用第一层的页面缓存进行应答,如果未能命中,则继续尝试使用第二层的标识符缓存。实验显示这种层次化的缓存机制较传统的仅依赖于单一缓存形式的机制,在平均查询响应时间上,取得了可观的性能提升:例如,相对单纯的页面缓存,平均达到9%,最好情况下达到11%。其次,该机制在标识符缓存的基础上,设计了一种启发式的预取策略,对用户查询检索的空间局部性进行挖掘。实验显示,这种预取策略的融合,能进一步促进检索系统性能的有效提升,从而最终建立起一套时空完备的、有效的结果缓存机制。 ",MESS201601010
搜索引擎的一种在线中文查询纠错方法,胡熠1:34743842|刘云峰2:34743843|杨海松2:32663939|张小鹏2:34115403|段建勇3:23130482|张梅3:22348976|乔建秀2:29865605,8,中文查询纠错; 多特征; 核函数排序;,"该文主要解决中文搜索引擎的查询纠错问题。错误的查询,已经偏离用户真实的搜索意图时,搜索质量很差,甚至导致搜索结果数为零。为此该文提出了一种服务于实际搜索引擎,较为完整的查询纠错方案。该文重点描述了纠错查询候选生成、纠错查询候选评价、以及基于核函数,挑选最优纠错查询候选等内容。通过在开放测试集上的准确率/召回率验证,以及在搜索引擎中实际的DCG评测,该文的方案都取得了较好的效果。 ",MESS201601011
网页搜索中查询时效性的实时计算模型,胡熠1:34743842|刘云峰2:34743843|段建勇3:23130482|熊展志2:34743844|乔建秀2:29865605|张梅3:22348976,7,查询时效性; 时效性用户模型; 时效性媒体模型;,"网页搜索中的查询时效性是指查询对新闻网页的需求。这种时间相关的因素,在网页排序过程中用于平衡其他非时间性因素,使排序更好地满足用户体验。为此该文提出了一种查询时效性的实时计算模型:从用户搜索和媒体报道两个角度,分别对时效性建模,然后这两种不同来源的时效性相互补充,综合计算某个时刻用户搜索某个查询时,其综合时效性得分。这个量化得分在网页排序阶段用于提高或抑制新闻网页的露出;同时也为网页搜索结果中展现新闻直达区提供依据。在人工评测以及用户点击通过率统计上,该模型均取得了不错的实际效果。 ",MESS201601012
LinkMF:结合Linked Data的协同过滤推荐算法,,8,推荐系统; 矩阵分解; Linked Data; 数据稀疏性; 冷启动;,"协同过滤(CF)是推荐系统中应用最为广泛的推荐算法之一,然而数据稀疏性和冷启动问题是协同过滤方法的两个主要挑战。由于Linked Data整合了关于实体的丰富且结构化的特征,可以作为额外的信息源来缓解以上两种挑战。该文中我们首次提出了结合Linked Data改进CF推荐算法,基于矩阵分解提出了一种新的CF模型——LinkMF,在保证推荐准确度的基础上利用Linked Data缓解数据稀疏性和冷启动问题。首先,我们从Linked Data中抽取项目的特征表示并为项目建模;然后提出新的相似度度量方法计算项目相似度;最后利用项目相似度约束和指导MF分解过程产生推荐。在MovielLens和YAGO标准数据集上的大量实验结果表明,LinkMF优于现有的一些CF方法,特别在缓解数据稀疏性和冷启动问题上取得很好地效果。 ",MESS201601013
基于微博用户模型的个性化新闻推荐,古万荣:31911458|董守斌:07545913|曾之肇:31911459|何锦潮:30595876|刘崇:33847013,8,新闻推荐; 文本分类; 微博分析;,"新闻推荐是互联网推荐系统的研究热点之一,传统的新闻推荐方法是在新闻网站内,通过记录用户浏览的新闻来实现推荐应用。然而,许多新闻网站并不强制要求用户必须注册才能浏览新闻。微博作为目前最主流的自媒体形式,它由用户自己发起或传递,进而实现草根媒体的职能。对新闻进行高效组织并使用微博进行新闻推荐,这是之前研究欠缺的。该文通过提出基于微博分析的新闻推荐,提出了基于新闻和微博本身特点的解决方法,从而实现微博和新闻的关联。实验表明,该文设计的各模块具备较高的效率和实用效果。 ",MESS201601014
基于同义词词林信息特征的语义角色自动标注,"李国臣1,2:25955427|吕雷2:31019209|王瑞波3:13897708|李济洪3:08401319|李茹2:08453268",8,语义角色标注; 同义词词林; 条件随机场; 正交表;,"该文使用同义词词林语义资源库,以词林中编码信息为基础构建新的特征,使用条件随机场模型,研究了汉语框架语义角色的自动标注。该文在先前的基于词、词性、位置、目标词特征的基础上,在模型中加入不同的词林信息特征,以山西大学的汉语框架语义知识库为实验语料,研究了各词林信息特征分别对语义角色边界识别与分类的影响。实验结果表明,词林信息特征可以显著提高语义角色标注的性能,并且主要作用在语义角色分类上。 ",MESS201601015
中心修正增量主成分分析及其在文本分类中的应用,陈素芬1:11709513|曾雪强2:24755513,7,主成分分析; 中心化修正; 流数据; 维数约减; 增量学习;,"增量式学习模型是挖掘大规模文本流数据的一种有效的数据处理技术。无偏协方差无关增量主成分分析(Candid Covariance-free Incremental Principal Component Analysis,CCIPCA)是一种增量主成分分析模型,具有收敛速度快和降维效果好的特点。但是,CCIPCA模型要求训练数据是已经中心化或中心向量固定的。在实际的应用中,CCIPCA往往采用一种近似的中心化算法对新样本进行处理,而不会对历史数据进行中心化修正。针对这一问题,该文提出了一种中心修正增量主成分分析模型(Centred Incremental Principal Component Analysis,CIPCA)。CIPCA算法不仅对新样本进行中心化处理,而且会对历史数据进行准确的中心化修正。在文本流数据上的实验结果表明,CIPCA算法的收敛速度和分类性能明显优于CCIPCA算法,特别是在原始数据的内在模型不稳定的情况下,新算法的优势更为明显。 ",MESS201601016
基于主位-述位结构理论的英文作文连贯性建模研究,徐凡:31367729|王明文:08472511|谢旭升:07870472|李茂西:29475622|万剑怡:07869967,9,衔接性; 连贯性; 主位-述位结构理论; 篇章关系; 线性组合;,"该文在研究了有监督的基于实体和基于篇章关系网格的篇章连贯性模型的基础上,提出了一个无监督的基于主位-述位结构理论的篇章连贯性模型。该模型通过引入词语的词干、上下位、近义和复述等语义方面的信息来计算相邻句子中主位和述位的相似度,并利用此相似度值来描述篇章的连贯性。同时,该文提出了一种简单有效的基于篇章关系计数的连贯性模型,并采用线性组合方法将其与基于主位-述位结构理论的连贯性模型加以集成。上述模型在国际基准英文作文语料上进行试验,实验结果表明采用线性组合的连贯性模型后,作文连贯性检测准确率与目前基于实体和篇章关系网格的模型相比得到显著提升。 ",MESS201601017
基于词干的蒙古语语音关键词检测方法的研究,飞龙:23670720|高光来:05981929|王宏伟:08639646,5,蒙古语; 词干; 混淆网络; 置信度;,"为了提高蒙古语语音关键词检测任务中的集内词检测性能,该文结合蒙古文的构词特点提出了基于词干进行检测的蒙古语语音关键词检测方法。首先,该文采用基于分割识别的蒙古语语音识别系统将语音解码成了网格文本,并对网格文本进行了混淆网络的转换;其次,采用关键词的词干部分对混淆网络文本进行了关键词的检测。实验结果表明,基于词干进行检测的蒙古语语音关键词检测方法明显优于基于词混淆网络的蒙古语关键词检测方法,并有效提高了系统的召回率和精确率。 ",MESS201601018
彝语言语料资源数据库的设计与共享的实现,王成平:10225120,5,彝语言; 语料库; 数据库设计; 共享;,"该文以收集整理翻译的彝语言语料为基础,在SQL Server 2008数据库环境下,通过ODBC,利用VC++6.0编写彝语言语料入库程序,实现了彝语言语料U文件(Unicode彝文)和Y文件(YIWIN彝文)的自动入库,完成了彝语言语料资源数据库的设计;通过编写WEB服务端的查询和统计程序,利用C/S方式实现了彝语言语料基于WEB浏览器的访问和远程共享,同时也为其他少数民族文字信息处理中的类似问题提供了一个可参考的解决方案。 ",MESS201601019
基于N-Gram模型的蒙古语文本语种识别算法的研究,马志强:08017129|张泽广:32774786|闫瑞:33342587|刘利民:07987252|冯永祥:07998073|苏依拉:07987316,7,语种识别; N-Gram模型; 平均距离识别算法; 蒙古语文本;,"互联网上蒙古语文本正在不断地增加,如何让网络中的蒙古语内容为搜索引擎和舆情分析等应用提供服务引起了社会的高度关注。首先要解决如何采集网络中蒙古语文本数据,核心是准确识别网络中蒙古语文本的问题。该文提出了基于N-Gram模型的平均距离识别算法,建立了一个能够对目标语种识别的实验平台。实验结果表明,识别算法能够很好地从中文、英文、蒙古文以及混合语言文本中识别出蒙古语文本,准确率达到99.5%以上。 ",MESS201601020
细粒度意见挖掘中维吾尔语文本情感分析研究,罗亚伟1:31640545|田生伟2:09220503|禹龙3:09256058|吐尔根·依布拉音1:17705003|艾斯卡尔·艾木都拉2:17704444,9,细粒度; 陈述级; 情感分析; CRFs; 维吾尔语;,"传统的情感分析研究通过分析,确定词语、句子或篇章的情感,但忽略了情感表达的主题。针对这一不足,该文提出了一种基于双层CRFs模型的细粒度意见挖掘中维吾尔语意见型文本陈述级情感分析方法。第一层模型识别意见型文本中的主题词和意见词,确定意见陈述的范围,并将识别结果传递给第二层模型,将其作为重要特征之一,用于陈述级情感分析。细粒度意见挖掘中情感分析的目标是构建<意见陈述,主题词,意见词,情感>四元组。该方法用于维吾尔语陈述级情感分析的准确率为77.41%,召回率为78.51%,证明了该方法在细粒度意见挖掘中情感分析任务上的有效性。 ",MESS201601021
维吾尔语比较句识别研究,王慧云1:32104345|禹龙2:09256058|田生伟3:09220503|加米拉·吾守尔1:22592621|冯冠军4:09220102,8,维吾尔语; 比较句识别; 双向CSR挖掘算法; 文本分类;,"识别比较句并提取被比较事物之间的关系是细颗粒度意见挖掘的重要研究内容之一。该文给出维吾尔语比较句的范畴、语法特点,定义了维吾尔语比较句识别的任务。提出两层识别模型,第一层是基于比较词的粗识别,第二层提出双向CSR挖掘算法(Bidirectional CSR Mining),以挖掘的模式为特征,利用支持向量机(SVM)筛选得到比较句,实现维吾尔语比较句的识别。实验F值达到70.93%,证明提出的两层识别模型可以有效识别维吾尔语比较句。 ",MESS201601022
基于多模板归一化的维吾尔文字母识别算法,"刘卫1,2:28759952|李和成2:08819444",6,维吾尔文字符; 归一化; 宽高比; 分类器;,"该文针对手写维文字符识别中字符宽高比变化剧烈,单一模板归一化后提取字符特征,不能有效增加异类字符之间的差异性,提出了针对维文字形特点的多模板归一化算法。训练阶段,由多模板归一化字符图像,提取特征并训练对应分类器;识别阶段,用主笔画散度方向作为维文字形参数,对不同字形选用最优模板进行归一化处理后提取特征,并送入该模板对应的分类器。多模版归一化有效利用了手写维文字符字形特征,克服了单模板归一化时异类维文字符差异减小的不利影响。实验结果表明多模板归一化算法较单模板归一化算法在识别性能上有所提高。 ",MESS201601023
交通数据中的会话识别,娄新燕:31594216|刘洋:08213416|禹晓辉:31367730,8,会话识别; 超时方法; 统计语言模型;,"会话识别因其能够提供对用户行为模式的深入理解而备受关注。交通数据会话是指用户为了完成某个任务而经过的交通路口序列。该文中我们采用超时和统计语言模型两种方法来进行会话识别。超时方法主要考察相邻交通路口之间的时间间隔对会话识别的影响,而统计语言模型则考虑路口序列的全局规律性。我们在交通数据集上进行了大量的实验,并通过比较分析两种方法性能上的差异得知时间因素比全局规律性在会话识别中的影响更大。 ",MESS201601024
MBNER:面向生物医学领域的多种实体识别系统,杨娅1:33715318|杨志豪1:06523490|林鸿飞1:06504899|宫本东2:34743845|王健1:06522915,7,机器学习; 特征耦合泛化; CRF; 全称缩写对;,"生物命名实体识别,就是从生物医学文本中识别出指定类型的名称。目前,面向生物医学领域的实体识别研究不断出现,从海量生物医学文本自动提取生物实体信息的技术变得尤为重要。该文介绍了一个面向生物医学领域的多实体识别系统MBNER(Multiple Biomedical Named Entity Recognizer)。该系统可以在生物医学文本中同时识别出基因(蛋白质)、药物、疾病实体,其对基因(蛋白质)、药物、疾病实体识别在各自数据集上分别得到了89.05%,76.73%,90.12%的综合分类率(F-score)。该系统以可视化的形式给出对三种命名实体的识别结果。 ",MESS201601025
基于语义资源的生物医学文献知识发现研究,李宗耀1:23552007|杨志豪1:06523490|吴晓芳1:27135988|林鸿飞1:06504899|宫本东2:34743845|王健1:06522915,7,隐含知识发现; 共现; 语义关系;,"目前,生物医学文献的数量正在呈指数的方式快速增长,这些文献中隐含着大量有用的信息,挖掘这些文献可以形成医学假设。但传统的基于简单共现的方法会产生大量的目标词,导致很难发现有用的假设。该文提出了一种基于语义资源的方法,利用SemRep工具抽取句子内实体之间的关系,结合语义类型、概念的信息量以及关联规则对连接词、目标词进行过滤,并根据统计量信息对目标词进行排序。通过对Swanson发现的经典病例进行验证,实验结果表明该方法取得很好的效果。 ",MESS201601026
网络游戏案例研究:用户行为分析和流失预测,过岩巍1:31343806|吴悦昕1:32936763|赵鑫1:29227474|闫宏飞1:06276313,8,行为分析; 特征提取; 流失预测; 网络游戏;,"用户流失预测在很多领域得到关注,目前主流的用户流失预测方法是使用分类法。网络游戏领域发展迅猛,但用户特征选取、特征处理和流失预测的相关研究较少。本文以一款网页网络游戏的用户记录为数据,对用户游戏行为进行分析对比,发现流失用户在游戏投入、博彩热情、玩家互动方面与正常用户存在显著差异;同时发现网络游戏数据存在样本分布不平衡、候选特征库庞大和干扰差异多等难点。在此分析基础上,本文探讨了网游用户的关键特征提取的关注方向,以及归一化和对齐化在特征处理中的关键作用。实验表明,本文提取的特征具有很好的区分度。 ",MESS201601027
一种中文伪评论语料半自动获取方法,郝秀兰:23893967|许方曲:30968061|蒋云良:05981975,8,计算机应用; 中文信息处理; 倾向性分析; 伪中文评论; 半自动获取;,"该文提出了一种中文伪评论语料半自动收集方法,主要包括数据收集、句法分析、情感倾向性分析等方法,并对影响方法正确性的错误进行了总结。文中着重介绍了一种句法分析方法,在句法分析的基础上提出了<评价对象,评价短语>的提取方法。该提取方法简化了情感二元对的句法呈现模式。同时,对部分实验结果进行了分析,对提高文本情感分析的准确率提出了一些建议。 ",MESS201601028
基于维基百科的双语可比语料的句子对齐,胡弘思:29155378|姚天昉:08576605,6,句子对齐; 可比语料; 维基百科; SVM;,"该文提出了一种从维基百科的可比语料中抽取对齐句子的方法。在获取了维基百科中英文数据库备份并进行一定处理后,重构成本地维基语料数据库。在此基础上,统计了词汇数据、构建了命名实体词典,并通过维基百科本身的对齐机制获得了双语可比语料文本。然后,该文在标注的过程中分析了维基百科语料的特点,以此为指导设计了一系列的特征,并确定了""对齐""、""部分对齐""、""不对齐""三分类体系,最终采用SVM分类器对维基百科语料和来自第三方的平行语料进行了句子对齐实验。实验表明:对于语言较规范的可比语料,分类器对对齐句的分类正确率可达到82%,对于平行语料,可以达到92%,这说明该方法是可行且有效的。 ",MESS201601029
基于释义扩展的术语归类研究,贺刚1:30618581|吕学强1:10724564|肖诗斌1:11155415,6,术语归类; 释义扩展; 向量距离; 类中心向量;,"术语归类研究对领域本体构建与特定领域词表扩展有十分重要的意义。该文针对中国知网概念知识元库中存在的术语归类错误问题,研究如何提高术语归类正确率。经分析发现术语具有释义文本短、所包含的能够区分术语类别的特征词较少的特点。该文提出一种基于释义扩展的术语归类方法,该方法引入了释义扩展思想,以搜索引擎为工具,获取术语相关的互联网知识,抽取查询结果的锚文本和摘要文本等内容扩展术语释义文本;采用向量距离算法计算术语释义文本特征向量与类中心向量之间的距离,实现对术语的归类。实验得到的术语归类总体正确率为73.32%,与未经释义扩展得到的术语归类正确率相比,提高了近10%。实验结果表明,该方法对提高术语归类正确率是有效的。 ",MESS201601030
不对称和标记论,,1, ,"<正>从语言结构之外寻找解释语法现象的方法开本:32开书号:978-7-100-11270-3定价:35.00元本书借鉴语言类型学、语用学、篇章语言学、认知语言学的研究成果,用新的""标记理论""对汉语语法的各种对称和不对称现象做出统一的描写和解释,证明语言的结构与演化跟语言的使用和人的认知方式密切关联。 ",MESS201601031
普遍语法探究:句法和语义获得实验指南,,1, ,"<正>系统介绍研究儿童句法和语义获得的经典实验方法开本:32开书号:978-7-100-10945-1定价:49.00元本书是国外儿童语言获得研究的经典教材,是将生成语法理论的假设与儿童语言实证研究紧密结合的典范。书中展示了大量儿童句法、语义获得研究的实验,详细阐述了实验设计的理念、必须满足的合理性条件、具体实施的步骤以及存在的问题,为开展儿童语言的科学实验提供了很强的实用性指导。 ",MESS201601032
三位一体字标注的汉语词法分析,于江德1:17660227|胡顺义1:17445814|余正涛2:05982358,7,汉语词法分析; 最大熵模型; 三位一体; 字标注;,"针对汉语词法分析中分词、词性标注、命名实体识别三项子任务分步处理时多类信息难以整合利用,且错误向上传递放大的不足,该文提出一种三位一体字标注的汉语词法分析方法,该方法将汉语词法分析过程看作字序列的标注过程,将每个字的词位、词性、命名实体三类信息融合到该字的标记中,采用最大熵模型经过一次标注实现汉语词法分析的三项任务。并在Bakeoff2007的PKU语料上进行了封闭测试,通过对该方法和传统分步处理的分词、词性标注、命名实体识别的性能进行大量对比实验,结果表明,三位一体字标注方法的分词、词性标注、命名实体识别的性能都有不同程度的提升,汉语分词的F值达到了96.4%,词性标注的标注精度达到了95.3%,命名实体识别的F值达到了90.3%,这说明三位一体字标注的汉语词法分析性能更优。 ",MESS201506001
基于简单名词短语的汉语介词短语识别研究,桑乐园:33384083|黄德根:06527360,6,简单名词短语识别; CRF; 分词融合;,"该文提出一种融入简单名词短语信息的介词短语识别方法。该方法首先使用CRF模型识别语料中的简单名词短语,并使用转换规则对识别结果进行校正,使其更符合介词短语的内部短语形式;然后依据简单名词短语识别结果对语料进行分词融合;最后,通过多层CRFs模型对测试语料进行介词短语识别,并使用规则进行校正。介词短语识别的精确率、召回率及F-值分别为:93.02%、92.95%、92.99%,比目前发表的最好结果高1.03个百分点。该实验结果表明基于简单名词短语的介词短语识别算法的有效性。 ",MESS201506002
汉语复句关系的特征结构,冯文贺:26510566,10,复句关系; 特征结构; 语义分析;,"通常复句关系分析基于分类机制,由于缺乏统一逻辑,面临不少分歧。该文提出基于特征结构描写复句关系。复句关系的特征结构由[特征:值]元组构成,该文初步构拟汉语复句关系的特征结构系统,并用于具体分析。较之分类机制,特征结构对复句关系的描写深刻,且分析判断准确、易行。目前特征结构系统开放,但特征调整,可以完善而不大量更改已有特征描写结果。特征结构可用于复句关系的深度语义分析资源构建与计算研究。 ",MESS201506003
基于知网义原词向量表示的无监督词义消歧方法,"唐共波1,2:32869880|于东1,2:26514992|荀恩东1,2:06433984",7,词向量; 《知网》; 词义消歧; 无监督方法;,"词义消歧一直是自然语言处理领域中的重要问题,该文将知网(HowNet)中表示词语语义的义原信息融入到语言模型的训练中。通过义原向量对词语进行向量化表示,实现了词语语义特征的自动学习,提高了特征学习效率。针对多义词的语义消歧,该文将多义词的上下文作为特征,形成特征向量,通过计算多义词词向量与特征向量之间相似度进行词语消歧。作为一种无监督的方法,该方法大大降低了词义消歧的计算和时间成本。在SENSEVAL-3的测试数据中准确率达到了37.7%,略高于相同测试集下其他无监督词义消歧方法的准确率。 ",MESS201506005
基于语义依存图库的兼语句句模研究,郑丽娟:32278868|邵艳秋:32278869,8,句模; 语义分析; 语义依存图; 兼语句;,"句子语义分析是语言研究深入发展的客观要求,也是当前制约语言信息处理技术深度应用的主要因素。在探索深层语义分析方法的基础上,该文根据汉语的特点,提出了一整套语义依存图的构建方法,并建立了一个包含30 000个句子的语义依存图库。以兼语句为重点研究对象,该文研究了语料库中所有纯粹的兼语句所对应的句模情况,进而试图构建基于语义依存图的句模系统,总结句型和句模的映射规则,从而为更好的建立语义自动分析模型提供相应的知识库。 ",MESS201506006
汉语形名复合词的语义建构:基于物性结构与概念整合理论,张念歆:34417197|宋作艳:25019866,8,形名复合词; 语义建构; 生成词库理论; 物性结构; 概念整合理论;,"该文用定量和定性分析相结合的方法,考察了现代汉语双音节形名复合词的物性修饰关系,发现形语素有选择地约束名语素的不同物性角色。当形语素修饰名语素的形式角色或构成角色时,语义解读时常需要补充名词;当形语素修饰名语素的施成角色、功用角色或规约化属性时,语义解读时常需要补充动词。形名复合词的语义建构是物性结构和概念整合共同作用的结果,当形语素激活的物性角色或物性值不止一个时,就会出现多义或歧义。 ",MESS201506007
语言网络研究的数学模型——从复杂网络、社会网络到语言网络,赵怿怡1:30602481|刘海涛2:09332506,8,语言网络; 网络技术; 网络演化; 图论; 复杂网络特征;,"复杂网络技术的发展为大数据时代的语言研究提供了新的视角。网络方法应用到语言研究的重要目的是探索语言网络的结构特征规律和功能演化规律。该文综述了以图论为基础的复杂网络发展及社会网络、语言网络的主要数学模型,试图从复杂网络共性特征——小世界、无标度特征中进一步剥离出语言网络的个性特征,为语言符号多层级网络结构、功能研究提供参考。 ",MESS201506008
面向汉语(二语)教学的语法点知识库构建及语法点标注研究,谭晓平:31118741|杨丽姣:06366403|苏靖杰:34417198,8,语法点; 知识库; 标注; 语料库; 汉语国际教育;,"语法是汉语(二语)教学中的重点和难点,而面向语法教学领域的知识库、语料库较少,不能满足汉语国际教育事业发展的需求。该文首先根据三个平面理论和对外汉语教学语法理论提出了面向汉语(二语)教学的语法点描述框架,建立了包含121个教学常用语法点的知识库。其次,在141 464条对外汉语教材语料和新HSK样题文本语料中对121个语法点进行了句法语义信息的综合标注,共获得95 592个句次的标注语料,涉及形式类别580项,语义类别233项,形成了与语法点知识库配套的语法点标注语料库。最后,讨论了语法点知识库和语法点标注语料库在汉语(二语)教学及教材研究领域的应用。 ",MESS201506009
对外汉语教学领域话题语料库的研究与构建,胡韧奋:24106271|朱琦:32852065|杨丽姣:06366403,7,对外汉语; 话题; 语料库;,"对外汉语教学领域,教材上的课文通常围绕一个话题展开,话题是教学内容的集中体现,也与词汇、语法等不同层面的语言知识间有着密切关联。该文基于大规模教材语料库研究教学话题分类体系,设计了一个包含四个一级话题、23个二级话题和246个三级话题的三层话题框架,并据此对197册汉语经典教材中的5 457个文段进行了人工标注及校对,构建了一个规模约12万句的面向对外汉语教学的话题语料库。为了更好地服务于汉语教学及相关研究工作,还抽取、计算了文段的语法点和新HSK词语等级信息,作为话题标注的补充维度加入资源库,以期为汉语教学领域的教师、研究者及教材编写者提供较为全面的话题信息参考。 ",MESS201506010
借助汉-越双语词对齐语料构建越南语依存树库,"李发杰1,2:33942766|余正涛1,2:05982358|郭剑毅1,2:07895859|李英1,2:23813164|周兰江1,2:07894197",6,越南语依存树库; 汉语依存句法分析; 汉-越语言对齐关系;,"由于对越南语的研究工作相对较少,因此还没有建立规模相对较大的依存树库。相对于已经拥有了形态丰富、语料成熟的汉语,越南语的依存句法分析要困难得多,所以该文提出了一种借助汉-越双语词对齐语料构建越南语依存树库的方法。首先对汉语-越南语句子对进行词对齐处理,然后对汉语句子进行依存句法分析。最后结合越南语本身的语言特点和有关的语法规则将汉语的依存关系通过汉-越双语词对齐关系映射到越南语句子中,从而生成越南语的依存树库。实验表明,该方法简化了人工收集和标注越南语依存树库的过程,节省了人力和构建树库的时间。实验结果表明,该方法相比采用机器学习的方法准确率明显提高。 ",MESS201506011
领域相关的汉语情感词典扩展,宋佳颖:34071695|贺宇:32278879|付国宏:22432184,9,情感分析; 情感词典扩展; PolarityRank; 意见要素一致化;,"动态情感知识的获取,特别是领域相关极性词典的构建一直是意见挖掘和情感分析系统在开放应用时面临的主要挑战之一。该文面向产品评价文本提出一种汉语情感极性词典扩展方法。该方法首先采用序列标注方法从意见文本中抽取产品意见要素,同时构建属性-评价对;然后,对抽取的属性-评价对进行正规化,以减少词典扩展中的复杂性和噪声;最后,改进PolarityRank算法的构图方式以使其适用于汉语文本,从而完成词典扩展。在汽车和手机两个领域的意见文本的实验结果表明领域相关的情感极性词语的扩展有利于情感极性分类性能的提高。 ",MESS201506012
中文模糊限制语语料库的研究与构建,周惠巍1:13896094|杨欢1:29895357|张静2:17320983|亢世勇2:10882043|黄德根1:06527360,7,中文模糊限制语; 分类; 语料库; 一致性分析;,"模糊限制语常用来表示不确定性和可能性的含义,由模糊限制语所引导的信息为模糊限制信息。为进行中文事实信息的抽取,应将模糊限制信息与事实信息区分开来。然而中文模糊限制语语料资源却十分缺乏,影响了中文模糊限制语和模糊限制信息检测的研究。该文研究了中文模糊限制语的分类,并在生物医学和维基百科两个领域,设计构建了一个具有2.4万句规模的中文模糊限制语语料库。统计分析了语料标注的一致性,以及模糊限制语的类型和领域之间的关系。这些资源对于中文模糊限制信息检测研究,以及中文事实信息的抽取具有重要意义。同时,为语言学家从语义和语用等方面进行模糊限制语的研究提供了强大的知识库支持。 ",MESS201506013
基于全局/局部共现词对分布的汉越双语新闻事件线索分析,高盛祥:07892541|余正涛:05982358|龙文旭:33955151|丁硙:34417199|闫春婷:34417200,8,汉语-越南语; 新闻事件线索; 全局/局部共现词对; 子话题分布; 双语主题模型;,"针对汉越双语新闻事件线索分析,提出了基于全局/局部共现词对分布的汉越双语事件线索生成方法。该方法首先将新闻话题词语分布作为全局词语表征全局事件,然后用一定时间粒度下新闻片段特有的时间、人物、地点等事件元素作为局部词语,分析新闻片段中全局词语和局部词语的共现关系,将全局/局部词语的共现规律作为监督信息,结合RCRP算法和汉越双语新闻的对齐语料,构建有监督话题生成主题模型,获得相应时间跨度下代表事件发展进程的子话题分布,通过子话题的分布反映事件发展的线索,从而构建出在线汉越双语事件线索生成模型。实验在汉越混合新闻数据集上进行,事件线索生成对比实验结果证明了提出的方法的有效性。 ",MESS201506014
基于框架的汉语篇章结构生成和篇章关系识别,"吕国英1:08401954|苏娜1:34417201|李茹1,2:08453268|王智强1:25200586|柴清华3:23254647",12,篇章单元; 篇章结构; 篇章关系; 贪婪算法;,"针对汉语篇章分析的三个任务:篇章单元切割、篇章结构生成和篇章关系识别,该文提出引入框架语义进行分析研究。首先基于框架构建了汉语篇章连贯性描述体系以及相应语料库;然后抽取句首、依存句法、短语结构、目标词、框架等特征,分别训练基于最大熵的篇章单元间有无关系分类器和篇章关系分类器;最后采用贪婪算法自下向上生成篇章结构树。实验证明,框架语义可以有效切割篇章单元,并且框架特征可以有效提升篇章结构以及篇章关系的识别效果。 ",MESS201506015
面向不平衡数据的隐式篇章关系分类方法研究,朱珊珊:32017553|洪宇:25038035|丁思远:33952665|姚建民:13898051|朱巧明:05968617,9,隐式篇章关系分类; 不平衡数据; 框架语义向量;,"隐式篇章关系分类是篇章分析领域的一个重要研究子任务,大部分已有研究都假设参与分类的正类样本和负类样本数量相等,采用随机欠采样等不平衡数据处理方法保持训练样本中数据平衡,然而,在实际语料中正类样本和负类样本的分布是不平衡的,这一现象往往制约隐式篇章关系分类性能的有效提升。针对该问题,该文提出一种基于框架语义向量的隐式篇章关系分类方法,该方法借助框架语义知识库,将论元表示成框架语义向量,在此基础上,从外部数据资源中挖掘有效的篇章关系样本,对训练样本进行扩展,解决数据不平衡问题。在宾州篇章树库(Penn Discourse Treebank,PDTB)语料上的实验结果表明,相较于目前主流的不平衡数据处理方法,该文方法能够明显提高隐式篇章关系分类性能。 ",MESS201506016
基于知识话题模型的文本蕴涵识别,"任函1,2:34417202|盛雅琦3,2:32989918|冯文贺3,2:22135161|刘茂福4,2:11187335",8,文本蕴涵识别; 话题模型; 蕴涵分类; 推理知识;,"该文分析了现有基于分类策略的文本蕴涵识别方法的问题,并提出了一种基于知识话题模型的文本蕴涵分类识别方法。其假设是:文本可看作是语义关系的组合,这些语义关系构成若干话题;若即若文本T蕴涵假设H,说明T和H具有相似的话题分布,反之说明T和H不具有相似的话题分布。基于此,我们将T和H的蕴涵识别问题转化为相关话题的生成过程,同时将文本推理知识融入到抽样过程,由此建立一个面向文本蕴涵识别的话题模型。实验结果表明基于知识话题模型在一定程度上改进了文本蕴涵识别系统的性能。 ",MESS201506017
文言信息的自动抽取:基于统计和规则的尝试,"虞宁翌1:34417203|饶高琦2,1:28523622|荀恩东1:06433984",9,文言标注; 文本分类; 规则模型; 统计模型;,"文言信息的自动抽取有利于语言监测和语料库构建。同时该文的计算研究也验证了语言学界关于汉语文白系统连续性的自省结论。该文将从混合语料中标注文言文的问题视为短文本分类的问题进行处理。使用基于规则和基于统计的方法对文言文、白话文本进行分类。在基于规则的方法中,考虑文言常用虚词和句式的影响,对N-gram、朴素贝叶斯、最大熵、决策树模型的性能进行了研究。结果表明监测虚词系统的一元语言模型的F值达到了0.98。 ",MESS201506018
基于超图的文本摘要与关键词协同抽取研究,莫鹏:34417204|胡珀:07625508|黄湘冀:34417205|何婷婷:07640959,6,超图; 文本摘要; 关键词抽取; 协同抽取;,"文本摘要和关键词抽取是自然语言处理领域的两个重要研究课题,它们均以生成描述文本主旨内容的精简信息为目标。尽管这两个任务目标相似,但它们通常被作为两个独立的问题分别研究,而较少考虑其彼此间的自然关联性。尽管已有学者提出了基于图模型的协同抽取方法,该方法同时考虑了句子与句子、词与词、句子与词之间的各种关系,以迭代强化的方式同时生成文本摘要和关键词,但现有模型大多仅限于表达句子与词之间的各种二元关系,而忽视了不同文本单元间潜在的若干重要的高阶关系。鉴于此,该文提出了一种新的基于超图的协同抽取方法。该方法以句子作为超边,以词作为节点构建超图,在一个统一的超图模型下同时利用句子与词之间的高阶信息来生成摘要和关键词。在NLPCC 2015面向微博的新闻文本摘要任务数据集上的实验结果验证了所提方法的可行性和有效性。 ",MESS201506019
基于自然标注信息和隐含主题模型的无监督文本特征抽取,"饶高琦1,2:28523622|于东1:26514992|荀恩东1:06433984",9,自然标注信息; 自然语块; 隐含主题模型; 领域特征; 文体特征;,"术语和惯用短语可以体现文本特征。无监督的抽取特征词语对诸多自然语言处理工作起到支持作用。该文提出了""聚类-验证""过程,使用主题模型对文本中的字符进行聚类,并采用自然标注信息对提取出的字符串进行验证和过滤,从而实现了从未分词领域语料中无监督获得词语表的方法。通过优化和过滤,我们可以进一步获得了富含有术语信息和特征短语的高置信度特征词表。在对计算机科学等六类不同领域语料的实验中,该方法抽取的特征词表具有较好的文体区分度和领域区分度。 ",MESS201506020
融合热点话题的微博转发预测研究,"陈江1:06302791|刘玮2,3,4:28474628|巢文涵1:22036030|王丽宏2:28474623",9,转发行为; 转发预测; 热点话题;,"微博转发行为是实现信息传播的重要方式,微博转发预测对微博影响力分析、微博话题分析具有重要价值。现有微博转发预测研究大多围绕消息属性、用户属性等微博自身特征,该文提出融合热点话题的微博转发预测方法,对背景热点话题内容和传播趋势对用户转发行为的影响进行量化分析,提出融合背景热点信息的转发兴趣、转发活跃度、行为模式等特征,并基于分类算法建立了面向热点话题相关微博的转发预测模型,在真实数据上的实验结果表明,该方法的预测准确性达到96.6%,提升幅度最高达到12.14%。 ",MESS201506021
基于卷积神经网络的微博情感倾向性分析,刘龙飞:32017552|杨亮:14244075|张绍武:06536175|林鸿飞:06504899,7,深度学习; 情感倾向性分析; 卷积神经网络; 词向量;,"微博情感倾向性分析旨在发现用户对热点事件的观点态度。由于微博噪声大、新词多、缩写频繁、有自己的固定搭配、上下文信息有限等原因,微博情感倾向性分析是一项有挑战性的工作。该文主要探讨利用卷积神经网络进行微博情感倾向性分析的可行性,分别将字级别词向量和词级别词向量作为原始特征,采用卷积神经网络来发现任务中的特征,在COAE2014任务4的语料上进行了实验。实验结果表明,利用字级别词向量及词级别词向量的卷积神经网络分别取得了95.42%的准确率和94.65%的准确率。由此可见对于中文微博语料而言,利用卷积神经网络进行微博情感倾向性分析是有效的,且使用字级别的词向量作为原始特征会好于使用词级别的词向量作为原始特征。 ",MESS201506022
面向微博的社会情绪词典构建及情绪分析方法研究,蒋盛益1:06844554|黄卫坚2:34417207|蔡茂丽2:34417208|王连喜3:24688918,7,微博; 社会情绪; 词典; 情绪分析;,"该文旨在探索一种面向微博的社会情绪词典构建方法,并将其应用于社会公共事件的情绪分析中。首先通过手工方法建立小规模的基准情绪词典,然后利用深度学习工具Word2vec对社会热点事件的微博语料通过增量式学习方法来扩展基准词典,并结合HowNet词典匹配和人工筛选生成最终的情绪词典。接下来,分别利用基于情绪词典和基于SVM的情绪方法对实验标注语料进行情绪分析,结果对比分析表明基于词典的情绪分析方法优于基于SVM的情绪分析方法,前者的平均准确率和召回率比后者分别高13.9%和1.5%。最后运用所构建的情绪词典对热点公共事件进行情绪分析,实验结果表明该方法是有效的。 ",MESS201506023
结合卷积神经网络和词语情感序列特征的中文情感分析,陈钊1:21844885|徐睿峰1:07001926|桂林1:30330029|陆勤2:09238733,7,卷积神经网络; 情感分析; 词语情感序列特征;,"目前基于词嵌入的卷积神经网络文本分类方法已经在情感分析研究中取得了很好的效果。此类方法主要使用基于上下文的词嵌入特征,但在词嵌入过程中通常并未考虑词语本身的情感极性,同时此类方法往往缺乏对大量人工构建情感词典等资源的有效利用。针对这些问题,该文提出了一种结合情感词典和卷积神经网络的情感分类方法,利用情感词典中的词条对文本中的词语进行抽象表示,在此基础上利用卷积神经网络提取抽象词语的序列特征,并用于情感极性分类。该文提出的相关方法在中文倾向性分析评测COAE2014数据集上取得了比目前主流的卷积神经网络以及朴素贝叶斯支持向量机更好的性能。 ",MESS201506024
基于简介和评论的标签推荐方法研究,褚晓敏:21810477|王中卿:23843509|朱巧明:05968617|周国栋:13898054,6,自然语言处理; 社会标签; 社会关系网络; 分类器融合;,"Web 2.0时代,社会标签是信息资源组织的一种重要方式。标签推荐能够有效的帮助用户收集、定位、查找和共享在线资源。以往的标签推荐算法只是基于一种文本信息,比如基于电影的简介文本来进行标签推荐。但是实际上电影往往存在多种文本信息,比如同时存在摘要信息和评论信息,不同类型的信息能够反映电影的不同方面的属性,因此为了提高电影标签推荐的准确率和有效性,我们同时根据电影的简介和短评进行电影标签自动推荐,并使用多种方法融合基于不同类型文本的标签推荐的结果,实验证明,使用不同类型信息进行标签推荐能够比单一使用一种文本信息进行标签推荐有很大的提升。 ",MESS201506025
基于词项共现关系图模型的中文观点句识别研究,王明文:08472511|付翠琴:34172616|徐凡:31367729|洪欢:29895355,8,词项共现; 图模型; 观点句识别; 特征值; 有监督学习;,"不同于传统的词项间强独立性假设的词袋模型驱动的观点句识别方法,该文提出了一种新型的基于词项共现关系的图模型方法。该方法通过构建词项共现关系图模型,利用词项与词项之间的共现性和句法关系来描述词项在观点句和非观点句集合中的分布差异,同时采用基于入度的词项权重计算方法来计算词项特征值。上述研究在基准语料上进行实验,实验表明采用基于词项关系图模型方法后,中文观点句识别准确率相比目前基于词袋的方法得到显著提升。 ",MESS201506026
基于评论挖掘的药物副作用发现机制,赵明珍:33405430|程亮喜:33090565|林鸿飞:06504899,10,药物副作用; 用户评论; 文本挖掘; 实体标准化;,"从医疗社交网站的用户评论中挖掘药物副作用时,由于人们可能采用不同的表述方式来描述副作用,而新药的上市与用药者的差异性也会造成新的副作用出现,因此从评论中识别新的副作用名称并进行标准化十分重要。该文利用条件随机场模型识别评论中的副作用,对识别出的副作用名称进行标准化,最后得到药物的副作用。通过将挖掘出的药物已知的副作用与数据库记录进行对比验证了本文方法的有效性,同时得到一个按评论中的发生频率排序的药物潜在副作用列表。实验结果显示,条件随机场模型可以识别出已知的与新的副作用名称,而标准化技术将副作用名称进行聚合与归并,有利于药物副作用的发现。 ",MESS201506027
TIP-LAS:一个开源的藏文分词词性标注系统,李亚超:27243481|江静:28750005|加羊吉:24688520|于洪志:09120080,5,藏文; 分词; 词性标注; 条件随机场; 最大熵;,"TIP-LAS是一个开源的藏文分词词性标注系统,提供藏文分词、词性标注功能。该系统基于条件随机场模型实现基于音节标注的藏文分词系统,采用最大熵模型,并融合音节特征,实现藏文词性标注系统。经过试验及对比分析,藏文分词系统和词性标注系统取得了较好的实验效果,系统的源代码可以从网上获取。希望该研究可以推动藏文分词、词性标注等基础工作的发展,提供一个可以比较、共享的研究平台。 ",MESS201506028
基于形态分析的现代维吾尔语名词词干识别研究,"艾孜尔古丽1,2:26177339|阿力木·木拉提1,2:31172267|玉素甫·艾白都拉1:22251454",5,现代维吾尔语; 形态分析; 名词词干识别;,"现代维吾尔语名词词干识别是自然语言处理领域的重要基础性研究,主要目的是从句子中提取名词词干,提高名词识别效率。首先陈述形态分析概念,通过这些形态特征可以准确地识别其词性的意义;其次讨论维吾尔语的词类划分标准、名词的形态特征分析,总结词缀歧义及消解规则;该文提出研究总体思路,设计现代维吾尔语新词中名词识别算法,其中包括特征选择及参数估计、词内部特征、前后依存词特征等;最后将初中、高中物理维吾尔语教材作为验证对象,对名词词干进行统计与分析。 ",MESS201506029
基于知识融合的CRFs藏文分词系统,洛桑嘎登1:34260763|杨媛媛2:33300830|赵小兵3:22390615,7,藏文; 分词; 条件随机场; 知识融合;,"藏文分词问题是藏文自然语言处理的基本问题之一,该文首先通过对35.1M的藏文语料进行标注之后,通过条件随机场模型对其进行训练,生成模型参数,再用模版对未分词的语料进行分词,针对基于条件随机场分词结果中存在的非藏文字符切分错误,藏文黏着词识别错误,停用词切分错误,未登录词切分错误等问题分别总结了规则,并对分词的结果利用规则进行再加工,得到最终的分词结果,开放实验表明该系统的正确率96.11%,召回率96.03%,F值96.06%。 ",MESS201506030
基于SVM和泛化模板协作的藏语人物属性抽取,"朱臻1,2:34418961|孙媛1,2:31992289",8,人物属性抽取; 藏语语言处理; SVM; 层次分类器;,"该文提出了一种基于SVM和泛化模板协作的藏语人物属性抽取方法。该方法首先构建了基于藏语语言规则的模板系统,收集了包括格助词、特殊动词等具有明显语义信息的特征建设模板并泛化。针对规则方法的局限性,该文在模板的基础上,采用SVM机器学习方法,设计了一种处理多分类问题的层次分类器结构,同时对多样化的特征选取给予说明。最后,实验结果表明,基于SVM和模板相结合的方式可以对人物属性抽取的性能有较大提高。 ",MESS201506031
欢迎订阅《中文信息学报》,,1, ,"<正>《中文信息学报》(Journal of Chinese Information Processing)是全国一级学会——社团法人中国中文信息学会和中国科学院软件研究所联合主办的学术性刊物,创刊于1986年10月,现为双月刊。2007年改版为大16开,每期126页,由商务印书馆出版,成为商务印书馆期刊方阵中的期刊之一,清华大学印刷厂印刷。《中文信息学报》是我国计算机、计算技术类83 ",MESS201506004
中文信息学报(双月刊)2015年第29卷总目次,,14, , ,MESS201506032
“2016中青年语言学者沙龙”在商务印书馆召开《语言战略研究》创刊号首发,,1, ,"<正>2016年1月17日,由中国社会科学院语言研究所、北京语言大学、商务印书馆联合主办的""2016中青年语言学者沙龙""暨《语言战略研究》创刊号首发式在商务印书馆召开,沙龙议题为""""一带一路""的语言问题""。 ",MESS201506033
“X什么”类否定义构式探析,夏雪:28255848|詹卫东:06264050,8,构式; 否定义; 什么;,"该文区分了""言语行为否定""和""命题真值否定""两类否定义:前者表达对某种行为状态的否定态度(谴责、拒绝、禁止等);后者否定某个命题:或者否定命题的""真值条件""、或者否定命题的""适宜条件""、或者否定命题主目的""典型条件"",表达""X未达某标准""。此外,进一步对两类否定义的基本要素及要素间的关系进行分析,讨论了表达每一类语义的""X什么""类构式的变项选择限制与实际使用情况,并总结了""X什么""类构式间的异同。 ",MESS201505001
名词词义描写和研究需要什么样的语义学知识?,李强:06258022|袁毓林:06263991,11,词汇语义学理论; 生成词库理论; 物性结构; 名词分析; 自然语言处理;,"该文主要讨论名词的词义描写和研究问题。首先通过对几种主要的词汇语义学理论(包括结构主义语义学、生成主义语义学、概念语义学和自然语义元语言理论)进行介绍和评述,指出它们在对名词进行语义刻画方面存在缺陷和不足;然后,重点引入生成词库理论的物性结构的描写方式,阐明它与前几种理论的区别及其自身的特点;最后,在生成词库理论的基础上,展示物性结构知识在有关名词分析中的四个研究案例(词语缺省、隐喻义生成、供用句、中动句)和在自然语言处理中的可能应用。 ",MESS201505002
用语图分析揭示语言系统中的隐性规律——赢家通吃和赢多输少算法,陈振宁1:33574265|陈振宇2:06703030,11,隐性规律; 图论; 博弈论; 规则挖掘;,"该文用""图""这一数学工具,通过定量分析来揭示语言系统中的隐性规律,设计了""赢家通吃""和""赢多输少""两种生成算法,将理想算法""步步竞争、择优而行""的博弈论思路贯彻到非理想状态。两种新算法都较前人有更好的概括能力。赢多输少算法更兼顾了充分概括和适度概括均衡。生成语图后,该设计着重准确率的最小简图和着重覆盖率的最大简图归纳算法,挖掘控制的主流规则、分析语言系统的语言学规律。在最小简图基础上提出控制度公式以评价语言系统。 ",MESS201505003
花园幽径模式行进错位的量化研究:计算语言学视角,"杜家利1,2:29594142|于屏方3:06841098",9,计算语言学; 花园幽径模式; 行进错位; 局部歧义; 困惑商;,"该文讨论了花园幽径模式行进错位过程中的困惑商指数。非对称性信息断层的存在导致解码呈现否定之否定的螺旋上升态势。行进错位的潜在效应幅度可通过困惑商指数得到测定。基于大数据语料库统计方法和在线剖析器分析方法,我们测算出优选结构困惑商指数介于(-∞,1];非优选结构困惑商指数介于[1,2];两结构临界值分别为0.72和1.28;歧义域为[0.72,1.28]。结论认为,多结构频数差异是导致困惑商指数变化的根本;行进错位的幅度和非对称性信息补偿的强度均与困惑商指数相关;基于统计的困惑商指数可对局部歧义的复杂句结构提供前瞻性解码信息。 ",MESS201505004
基于聋人案例的空间隐喻语义认知计算,"姚登峰1,2,3:32210942|江铭虎1,2:08821580|阿布都克力木·阿布力孜1,2:34071683|侯仁魁1,4:34071684|哈里旦木·阿布都克里木5:34071685",10,空间隐喻; 语义计算; 聋人;,"我们从心理语言学的角度,对空间隐喻进行相似性分类和计算,使用多维量表和聚类方法,以聋人为被试分别进行了两个实验。实验结果表明,聋人为实现空间隐喻理解的计算,使用了地形空间和语法空间的特征信息,同时受手语语言特点的影响,其空间隐喻的认知主题包括手势者自身参照系、参照物的相对坐标系、手势空间的饱和度、以手部或胸部为边界。同时表明由于两种空间的存在,聋人大脑对空间隐喻的理解存在着层次,并且在长期使用手语交流的过程中,其地形空间和语法空间相互作用,影响了聋人大脑空间隐喻的结构和表征,从而导致了独特的高效快速空间隐喻计算。 ",MESS201505005
基于感知器的中文分词增量训练方法研究,韩冰:06992385|刘一佳:29475623|车万翔:06987220|刘挺:06994824,6,中文分词; 领域适应; 增量训练;,"该文提出了一种基于感知器的中文分词增量训练方法。该方法可在训练好的模型基础上添加目标领域标注数据继续训练,解决了大规模切分数据难于共享,源领域与目标领域数据混合需要重新训练等问题。实验表明,增量训练可以有效提升领域适应性,达到与传统数据混合相类似的效果。同时该文方法模型占用空间小,训练时间短,可以快速训练获得目标领域的模型。 ",MESS201505006
基于Active Learning的中文分词领域自适应,许华婷:33535037|张玉洁:10874141|杨晓晖:11090715|单华:34071686|徐金安:25200603|陈钰枫:33219873,8,中文分词; 领域自适应; 主动学习;,"在新闻领域标注语料上训练的中文分词系统在跨领域时性能会有明显下降。针对目标领域的大规模标注语料难以获取的问题,该文提出Active learning算法与n-gram统计特征相结合的领域自适应方法。该方法通过对目标领域文本与已有标注语料的差异进行统计分析,选择含有最多未标记过的语言现象的小规模语料优先进行人工标注,然后再结合大规模文本中的n-gram统计特征训练目标领域的分词系统。该文采用了CRF训练模型,并在100万句的科技文献领域上,验证了所提方法的有效性,评测数据为人工标注的300句科技文献语料。实验结果显示,在科技文献测试语料上,基于Active Learning训练的分词系统在各项评测指标上均有提高。 ",MESS201505007
面向普通未登录词理解的二字词语义构词研究,"吉志薇1,2:32384520|冯敏萱1:08753478",7,二字词; 普通未登录词; 语义构词;,"把词素作为基本资源,从语义上寻找他们组合成词的规律,可以辅助自然语言理解。该文首先参照《现代汉语词典》和知网标注了二字词的词素意义,继而从意合结构、意根分布、意指方式、意变类型四个角度标注了词素间的词化意义,最后综合词素意义和词化意义,在定量统计的基础上建立了一个二字词的语义描写体系。通过对论坛及《现代汉语词典》的新词进行实验,我们发现二字词的语义构词研究在普通未登录词的理解中具有一定的应用价值。 ",MESS201505008
多领域中文依存树库构建与影响统计句法分析因素之分析,邱立坤1:28907681|史林林1:34071687|王厚峰2:06274413,7,依存树库; 领域迁移; 依存句法分析;,"为提升依存分析并分析影响其精度的相关因素,该文构建了大规模中文通用依存树库和中等规模领域依存树库。基于这一系列树库,通过句法分析实验考察质量、规模、领域差异等因素对中文依存分析的影响,实验结果表明:(1)树库规模和质量均与句法分析精度成正相关关系,质量应先于规模因素被优先考虑;(2)通用树库和领域树库之间的差异程度与前者对后者的替代性成相关关系;(3)两种树库混合使用的效果同样与领域差异有关。 ",MESS201505009
基于word2vec的大中华区词对齐库的构建,王明文:08472511|徐雄飞:32990357|徐凡:31367729|李茂西:29475622,8,大中华区; 词对齐; 最长公共子序列; word2vec;,"该文针对大陆、香港和台湾地区(简称大中华区)存在同一种语义但采用不同词语进行表达的语言现象进行分析。首先,我们抓取了维基百科以及简繁体新闻网站上的3 200 000万组大中华区平行句对,手工标注了一致性程度达到95%以上的10 000组大中华区平行词对齐语料库。同时,我们提出了一个基于word2vec的两阶段大中华区词对齐模型,该模型采用word2vec获取大中华区词语的向量表示形式,并融合了有效的余弦相似度计算方法以及后处理技术。实验结果表明我们提出的大中华区词对齐模型在以上两种不同文体的词对齐语料库上的F1值显著优于现有的GIZA++和基于HMM的基准模型。此外,我们在维基百科上利用该词对齐模型进一步生成了90 029组准确率达82.66%的大中华区词语三元组。 ",MESS201505010
基于单语语料的面向日语假名的日汉人名翻译对抽取方法,王东明:34071688|徐金安:25200603|陈钰枫:33219873|张玉洁:10874141,7,机器翻译; 命名实体; 日语假名; 归纳学习法; 音译;,"命名实体的翻译等价对在跨语言信息处理中非常重要。传统抽取方法通常使用平行语料库或可比语料库,此类方法受到语料库资源的质量和规模的限制。在日汉翻译领域,一方面,双语资源相对匮乏;另一方面,对于汉字命名实体,通常使用汉字对照表;对于日语纯假名的命名实体,通常采用统计翻译模型,此类方法受到平行语料库的质量和规模的限制,且精度低下。针对此问题,该文提出了一种基于单语语料的面向日语假名的日汉人名翻译对自动抽取方法。该方法首先使用条件随机场模型,分别从日语和汉语语料库中抽取日语和汉语人名;然后,采用基于实例的归纳学习法自动获取人名实体的日汉音译规则库,并通过反馈学习来迭代重构音译规则库。使用音译规则库计算日汉人名实体之间的相似度,给定阈值判定人名实体翻译等价对。实验结果表明,提出的方法简单高效,在实现系统高精度的同时,克服了传统方法对双语资源的依赖性。 ",MESS201505011
中文维基百科的实体分类研究,"徐志浩1,2:34071689|惠浩添1,2:32503669|钱龙华1,2:08844995|朱巧明1,2:09891804",8,维基百科; 实体分类; 半结构化信息; 信息框;,"维基百科实体分类对自然语言处理和机器学习具有重要的作用。该文采用机器学习的方法对中文维基百科的条目进行实体分类,在利用维基百科页面中半结构化信息和无结构化文本作为基本特征的基础上,结合中文的特点使用扩展特征和语义特征来提高实体分类性能。在人工标注的语料库上的实验表明,这些额外特征有效地提高了ACE分类体系上的实体分类性能,总体F1值达到96%,同时在扩展实体分类上也取得了较好的效果,总体F1值达95%。 ",MESS201505012
话题内相关文本的内容计算,刘冬明1:15080973|杨尔弘2:06429879,6,话题定义; 文本表示; 话题检测; 文本内容计算;,"信息的暴涨给文本处理带来了更多的挑战。话题检测能够把大量的信息以话题为单位有效地组织起来,然而最终用户有可能并不需要涉及某一话题的所有文本,而是仅仅关心该话题的具体内容。在我们根据相关文本智能表达话题内容推送给用户之前,自动从相关文本中挑选符合用户需求的文本是一个非常有意义的工作。本文致力于相同话题文本之间的内容比较,目的是有效地选出满足需求的文本。我们通过对话题进行重新定义,并根据此定义设定了话题和文本的表示方法,给出了基于该表示方法的话题和文本之间的内容比较计算方法。最后,通过实验说明了这一系列方法的有效性。 ",MESS201505013
一种改进的社交媒体文本规范化方法,宋亚军1:34071690|于中华1:08759534|陈黎1:09785238|丁革建2:09420917|罗谦3:26044077,8,社交媒体; 文本规范化; 自然语言处理; 词嵌入;,"社交媒体具有文本不规范的特点,现有自然语言处理工具直接应用于社交媒体文本时效果不甚理想,并且基于关键词的算法和应用也达不到预期效果。因此,研究如何更好地规范化社交媒体文本是非常有意义和价值的。本文基于社交媒体文本中非规范词与其规范形式具有相似上下文的假设,引入词嵌入模型来更好地刻画上下文的相似性,提出了一种改进的基于图的社交媒体文本规范化方法,该方法是无监督并且语言无关的,可以处理不同类型语言的大规模无标注社交媒体文本。实验结果表明,该方法能够改进前人方法的不足,并且在与相关方法的对比实验中取得了最好的F值。 ",MESS201505015
高斯加权的重构性K-NN算法研究,刘作国:34071691|陈笑蓉:06939837,5,文本聚类; K-NN算法; 高斯加权; 近邻域规则; 聚类重构;,"该文提出基于高斯加权距离以及聚类重构机制的K-NN文本聚类算法。文章提出K-NN近邻域的概念,通过高斯加权的近邻域算法实施K-NN聚类。利用高斯函数根据样本与聚类中心的距离为样本赋权,计算聚类距离。基于近邻域权重和聚类密度对形成的聚类实施重构,实现聚类数目的自适应调整。使用拆分算子拆分稀疏聚类并调整异常样本;使用合并算子合并相似聚类。实验显示聚类重构机制能够有效地提高聚类的准确率及召回率,增加聚类密度,使得形成的聚类结果更加合理。 ",MESS201505016
基于多源知识和Ranking SVM的中文微博命名实体链接,陈万礼:34071692|昝红英:09467924|吴泳钢:33384081,8,命名实体; 中文微博实体链接; 同义词词典; 百科资源; Ranking SVM; 语义特征;,"命名实体是文本中承载信息的重要单元,正确分析存在歧义的命名实体对文本的理解起着关键性作用。该文提出基于多源知识和Ranking SVM的中文微博命名实体链接,结合同义词词典、百科资源等知识产生初始候选实体集合,同时从文本中抽取多种组合特征,利用Ranking SVM对候选实体集合进行排序,从而得到目标实体。在NLP&CC20141中文微博实体链接评测数据集上进行了实验,获得了89.40%的平均准确率,与NLP&CC2014中文微博实体链接评测取得最好成绩的系统相比,本文的系统具有一定的优势。 ",MESS201505017
面向篇章机器翻译的英汉翻译单位和翻译模型研究,宋柔:34071693|葛诗利:24597890,11,翻译单位; 翻译模型; 广义话题结构; naming-telling小句;,"篇章机器翻译的首要问题是确定翻译单位。基于汉语和英语的语言知识和英汉翻译的实践,该文提出面向篇章机器翻译的基本单位和复合单位的双层单位体系,讨论了这两种单位支持篇章翻译应满足的性质,并据此勾画了篇章机器翻译的拆分、翻译、装配三步模型(PTA模型)。该文提出,汉语篇章机器翻译的复合单位为广义话题结构对应的文本块,基本单位则是根据广义话题结构流水模型得到的话题自足句;英语篇章机器翻译的复合单位为句号句,基本单位为naming-telling小句(NT小句),即指称性成分加上对它的陈述或后修饰成分所构成的小句。该文展示了在这样的翻译单位体系下采用PTA模型的英汉翻译过程实例,规划了面向篇章翻译的英汉小句对齐语料库的建设任务,讨论了PTA模型的可行性。 ",MESS201505018
利用Markov网络抽取复述增强机器译文自动评价方法,翁贞:34071694|李茂西:29475622|王明文:08472511,7,复述; 机器译文自动评价; Markov网络; 相关性;,"在机器译文自动评价中,匹配具有相同语义、不同表达方式的词或短语是其中一个很大的挑战。许多研究工作提出从双语平行语料或可比语料中抽取复述来增强机器译文和人工译文的匹配。然而双语平行语料或可比语料不仅构建成本高,而且对少数语言对难以大量获取。我们提出通过构建词的Markov网络,从目标语言的单语文本中抽取复述的方法,并利用该复述提高机器译文自动评价方法与人工评价方法的相关性。在WMT14 Metrics task上的实验结果表明,我们从单语文本中提取复述方法的性能与从双语平行语料中提取复述方法的性能具有很强的可比性。因此,该文提出的方法可在保证复述质量的同时,降低复述抽取的成本。 ",MESS201505019
面向主题的微博热门话题舆情监测研究——以“北京单双号限行常态化”舆情分析为例,张瑜:06634351|李兵:06624762|刘晨玥:30213450,10,舆情监测; 短文本情感分析; 朴素贝叶斯;,"社交媒体舆情监测是社交媒体分析的热点研究问题,学界和工业界取得了很多研究成果。但目前针对热门话题舆情监测研究中,往往只在整体上关注事件舆情趋势,而没有对事件内部不同的讨论主题进行分析。鉴于此,该研究将主题分类模型引入到舆情监测中来,并在此基础上,以时间为脉络进行面向主题的情感分析。并以""北京市单双号限行常态化""这一微博话题为例进行实证研究,通过各个时段""北京市单双号限行常态化""这一微博话题群体情感倾向变化的分析,为舆情的监测提供对象和时点选择的参考建议。 ",MESS201505020
基于极性转移和LSTM递归网络的情感分析,梁军1:31758529|柴玉梅1:09463011|原慧斌2:25270833|高明磊1:26446513|昝红英1:09467924,8,LSTM; 递归神经网络; 情感分析;,"长短时记忆(long short term memory,LSTM)是一种有效的链式循环神经网络(recurrent neural network,R2 NN1),被广泛用于语言模型、机器翻译、语音识别等领域。但由于该网络结构是一种链式结构,不能有效表征语言的结构层次信息,该文将LSTM扩展到基于树结构的递归神经网络(Recursive Neural Network,RNN)上,用于捕获文本更深层次的语义语法信息,并根据句子前后词语间的关联性引入情感极性转移模型。实验证明本文提出的模型优于LSTM、递归神经网络等。 ",MESS201505021
基于模糊推理机的汉语主观句识别,宋洪伟:32278878|宋佳颖:34071695|付国宏:22432184,8,主观句识别; 模糊集合; 模糊IF-THEN规则; 模糊推理机;,"该文提出一种基于词汇模糊集合的模糊推理机以识别汉语主观句。首先,根据主、客观词概念的模糊性,我们定义了两个相应的模糊集合,并在模糊统计方法下,利用TF-IDF从训练语料中获取隶属度函数。然后制定了两个模糊IF-THEN规则,并据此实现了一个模糊推理机以识别汉语主观句。NTCIR-6中文数据上的实验结果表明我们的方法具有一定的可行性。 ",MESS201505022
基于聚类和分类的金庸与古龙小说风格分析,肖天久:31474727|刘颖:08230768,11,计算风格学; N元文法; 聚类; 分类; 句子破碎度;,"该文以金庸与古龙的小说作为语料,从计算风格学的角度考察二人的风格差异。对比了两人小说的文本从众性、句子破碎度,同时,使用文本聚类的方法对词和词类的N元文法,标点符号的N元文法以及多种特征的总体情况进行了考察,还使用主成分分析和文本分类对八种特征从总体上进行了比较,结果证实金庸与古龙小说风格存在较大差异:金庸小说从众性大于古龙,较多使用俚语方言,口语性更强,同时在语法结构、短语结构、文本节奏以及文本可读性和语言变化程度上也有较大的差异。 ",MESS201505023
利用词的分布式表示改进作文跑题检测,"陈志鹏1,2:34071696|陈文亮1,2:33224970|朱慕华3:34071699",8,文本相似度; 词分布式表示; 跑题检测; 文本表示;,"作文跑题检测任务的核心问题是文本相似度计算。传统的文本相似度计算方法一般基于向量空间模型,即把文本表示成高维向量,再计算文本之间的相似度。这种方法只考虑文本中出现的词项(词袋模型),而没有利用词项的语义信息。该文提出一种新的文本相似度计算方法:基于词扩展的文本相似度计算方法,将词袋模型(Bag-of-Words)方法与词的分布式表示相结合,在词的分布式表示向量空间中寻找与文本出现的词项语义上相似的词加入到文本表示中,实现文本中单词的扩展。然后对扩展后的文本计算相似度。该文将这种方法运用到英文作文的跑题检测中,构建一套跑题检测系统,并在一个真实数据中进行测试。实验结果表明该文的跑题检测系统能有效识别跑题作文,性能明显高于基准系统。 ",MESS201505024
《红楼梦》中社会权势关系的提取及网络构建,"陈蕾1:21994280|胡亦旻1:34071700|艾苇1:34071701|胡俊峰1,2:06243608",10,关系提取; 权势关系; 社会关系网络; 最小树形图;,"社会地位与权势的研究一直是社会语言学领域的一个热点话题。该文借助数据挖掘中的关系提取方案雪球算法(Snowball Algorithm),实现了《红楼梦》文本中候选的特征语言模式(pattern)和人物关系对之间的相互定位与赋权,对小说中频繁同现的人物对之间的社会等级关系进行挖掘,以此建立了能反映人物等级关系的有向加权人际关系网络。进一步应用最小树形图算法,生成了涵盖192个《红楼梦》主要人物的单向联通的树状社会关系图。通过这种方法生成的社会关系图不但能有效反映人际交往亲密度与社区影响力,同时还透视了人与人之间的社会等级差异。相较于单纯基于人际交往亲密程度的无向关系网络,能更加客观地表达出社会交往中人际关系网络的真实图景。 ",MESS201505025
限定领域口语对话系统中超出领域话语的协处理方法,王俊东:34071702|黄沛杰:24966316|林仙茂:30821747|徐禹洪:34071703|李凯茵:34071704,10,超出领域话语; 协处理; AIML; 有限状态自动机; 口语对话系统;,"领域外话语的开放性、口语化以及表达多样性,使得现有的限定领域口语对话系统不能很好地处理超出领域话语。该文提出了一种限定领域口语对话系统协处理方案,基于人工智能标记语言AIML,设计一套理解开放语义用户话语的理解模板,并对未匹配话语基于话语相似度进行理解模板分类,进而采用扩展有限状态自动机处理模式,结合对话流程上下文的状态及信息,实现理解模板到应答模板的转换,改变了单纯模板匹配方法在对话流程控制方面的相对缺失。中文手机导购领域的测试表明,该文所提出的协处理方法能有效地辅助口语对话系统完成限定领域完整对话流程,得到更好的用户满意度。 ",MESS201505026
融合多策略的维吾尔语词干提取方法,赛迪亚古丽·艾尼瓦尔1:34071705|向露2:34071706|宗成庆2:10815045|艾克白尔·帕塔尔1:22511430|艾斯卡尔·艾木都拉1:17704444,7,维吾尔语; 形态; 词干提取; N-gram模型; 词性特征; 上下文词干信息;,"维吾尔语是形态变化复杂的黏着性语言,维吾尔语词干词缀切分对维吾尔语信息处理具有非常重要的意义,但到目前为止,维吾尔语词干提取的性能仍存在较大的改进空间。该文以N-gram模型为基本框架,根据维吾尔语的构词约束条件,提出了融合词性特征和上下文词干信息的维吾尔语词干提取模型。实验结果表明,词性特征和上下文词干信息可以显著提高维吾尔语词干提取的准确率,与基准系统比较,融入了词性特征和上下文词干信息的实验准确率分别达到了95.19%和96.60%。 ",MESS201505027
基于藏语字性标注的词性预测研究,"龙从军1,2:31758532|刘汇丹1:09573793|诺明花1:15570459|吴健1:09573880",5,藏语; 语字标注; 分词; 词性标注;,"该文选取了藏语文中小学教材的部分语料,构建了带有藏语字性标记、词边界标记和词性标记的语料库,通过比较不同的分词、标注方法,证明分词、词性标注一体化效果比分步进行的效果好,准确率、召回率和F值分别提高了0.067、0.073和0.07。但词级标注模型难以解决词边界划分的一致性和未登录词的问题。基于此,作者提出可以利用字性和字构词的规律预测合成词的词性,既可以融入语言学知识又可以减少由未登录词导致的标注错误,实验结果证明,作为词性标注的后处理模块,基于字性标注的词性预测准确率提高到了0.916,这个结果已经比分词标注一体化结果好,说明字性标注对纠正词性错误标注有明显的效果。 ",MESS201505028
中国手语信息处理述评,"姚登峰1,2,3:32210942|江铭虎1,2:08821580|阿布都克力木·阿布力孜1,2:34071683|李晗静3:31844220|哈里旦木·阿布都克里木4:34071685|夏娣娜5:34071707",12,中国手语; 信息处理; 书写系统;,"为了能够有效地对中国手语进行信息处理,需要针对中国手语的特性提出相应的信息处理方案。该文根据国内外的研究进展情况,从基于规则和基于语料库的角度,讨论了中国手语信息处理过程中遇到的有关问题,并提出可借鉴的中国手语信息处理技术,同时从中国手语自身的词法、句法出发,参考国外手语语言学的最新研究成果,讨论了中国手语信息处理中有关信息表征、理解、生成等问题。最后指出未来手语的信息处理将会更多地建立在跨学科、多模式的基础之上,该项研究将有力地促进信息无障碍技术的发展。 ",MESS201505029
第十四届全国计算语言学会议在广东外语外贸大学成功召开,,1, ,"<正>""中国中文信息学会2015年学术年会暨第十四届全国计算语言学会议""与""第三届基于自然标注大数据的自然语言处理国际学术研讨会""于2015年11月13—14日在广东外语外贸大学成功举行。会议主办单位为中国中文信息学会,组织单位为清华大学智能技术与系统国家重点实验室,承办单位为广东外语外贸大学。中国中文信息学会理事长李生教授和广东外语外贸大学校长仲伟合教授在开幕式上致辞,中国中文信息学会副理事长清华大学孙茂松教授、中国中文信息学会副理事长北京理工大学黄河燕教授 ",MESS201505014
欢迎订阅《中文信息学报》,,1, ,"<正>《中文信息学报》(Journal of Chinese Information Processing)是全国一级学会——社团法人中国中文信息学会和中国科学院软件研究所联合主办的学术性刊物,创刊于1986年10月,现为双月刊。2007年改版为大16开,每期126页,由商务印书馆出版,成为商务印书馆期刊方阵中的期刊之一,清华大学印刷厂印刷。《中文信息学报》是我国计算机、计算技术类83 ",MESS201505030
商务印书馆新近推出《汉字构形学导论》,,1, ,"<正>""汉字构形学导论""旨在为汉字创建科学的基础理论《汉字构形学导论》王宁著ISBN:978-7-100-11090-7定价:29.00元本书吸收了系统科学的方法,对传统""六书""的精神重新阐发,在汉字表意特性和汉字构形系统这两个基本原则的基础上,提出了适用于古今各种体制的汉字结构分析、系统描写的普遍原理和可操作的方法,自汉字存在和发展的诸多现象 ",MESS201505031
多策略机器翻译研究综述,"李业刚1,2:26776335|黄河燕1:23136252|史树敏1:24549646|冯冲1:24549647|苏超1:31109924",10,机器翻译; 多策略机器翻译; 融合机器翻译; 混合机器翻译; 多引擎机器翻译;,"该文全面综述和分析了多策略机器翻译的研究。根据所采用策略方式的差异,我们将多策略机器翻译分为系统级策略融合和模块级策略融合。在分别介绍了不同的翻译方法后,着重介绍了系统级策略融合和模块级策略融合各自具有代表性的研究工作。最后,对多策略机器翻译的研究进行了展望。 ",MESS201502001
微博检索的研究进展,"卫冰洁1,2:29695125|王斌3:33053079|张帅1:17749287|李鹏3:33053080",14,微博检索; 时间信息; 微博特性; 文本表示; 文档先验; 查询扩展;,"随着微博的快速发展,微博检索已经成为近年来研究领域的热点之一。该文首先以TREC Microblog数据为基础,从分析微博文档和微博查询两方面出发,得出微博检索与传统文本检索之间的两点不同:一是微博文档相较于网页具有很多独有的特征;二是微博查询属于时间敏感查询,即在排序时除了考虑文本的语义相似度,还需要考虑时间因素,将这类方法统称为时间感知的检索技术。这两点差异使得已有的信息检索技术不能满足微博搜索的需求。该文主要介绍了近年来这两方面的相关研究:首先描述了微博本身的多种特征以及基于这些特征提出的检索方法;然后以传统信息检索过程为主线,分别介绍了将时间信息用于文本表示、文档先验、查询扩展三方面的排序模型,最后总结了已有工作并且对未来研究内容进行了展望。 ",MESS201502002
倒排索引中的文档序号重排技术综述,史亮1:33053081|张鸿1:10630029|刘欣然1:10628857|王勇1:15547529|王斌2:33053079,9,搜索引擎; 性能优化; 索引压缩; 文档序号重排; 局部连续性;,"倒排索引作为文本搜索的核心索引技术,广泛应用于搜索引擎、桌面搜索和数字图书馆领域。倒排索引由字典和对应的倒排表组成,倒排表一般采用差值存储和整数编码进行压缩。研究表明,当倒排表具有较好的局部连续性时,上述方法能够获得很高的压缩率。整数编码研究通过不断改进编码算法来充分利用倒排表的局部连续性特征,而文档序号重排正是一种对文档序号重新排列来产生局部连续性的技术。通过文档序号重排,索引压缩率得到显著提高。该文主要介绍近年来文档序号重排技术取得的研究成果:首先介绍索引压缩的基本原理,然后详细介绍文档序号重排技术,包括分析、对比各个方法的优劣;最后对文档序号重排技术进行总结、整理和展望。 ",MESS201502003
向上学习方法改进移进-归约中文句法分析,朱慕华:06581713|王会珍:06579162|朱靖波:06569435,7,中文句法分析; 移进-归约分析; 伯克利句法分析器; 向上学习; 无标注数据;,"基于移进-归约的句法分析系统具有线性的时间复杂度,因此在大规模句法分析任务中具有特别实际的意义。然而目前移进-归约句法分析系统的性能远低于领域内最好的句法分析器,例如,伯克利句法分析器。该文研究如何利用向上学习和无标注数据改进移进-归约句法分析系统,使之尽可能接近伯克利句法分析器的性能。我们首先应用伯克利句法分析器对大规模的无标注数据进行自动分析,然后利用得到的自动标注数据作为额外的训练数据改进词性标注系统和移进-归约句法分析器。实验结果表明,向上学习方法和无标注数据使移进-归约句法分析的性能提高了2.3%,达到82.4%。这个性能与伯克利句法分析器的性能可比。与此同时,该文最终得到的句法分析系统拥有明显的速度优势(7倍速度于伯克利句法分析器)。 ",MESS201502004
基于归约的汉语最长名词短语识别方法,钱小飞1:26162463|侯敏2:10316023,9,最长名词短语; 识别; 归约; 基本名词短语;,"该文提出了最长名词短语(MNP)的操作性定义,分析了其构造和分布特征,并设计了一种基于baseNP归约的识别方法,利用MNP结构特性及起始有定成分、语义核心等语言学特征,缓解了最长名词短语长距离依赖与模型观察窗口受限的矛盾。开放测试取得了88.68%的正确率和89.21%的召回率;归约方法全面提升了识别性能,特别是将多词结构的调和平均值提高1%,优化幅度达6%以上,并且对长距离复杂结构有着更好的识别效果。 ",MESS201502005
基于有监督学习的医古文叙述性术语语义标注,丁长林:27511493|白宇:24679275|蔡东风:24679274,9,语义标注; 叙述性术语; 有监督学习; 中医古籍文献;,"对自由文本形式的中医古籍文献(医古文)进行标注,是对其进行深入分析的前提,语义标注技术是实现该目的的方法之一。该文将中医古籍文献中包含的术语分为名称性术语以及叙述性术语。在分析叙述性术语特点的基础上,将对其语义标注转化为基于有监督学习的短句序列标注或分类问题,并提出了名词性术语规约操作以及基于知网的替换操作两种预处理方法。最后该文通过实验对比了三种学习模型及四种特征选择算法,并证明了问题转化的可行性以及两种预处理方法的有效性。 ",MESS201502006
一种基于图模型的维基概念相似度计算方法及其在实体链接系统中的应用,张涛:13621938|刘康:13898613|赵军:10891784,10,实体消歧; 实体链接; 语义相似度计算; 排序学习; 随机游走;,"实体链接是指将文本中具有歧义的实体指称项链接到知识库中相应实体的过程。该文首先对实体链接系统进行了分析,指出实体链接系统中的核心问题—实体指称项文本与候选实体之间的语义相似度计算。接着提出了一种基于图模型的维基概念相似度计算方法,并将该相似度计算方法应用在实体指称项文本与候选实体语义相似度的计算中。在此基础上,设计了一个基于排序学习算法框架的实体链接系统。实验结果表明,相比于传统的计算方法,新的相似度计算方法可以更加有效地捕捉实体指称项文本与候选实体间的语义相似度。同时,融入了多种特征的实体链接系统在性能上获得了达到state-of-art的水平。 ",MESS201502008
强语义模糊性词语的情感分析,"张志飞1,2:10097252|苗夺谦1:08963093|岳晓冬3:29114451|聂建云2:07985895",11,情感分析; 语义模糊性; 粗糙集; 贝叶斯分类;,"语义的模糊性给词语的情感分析带来了挑战。有些情感词语不仅使用频率高,而且语义模糊性强。如何消除语义模糊性成为词语情感分析中亟待解决的问题。该文提出了一种规则和统计相结合的框架来分析具有强语义模糊性词语的情感倾向。该框架根据词语的相邻信息获取有效的特征,利用粗糙集的属性约简方法生成决策规则,对于规则无法识别的情况,再利用贝叶斯分类器消除语义模糊性。该文以强语义模糊性词语""好""为例,对提出的框架在多个语料上进行实验,结果表明该框架可以有效消除""好""的语义模糊性以改进情感分析的效果。 ",MESS201502009
基于MapReduce的并行PLSA算法及在文本挖掘中的应用,"李宁1,2,3:21842738|罗文娟1:26496184|庄福振1:22522851|何清1:09596209|史忠植1:05966545",8,概率主题模型; MapReduce; 并行; 语义分析;,"PLSA(Probabilistic Latent Semantic Analysis)是一种典型的主题模型。复杂的建模过程使其难以处理海量数据,针对串行PLSA难以处理海量数据的问题,该文提出一种基于MapReduce计算框架的并行PLSA算法,能够以简洁的形式和分布式的方案来解决大规模数据的并行处理问题,并把并行PLSA算法运用到文本聚类和语义分析的文本挖掘应用中。实验结果表明该算法在处理较大数据量时表现出了很好的性能。 ",MESS201502010
统计机器翻译和翻译记忆的动态融合方法研究,汪昆1:29695116|宗成庆1:10815045|苏克毅2:33062710,9,统计机器翻译; 基于短语的翻译模型; 翻译记忆; 模型融合; 动态加入翻译记忆短语对;,"在融合翻译记忆和统计机器翻译的整合式模型的基础上,该文提出在解码过程中进一步地动态加入翻译记忆中新发现的短语对。它在机器翻译解码过程中,动态地加入翻译记忆片段作为候选,并利用翻译记忆的相关信息,指导基于短语的翻译模型进行解码。实验结果表明该方法显著提高了翻译质量:与翻译记忆系统相比,该方法提高了21.15个BLEU值,降低了21.47个TER值;与基于短语的翻译系统相比,该方法提高了5.16个BLEU值,降低了4.05个TER值。 ",MESS201502011
利用句法短语改善统计机器翻译性能,"孙水华1,2:33053082|丁鹏1:25360418|黄德根1:06527360",8,统计机器翻译; EM算法; 双语句法短语;,"短语表是基于短语的统计机器翻译系统的一个核心组成部分,基于启发式方法抽取到的短语表受单词对齐错误和未对齐词的影响严重,同时抽取到的短语也并非句法意义上的短语。该文提出一种基于EM(Expectation-maximization)算法的双语句法短语抽取方法来抽取双语句法短语,此方法可以通过不断迭代的方式使各参数值达到最优。通过加入双语句法短语、增加新特征、重新训练三种不同的方法,将获得的双语句法短语与基于短语的统计机器翻译方法结合以提高统计机器翻译系统的性能。结果表明:三种方法都不同程度提高了译文的BLEU(BiLingual Evaluation Understudy)值,其中增加新特征方法提高了0.64个点。 ",MESS201502012
基于句本位句法体系的古汉语机器翻译研究,韩芳:06362190|杨天心:31524541|宋继华:06364557,9,古汉语; 黎氏语法; 词义消歧; 机器翻译;,"该文通过构建古汉语词典模型,结合黎锦熙先生提出的句本位句法相关规则构造知识库,使用词义消歧算法,对古汉语进行基于规则的机器翻译研究。实验以基于句本位语法进行句法标注后的《论语》作为测试语料,以句子为单位进行机器翻译,通过获取待选义项、构建义项选择模型、调整句法顺序等手段生成翻译结果集,并使用二元语法模型对结果进行优选,得到机器翻译最终结果,最后对翻译结果进行了分析测评。 ",MESS201502013
基于统计专用字符的维、哈、柯文文种识别研究,"买买提依明·哈斯木1,2:24939138|吾守尔·斯拉木1:17705001|维尼拉·木沙江1:17704505|努尔麦麦提·尤鲁瓦斯1:28479964",7,文种识别; 专用字符; 复合字符; 维文; 哈文; 柯文; Unicode;,"在Unicode编码方案中维、哈、柯文字符安排在阿拉伯字符区域,三种语言中共享字符比较多,跟阿拉伯字符区域混在一起,没有专用的语言ID。在信息检索和自然语言处理领域对维、哈、柯文的识别、处理带来不便。该文首先分析并总结了维、哈、柯文三种语言中的专用字符、复合字符、某些字符在某种语言中出现形势的独特性等特征,然后在此基础上设计了维、哈、柯文种识别算法。实验结果表明该文提出的文种识别算法的正确率在文本多于70词时达到96.67%以上。 ",MESS201502014
关于维吾尔语口语语料的三音子选取方法研究,徐宝龙:33053083|努尔麦麦提·尤鲁瓦斯:28479964|吾守尔·斯拉木:17705001,7,维吾尔语; 语音识别; 语料库; 三音子;,"在大词汇量连续语音识别应用中,优质的语音训练语料是所有识别工作的基础和前提,能否挑选出覆盖更多语音现象的语料是提高语音识别性能的关键。该文在多种维吾尔文口语化传播平台中采集了大量口语句子语料,并考虑协同发音的影响和常用词的适用性,根据评估函数对语料筛选。经过筛选后的语料包含的三音子更加均衡和高效,囊括的语音现象更加全面,为训练准确而牢靠的语音模型打下了稳固的根基。 ",MESS201502015
藏文停用词选取与自动处理方法研究,"珠杰1,2:28527554|李天瑞1:10222865",8,藏文停用词; 词频统计; 文档频数; 熵;,"停用词的处理是文本挖掘中一个关键的预处理步骤。该文结合现有停用词的处理技术,研究了基于统计的藏文停用词选取方法,通过实验分析了词项频率、文档频率、熵等方法的藏文停用词选用情况,提出了藏文虚词、特殊动词和自动处理方法相结合的藏文停用词选取方法。实验结果表明,该方法可以确定一个较合理的藏文停用词表。 ",MESS201502016
维吾尔语多词领域术语的自动抽取,田生伟1:09220503|钟军2:26990894|禹龙3:09256058,9,维吾尔语; 多词领域术语; 互信息; 对数似然比率; 相对词频差值;,"多词领域术语抽取是自然语言处理技术中的一个重点和难点问题,结合维吾尔语语言特征,该文提出了一种基于规则和统计相结合的维吾尔语多词领域术语的自动抽取方法。该方法分为四个阶段:1语料预处理,包括停用词过滤和词性标注;2对字串取N元子串,利用改进的互信息算法和对数似然比率计算子串内部的联合强度,结合词性构成规则,构建候选维吾尔语多词领域术语集;3利用相对词频差值,得到尽可能多的维吾尔语多词领域术语;4结合C_value值获取最终领域术语并作后处理。实验结果准确率为85.08%,召回率为73.19%,验证了该文提出的方法在维吾尔语多词领域术语抽取上的有效性。 ",MESS201502017
一种女书手写字符规范字形自动生成方法,李波:09995737|王江晴:10167601|魏红昀:10167627|孙阳光:28602654|王新年:24095457|徐凌:32253794,8,女书; 规范化; 笔段;,"中国女书是具有鲜明民族特色的文字,目前国内还没有公认的女书规范字库。针对手写体文字规范化字体生成过程多采用人工修正方式、效率低下的现状,该文设计了一种女书手写字符规范字自动生成方法。基于手写文字样本,提取其单像素骨架,并结合字符轮廓信息进行骨架畸变点校正;然后提取骨架特征点和笔段,根据笔段连通性和交角情况建立笔段关联矩阵;基于笔段关联矩阵由笔段恢复笔画,获取笔画路径关键点序列;最后基于三次Bezier曲线重绘字符笔画并均匀加粗,形成笔画粗细一致、平滑无毛刺、无畸变的规范字体。实验结果表明,该方法自动便捷,效果良好,效率优于人工方式,经改进后可以推广到其他手写字符的规范化过程。 ",MESS201502018
基于OpenType技术的方块苗文字库研究,莫礼平1:07730189|周恺卿2:28168487|蒋效会1:17328729,7,方块苗文; Unicode标准; 字符编码; OpenType技术; 字库;,"方块苗文是民间苗文的代表,其信息处理研究对于保护民间苗族文化遗产和弘扬苗族文化有着重要意义。字库开发是方块苗文信息处理研究内容的重要部分。根据方块苗文字库开发的实际需要,该文以文字结构分析为基础,提出了基于Unicode标准的方块苗文编码方案设计思想,介绍了方块苗文字符字模制作的基本步骤,并以标签定义、操作符定义和变换规则定义为重点,探讨了基于OpenType技术的方块苗文字库设计和开发的方法。测试结果表明,方块苗文OpenType字库具有文件小、易扩充等优点,能够解决英文、汉字和方块苗文的混排问题。 ",MESS201502019
基于逆向匹配的电子商务网站实体模板半自动构建方法,傅彦:00128534|徐昭邦:33053084|夏虎:22107781|周俊临:06549467,7,逆向匹配; DOM树; 模板构建; 信息提取;,"Web页面中的主题信息一般分布比较集中,可利用网页的这一特性进行网页主题信息的自动提取。网页源代码中的HTML标签不规范,使得正向匹配难以生成嵌套结构准确的DOM树,该文提出一种通过逆向匹配的方法,构建完整的网页源代码DOM树。通过对DOM树进行剪枝,删除无关节点,对保留下来的信息块的节点标签进行人工选择与唯一性判定,从而生成提取模板。该方法能够实现对电子商务网站源网页中的主题信息进行提取,是一种半自动、通用的方法,可用于信息检索系统中的信息采集。 ",MESS201502020
基于文本特征的短文本倾向性分析研究,程南昌1:33062711|侯敏2:10316023|滕永林2:15395593,7,短文本; 文本特征; 归总句; 倾向性分析; 词典与规则;,"语篇倾向性分析是倾向性分析的较高层次领域。根据文本篇幅和结构可以将语篇分为短文本和长文本。该文以网络商品评论作为样本研究短文本倾向性分析的特点和策略。根据倾向极性在文中的决定性因素的不同表现,短文本可以分为含显性归总句、含隐性归总句、含特征词以及一般文本四类,针对不同类别文本采用不同的处理策略。在此基础上,运用词典、规则的方法构建了语篇倾向性分析系统CUCsas,该方法在第四届中文倾向性分析评测(COAE2012)中取得了较好成绩。 ",MESS201502021
基于D-S证据理论的微博客蕴含交通信息提取方法,张恒才:27622616|陆锋:09607498|仇培元:30264955,9,微博客; 交通信息; 文本聚类; 证据理论; 维基百科;,"微博客消息中经常蕴含大量实时交通信息,有望与现有实时交通信息采集方式形成互补。该文针对微博客消息语义模糊性及用户描述差异性问题,提出了一种微博客消息蕴含交通信息的D-S证据理论提取方法。该方法首先构建微博客消息蕴含交通状态信息评价体系,利用百科知识提高评价精度,然后定义微博客消息源的基本概率分配函数,通过证据合成与证据决策,实现微博客消息蕴含实时交通信息的甄别与融合。实验结果表明,该方法能够对微博客消息蕴含实时交通信息的可信度进行有效判断,并能够在最大程度上利用不同微博客用户发布消息的信息内容,且较之传统的文本聚类融合方法具有更高的准确率。 ",MESS201502022
基于上下文的话题演化和话题关系抽取研究,章建:28286295|李芳:09595202,11,话题; 话题上下文; 话题演化; 话题关系;,"自动挖掘大规模语料中的语义信息以及演化关系近年来已受到广大专家学者的关注。话题被认为是文档集合中的潜在语义信息,话题演化用于研究话题内容随时间的变化。该文提出了一种基于上下文的话题演化和话题关系抽取方法。分析发现,一个话题常和某些其他话题共现在多篇文档中,话题间的这种共现信息被称为话题的上下文。上下文信息可以用于计算同时间段话题间的语义关系以及识别不同时间段中具有相同语义的话题。该文对2008年~2012年两会报告以及2007年~2011年NIPS科技文献进行实验,通过人工分析,利用话题的上下文信息,不但可以提高话题演化的正确率,而且还能挖掘话题之间的语义关系,在话题演化的基础上,显示话题关系的演化。 ",MESS201502024
维基百科中翻译对的模板挖掘方法研究,段建勇1:23130482|闫启伟1:31358293|张梅1:22348976|胡熠2:31549598,9,双语翻译对; 维基百科; 模板挖掘; 信息抽取;,"双语翻译对在跨语言信息检索、机器翻译等领域有着重要的用途,尤其是专有名词、新词、俚语和术语等的翻译是影响其系统性能的关键因素,但是这些翻译对很难从现有的词典中获得。该文针对维基百科的领域覆盖率和结构特征,提出了一种从维基百科中自动获取高质量中英文翻译对的模板挖掘方法,不但能有效地挖掘出常见的模板,而且能够发现人工不容易察觉的复杂模板。主要方法包括三步:1)从语言工具栏中直接抽取翻译对,作为进一步挖掘的启发知识;2)在维基百科页面中采用PAT-Array结构挖掘中英翻译对模板;3)利用挖掘的模板在页面中自动挖掘其他中英文翻译对,并进行模板评估。实验结果表明,模板发现翻译对的正确率达90.4%。 ",MESS201502025
槽填充中抽取模式的优化方法,沈晓卫:29482159|李培峰:09886822|朱巧明:09891804,8,槽填充; 模式优化; 信息抽取;,"在传统的信息抽取中,模式匹配已经被证实为简便而有效的方法,而依存路径也是最为常用的模式之一。在槽填充任务中就有众多的参与者引入了以依存路径为基础的模式匹配方法;该文就针对该方法中存在的包括模式平衡性,模式抽取方式和模式筛选策略等方面的问题,提出了模式裁剪、模式转置、模式扩展和模式语义定义等主要的优化方法并实现了相关系统,在TAC-KBP2010的目标语料上进行了测试。该文提出的方法F值为20.8%,比基准系统的14.3%提高了6.5%。 ",MESS201502026
第四届全国社会媒体处理大会(SMP2015),,2, ,"<正>第四届全国社会媒体处理大会(SMP2015)由中国中文信息学会社会媒体处理专委会主办,华南理工大学软件学院和华南理工大学南校区大学城管委会承办。该系列会议每年举办一次,现已成为社会媒体处理的重要学术活动。社会媒体处理大会专注于以社会媒体处理为主题的科学研究与工程开 ",MESS201502007
全国第十四届计算语言学会议(CCL 2015)及第三届基于自然标注大数据的自然语言处理国际学术研讨会(NLP-NABD 2015)联合征稿启事,,3, ,"<正>""第十四届全国计算语言学学术会议""(The Fourteenth China National Conference on Computational Linguistics,CCL 2015)将于2015年11月13日—14日在广东外语外贸大学举行。作为国内最大的自然语言处理专家学者的社团组织——中国中文信息学会(CIPS)的旗舰会议,全国计算语言学会议从1991年开始每两年举办一次,从2013年开 ",MESS201502023
商务印书馆新书介绍,,1, ,"<正>《语言与国家》赵世举主编ISBN 978-7-100-10822-5 45.00元语言强弱系国运语言是硬实力也是软实力本书由国家语言文字工作委员会牵头组织,汇集当今语言生活研究领域的一流学者撰写而成。全书对语言与国家的关系进行了全方位的考察和探讨;对语言在国家生活各个领域的 ",MESS201502027
共指消解研究方法综述,宋洋:06262013|王厚峰:06274413,12,共指消解; 指代消解; 有指导学习; 无指导学习;,"共指消解作为自然语言处理中的一个重要问题一直受到学术界的重视。二十多年来,基于规则的和基于统计的不同方法被提出,在一定程度上推进了该问题研究的发展,并取得了大量研究成果。该文首先介绍了共指消解问题的基本概念,并采用形式化的方法对该问题做了描述;然后,针对国内外近年来在共指消解研究中的方法进行了总结;之后,对共指消解中重要的特征问题进行了分析与讨论;最后,历数了共指消解的各种国际评测,并对未来可能的研究方向进行了展望。 ",MESS201501001
汉语复句信息处理研究二十年,吴锋文:26237197,6,信息处理; 复句; 关系标记; 自动识别;,"加强汉语复句信息处理研究对中文信息处理具有重要意义。该文介绍了汉语复句信息工程的概况,将复句知识建模、关系标记识别、非分句识别、复句句法语义关系判定、复句知识库建设等成果条理化,结合已有成果的研究视角、方法及关注焦点来分析复句信息处理的研究现状,并对其发展趋势进行了展望。 ",MESS201501002
基于语料库的明清小说人名与称谓研究,熊丹1:31878007|陆勤1:09238733|罗凤珠2:09278763|石定栩3:09238752|赵天成1:32733780,10,命名实体标注; 人名和称谓分类; 语料库构建;,"在自然语言处理及其应用领域,人名和称谓作为重要的命名实体,是信息处理的关键部分之一。该文从命名实体识别和资讯提取的角度出发,在对4部明清古典小说的语料库进行标注的前提下,建构了姓名、字号和称谓作为命名实体的分类及标注系统。人名和称谓总体上分为单一型和复合型,根据复合型的内部组成元素和组合方式,将其进一步分为固定式、同位式、附属嵌套式、灵活嵌套式。结合语料库的完整数据统计,该文对各类型人名和称谓进行了比较分析,并分别展示了4部名著在人名、称谓使用上的特点。 ",MESS201501003
花园幽径现象理解折返性的数据结构分析,"杜家利1,2:29594142|于屏方3,4:06841098",10,花园幽径现象; 数据结构; 认知; 折返性; 语义触发;,"该文讨论了花园幽径现象(GPP)的数据结构。GPP数据结构呈现理解折返的认知树形结构,不同于语法前状态的词集合结构、句子理解的语法线性结构和语义匹配多对多的歧义图状结构。GPP结构的显著性特征如下:(1)GPP理解初期,数据结构呈线性特征;(2)GPP理解中期,语义触发点迫使原解码模式被推翻,数据结构表现为词集合结构;(3)GPP理解末期,行进式错位导致回溯形成,解码结构最终呈现树形结构;(4)GPP动态解码融合了除歧义图状结构之外的两种结构特征,语义触发语的激活产生额外认知负担。GPP树形结构与歧义图状结构的不同从数据结构角度证实了两种语法现象的迥异,从而为计算语言学解读GPP提供了理论支撑。 ",MESS201501004
记叙文语篇修辞结构对焦点分布影响的研究,"赵建军1,2:32733782|杨晓虹2:23368351|杨玉芳2:09646963",6,记叙文; 语篇修辞结构; 焦点分布;,"该研究让20名被试对30篇汉语记叙文进行焦点标定,在焦点标定的基础上,结合文本标注和统计分析,对语篇修辞结构对焦点分布的影响进行了探讨。结果主要发现,记叙文语篇中有大约30%的小句没有获得焦点;核心性对焦点的分布有重要影响,大约80%的核心句中有焦点,而只有60%的辅助句中有焦点;最高层级的小句焦点数量相对较少;记叙文语篇主要由10种修辞关系构成,联合关系和阐述关系小句中焦点数量最多,归属关系小句中焦点数量最少。 ",MESS201501005
基于规则的复句关系词的自动标识,贾遂民1:28925622|雷利利2:32735346|胡明生1:27227783,6,关系词; 规则; 复句; 自动标识;,"关系词的自动标识是中文信息处理领域的基础性研究课题,该文利用规则实现其自动标识。首先通过语料的分析总结出关系词在使用过程中的12种特征,以这些特征建立规则的约束条件;然后提出包含匹配算法实现复句准关系词序列与规则索引词的匹配,以此获取目标规则,并根据目标规则约束条件与关系词所在语境的匹配结果得到匹配规则;最后利用匹配规则的结论实现关系词的自动标识。实验结果表明,该方法对关系词标识的正确率达到70.9%。 ",MESS201501006
基于声学特征的阳声韵元音鼻化程度的计算研究,孙锐欣:21961732,8,阳声韵结构; 鼻化元音; 共振峰带宽;,"在以鼻音为韵尾的音节中,元音可能会受韵尾的鼻音影响而带上鼻化音色,该文在对阳声韵韵母声学特征物理分析的基础上提出了阳声韵元音鼻化程度的计算方法。利用元音鼻化段时长和鼻化元音共振峰带宽构建的一个三维向量作为描述鼻化元音的依据,把这个向量的模作为元音鼻化程度的标度。经过实验和计算,我们发现前鼻音韵母中的元音的鼻化程度比较低,标度均值0.410,而后鼻音韵母中的元音的鼻化程度比较高,标度均值0.718,在所有阳声韵中,韵腹是高元音的阳声韵元音鼻化程度最高的。 ",MESS201501007
一个面向信息抽取的中文跨文本指代语料库,,10,跨文本指代; 信息抽取; 语料库标注; 困惑度;,"跨文本指代(Cross Document Coreference,CDC)消解是信息集成和信息融合的重要环节,相应地,CDC语料库是进行跨文本指代消解研究和评估所不可或缺的平台。由于目前还没有一个公开发布的面向信息抽取的中文CDC语料库,因此该文在ACE 2005语料库的基础上,采用自动生成和人工标注相结合的方法,构建了一个面向信息抽取的涵盖所有ACE实体类型的中文CDC语料库,并将该语料库公开发布,旨在促进中文跨文本指代消解研究的发展。同时,该文以该语料库为基础,分析了中文环境下跨文本指代现象的类型和特点,提出了用""多名困惑度""和""重名困惑度""两个指标来衡量跨文本指代消解任务的难度,为今后的跨文本指代消解研究提供一些启示。 ",MESS201501008
高正确率的双语语块对齐算法研究,"俞敬松1,2:22512348|王惠临3:09512639|吴胜兰2:32733783",9,语块对齐; 机器翻译; 平行文本; 双语对齐;,"高质量的自动对齐双语语块,对于机器翻译系统,特别是计算机辅助翻译系统的性能提高有重要作用,而且对于人工翻译以及辞典编纂也都有巨大的应用价值。该文提出基于单词间粘合度与松弛度的语块划分评分方法以及双语语块划分的双向约束算法,使得源语言和目标语言的语块的划分与对齐能相互促进。与传统方法相比,因为无需事先进行双语语块划分,而是在搜索最佳对齐时动态地考察划分效果,故可以减少边界划分错误对对齐结果的影响。该算法获得了远超过传统算法的高正确率。 ",MESS201501009
面向机器翻译的句类依存树库构建及应用,王慧兰1:30981522|张克亮2:21027033,7,机器翻译; 概念层次网络理论; 句类依存树库;,"该文以汉英机器翻译为应用目标,以概念层次网络理论的语义网络和句类分析方法为理论基础,探讨了句类依存树库构建的理论和标注实践等问题,描述了构建树库所需的概念类别标注集和句类关系标注集。并通过与已有汉语树库进行对比,以汉语显性轻动词句的标注为例,分析了汉语句类依存树库的特点。该文在应用层面定义了面向汉英机器翻译的融句法语义信息于一体的""句类依存子树到串""双语转换模板,尝试基于汉语句类依存树库提取汉英转换模板。 ",MESS201501010
基于信息熵和词频分布变化的术语抽取研究,李丽双:06521783|王意文:32733784|黄德根:06527360,6,术语抽取; 信息熵; 词频分布变化;,"在分别研究了基于信息熵和基于词频分布变化的术语抽取方法的情况下,该文提出了一种信息熵和词频分布变化相结合的术语抽取方法。信息熵体现了术语的完整性,词频分布变化体现了术语的领域相关性。通过应用信息熵,即将信息熵结合到词频分布变化公式中进行术语抽取,且应用简单语言学规则过滤普通字符串。实验表明,在汽车领域的语料上,应用该方法抽取出1 300个术语,其正确率达到73.7%。结果表明该方法对低频术语有更好的抽取效果,同时抽取出的术语结构更完整。 ",MESS201501011
基于并列结构的部分整体关系获取方法,"夏飞1,2:28907682|曹馨宇1,2:26496186|符建辉1:25121025|王石1:23246662|曹存根1:10348278",9,部分整体关系; 图模型; 并列结构; 层次聚类; 边权重;,"部分整体关系是一种基础而重要的语义关系,从文本中自动获取部分整体关系是知识工程的一项基础性研究课题。该文提出了一种基于图的从Web中获取部分整体关系的方法,首先利用部分整体关系模式从Google下载语料,然后用并列结构模式从中匹配出部分概念对,据此形成图,用层次聚类算法对该图进行自动聚类,使正确的部分概念聚集在一起。在层次聚类基础上,我们挖掘并列结构的特性、图的特点和汉语的语言特点,采用惩罚逗号边、去除低频边、奖励环路、加重相同后缀和前缀等5种方法调整图中边的权重,在不损失层次聚类的高准确率条件下,大幅提高了召回率。 ",MESS201501012
可扩展的网页关键信息抽取研究,"郭少华1,2:32733785|郭岩1:09559534|李海燕1:32733786|刘悦1:09639001|张瑾1:22101466|程学旗1:09559496",7,关键信息; 信息抽取; 可扩展框架; 正交过滤;,"该文提出了一种可扩展的网页关键信息抽取框架。该框架很好地融合了模板无关的全自动信息抽取算法和基于模板的信息抽取算法,从本质上提高抽取精度和抽取效率。该框架中的一些关键环节可根据需求进行替换,因此该框架具有很好的可扩展性。同时,该文还提出了模板的正交过滤算法。将该算法引入基于模板的抽取算法中,能够从本质上提高生成的模板的准确性。实验结果验证了上述结论。 ",MESS201501013
一种基于Tri-training的半监督多标记学习文档分类算法,"高嘉伟1,2:17293751|梁吉业1,2:08408575|刘杨磊1,2:28090879|李茹1,2:08453268",7,半监督学习; 多标记学习; 文档分类;,"多标记学习主要用于解决因单个样本对应多个概念标记而带来的歧义性问题,而半监督多标记学习是近年来多标记学习任务中的一个新的研究方向,它试图综合利用少量的已标记样本和大量的未标记样本来提高学习性能。为了进一步挖掘未标记样本的信息和价值并将其应用于文档多标记分类问题,该文提出了一种基于Tritraining的半监督多标记学习算法(MKSMLT),该算法首先利用k近邻算法扩充已标记样本集,结合Tri-training算法训练分类器,将多标记学习问题转化为标记排序问题。实验表明,该算法能够有效提高文档分类性能。 ",MESS201501014
基于短文本信息流的回顾式话题识别模型,周泓1:23731687|刘金岭1:14209862|王新功2:44957023,8,短文本; 信息流; 话题识别; 聚类;,"近几年来,短文本信息流广泛应用于一些全民媒体,它在公开传递信息同时携带了丰富且具有极大价值的信息资源。该文提出了一种回顾式话题识别模型,改进了权值计算方法,有效提取了具有较强分辨话题能力的关键词,在聚类过程中将BIC值作为话题类别合并依据,提高了聚类的准确率。通过进行时间段分隔和去掉孤立点信息提高了算法的效率。实验结果表明,该方法有效地提高了短文本信息流的话题检测准确率和效率。 ",MESS201501015
文本流多粒度主题结构建模研究,陈千:29259586|郭鑫:27987630|王素格:08454306|张虎:08403299,8,主题检测; 多粒度主题建模; 文本流;,"主题检测近年来在文本挖掘和自然语言处理领域得到了广泛的应用,对主题进行结构建模是主题检测的基础。为了对文本流中的多粒度主题进行建模,提出一种基于语义层次树的主题结构模型。该模型利用领域本体的特点,将主题同本体作一一映射,结合概率理论,将概念集里的概念用主题树的叶子节点表示,每一层中的节点均是下一层节点的多项分布,使之更适合描述文本流中多粒度的主题结构。为了便于构建主题的空间结构,提出主题的相似度和事件相关度计算方法。该文结尾设计了实验构造真实新闻文本流数据上的主题树。实验结果表明,该结构模型能够体现主题丰富的多粒度空间语义特征。 ",MESS201501016
基于多层grams的在线支持向量机的中文垃圾邮件过滤,沈元辅1:07002876|沈跃伍2:29011653,7,特征抽取; 支持向量机; 垃圾邮件过滤。;,"该文提出一种多层grams特征抽取方法来提升基于在线支持向量模型的垃圾邮件过滤器。基于在线支持向量机模型的垃圾邮件过滤器在大规模垃圾邮件数据集已取得了很好的过滤效果,但与逻辑回归模型相比,计算性能的耗时是巨大的,很难被工业界所运用。该文提出的多层grams特征抽取方法能够有效减少特征数,抽取更精准有效的特征,大幅降低模型的运行时间,同时提升过滤器的过滤效果。实验表明,该方法使得在线支持向量机模型的运行时间从10337s减少到3784s,同时模型(1-ROCA)%降低了一半。 ",MESS201501017
基于预测误差扩展的可逆文本水印算法,"费文斌1:26559600|唐向宏1,2:07054395|王静1:14615780|林新建1:30044654",7,可恢复水印; 预测误差扩展; 文本文档; 搭配度; 混沌序列;,"为了避免在水印嵌入后造成文本内容的永久性改变,该文借鉴图像中可恢复水印的思想,将预测误差扩展应用于文本文档,提出了一种基于预测误差扩展的可逆中文文本水印算法。该算法以句子为单位,通过上下文搭配度大小选择可替换的词语,最后利用预测误差扩展和混沌序列,实现水印的嵌入。研究结果表明该算法不仅具有较高的安全性,而且能有效地提取水印和无损地恢复出原始文本。 ",MESS201501018
一种处理结构化输入输出的中文句法分析方法,赵国荣:08403415|王文剑:08402641,7,中文句法分析; 加权上下文无关文法; 结构化SVM; 二阶范数软间隔优化;,"中文句法结构复杂,特征维数较高,目前已知最好的汉语句法分析效果与其他西方语言相比还有一定的差距。为进一步提高中文句法分析的效率和精度,该文提出一种采用二阶范数软间隔优化的结构化支持向量机(Structural Support Vector Machines,Structural SVMs)方法对基于短语结构的中文句法进行分析,通过构造结构化特征函数ψ(x,y),体现句法树的输入信息,并根据中文句子本身具有的强相关性,在所构造的ψ(x,y)中增加中文句法分析树中父节点的信息,使ψ(x,y)包含了更加丰富的结构信息。在宾州中文树库PCTB上的实验结果表明,该文方法与经典结构化支持向量机方法以及Berkeley Parser相比可取得较好的效果。 ",MESS201501019
融合事件信息的中文问答系统问题语义表征,"魏楚元1,2:32438671|湛强1:32438672|樊孝忠1:05968220|毛煜1:32438674|张大奎1:32438673",9,复杂类问题; 事件; 问题语义表征; 语义组块; 问题理解;,"复杂类问题理解是中文问答系统研究的难点,基于组块的问句分析方法将整个问句转化为若干组块,降低了问句分析的难度和复杂性。针对以含有事件(动作)信息的复杂类问题,提出基于语义组块的中文问答系统问题语义表征模型,采用语义组块的思想将问题的语义成分定义为疑问焦点块、问题主题块和问题事件块三个语义组块,对问句中的事件语义信息,建立了问题事件语义结构,将一个问句表征为一个基于语义组块的问题语义表征结构,用于问答系统的问题理解。通过序列标注学习方法实现问题语义表征中语义组块自动标注。实验结果表明:问题语义组块标注效果较好,问题语义表征模型获取了问题的关键语义信息,为语义层面上的问题理解提供基础。 ",MESS201501020
一种扩展式CRFs的短语情感倾向性分析方法研究,"乌达巴拉1,2:32733787|汪增福1,2:09544732",8,短语; 情感倾向性分析; 条件随机场;,"短语情感倾向性分析是文本情感分析的重要研究内容。该文将短语情感倾向性分析问题视作序列标注问题,利用条件随机场模型实现短语的情感倾向性判断。条件随机场模型是利用序列特征处理序列标注问题的经典方法,然而现有条件随机场模型无法将词语的情感倾向性分析与短语的情感倾向性分析相结合,从而造成准确率不高。因此,该文提出一种扩展式条件随机场模型YACRFs。该模型在链式条件随机场模型的基础上进行扩充,将词语情感倾向性分析与短语情感倾向性分析有效地结合起来,引入了情感词汇、短语规则模板以及词性等特征。与传统的规则方法和统计分类方法进行对比实验,该文提出方法取得了最高准确率81.07%。进一步地,在应用于句子情感倾向性分析的实验中得到了94.30%的准确率。实验结果表明,该文所提出的YACRFs模型能够显著提高短语情感倾向性判断结果的准确率。 ",MESS201501021
基于迭代两步CRF模型的评价对象与极性抽取研究,张盛:32733788|李芳:09595202,7,迭代; 两步CRF; 评价对象;,"微博作为一种新兴媒体,已经在人们生活中扮演了一种不可或缺的角色。如何从大量微博中抽取出有意义的评价对象并识别出正确的情感倾向显得越来越重要。本文在传统的CRF模型基础上,提出了两步CRF模型及迭代两步CRF模型,对评价对象和极性进行抽取。两步CRF模型在COAE2014评测语料上取得了0.505的F值,迭代两步CRF模型通过不断增加训练语料,提高了召回率,使得F值达到了0.513,同时提高了模型的稳定性。实验对比了当前主流的几种方法,结果证明了本文提出的方法是行之有效的。 ",MESS201501023
Web藏文文本资源挖掘与利用研究,"刘汇丹1,2:09573793|诺明花1,2:15570459|马龙龙1:27055084|吴健1:09573880|贺也平1:10352407",8,Web; 语料; 文本挖掘; 信息抽取; 藏文信息处理; 中文信息处理;,"该文结合链接分析技术和藏文编码识别技术,使用网络爬虫实现对互联网上藏文文本资源的挖掘,分析了Web藏文文本资源的分布情况。统计数据显示,国内藏文网站50%以上在青海省;约87%的藏文网页集中分布在31个大型网站中;人们正在逐步弃用旧有藏文编码,使用Unicode编码来制作网页。利用HTML标记、栏目归属、标点符号等自然标注信息对这些文本进行抽取,可以构建篇章语料和文本分类语料,可以抽取互联网藏文词库,进行词频统计和训练藏文语言模型,结合双语词典和搜索引擎技术抽取双语平行语料。这些语料可用于藏文分词、命名实体识别、信息检索、统计机器翻译等研究领域。 ",MESS201501024
基于音素混淆网络的蒙古语语音关键词检测方法的研究,飞龙1:23670720|高光来1:05981929|鲍玉来2:07993806,5,蒙古语; 关键词检测; 集外词; 混淆网络; 音素混淆矩阵;,"蒙古语语音识别系统的词表很难覆盖所有的蒙古文单词,并且随着社会的发展,蒙古文的新词和外来词也越来越多。为了解决蒙古语语音关键词检测系统中的集外词检测问题,该文提出了基于音素混淆网络的蒙古语语音关键词检测方法,并采用音素混淆矩阵改进了关键词的置信度计算方法。实验结果表明,基于音素混淆网络的蒙古语语音关键词检测方法可以较好地解决集外词的检测问题。蒙古语语音关键词检测系统采用改进的置信度计算方法后精确率提高了6%,召回率提高了2.69%,性能得到明显的提升。 ",MESS201501025
藏文Web网络环境下的搜索策略研究,"陈新一1:10849379|夏建华1,2:27243478|杜玉祥1:32735349|万福成1:24274323|于洪志1:09120080",8,藏文Web网络; 度分布; 最大度链路; 双遍历器; 社区划分;,"该文分析了藏文Web网络的度分布和最大度优先搜索算法存在的问题,提出了搜索效率更高的二分度搜索算法和双遍历器的二分度与最大度同步搜索算法。根据社区划分原理,设计和构建了藏文Web社区环境下的搜索算法,实验结果表明,其平均搜索步数和平均查询信息量都优于实验中其他搜索算法。 ",MESS201501026
藏文排序优先级算法研究,边巴旺堆:09163661|卓嘎:09143915|董志诚:23642779|武强:10829816|王龙业:10216619,6,规则函数; 优先级; 藏文; 算法;,"为了顺利实现藏文词语的排序算法,在藏文构件元素识别算法的基础上,该文通过建立藏文规则函数和定义藏文构件的优先级,提出了基于笛卡尔积数学模型的现代藏文音节的优先级算法。该方法既遵循藏文构词原则,又符合语法规则,同时为藏文词语排序算法提供了新的研究思路。最后该文用藏文""""系的所有满足语法规则的词语对本算法进行测试,结果表明该算法符合现代藏文词典的排序要求,且排序效率更好。 ",MESS201501027
基于词典、规则的斯拉夫蒙古文词切分系统的研究,史建国:32733789|侯宏旭:08012191|飞龙:23670720,6,斯拉夫蒙古文; 词切分; 词典; 规则;,"斯拉夫蒙古文是蒙古国现行的文字,又称为西里尔蒙古文或新蒙古文。蒙古文词干和词缀包含着大量信息,斯拉夫蒙古文词切分是斯拉夫蒙古文信息处理众多后续工作的基础。该文尝试了将词典和规则结合的方法对斯拉夫蒙古文进行词切分。首先预处理部分蒙古文词,然后基于词典切分高频和部分不符合规则的词。最后对剩余的词,用切分规则生成多个候选的词切分方案,然后在这些方案中选出最优方案。通过两种方法的有机结合,发挥各自的优点,得到了性能较好的斯拉夫蒙古文词切分系统。 ",MESS201501028
第十四届机器翻译峰会(MT Summit XIV)综述,"张霄军1,2:32273725|刘群1,3:30840521",4, ,"<正>2013年9月2日至9月6日,第十四届机器翻译峰会(Machine Translation Summit XIV,以下简称""峰会"")在风景优美的法国南部海滨城市尼斯(Nice)举行,会议议程为:9月2日至9月3日为专题讲座(Tutorial)和专题研讨会(Workshop),9月4日至9月6日为主会议(Main Conference),详见 ",MESS201501029
中国中文信息学会颁发2014年度“钱伟长中文信息处理科学技术奖”“汉王青年创新奖”及“拓尔思优秀博士学位论文奖”,,2, ,"<正>2014年12月20—21日,中国中文信息学会学术年会暨理事会在北京中国科技会堂隆重举行,会上颁发了""钱伟长中文信息处理科学技术奖"",""汉王青年创新奖"",以及中国中文信息学会优秀博士学位论文""拓尔思优秀博士学位论文奖"";邀请了6位专家进行了学术报告。来自中国科协、民政部、教育部、国家自然科学基金委等部委的领导和中文信息 ",MESS201501022
厦门大学牵头完成的《汉字简繁文本智能转换系统》在京发布,,1, ,"<正>由厦门大学、教育部语言文字应用研究所、北京师范大学联合研发的""汉字简繁文本智能转换系统""2014年11月18日在北京发布。教育部副部长、国家语言文字工作委员会主任李卫红,中共中央台办、国务院台办主任助理龙明彪、两岸语言文字交流与合作协调小组组长李宇明,教育部语 ",MESS201501030
中国中文信息学会与Springer合作出版学术论文集,,1, ,"<正>自2013年起,中国中文信息学会与世界著名的科技期刊和图书出版公司Springer开展合作,努力将中文信息处理领域的最新研究成果和学术思想广泛推介、传播到国际学术界。2013年,由中国中文信息学会主办的""第十二届全国计算语言学学术会议""(CCL 2013)和""第一届基于自然标注大数据的自然语言处理国际学术研讨会""(NLP-NABD 2013)的英文论文集在Springer Lecture Notes in Computer Science出版,卷号为LNAI 8202,ISBN为978-3- ",MESS201501031
商务印书馆新书目录,,1, , ,MESS201501032
基于字符的中文分词、词性标注和依存句法分析联合模型,郭振:29895361|张玉洁:10874141|苏晨:29895360|徐金安:25200603,9,联合模型; 中文分词和词性标注; 依存句法分析; 词语内部依存结构; 半监督学习;,"目前,基于转移的中文分词、词性标注和依存句法分析联合模型存在两大问题:一是任务的融合方式有待改进;二是模型性能受限于全标注语料的规模。针对第一个问题,该文利用词语内部结构将基于词语的依存句法树扩展成了基于字符的依存句法树,采用转移策略,实现了基于字符的中文分词、词性标注和依存句法分析联合模型;依据序列标注的中文分词方法,将基于转移的中文分词处理方案重新设计为4种转移动作:Shift_S、Shift_B、Shift_M和Shift_E,同时能够将以往中文分词的研究成果融入联合模型。针对第二个问题,该文使用具有部分标注信息的语料,从中抽取字符串层面的n-gram特征和结构层面的依存子树特征融入联合模型,实现了半监督的中文分词、词性标注和依存句法分析联合模型。在宾州中文树库上的实验结果表明,该文的模型在中文分词、词性标注和依存分析任务上的F1值分别达到了98.31%、94.84%和81.71%,较单任务模型的结果分别提升了0.92%、1.77%和3.95%。其中,中文分词和词性标注在目前公布的研究结果中取得了最好成绩。 ",MESS201406001
基于联合音变还原和形态切分的形态分析方法,张海波:26829667|蔡洽吾:32278863|姜文斌:23136246|吕雅娟:13898594|刘群:09638994,9,形态分析; 音变还原; 形态切分;,"传统的形态分析方法,一般是先进行音变还原工作,再进行形态切分工作。音变还原工作的好坏直接影响形态切分工作的优劣,两者之间存在错误传播的问题。鉴于传统形态分析方法存在的错误传播问题,该文提出了基于联合音变还原和形态切分的形态分析方法。该方法通过使用具有双重功能的联合标签,同时实现了音变还原及形态切分的功能。由于该方法不依赖于黏着语的特有的语言学规则,因此便于扩展到新的语言上。结果表明,联合音变还原和形态切分的形态分析方法要优于传统的先进行音变还原后形态切分的形态分析方法,能够很好地解决先音变还原后形态切分带来的错误传播问题。 ",MESS201406002
基于字的分布表征的汉语基本块识别,李国臣1:25955427|党帅兵2:32278864|王瑞波3:13897708|李济洪3:08401319,9,汉语基本块; 分布表征; 深层神经网络; 序列标注;,"汉语的基本块识别是汉语句法语义自动分析中的重要任务之一。传统的方法大多数直接将汉语基本块识别任务转化成词层面的一个序列标注问题,采用CRF模型来处理。虽然,在许多评测中得到最好的结果,但基于词为标注单位,在实用中受限于自动分词系统以及汉语词特征的稀疏性。为此,该文给出了一种以字为标注单位,以字为原始输入层,来构建汉语的基本块识别的深层神经网络模型,并通过无监督方法,学习到字的C&W和word2vec两种分布表征,将其作为深层神经网络模型的字的表示层的初始输入参数来强化模型参数的训练。实验结果表明,使用五层神经网络模型,以[-3,3]窗口的字的word2vec分布表征,其准确率、召回率和F值分别达到80.74%,73.80%和77.12%,这比基于字的CRF高出约5%。这表明深层神经网络模型在汉语的基本块识别中是有作用的。 ",MESS201406003
面向图解树库的标注工具开发与优化,赵敏:06374679|彭炜明:24186788|宋继华:06364557|杨天心:31524541,8,树库; 句式结构; 图解标注;,"一个高效便捷的标注工具对树库建设起到至关重要的作用,该文在现有的基于句式结构的图解标注工具的基础上,针对其不足之处,进行了重新设计,加入词类和义项等标注信息,实现了人机结合的可视化图解标注工具,并从实践角度详细介绍标注工具在树库构建工程中的操作模式和功能。 ",MESS201406004
"“A+一+X,B+一+Y”构式的分类及释义模板","刘洪超1:32285370|詹卫东1,2,3:06264050",7,"“A+一+X,B+一+Y”; 构式知识库; 释义模板;","该文以现代汉语中的""A+一+X,B+一+Y""格式为例,介绍了构建《现代汉语构式知识库》的初步工作。""A+一+X,B+一+Y""格式可根据其表义功能不同分为三个大类,十个小类。该文重点阐释了该构式表达""因果倚变义、事物交错义、状态交替义、动作行为交替义、周遍大量义、让步小量义""等6种意义的判定条件及相应的释义模板。 ",MESS201406005
中文非投射语义依存现象分析研究,郑丽娟:32278868|邵艳秋:32278869|杨尔弘:06429879,7,语义分析; 语义依存; 非投射结构; 依存图;,"汉语是一种语序灵活的语言,句子变式很多,基于传统依存树的投射现象还不能很好解决某些句式的语义理解问题。文章以10 000个句子的汉语语义依存图库为基础,验证并明确了汉语非投射现象的客观存在性,考察了汉语句子中存在的非投射现象,并从语言学和句子深层语义理解的角度对非投射现象进行了归纳和解释。文章总结了7类出现非投射现象的情况,包括小句宾语句、比较句、主谓谓语句、紧缩复句、代词、动补谓语句以及注释短语或复句。这对于自动语义依存标注有重要的指导作用。 ",MESS201406006
汉语核心框架语义分析,"石佼1:29475626|李茹1,2:08453268|王智强1:25200586",8,汉语框架网; 核心框架语义; 语义分析;,"汉语核心框架语义分析是从框架语义角度,通过抽取句子的核心框架,获取汉语句子的核心语义骨架。该文将核心框架语义分析分为核心目标词识别、框架选择和框架元素标注三个子任务,基于各个子任务的不同特点,采取最大熵模型分别对核心目标词识别与框架选择任务进行建模;采用序列标注模型条件随机场对框架元素标注任务进行建模。实验在汉语框架网资源的10 831条测试语料中显示,核心目标词识别和框架元素标注F值分别达到99.51%和59.01%,框架选择准确率达到84.73%。 ",MESS201406007
基于分层输出神经网络的汉语语义角色标注,,7,语义角色标注; 深度学习; 特征向量;,"语义角色标注是自然语言处理中的一项重要任务。当下针对中文语义角色标注的主流做法是通过基于特征的统计机器学习实现的。然而,统计机器学习的方法需要引入经验性的人工特征,这在一定程度上增加了工作量。深度学习在自然语言处理领域的应用使得特征的自动学习成为可能。文章尝试了一种适用于语义角色标注的深层神经网络架构,该模型能自然地推广到其他标注任务。实验表明,深度学习算法能够有效地用于语义角色标注任务,但是我们仍然发现,模型对语义层面知识的学习是相当有限的,基于深度学习的方法还不能取代基于人工特征的统计机器学习算法。 ",MESS201406008
基于语义解析的中文GIS自然语言接口实现研究,周俊生1:08116958|曲维光1:08112756|许菊红1:32278870|龙毅2:08081940|朱耀邦1:32278871,9,地理信息系统; 自然语言接口; 语义解析;,"该文对基于语义解析的中文地理信息系统(GIS)自然语言接口实现技术与方法进行了探索性的研究。首先,我们针对一个具体GIS应用领域设计和开发了一种函数式的形式化意义表示语言GISQL和一个中文语义解析标注语料库;然后,我们通过引入混合树作为隐变量用于构造输入句子与输出表示结构之间的对应关系,提出了一种基于含隐变量的感知器模型的语义解析算法。在开发的中文语义解析标注语料库上的实验结果显示,该文提出的语义解析算法的F1值达到了90.67%,明显优于baseline系统。更重要的是,该文的研究证明了基于语义解析方法实现中文GIS的自然语言接口是一种有效可行的途径。 ",MESS201406009
语法和语义相结合的中文对话系统问题理解研究,黄沛杰:24966316|黄强:30821750|吴秀鹏:30821749|吴桂盛:32278872|郭庆文:32278873|陈楠挺:32278874|陈楚萍:32278875,9,问题理解; 对话系统; 句型模式; 中文;,"针对中文口语问句的表达多样性对对话系统问题理解带来的挑战,该文采用""在语法结构之上获取语义知识""的设计理念,提出了一种语法和语义相结合的口语对话系统问题理解方法。首先人工编制了独立于领域和应用方向的语法知识库,进而通过句子压缩模块简化复杂句子,取得结构信息,再进行问题类型模式识别,得到唯一确定问题的语义组织方法、查询策略和应答方式的句型模式。另一方面,根据领域语义知识库,从源句子中提取相应的语义信息,并根据识别到的句型模式所对应的知识组织方法进行语义知识组织,完成对问句的理解。该文的方法被应用到开发的中文手机导购对话系统。测试结果表明,该方法能有效地完成对话流程中的用户问题理解。 ",MESS201406010
面向政治新闻领域的中文文本校对方法研究,张仰森:15552896|唐安杰:32278876|张泽伟:31225409,7,政治新闻; 文本校对; 查错模型;,"政治新闻领域内文本错误多为语义级错误。在研究新闻领域文本政治性差错的语言表述特征的基础上,分析了报刊新闻中政治性差错的表现类型,构建了面向各类错误侦测的词库和知识库。通过研究政治新闻文本的语言学特征,提出了一个政治性差错文本错误侦测规则的一般形式化模型,采用统计与规则相结合的策略实现政治新闻领域文本的语义校对。实验结果显示,该方法的召回率为65.5%,精确率为80.5%,具有较好的应用前景。 ",MESS201406011
汉语动词资源馆(Chinese Verb Library)的构建,"汪梦翔1,2:29615765|王厚峰1:06274413|刘杨1:06258881|饶琪3:21700904",10,汉语动词资源馆; 生成词库论; 事件结构;,"该研究以动词的语义聚合层次为核心,构建了含有四个语义层级的动词分类系统,依托生成词库理论、语义格框理论和构式语法理论,从事件结构、语义格框架、物性角色、句法格式四个角度来对动词的自身属性以及组合性等特征进行描述,从而构造出能够解释并深入描述动动之间、动名之间甚至是超常搭配用法的汉语动词资源馆Chinese Verb Library(CVL)。实验表明,该研究可以为句法分析、语义角色标注、尤其是揭示隐含的谓间关系提供新的支持。 ",MESS201406012
词位重构与平行语言资源的再生性建设,"萧国政1,2,3:08990551|高精鍊1,2,3,4:28122902|双文庭1,2,3,5:27472298|姬东鸿2,3,6:09004523|郭婷婷1,2,3:09003670|吴泓渺2,3,7:23616151",6,词位重构; 平行语言资源; 资源再生性建设; 语言信息处理理论;,"该文以大数据意识为背景,通过语言学范畴""词位""内涵、外延的重构,以自然和人工平行性语言资源为基础,提出和讨论语言资源的再生性建设命题。并以期""通过资源建构资源""的再生性模式,推动语言资源多类型、高覆盖、跨语言快速发展及语言应用理论建设。 ",MESS201406013
汉语显式篇章关系分析,丁彬:27830998|孔芳:08865090|李生:26803240|周国栋:13898054,6,连接词识别; 语义关系分类; 最大熵分类器;,"篇章关系分为显式和隐式两种。显式关系的显著特征是篇章的基本单元之间存在显式连接词。针对汉语显式篇章关系,构建了包括汉语连接词识别和篇章关系分类的显式篇章关系分析平台。该文选取汉语宾州树库(Chinese Penn Treebank,CTB)中的500篇文本进行了汉语显式篇章关系标注;结合连接词的中心词,采用最大熵分类器构建了汉语连接词识别模块,其性能F1值达到了66.79%;基于连接词及其词性等上下文特征,构建了篇章关系分类器,其在最顶层4大类语义关系上的分类性能的F1值为91.92%。 ",MESS201406014
广义话题结构理论视角下话题自足句成句性研究,尚英1:06428017|宋柔2:05982879|卢达威2:30152896,8,广义话题结构; 话题自足句; 成句性;,"话题自足句是在广义话题结构理论的基础上定义的。话题自足句的成句性是广义话题结构的重要性质之一。该文在38万字不同语体的广义话题结构语料库中对话题自足句的成句性进行了实证性调查,发现有少量话题自足句不成句,对不成句现象进行了分析、分类,并提出了使其成句的办法。这将进一步完善广义话题结构理论,并能提高使用话题自足句的应用系统的性能。 ",MESS201406015
基于协同训练的文本蕴含识别,"任函1:26953088|万菁2:11504672|吴泓缈1,2:08989878|冯文贺3:22135161",6,文本蕴含识别; 协同训练; 语义树核;,"针对文本蕴含的训练数据不足的问题,该文提出了基于协同训练的文本蕴含识别方法。该方法利用少量已标注的蕴含数据和大量未标注数据进行协同训练。为此,该文利用改写视图和评估视图,从结构和非结构两个角度考察蕴含关系,并将语义树核分类器和基于统计特征的分类器应用于两个视图,同时利用协同训练的结果训练一个综合分类器,用于对新数据进行预测。实验表明,基于协同训练的蕴含识别方法能在少量训练数据的情况下获得较好的识别性能。 ",MESS201406016
基于单文本指代消解的人物家庭网络构建研究,"顾静航1,2:28781784|朱苏阳1,2:26803241|钱龙华1,2:08844995|朱巧明1,2:09891804",9,社会关系网络; 家庭网络; 单文本指代消解;,"人物家庭网络是社会关系网络中的一个重要组成部分,因此,如何高效准确地提取出人物的家庭网络具有重要研究意义。该文在前人工作的基础上提出一种基于单文本指代消解技术的人物家庭关系抽取方法,以此扩大人物家庭关系抽取的范围,进而提高人物家庭网络的召回性能。该文还提出了一种基于人物虚拟边的家庭网络评估指标,用于更合理地评价构建出的人物家庭网络的性能。在大规模中文语料Gigaword上的实验表明,该方法可以较为准确地抽取出人物的家庭关系,进而提高人物家庭网络的召回性能,从而为社会网络分析提供基础数据。 ",MESS201406017
基于图排序的词汇情感消歧研究,杨亮:14244075|张绍武:06536175|林鸿飞:06504899|宋艳雪:27030931,8,多情感词汇; 图排序; 情感消歧;,"词汇情感消歧是文本情感倾向性分析的关键技术之一。该文在分析比较了词汇情感消歧和词义消歧异同后,从情感分析角度出发,提出了基于图排序的词汇情感消歧方法。该方法通过自动获取和人工校正相结合的方式获得多情感词汇,然后根据语义关系构建词义关系图,进而在词义关系图上迭代计算直至收敛,最后选择多情感词汇的词义中权值最大的词义作为结果输出,从而实现情感消歧。该文分别在新浪微博语料库和情感语料库上验证了该方法的有效性。 ",MESS201406018
基于模糊集合的汉语主观句识别,宋洪伟:32278878|贺宇:32278879|付国宏:22432184,7,主观句识别; 情感密度; 模糊集合; 优势率;,"主观句识别的工作在诸如情感分类和意见摘要等意见挖掘系统中占有很重要的地位。在该文中,我们提出一种基于情感密度的模糊集合分类器以识别汉语主观句。首先,我们利用优势率方法从训练语料中抽取主观性线索词;然后,为了能更好的表达一个句子的主观性,我们利用抽取出的主观性线索词计算出每个句子的情感密度;最后,我们结合情感密度的特点实现了一个三角形隶属度函数的模糊集合分类器以识别主观句。我们在NTCIR-6中文数据中做了两组实验。实验结果表明我们的方法具有一定的可行性。 ",MESS201406019
基于有监督学习方法的多文档文本情感摘要,"李艳翠1,2:17502135|林莉媛1,3:30773777|周国栋1,3:13898054",7,情感摘要; 评论质量; 情感特征; 有监督学习; 最大熵分类器;,"该文研究有监督学习方法在多文档文本情感摘要中的应用。利用从亚马逊中文网和亚马逊英文网上收集的产品评论语料,抽取文本内特征、PageRank特征、情感特征和评论质量特征,基于有监督方法进行多文档文本情感摘要抽取。实验结果表明有监督学习方法比无监督学习方法在ROUGE值上有显著的提高,情感特征和评论质量特征均有助于文本情感摘要。 ",MESS201406020
中文微博用户性别分类方法研究,王晶晶:08846650|李寿山:27030929|黄磊:31374439,7,性别分类; 新浪微博; 文本分类; 社交网络;,"该文旨在研究中文微博用户的性别分类问题,即根据微博提供的中文文本信息对注册用户的性别进行识别。虽然基于微博的性别分类已经有一定研究,但是针对中文的性别分类工作还很缺乏。该文首先提出分别利用用户名和微博文本构建两个分类器对用户的性别类型进行判别,并对不同的特征(例如,字特征、词特征等)进行了研究分析;其次,在针对用户名和微博文本的两个分类器的基础上,使用贝叶斯融合方法进行分类器融合,从而达到采用这两种文本分类信息同时对用户性别进行性别判断。实验结果表明该文的方法可以达到较高的识别准确率,并且分类器融合的方法明显优于仅利用用户名或者微博文本的分类方法。 ",MESS201406021
一种基于弱监督学习的论坛帖子对话行为分类方法,孙承杰:06996605|林磊:06988910|刘秉权:06988938,7,弱监督学习; 特征约束; 对话行为分类; 论坛线索结构分析;,"论坛帖子对话行为分类可以明确每个帖子在当前线索中的角色,有助于重构论坛线索中的对话关系,提高论坛信息检索的效果。该文提出了一种基于弱监督学习的论坛帖子对话行为分类方法,把帖子的对话行为分类作为线索的序列标注问题来解决。该方法的特点是只要指定合理的特征约束,就可以训练对话行为分类模型。方法在CNET和edX数据集上的分类精确率分别达到75.6%和60.7%,优于有监督的条件随机域方法。 ",MESS201406022
社交网络账号的马甲关系辨识方法,"樊茜1,2:31105282|许洪波1:10348532|梁英1:09559591",7,马甲识别; 语言风格; 关系特征; 社交网络;,"正确辨识网络账号的马甲关系,能够维护网络环境的安全与和谐,抑制网络中不法行为和虚假信息。基于文本挖掘的作者身份识别一直受到广泛关注,但对社交网络中文本作者关系鉴别的研究较少,该文提出了一种社交网络账号的马甲识别方法,基于网络语言的风格和账号关系,分别提取网络文本特征和账号之间的回复关系频次两组特征构成特征集合,同时基于账号组合构建训练样本向量空间,鉴别网络账号的马甲关系。结合论坛数据对所提方法进行了实验验证,准确率达到80%,结果表明该方法具有较高的马甲辨别准确率。 ",MESS201406023
基于条件随机场与时间词库的中文时间表达式识别,吴琼:06523187|黄德根:06527360,7,CRF; 规则; 时间触发词; 时间缀词;,"该文提出一种统计与规则相结合的时间表达式识别方法。首先,通过分析中文文本中时间表达式的词形、词性和上下文信息,采用条件随机场识别时间单元而非时间表达式整体,避免了中文时间表达式边界定位不准确的问题;然后,从训练语料中自动获取候选触发词,并依据评价函数对候选触发词打分,筛选出正确的触发词完善触发词库;最后,根据时间触发词库与时间缀词库,制定规则对时间表达式边界进行定位。实验结果显示开式测试F1值达到98.31%。 ",MESS201406024
观点句中评价对象/属性的缺省项识别方法研究,"刘慧慧1:32278880|王素格1,2:08454306|赵策力3:32278881",8,缺省项; 识别规则; 词法特征; 依存句法; C4.5算法;,"在多对象、多属性的评论文本中,评价对象和评价属性的缺省识别对于观点挖掘有着重要的作用。针对情感观点句中评价对象和评价属性的缺省问题,该文提出一种有效的缺省项识别方法。首先构造缺省项识别规则集,用于获取待识别的缺省项侯选集;将缺省项识别问题看作一个二元分类问题,选用词法和依存句法作为特征,使用决策树分类算法C4.5训练分类器模型,在测试集上对待识别的缺省项进行判别。实验结果表明,使用依存句法特征集分类的F值优于词法特征集约2%。将词法和依存句法两类特征融合与单类特征相比,分类精确率和F值分别提高了10%和5%左右,说明词法特征和依存句法特征的融合有利于缺省项识别。 ",MESS201406025
基于句法语义特征的中文实体关系抽取,"郭喜跃1,2:28899685|何婷婷3:07640959|胡小华3:32278882|陈前军1,4:31973007",7,句法特征; 语义特征; 实体关系抽取; SVM;,"实体关系抽取的核心问题是实体关系特征的选择。以往的研究通常都以词法特征、实体原始特征等来刻画实体关系,其抽取效果已难再提高。在传统方法的基础上,该文提出一种基于句法特征、语义特征的实体关系抽取方法,融入了依存句法关系、核心谓词、语义角色标注等特征,选择SVM作为机器学习的实现途径,以真实新闻文本作为语料进行实验。实验结果表明该方法的F1值有明显提升。 ",MESS201406026
基于话题检测的自适应增量K-means算法,李胜东1:28515632|吕学强2:10724564|施水才2:10612775|孙军3:32278883,4,话题检测; 增量聚类; K-means算法; 话题检测与跟踪评测;,"根据话题检测任务的定义和特点,本文分析了传统的增量聚类算法和K-means算法的优缺点,提出了基于话题检测的自适应增量K-means算法,设计了话题检测实验,实验结果证明了该算法提高了话题检测性能,具有良好的应用前景。 ",MESS201406027
基于文本聚类的语言韵律和节奏风格特征挖掘,贺湘情:32278884|刘颖:08230768,8,特征挖掘; 韵律; 节奏; 文本聚类;,"该文以朱自清、汪曾祺和刘亮程的散文作品为语料,旨在从文本的韵律和节奏出发,采用文本聚类的方法来挖掘出新的能够代表作品风格的特征。实验表明,以句末用字韵母的n元组合、分句句长的n元组合、标点符号和整句句长作为风格特征,能成功地将这三位作家的作品区分开来。其中刘亮程句尾韵的舌位高于汪、朱二人,朱自清对韵脚的选择不如刘、汪二人丰富。汪曾祺的分句长最短,且最为讲究句式长短的对齐;刘亮程兼顾长短句的交错,节奏更富于变化;朱自清的句长变化最为平稳。 ",MESS201406028
基于词项—句子—文档三层图模型的多文档自动摘要,熊娇:32278885|王明文:08472511|李茂西:29475622|万剑怡:07869967,7,图模型; 多文档自动摘要; 句子相似度; 词项—句子—文档图;,"应用图模型来研究多文档自动摘要是当前研究的一个热点,它以句子为顶点,以句子之间相似度为边的权重构造无向图结构。由于此模型没有充分考虑句子中的词项权重信息以及句子所属的文档信息,针对这个问题,该文提出了一种基于词项—句子—文档的三层图模型,该模型可充分利用句子中的词项权重信息以及句子所属的文档信息来计算句子相似度。在DUC2003和DUC2004数据集上的实验结果表明,基于词项—句子—文档三层图模型的方法优于LexRank模型和文档敏感图模型。 ",MESS201406029
基于依存句法分析的社会媒体文本挖掘方法——以饮食习惯特色分析为例,任彬:32278886|车万翔:06987220|刘挺:06994824,8,依存句法分析; 文本挖掘; 社会媒体; 饮食习惯特色分析;,"在进行社会媒体文本挖掘时,传统的基于词表的方法,存在准确率较低、词表难获得等问题。该文提出一种基于依存句法分析的文本挖掘方法,通过规则匹配的方式从社会媒体文本中提取信息。该方法不依赖词表,且实验证明了相比基于词表的方法在准确率上有大幅提高。应用基于依存句法分析的文本挖掘方法,我们在微博文本上进行了饮食习惯特色分析,实现了性别、地区、时间等维度的饮食习惯特色分析并可进行交叉分析,最终用词云的方式展示了结果。 ",MESS201406030
基于LM算法的领域概念实体属性关系抽取,"刘丽佳1,2:32278887|郭剑毅1,2:07895859|周兰江1,2:07894197|余正涛1,2:05982358|邵发1,2:32173560|张金鹏1,2:32173561",7,BP神经网络; LM算法; 属性关系抽取;,"针对非结构化自由文本中关系模式比较复杂,关系抽取性能不高的问题,该文提出了利用BP神经网络的优化算法-LM算法,对非结构化自由文本信息中的领域概念实体属性关系进行抽取。首先对语料进行预处理,然后利用CRFs模型对领域概念的实例、属性和属性值进行实体识别,然后根据领域中各类关系的特点分别进行特征提取,构造BP神经网络模型,利用LM算法抽取相应关系。和适用于二分类问题的SVM相比,人工神经网络优化算法自主学习能力强,识别精度高,更适用于多分类的问题。通过几组实验表明,该方法在领域概念实体属性关系抽取方面取得了良好的效果,F值提高了12.8%。 ",MESS201406031
2015年《中文信息学报》征订启事,,1, ,"<正>《中文信息学报》是全国一级学会—社团法人中国中文信息学会和中国科学院软件研究所联合主办的学术性刊物,创刊于1986年10月,现为双月刊,大16开,每期206面,由商务印书馆出版,成为商务印书馆期刊方阵中的期刊之一,清华大学印刷厂印刷。《中文信息学报》是我国计算机、计算技术类刊物中的中文核心期刊。主要刊登中文信息处理基础理论与应用技术方面的高水平学术论文,内容涵盖计算语言学(包括语音与音位、词法、句法、语义、语用等各个层面上的计算),语言资源建设(包括计算词汇学、术语学、电子词典、语 ",MESS201406032
商务印书馆新书介绍,,1, ,"<正>《语法修辞讲话》是汉语语法研究的经典著作。1951年6月6日开始在《人民日报》连续刊登,并很快出版了单行本,在全国掀起了学习语法修辞的热潮,极大地推动了我国语言文字应用的规范化进程,影响极为深远。2011年,适逢《语法修辞讲话》发表60周年,这部经典著作转由商务印书馆重新出版。 ",MESS201406033
基于字符的中文分词、词性标注和依存句法分析联合模型,郭振:29895361|张玉洁:10874141|苏晨:29895360|徐金安:25200603,9,联合模型; 中文分词和词性标注; 依存句法分析; 词语内部依存结构; 半监督学习;,"目前,基于转移的中文分词、词性标注和依存句法分析联合模型存在两大问题:一是任务的融合方式有待改进;二是模型性能受限于全标注语料的规模。针对第一个问题,该文利用词语内部结构将基于词语的依存句法树扩展成了基于字符的依存句法树,采用转移策略,实现了基于字符的中文分词、词性标注和依存句法分析联合模型;依据序列标注的中文分词方法,将基于转移的中文分词处理方案重新设计为4种转移动作:Shift_S、Shift_B、Shift_M和Shift_E,同时能够将以往中文分词的研究成果融入联合模型。针对第二个问题,该文使用具有部分标注信息的语料,从中抽取字符串层面的n-gram特征和结构层面的依存子树特征融入联合模型,实现了半监督的中文分词、词性标注和依存句法分析联合模型。在宾州中文树库上的实验结果表明,该文的模型在中文分词、词性标注和依存分析任务上的F1值分别达到了98.31%、94.84%和81.71%,较单任务模型的结果分别提升了0.92%、1.77%和3.95%。其中,中文分词和词性标注在目前公布的研究结果中取得了最好成绩。 ",MESS201406001
基于汉语音位发音想象的脑机接口研究,"杨晓芳1,2:31760398|江铭虎1,2:08821580",11,脑机接口; 运动想象; 音位发音;,"该文提出了一个基于汉语音位发音想象的脑机接口系统框架,使得受试者使用脑机接口系统时能更加自然和流畅。三名受试者参与了本实验研究,实验过程中受试者被要求想象四个汉语元音和四个辅音音位的发音部位及语音发音,以及一个不作想象任务的控制条件,同时记录其脑电数据。在数据处理阶段,本文对采集到的头皮脑电数据进行了频域、时域、空域分析,以提取出音位发音想象效应最优化的特征向量用于提高每两个条件间的配对分类效果。实验结果表明,音位发音想象效应的最优脑电频段为2~10Hz,时段为刺激呈现后300~500ms,头皮空间分布主要集中在感觉运动皮层区域。音位发音想象任务和控制条件相比具有较高的分类正确率,最高可达83%,为基于音位发音想象的汉语脑机接口系统研究提供了理论基础。此外,刺激材料间的Jaccard距离和分类正确率的高度相关性表明,音位发音想象任务可被视为复杂的发音器官运动想象任务,并且可由人脑感觉运动皮层区域的脑电信号来解码预测。 ",MESS201405002
语言同现网、句法网、语义网的构建与比较,赵怿怡1:30602481|刘海涛2:09332506,9,同现网; 句法网; 语义网;,"网络方法应用于语言研究是语言研究大数据时代的新趋势。语言是一个多层级的符号系统,选择哪种语言单位作为网络节点,选择哪种语言单位间的关系作为网络联结,影响到语言网络的结构和功能。该文梳理了以汉语词为单位,以同现、句法、语义关系为联结依据的几类网络构造方法,并针对同一文本构造三类网络发现:句法网络的网络直径、平均路径长度远小于同现网络,实词在语义网络中占据中心节点位置。这提示我们网络分析方法的应用仍要以可靠的语言学理论为指导,从语言学内部出发才能更好解释各类语言网络的差异。 ",MESS201405003
基于语块和条件随机场(CRFs)的韵律短语识别,"钱揖丽1,2:09166197|冯志茹1:31758520",7,韵律短语; 边界预测; 语块结构; 条件随机场;,"该文提出一种基于汉语语块这一浅层句法信息,并利用条件随机场模型的中文文本韵律短语边界预测方法。首先介绍语块的定义和标注算法,然后在进行了语块结构标注以及归并处理的语料上,利用CRFs算法生成相应模型对韵律短语进行识别。实验结果表明,基于语块信息的CRFs韵律短语识别模型的识别效果优于不利用语块结构的模型,其F值平均能够提高约十个百分点。 ",MESS201405004
利用扩展标记集的词结构分析,孙静:08848038|方艳:31568590|丁彬:27830998|周国栋:13898054,8,扩展标记集; 词结构分析; 前后缀; 序列标注问题;,"该文给出了一种与传统分词不同的词法分析选择,提出了一种利用扩展标记集来实现词内部结构分析的方法。首先阐述了词的内部结构特点,把结构中的前后缀视为特殊的词,进而通过识别出每一个词的前后缀来识别词的内部结构。方法是把词内部结构识别问题转换成序列标注问题,通过扩展标记集,采用CRF模型来实现词的内部结构分析。最终实验表明,无论是在总体性能上,还是在各层结构的识别上都取得了较高的准确度。 ",MESS201405005
量化词语的领域特征,刘冬明1:15080973|杨尔弘2:06429879,5,词的领域性; 话题检测; TF*IDF;,"词作为最小的语义单位,同领域之间具有复杂的关系,特别是较为常用的词,通常难以明确界定其所属领域。在某些应用中并非必须确定词和领域的明确关系,仅仅依赖词的领域性的量化值就能够取得较好的效果。该文根据大规模语料库中词的关联信息,采用无指导的方法,对词的领域性进行量化,其结果可以作为词的一种特征应用于文本分类、话题检测、信息检索等相关的自然语言处理中。最后,通过和常用的特征——TF*IDF在话题检测应用中进行对比,证明了其有效性。 ",MESS201405006
基于Word Embedding语义相似度的字母缩略术语消歧,"于东1,2:26514992|荀恩东1,2:06433984",9,字母缩略术语; 术语消歧; Word Embedding; 语义相似度;,"该文提出基于Word Embedding的歧义词多个义项语义表示方法,实现基于知识库的无监督字母缩略术语消歧。方法分两步聚类,首先采用显著相似聚类获得高置信度类簇,构造带有语义标签的文档集作为训练数据。利用该数据训练多份Word Embedding模型,以余弦相似度均值表示两个词之间的语义关系。在第二步聚类时,提出使用特征词扩展和语义线性加权来提高歧义分辨能力,提高消歧性能。该方法根据语义相似度扩展待消歧文档的特征词集合,挖掘聚类文档中缺失的语义信息,并使用语义相似度对特征词权重进行线性加权。针对25个多义缩略术语的消歧实验显示,特征词扩展使系统F值提高约4%,使用语义线性加权后F值再提高约2%,达到89.40%。 ",MESS201405007
基于量词的名词概念获取研究,王萌1:11695873|俞士汶2:06272028,6,概念获取; 量名搭配; 量词; 聚类;,"概念获取是自然语言理解领域中重要的研究课题。该文提出了一种基于汉语量词的名词概念描述方法,设计并实现了一个权重计算方案。通过聚类实验探索了量词对名词语义区分的作用和贡献,实验结果表明基于量词的名词概念表达方式是有效的,可以区分大部分名词概念。 ",MESS201405008
汉语语义选择限制知识的自动获取研究,贾玉祥1:10308738|王浩石1:31758521|昝红英1:09467924|俞士汶2:06272028|王治敏3:11255396,8,语义选择限制; 知识获取; HowNet; LDA(Latent Dirichlet Allocation);,"语义选择限制刻画了谓语对论元的语义选择倾向,是一种重要的词汇语义知识,对自然语言的句法、语义分析具有重要作用。该文研究汉语语义选择限制知识的自动获取,提出基于HowNet和基于LDA(Latent Dirichlet Allocation)的两种知识获取方法,对方法进行了实验对比与分析。实验表明,前者所获取的知识可理解性更好,后者所获取的知识应用效果更好。两种方法具有很好的互补性,我们提出了一个二者的融合方案。 ",MESS201405009
汉语语义倾向语料库的建设,杨江1:07440576|李薇2:22493291|彭石玉2:17420604,9,语义倾向; 语料库; 主观性; 建设;,"该文从研究背景、设计思路、标注体系和方法、加工步骤等方面介绍了汉语语义倾向语料库的建设过程。该语料库是一个以研究语言主观性表达为目的的共时、非平衡、单语标注语料库,依据语言主观性多维度描述体系而设计,规模为100万字,配备有集检索与统计、结果检查与可视化于一体的专用语料库工具箱系统,具有可用性大、标注质量高、语言学理据强等特点。 ",MESS201405010
面向微博文本的情绪标注语料库构建,姚源林1:31758522|王树伟1:31758523|徐睿峰1:07001926|刘滨1:26013754|桂林1:30330029|陆勤2:09238733|王晓龙1:06993266,9,情绪语料库; 语料库构建; 情绪标注; 微博文本;,"文本情绪分析研究近年来发展迅速,但相关的中文情绪语料库,特别是面向微博文本的语料库构建尚不完善。为了对微博文本情绪表达特点进行分析以及对情绪分析算法性能进行评估,该文在对微博文本情绪表达特点进行深入观察和分析的基础上,设计了一套完整的情绪标注规范。遵循这一规范,首先对微博文本进行了微博级情绪标注,对微博是否包含情绪及有情绪微博所包含的情绪类别进行多标签标注。而后,对微博中的句子进行有无情绪及情绪类别进行标注,并标注了各情绪类别对应的强度。目前,已完成14 000条微博,45 431句子的情绪标注语料库构建。应用该语料库组织了NLP&CC2013中文微博情绪分析评测,有力地促进了微博情绪分析相关研究。 ",MESS201405011
基于HowNet的航空术语语义知识库的构建,张桂平:24679273|刁丽娜:31758524|王裴岩:24679272,10,航空术语; HowNet; 语义知识库; KDML;,"语义知识库的构建是自然语言处理基础性工作,对于语言信息的处理有重要的作用,但面向特定领域的语义知识库的构建还是一个难点。该文在分析了航空术语的基本特点的基础上,根据HowNet和KDML描述语言构建了面向航空领域的术语语义知识库,并在构建航空术语知识库的过程中总结形成了构建航空术语知识库的基础规则、动态角色/特征的选择规则。在文章最后对所构建的术语进行了相似度的计算,取得了较好的结果。 ",MESS201405012
基于话题链的汉语语篇连贯性描述体系,"周强1,2:08836151|周骁聪1,2:31758525",9,话题链; 话题评述关系; 连贯性描述体系; 汉语语篇分析;,"汉语简洁灵活的意合型篇章组合结构,对传统的基于关联词的篇章连贯性描述体系提出了新的挑战。该文引入话题链描述形式,设计不同类型的话题评述关系集,构建了以话题链为主,融合关联词语和其他连贯形式描述机制,覆盖话题评述、并列、因果、转折四大类关系的汉语语篇连贯性描述体系。在清华句法树库TCT上进行的验证实验,发现话题链和关联词语分别覆盖了约76%和50%的汉语复句,并且两者经常同时使用,初步证明了这个体系在句子连贯性描述方面的可行性和有效性。 ",MESS201405013
从广义话题结构考察汉语篇章话题认知复杂度,卢达威1:30152896|宋柔1:05982879|尚英2:06428017,13,广义话题结构; 认知机; 认知复杂度; 标点句; 话题自足句; 汉语篇章;,"语言理解问题从认知的角度已有大量的研究,但针对汉语的研究却很少。由于认知实验操作复杂,不容易大规模复制,因此难以量化其结论的普遍性以及对语言事实的覆盖度。该文尝试模拟人补足汉语篇章片段中话题-说明信息的过程,建立广义话题结构认知机模型,并通过认知机对大规模汉语语料进行定量分析,考察汉语标点句的话题认知所需的记忆资源及认知局限性。用作统计特征量的广义话题结构特征有标点句的深度、话题结构内折返度、话题栈深度、话题栈折返度、搁置区使用量。统计数据可从认知行为的视角得到合理解释。该文一方面揭示了说汉语者的话题认知能力的表现和局限性,另一方面又说明了广义话题结构认知机是话题认知的合理模型。 ",MESS201405016
统计机器翻译删词问题研究,"李强1:06579825|何燕龙2:31761881|栾爽3:31761882|肖桐1,4:11698781|朱靖波1,4:06569435",8,统计机器翻译; 删词问题; 人工评价;,"该文对基于短语的统计机器翻译模型的删词问题进行研究与分析,使用人工评价的方式将删词错误分为3类。该文通过两种方法,即基于频次的方法和基于词性标注的方法,对源语言句子中关键词汇进行识别。通过对传统的短语对抽取算法中引入源语言对空关键词汇的约束来缓解删词错误问题。自动评价方法以及人工评价方法证明,该方法在汉英翻译任务以及英汉翻译任务中显著的缓解了删词错误问题,同时得到一个精简的短语翻译表。 ",MESS201405017
融合格框架的基于语块的依存树到串日汉统计机器翻译模型, ,9,日汉机器翻译; 格框架; 依存树到串模型; 句法结构;,"该文提出了一种融合格框架的日汉基于语块的依存树到串统计机器翻译模型。其基本思想是从日语依存分析树获取格框架,在翻译模型的规则抽取及解码中,以日语格框架作为约束条件,指导依存树的句法结构重排,调整日语和汉语的句法结构差异,实现格框架与日汉依存树到串模型的融合。实验结果表明,该文提出的方法可有效改善日汉统计机器翻译的句法结构调序和词汇翻译,同时,还可有效提高日汉统计机器翻译的译文质量。 ",MESS201405018
翻译规则剪枝与基于半强制解码和变分贝叶斯推理的模型训练,高恩婷1:22746197|段湘煜2:31758526|巢佳媛2:29222961|张民2:31758527,7,机器翻译; 规则剪枝; 半强制解码; 变分贝叶斯;,"统计机器翻译一般采用启发式方法训练翻译模型。但启发式方法的理论基础不够完善,因此,会导致翻译模型规模庞大以及模型参数精确率不高。针对以上两个问题,该文提出一种基于变分贝叶斯推理的模型训练方法,形成更精确的精简翻译模型。该方法首先通过强制解码对齐语料,然后利用变分贝叶斯EM算法获得模型参数。该文的实验语料为NIST汉英翻译任务数据,实验结果显示,基于句法(基于短语)的统计机器翻译中,超过95%(76%)的规则被剪枝,且BLEU值显著提高。 ",MESS201405019
微博汽车领域中用户观点句识别方法的研究,潘艳茜:31758528|姚天昉:08576605,7,微博; 观点句识别; 意见挖掘; SVM;,"该文主要研究如何自动识别微博中用户对各品牌汽车进行评价的句子。针对微博中汽车宣传信息较多而由真正汽车用户发出的观点句所占比例很小的特点,该文提出了结合微博和汽车评论语料的基于SVM模型的分类方法。选取的特征包括词语、评价词个数、与评价对象有关的词语以及微博相关特征。实验表明,评价词特征和部分微博相关特征可有效提高分类器性能,使用微博和汽车评论两种语料进行训练的分类器性能要比仅使用微博语料的方法好。 ",MESS201405020
基于深度学习的微博情感分析,梁军1:31758529|柴玉梅1:09463011|原慧斌2:25270833|昝红英1:09467924|刘铭1:14915075,7,深度学习; 微博情感分析; 递归神经网络; 自编码;,"中文微博情感分析旨在发现用户对热点事件的观点态度。已有的研究大多使用SVM、CRF等传统算法根据手工标注情感特征对微博情感进行分析。该文主要探讨利用深度学习来做中文微博情感分析的可行性,采用递归神经网络来发现与任务相关的特征,避免依赖于具体任务的人工特征设计,并根据句子词语间前后的关联性引入情感极性转移模型加强对文本关联性的捕获。该文提出的方法在性能上与当前采用手工标注情感特征的方法相当,但节省了大量人工标注的工作量。 ",MESS201405021
蒙古语短语结构树的自动识别,乌兰1:07985123|达胡白乙拉1:07994523|关晓炟2:31758530|周强3:08836151,9,蒙古语; 短语结构语法; 句法树库; 自动识别;,"句法分析在自然语言信息处理中处于非常关键的位置。该文在描述蒙古语特点的同时提出蒙古语句子中短语结构分析难点。根据蒙古语自身特点,归纳了短语标注体系,建立了蒙古语短语树库,尝试实现蒙古语句子的自动分析。初次开发的句法分析器的分析准确率达到62%,自动分析器的测试结果表明该分析器能在较大程度上辨别出短语结构类型,能生成句法树结构,但在短语结构内部关系方面的识别效果还有很大改进空间。最后总结了分析器近期能解决的相关问题。 ",MESS201405022
基于错误驱动学习策略的藏语句法功能组块边界识别,"王天航1:31758531|史树敏1,2:24549646|龙从军3:11531165|黄河燕1,2:23136252|李琳3:28907685",7,错误驱动学习; 藏语句法功能组块; 组块边界识别; CRFs; TBL;,"藏语句法功能组块分析旨在识别出藏语句子的句法成分,为后续句子级深入分析提供支持。根据藏语的语言特点,该文在藏语句法功能组块描述体系基础上,提出基于错误驱动学习策略的藏语功能组块边界识别方法。具体思路为,首先基于条件随机场(Conditional Random Fields,CRFs)识别组块,然后分别基于转换规则的错误驱动学习(Transformation-based Error-driven Learning,TBL)及基于新特征模板的CRFs错误驱动学习进行二次识别,并对初次结果进行校正,F值分别提高了1.65%、8.36%。最后通过实验分析,进一步将两种错误驱动学习机制融合,在18 073词级的藏语语料上开展实验,识别性能进一步提高,准确率、召回率与F值分别达到94.1%、94.76%与94.43%,充分验证了本文提出方法的有效性。 ",MESS201405023
基于多策略的藏语语义角色标注研究,"龙从军1,2:31443610|康才畯1:31758533|李琳3:28907684|江荻1:09888697",6,藏语; 语义角色标注; TBL; CRFs;,"语义角色标注研究对自然语言处理具有十分重要的意义。英汉语语义角色标注研究已经获得了很多成果。然而藏语语义角色标注研究不管是资源建设,还是语义角色标注的技术探讨都鲜有报道。藏语具有比较丰富的句法标记,它们把一个句子天然地分割成功能不同的语义组块,而这些语义组块与语义角色之间存在一定的对应关系。根据这个特点,该文提出规则和统计相结合的、基于语义组块的语义角色标注策略。为了实现语义角色标注,文中首先对藏语语义角色进行分类,得到语义角色标注的分类体系;然后讨论标注规则的获得情况,包括手工编制初始规则集和采用错误驱动学习方法获得扩充规则集;统计技术上,选用了条件随机场模型,并添加了有效的语言特征,最终语义角色标注的结果准确率、召回率和F值分别达到82.78%、85.71%和83.91%。 ",MESS201405024
维吾尔语语音检索技术研究,张力文:31758534|努尔麦麦提·尤鲁瓦斯:28479964|吾守尔·斯拉木:17705001,6,维吾尔语; 语音检索; 语音识别; 词图; 混淆网络; 倒排索引;,"随着大数据时代的到来,各种音频、视频文件日益增多,如何高效地定位关键敏感信息具有非常重要的研究意义。目前研究人员对针对英语和汉语的语音检索技术进行了深入的研究,而针对维吾尔语的语音检索技术还处于起步阶段。该文对维吾尔语语音关键词检索技术进行了研究并采用了大词汇量连续语音识别、利用聚类算法将多候选词图转换为混淆网络、倒排索引、置信度以及相关度的计算等技术和方法,对维吾尔语语音检索系统进行了研究与搭建。最后在测试集上对该系统进行测试,测试结果显示,在语音识别正确率为82.1%的情况下,检索系统的召回率分别达到97.0%和79.1%时,虚警率分别为13.5%和8.5%。 ",MESS201405025
基于感知器算法的维吾尔语词性标注研究,帕提古力·依马木:31758536|买合木提·买买提:22440290|吐尔根·依布拉音:17705003|卡哈尔江·阿比的热西提:31758537,5,词性标注; 感知器算法; 维吾尔语词性标注;,"维吾尔语自动标注是维吾尔语信息处理后续句法分析、语义分析及篇章分析必不可少的基础工作。词性是词的重要的语法信息,假如一个词的词性无法确定或一个词给予错误的词性,对后续句法分析造成直接的影响。本文使用感知器训练算法和viterbi算法对维吾尔语进行词性标注,并在词性标注时利用词的上下文信息作为特征。实验结果表明,该方法对维吾尔语词性标注有良好的效果。 ",MESS201405026
现代维吾尔语常用词统计关键技术研究,艾孜尔古丽:26177339|努尔艾合买提:31758538|玉素甫·艾白都拉:22251454,6,现代维吾尔语; 语料库; 常用词候选表; 计量分析;,"本文研究了构建现代维吾尔语语料库的关键技术与方法,特别是现代维吾尔语语料库的构建,并对现代维吾尔语语料预处理技术,现代维吾尔语语料统计技术,现代维吾尔语词干提取技术,现代维吾尔语数据分析技术进行了研究;研制了现代维吾尔语常用词候选表,从词语的使用频度和词语的分布两方面对词语进行了基本考察,将维吾尔语词语的""词种数、频次、频率、文本数、词长""作为常用词候选表的依据。 ",MESS201405027
基于规则的越南语命名实体识别研究,闫丹辉:26269178|毕玉德:20374626,9,命名实体识别; 越南语; 规则;,"命名实体识别是信息抽取的重要研究内容,主要包括对组织机构名、地名和人名的自动识别。针对英语和汉语的命名实体识别研究开始较早,主要采用基于规则和基于统计的方法进行识别,但目前国内还少有针对越南语命名实体识别的研究。该文分析了越南语命名实体的语言学特点,对其分类并进行了形式化表达,提出了一种基于规则的越南语命名实体识别方法,实验结果显示,该方法能够达到较高的识别准确率。 ",MESS201405028
基于跨场景推理的事件关系检测方法,杨雪蓉:28523621|洪宇:25038035|陈亚东:24880537|王潇斌:28130962|姚建民:13898051|朱巧明:09891804,9,事件关系; 框架语义; 事件场景向量; 事件场景;,"事件关系检测是一项面向事件之间逻辑关系的自然语言处理技术。事件关系识别的核心任务是以事件为基本语义单元,通过分析事件的篇章结构信息及语义特征,实现事件逻辑关系的深层检测。该文首次建立一套事件关系检测的任务和研究体系,包括任务定义、关系体系划分、语料采集与标注、评价方法等。同时,该文提出了一种跨场景推理的事件关系检测方法,该方法认为,具有相同事件场景的""事件对"",往往具有相同的事件关系类型。该文提出的基于跨场景推理的事件关系检测方法在针对四大类事件关系类型的检测精确率为54.21%。 ",MESS201405029
添加冒号和分号分类标签特征的汉语逗号分类,"李艳翠1,2,3:17502135|谷晶晶1,3:31568599|周国栋1,3:13898054",8,逗号分类; 冒号标签; 分号标签; 篇章分析;,"标点分析在句子和篇章分析中有重要作用,其中逗号的功能分类是标点分析的重点和难点。该文研究添加冒号和分号分类标签为特征的逗号自动分类。首先给出逗号、冒号和分号的分类方法;然后介绍基于此分类方法的逗号、冒号和分号标点分类语料库;最后分别考察添加冒号类别标签、分号类别标签以及同时添加冒号和分号类别标签为特征的逗号分类结果。实验结果表明,三种情况下的逗号分类正确率均有不同程度的提高。 ",MESS201405030
第十三届全国计算语言学会议(CCL2014)在华中师范大学召开,李波:07645434,1, ,"<正>2014年10月18日至19日,第十三届全国计算语言学会议(CCL 2014)在华中师范大学召开。会议主办单位是中国中文信息学会,组织单位是清华大学信息科学与技术国家实验室,承办单位是华中师范大学。全国计算语言学会议是中国中文信息学会的旗舰会议,从1991年开始每两年举办一次,从2013年开始 ",MESS201405014
2015年《中文信息学报》征订启事,,1, ,"<正>《中文信息学报》是全国一级学会—社团法人中国中文信息学会和中国科学院软件研究所联合主办的学术性刊物,创刊于1986年10月,现为双月刊,大16开,每期206面,由商务印书馆出版,成为商务印书馆期刊方阵中的期刊之一,清华大学印刷厂印刷。《中文信息学报》是我国计算机、计算技术类刊物中的中文核心 ",MESS201405015
商务印书馆新书介绍,,1, ,"<正>本书以语言学理论为纲,从现实交际活动出发,将理论研究与言语交际实践融为有机整体,构建了缜密独到的修辞学新体系;同时,力求解决表达与理解方面的问题,帮助读者提高运用语言的能力。自第一版出版以来,本书一直以其理论创新、科学实用而受到广泛赞誉,是众多高校修辞学课程的必备教材。不仅是学术研究的必读参考书,也是报考语言学及应用语言学专业研究生的重要参考书。 ",MESS201405031
开放式信息抽取研究进展,杨博1:28999911|蔡东风1:24679274|杨华2:24708721,12,开放式信息抽取; 联合推理; 文本理解;,"从大规模非结构化文本中自动地抽取有用信息是自然语言处理和人工智能的一个重要目标。开放式信息抽取在高效挖掘网络文本信息方面已成为必然趋势,按关系参数可分为二元、多元实体关系抽取,该文按此路线对典型方法的现状和存在问题进行分析与总结。目前多数开放式实体关系抽取仍是浅层语义处理,对隐含关系抽取很少涉及。采用马尔科夫逻辑、本体结构推理等联合推理方法可综合多种特征,有效推断细微完整信息,为深入理解文本打开新局面。 ",MESS201404001
焦点的韵律表达及认知加工研究综览,"厚露莹1,2:29402733|贾媛1:23372150",10,焦点; 重音; 韵律加工; 事件相关电位;,"焦点是语言学界广泛关注的问题。随着实验语音学与心理语言学的发展,国内外对焦点的韵律表达及认知加工方面的研究发展迅速,主要涉及焦点的语音与音系表征、焦点与重音的对应关系,以及句子理解中焦点加工与韵律加工的大脑机制等问题。该文从这一角度对相关研究进行回顾与总结,介绍该领域的发展状况及主要研究方向并提出见解和评论,以期对今后的研究有所启发。 ",MESS201404002
社会媒体短文本内容的语义概念关联和扩展,"肖永磊1,2:29294588|刘盛华1:28368035|刘悦1:09639001|程学旗1:09559496|赵文静3:22584224|任彦4:22393034|王宇平3:09040796",8,短文本; 概念; 非负矩阵分解; 锚文本; 语义相似度; 概念消歧; Wikipedia;,"随着微博、照片分享等社会化媒体的快速发展,每天产生了大量的短文本内容如评论、微博等,对其进行深入挖掘有重大的应用价值和学术意义。该文选取微博作为例子,详细阐述我们提出的方法。微博信息流因其简短和实时的特性而具有非常大的价值,已经成为市场营销,股票预测、舆情监控等应用的重要信息源。尽管如此,微博内容特征极其稀疏、上下文语境提取困难,使得微博信息的挖掘面临着很大挑战。因此,我们提出一种基于Wikipedia的微博语义概念扩展方法,通过自动识别那些与微博信息语义相关的Wikipedia概念来丰富它的内容特征,从而有效提高微博信息数据挖掘和分析的效果。该文工作首先通过可链接性剪枝、概念关联和消歧,发现微博信息中重要的n-gram所对应的Wikipedia概念;其次,采用基于概念-文档关联矩阵的NMF分解(非负矩阵分解)方法获取Wikipedia概念之间的语义近邻,为微博信息扩展相关的语义概念。基于TREC 2011的微博数据集和Wikipedia 2011数据集进行实验,与已有两个相关研究工作比较,该文提出的方法取得了较好的效果。 ",MESS201404003
基于多层协同纠错的中文层次句法分析,蒋志鹏:25567860|关毅:06991644|董喜双:25202940,8,层次句法分析; 条件随机域模型; 组块分析; 多层协同纠错;,"层次句法分析是一种简单快速的完全句法分析方法,该方法将句法分析分解为词性标注、组块分析和构建句法树三个阶段。该文将其中的组块分析细分为基本块分析和复杂块分析,利用条件随机域模型代替最大熵模型进行序列化标注。由于层次句分析中错误累积问题尤为严重,该文提出了一种简单可行的错误预判及协同纠错算法,跟踪本层预判的错误标注结果进入下一层,利用两层预测分数相结合的方式协同纠错。实验结果表明,加入纠错方法后,层次句法分析在保证解析速度的同时,获得了与主流中文句法分析器相当的解析精度。 ",MESS201404004
基于文本和视觉特征融合的Web动画素材标注,邱兆文:06579274|吴瑕:28143255|陈海燕:30923868,6,Web动画素材; 文本特征; 视觉特征; 语义标注;,"为了提高对Web动画素材的组织、管理,该文提出了基于文本特征和视觉特征融合的Web动画素材标注算法。首先利用自动提取的Web动画素材上下文信息,结合Web动画素材名称、页面主题、URL以及ALT等属性组成特征集,提取出文本关键字;然后利用视觉与标注字之间的相关性,对自动提取的标注字进行过滤,实现Web动画素材的自动标注。实验表明该文提出的基于文本特征和视觉特征融合的Web动画素材标注算法可有效地应用于Web动画素材自动标注。 ",MESS201404005
基于句式结构的高效语法图解标注系统,"杨天心1:31524541|彭炜明2,3:30613113|宋继华1:06364557",8,树库; 句本位语法; 句式结构; 图解标注;,"为支持基于句式结构的大规模树库建设与研究,该文设计了人机结合的可视化语法图解标注系统,通过句式结构的框架约束和词汇知识库的底层支持有效规范了标注结果的结构层次和词性标记,在一定程度上保证了树库标注的一致性和高效率。该文从实践角度介绍了基于句式结构的语法图解标注系统在辅助构建大规模汉语树库中的操作模式和功能。 ",MESS201404006
基于融合特征的微博主客观分类方法,"张晓梅1:31511192|李茹1,2:08453268|王斌1:08409033|吴迪1:25839873|高俊杰1:23136278",8,微博; 主客观分类; 特征选择; 融合算法;,"针对现有微博主客观分类方法特征冗余度高和未考虑特征选择方法之间的互补关系问题,该文提出了一种基于融合特征的微博主客观分类方法。通过对多种不同特征选择方法进行有效组合,利用特征融合算法对词特征、内容特征、微博特征等基本特征进行了选择和融合,以获取更加有效的主客观分类特征。在新浪微博数据上的实验结果表明,该特征融合算法能够获得比最优单一特征选择方法更好的分类效果。 ",MESS201404007
一种迭代式的概念属性名称自动获取方法,"汪平仄1,2:29246681|曹存根1:10348278|王石1:23246662",10,概念; 属性; 属性前缀; 属性后缀; 属性元; 知识获取;,"属性是一种用于描述概念和鉴别概念的特殊知识。属性名称是表示属性的专有名词。该文提出了一种基于前后缀迭代的方法,从Web网页中获取概念的属性名称。该方法的每一次迭代分为两个阶段:(1)从现有种子属性集中选择合适的前后缀,构造词汇-句法模式,从Web网页中提取候选属性;(2)采用基于相似性的验证模型对候选属性进行验证,以扩充现有属性集合。该文提出了一组验证模型对候选属性进行验证,比较各个模型的优缺点,并在地域类和商业主体类概念上分别得到了平均92.9%和90.7%的准确率,以及对原有种子属性集合近100倍的扩充率。 ",MESS201404008
完全加权正负关联规则挖掘及其在教育数据中的应用,余如1:24952312|朱朝阳2:27617937|黄名选2:10824273,8,概率比; 兴趣度; 完全加权关联规则; 文本挖掘;,"完全加权数据模型的特点是其项目权值分布在各个事务记录中,随着事务记录的不同而变化。现有的加权负关联规则挖掘算法不能适用于完全加权数据模型。该文提出一种新颖的基于概率比和兴趣度的完全加权正负关联规则的挖掘算法,探讨了算法在教育信息化数据中的应用。算法以概率比代替传统的置信度,采用支持度-概率比-兴趣度架构衡量完全加权正负关联规则,获得很好的挖掘效果。以真实的教育数据和文本数据为实验测试集,与现有正负关联规则挖掘算法比较,该文提出的算法更有效、更合理,具有较高的理论价值和应用前景。 ",MESS201404009
维基百科中争议性文章的发现方法研究,常天舒:29353015|林鸿飞:06504899,8,维基百科; 争议度排序; 社会网络分析;,"维基百科收录的文章和参与编辑的用户日益增多,其中不乏一些用户对同一条目持有不同的见解。该文旨在发现维基百科中的争议性文章,通过维基百科提供的历史信息,在传统的挖掘方法基础上,对具有特殊属性的用户角色进行总结并融合到排序模型中,探讨这类用户对争议性文章挖掘的作用。在16 745篇文章组成的数据集上进行了实验,除传统的PRF和NDCG评价外,该文给出了更直观的排序结果,与其他基准模型相比有较大的提升。 ",MESS201404010
基于带汇点流形的面向属性抽取式观点摘要,"徐学可1,2:28861560|谭松波1:09596688|刘悦1:09639001|程学旗1:09559496",9,在线顾客点评; 面向属性抽取式观点摘要; 带汇点的流形排序; 属性观点联合模型;,"该文研究面向在线顾客点评的面向属性抽取式观点摘要问题。传统方法主要考虑如何抽取属性相关观点,该文提出进一步考虑观点的富含信息(informativeness)、重要性(salience)及多样性(diversity)这三方面要求。该文提出了一个基于带汇点的流形排序的一体化的摘要抽取模型,在一体化的流形排序过程中同时考虑三方面要求。在餐馆点评数据上的实验表明了所提出三方面要求的合理性及摘要抽取模型的有效性。 ",MESS201404012
基于句法特征的评价对象抽取方法研究,戴敏:13965564|王荣洋:27033941|李寿山:27030929|朱珠:24245910|周国栋:13898054,6,情感分析; 评价对象; 句法特征; 条件随机场;,"评价对象抽取是情感分析任务中一个重要的子任务。该文使用基于条件随机场模型的监督学习方法实现英文的评价对象抽取。为了更好的捕捉评价对象和情感词之间的关系,引入句法分析用以加入丰富的句法特征提高评价对象抽取性能。实验中,我们在两个不同的数据集上考查了句法特征对评价对象抽取性能的影响,并做了详细的分析比较。实验结果表明,将句法特征应用在评价对象抽取任务中能够取得不错的效果,明显提高了评价对象的抽取召回率。 ",MESS201404013
一种基于类别先验信息的问题检索语言模型,"吉宗诚1,2:25200607|王斌1:09559997",7,社区问答; 问题检索; 类别; 类别先验信息; 语言模型;,"社区问答系统已经积累了大量的以层次类别结构进行组织的问题答案对。为了能够重用这些非常宝贵的历史问题答案对资源,设计出一个非常有效的问题检索模型至关重要。在该文中,我们在语言模型建模的框架下提出了一种新的基于问题类别先验信息的方法来提高相似问题检索的性能。特别地,我们将叶子类别语言模型看作是Dirichlet超参来对一元语言模型的参数进行加权,从而提出了一种新的基于类别先验信息的语言模型。该方法具有严格的数学推导依据。在来源于Yahoo!Answers的真实的大量数据集上做了实验比较和分析,实验结果表明我们提出的方法比之前简单的线性插值的方法具有非常显著的性能提升。 ",MESS201404014
基于词语关联度的查询缩略, ,7,查询缩略; 词语关联度; 评价方式;,"冗长查询指用户提交的句子成份复杂的查询。当前的搜索引擎对于关键字的检索取得了较好的结果。但是对于冗长的查询,如果将所有词作为关键字进行检索,往往只能返回相当有限的结果。我们尝试利用关键词之间的词语关联度,发现语义蕴含,删除""信息量""小的关键词,提高检索的效果。对于实验结果,我们分别从""面向机器""和""面向用户""两个角度进行评价。在""面向机器""的评价部分,我们根据搜索引擎返回结果的标红率和结果数进行自动评价;在""面向用户""的评价部分,我们对搜索结果文档进行人工评价。实验结果表明,我们的方法能够明显提高检索结果的数量和质量。 ",MESS201404015
交互式问答系统中待消解项的识别方法研究,张超:08850128|孔芳:08865090|周国栋:13898054,7,交互式问答; 待消解项识别; 指代消解;,"交互式问答系统能够与用户进行对话式交互进而处理用户提出的一系列问题。交互式问答技术是近些年来问答技术的一个热门方向。该文首次深入研究交互式问答中待消解项的识别方法。根据语料统计了交互式问答中待消解项的分布情况并进行相关实验,运用前人研究的启发式规则与平面特征相结合的方法在交互式问答中测试识别待消解项的性能。结合交互式问答的特点提出了专有名词的两个基于交互式问答特点的特征,并在TREC QA问题集语料中进行相关实验。实验结果表明,代词、有定名词用已有的方法识别效果较好,在加入本文提出的新特征后,在专有名词上也取得了较好的效果。 ",MESS201404016
基于标签混合语义空间的音乐推荐方法研究,闫俊:23546707|刘文飞:28368044|林鸿飞:06504899,6,音乐推荐; 社会化标签; 语义空间;,"目前,音乐越来越受到人们的青睐。如何为用户推荐符合用户需求的歌曲成为了很多音乐网站、电台以及其他相关音乐媒介关心的话题。针对这个问题,该文选取了社会化标签作为推荐方法的主要依据,首先将其分别映射到流派、情感和上下文信息三个语义空间中,然后在三个空间分别计算用户和歌曲的相似度,最后通过不同方法将三个空间的相似度进行融合从而对用户进行歌曲推荐。实验表明,融合不同空间相似度的推荐方法得到了很好的效果。 ",MESS201404017
基于多特征微博话题情感倾向性判定算法研究,刘全超:30593026|黄河燕:23136252|冯冲:24549647,9,微博; 微博话题; 情感分析; 观点分析; 情感倾向性;,"社交网络舆情分析是一种新的研究趋势,而其中微博话题的情感倾向性判定是社交网络舆情分析中的热点。针对微博内容特征以及微博间转发、评论关系特征,构建情感分析用词典、网络用语词典以及表情符号库,设计基于短语路径的微博话题情感倾向性判定算法,以及基于多特征的微博话题情感倾向性判定算法,并进一步利用微博间的转发和评论关系对基于多特征的微博话题情感倾向性判定算法进行优化,其微平均正确率与F值分别达到85.3%和79.4%。 ",MESS201404018
藏语自动分词中的几个关键问题的研究,完么扎西1:28070116|尼玛扎西2:09194628,8,未登录词; 紧缩词; 交集型歧义;,"在分析现有的藏语自动分词方法基础上,该文通过分析藏文构词规则、句法结构、词的前后词性关系、后加字的添接法和格助词的用法等来重点研究了未登录词、紧缩词和交集型歧义的识别及处理方法,并提出了""重组法"",""排除—还原法""和""词性规则法""三种方法。经测试,在文学类、诗歌类、医学类和新闻类等大小为1M的藏语语料中未登录词、紧缩词和交集型歧义的识别准确率分别达到99.84%、99.95%和92.02%。 ",MESS201404019
语义词特征提取及其在维吾尔文文本分类中的应用,吐尔地·托合提:17704504|艾克白尔·帕塔尔:22511430|艾斯卡尔·艾木都拉:17704444,5,维吾尔文分词; 词特征; dme-TS; 语义词特征; 文本分类;,"基于机器学习的文本分类中,维吾尔文传统分词方法表现出非常明显的不足和局限性。该文使用另外一种维吾尔文自动分词方法dme-TS。dme-TS中,不再以词间空格作为切分标记提取词特征,而是用一种组合统计量(dme)来度量文本中相邻单词之间的关联程度,并以dme度量的弱关联的词间位置作为切分点,提取对学习算法真正有意义的语义词特征。实验结果表明,用dme-TS提取文本特征可以降低特征空间的维度,同时也能有效的提高传统以单词为特征的分类算法的性能。 ",MESS201404020
书法字库的设计实现与管理,邱明锋:07980461,8,书法信息传播; 图像二值化; 字形技术; 书法字库; 字体管理;,"通过对书法字库现状分析,阐述了书法字模创作、纸质书法字模二值化处理,数字书法图像切分、曲线轮廓描述与编码的过程;应用OpenType字形技术的开源性来设计书法字库的特殊性和添加连笔、行气、章法、风格等脚本;利用字库编辑软件与脚本工具生成OpenType书法字库。提出了解决当前网页、手机浏览缺失书法字体的思路,是设计出与世界文字信息交流相匹配的书法字库,并实现其在操作系统中的管理,使中国传统的书法文化能在电子信息交流中更好地得到传承和发展。 ",MESS201404021
论贵州古彝文编码字符集构建,吴勰:17734144|禄玉萍:11414297|王明贵:27176010,6,古彝文; 编码字符集; 彝文信息处理;,"依托彝文古籍文献开展古彝文字符整理和规范研究,建立古彝文编码字符集有很高的要求和极大的工作量。这项工作有助于实现古彝文规范化应用,为古彝文信息技术开发提供基础保障。实现这一构想:需要最大限度地搜集整理古彝文字符,广泛听取彝文专家建议和意见,经过充分的科学论证,对搜集的古彝文字符进行甄别、查重、筛选和择定,剔除大量古彝文异体字形,在此基础上规范古彝文的字量、字形、字音和字序,实现计算机技术处理古彝文字符信息的规范化。 ",MESS201404022
第十二届国际语言学奥林匹克竞赛在北京语言大学成功举行,饶高琦:28523622,1, ,"<正>2014年7月21日,第十二届国际语言学奥林匹克竞赛(International Linguistics Olympiad,简称IOL)在北京语言大学隆重开幕。来自美国、加拿大、俄罗斯、西班牙、巴西、韩国、日本等28个国家的39支高中生代表队会聚北京。在经过激烈的个人赛和团体赛之后,本届大赛于25日落下帷幕。今年我国派出了两支高中生代表队,共获得了4枚个人赛银牌、1枚个人赛铜牌、1项个人优秀奖和公 ",MESS201404011
第二十届全国信息检索学术会议(CCIR2014)在昆明召开,,1, ,"<正>第二十届全国信息检索学术会议(CCIR2014)由昆明理工大学承办,于2014年8月8日至10日在昆明举行。会议得到了包括昆明能讯科技有限责任公司、云南云电同方科技有限公司、北京拓尔思信息技术股份有限公司、北京创新乐知信息技术有限公司、北京秒针信息咨询有限公司、百度、北京捷通华声语音技术有限公司、昆明英捷机电工程有限责任公司、北京搜狗科技发展有限公司大力支持。本届会议共收到论文315篇。通过通信评审和 ",MESS201404023
商务印书馆新书介绍,,1, ,"<正>《现代汉字学纲要》(第3版)苏培成著2014年6月出版开本:32开定价:33.00元ISBN 978-7-100-10440-1本书是现代汉字课程的教材,也是研究现代汉字的重要参考书,由作者在历年讲稿的基础上整理、补充而成,主要研究现代汉字的属性和应用,包括现代汉字的字量、字音、字序,汉字的 ",MESS201404024
基于规则的汉语名名组合的自动释义研究,魏雪:06260540|袁毓林:06263991,10,名名组合; 自动释义; 释义动词; 语义类; 释义模板; 施成/功能角色;,"该文以现代汉语(特别是网络搜索词)中的名名组合为主要研究对象,探索一种基于规则的汉语名名组合的自动释义方法。其研究步骤为:(1)利用《现代汉语语义词典》中名词的语义类别,来建立名名组合的语义类组合模式;(2)在""生成词库论""中物性角色思想的指导下,用名名组合中某个名词的施成角色或功能角色作为释义动词,来揭示这两个名词之间的语义关系;(3)以语义类组合模式为单位构建名名组合的释义模板,并汇集成名名搭配数据库;(4)利用《知网》资源,来获取具体名词的施成角色和功能角色,建立汉语名词知识库。在这两个数据库的基础上,我们初步实现了一个汉语名名组合的自动释义程序。 ",MESS201403001
衔接性驱动的篇章一致性建模研究,徐凡1:31367729|朱巧明2:05968617|周国栋2:13898054|王明文1:08472511,12,篇章衔接性; 篇章一致性; 主位—述位结构; 指代消解;,"该文系统地探索了衔接性理论对篇章一致性建模的作用。不同于目前有监督的基于实体和篇章关系网格的模型,该文提出的无监督模型揭示了系统功能语法中主位—述位结构理论对于篇章一致性建模的重要性,同时显示了基于主位和指代消解两种过滤机制对于篇章一致性建模的适用性。在三种不同文体的国际基准语料上进行的句子排序和文本摘要一致性检测任务实验表明主位—述位结构和指代消解信息能使篇章一致性检测准确率得到显著提升。 ",MESS201403002
动词引出新支话题的语用功能研究,季翠:29713692|卢达威:30152896|宋柔:05982879,6,新支话题; 动词; 分类体系;,"汉语是一种话题显著的语言。汉语篇章中,同一话题会多次延续,也可能发生话题转换。该文讨论一种话题转换现象:原话题的说明中的某个成分成为新话题,但该新话题及其说明并不构成原话题的说明或原话题说明的一部分。这种话题可称为新支话题。该文对动词按照词汇语义进行分类,揭示动词将其宾语引出成为新支话题的能力所在。文章给出了《围城》中动词引出新支话题的全部实例的词汇语义分布统计。 ",MESS201403003
英语情态句的情感倾向性分析,陈仲帅:29597471|刘洋:08213416|禹晓辉:31367730,8,情感倾向性分析; 意见挖掘; 情感分类; 情态句;,"该文研究了英语情态句的情感倾向性分析问题。情态句是英语中的常用句型,在用户评论文本中占有很大的比例。由于其独有的语言学特点,情态句中的情感倾向很难被已有的方法有效地分析。在该文中,我们借助词性标签进行了情态句的识别,并提出了一种情态特征用于帮助情态句情感倾向性的分析。为了进一步提高分析效果,我们还给出了通过合并同义情态特征来缓解情态特征稀疏性问题的方法。实验结果表明,在二元及三元情感倾向性分类问题上,该文提出的方法在F值上较经典分类方法分别有4%及7%的提高。 ",MESS201403004
基于条件随机场的汉语框架语义角色自动标注,宋毅君1:08408989|王瑞波1:13897708|李济洪1:08401319|李国臣2:25955427,12,汉语框架语义知识库; 语义角色标注; 条件随机场模型; 基本块;,"在给定目标词及其所属框架的条件下,汉语框架语义角色标注可以分为语义角色识别和角色分类两个步骤。该文将此任务通过IOB2标记策略形式化为词序列标注问题,以词为基本标注单元,采用条件随机场模型进行自动标注实验。先对语料使用清华大学的基本块自动分析器进行分析,提取出15个块层面的新特征,并将这些特征标记形式化到词序列上。以文献[20]已有的12个词层面特征以及15个块层面特征共同构成候选特征集,采用正交表方法来选择模型的最优特征模板。在与文献[20]相同的语料上,相同的3组2折交叉验证实验下,语义角色标注的总性能的F1-值比文献[20]的F1-值提高了近1%,且在显著水平0.05的t-检验下显著。实验结果表明:(1)基于词序列模型,新加入的15个块层面特征可以显著提高标注模型的性能,但这类特征主要对角色分类有显著作用,对角色识别作用不显著;(2)基于词序列的标注模型显著好于以基本块为标注单元以及以句法成分为标注单元的标注模型。 ",MESS201403005
汉语框架网中未登录词元的框架选择,"陈学丽1:29949665|李茹1,2:08453268|王赛1:31367731|王智强1:25200586",8,汉语框架网; 未登录词元; 词义信息;,"汉语框架网的低覆盖率导致汉语句子中存在许多未登录的词元,严重制约着汉语的框架语义分析任务。针对未登录词元的框架识别问题,该文借助同义词词林的词义信息,提出基于平均语义相似度计算及最大熵模型两种方法,采用静态特征与动态特征相结合的特征选择方法。实验证明,这两种方法都能有效地实现未登录词元的框架选择,基于相似度计算的方法(TOP-4)获得78.61%的准确率;基于最大熵的方法结果可达87.29%,同时在新闻语料上达到了75%的准确率。 ",MESS201403007
微博信息传播网络的结构属性分析,王晓明:11242400|王莉:08893016|杨敬宗:31367732,6,信息传播网络; 网络社区; 微元结构; 网络可视化;,"当前微博迅速流行,由于它交互结构的复杂性,其研究分析难度较大,该文提出了一种新颖的方法分析微博信息传播网络的属性。首先定义了信息源的概念,针对6个不同主题事件的微博传播结构,对各信息传播网络结构进行了可视化分析,并给出了信息源分布特征分析。带有时间标签的信息传播网络通常是有向非循环图,定义了3种信息传播微元结构,分别对应信息分散、信息聚集、信息传递。利用斯皮尔曼等级相关系数研究了它们之间的关联度,发现3种结构间有相当大的差异,基于这3种关系分析了信息传播网络的演变情况,得出信息分散结构在各时间片上的数量最多。 ",MESS201403008
中文微博客的垃圾用户检测,"李赫元1,2:31367733|俞晓明1:09560060|刘悦1:09639001|程学旗1:09559496|程工3:27764449",7,微博客; 垃圾用户; 检测;,"微博客的出现改变了我们获取信息的方式。然而,大量垃圾消息却此起彼伏,危害着微博的健康发展。该文研究了中文微博客中的垃圾用户检测问题。我们首先对垃圾用户的行为进行了分析,提出了基于用户图、用户资料、微博内容的3大类7种检测特征。随后,讨论了基于SVM分类器的垃圾用户检测方法。最后,我们对采集的微博数据进行了标注,并评价了分类器的效果。实验表明:分类器具有较高的准确率和召回率,该文提出的特征具有较好的区分度。 ",MESS201403009
基于传播模拟的消息流行度预测,"万圣贤1,2:31367734|郭嘉丰1:14336892|兰艳艳1:30526869|程学旗1:09559496",7,流行度预测; 传播模型; 最大熵模型;,"社交网络中的消息流行度预测问题对于信息推荐和病毒式营销等应用具有重要意义。该文提出了一种基于传播模拟的消息流行度预测方法,首先使用最大熵模型学习并预测用户转发消息的概率,然后使用独立级联传播模型在真实的社会网络上模拟消息的传播过程,从而完成消息流行度的预测。该方法的优点在于更充分的利用了社会网络的结构和用户特征信息。该文在Twitter数据集上的实验结果表明,相对于基准方法,该文提出的方法具有更高的准确率和稳定性。 ",MESS201403010
长尾查询搜索性能评价方法的研究,,7,长尾查询; 搜索引擎性能评价; 自动评价方法;,"各大搜索引擎公司都致力于准确而快速的帮助用户找到信息目标,搜索性能评价变得非常重要,而目前尚无对长尾查询性能评价的方法。该文通过分析长尾查询结果数据,提取了长尾查询三种类型特征,并对特征进行叠加分析。进一步地针对数据集的严重不平衡问题提出两种数据平衡方法。最后提出并改进了长尾查询评价方法。在真实搜索引擎结果数据集上的实验验证了所提出的评价方法取得一定的评价效果,其中对不相关文档的评价取得较高的准确率。 ",MESS201403011
机器翻译自动评价综述,,11,机器翻译; 自动评价; 自动评价分类;,"随着机器翻译的发展,对其质量进行评测的自动评价方法也越来越受重视。发展至今,各种评价方法与技术层出不穷,采用何种分类标准来组织和描述它们也是一个很大的挑战。根据核心技术的不同,该文重点介绍了三类主流的自动评价方法,包括:基于语言学检测点的方法、字符串匹配的方法和基于机器学习的方法。论文分别阐述了这些类别中颇具代表性的方法的工作原理并分析了各自的优缺点。此外,受限参考译文下的评价技术虽然不是主流的方法,但是其对提高自动化程度和评价性能的作用不能忽视,所以该文将其作为特殊的类别做了阐述。然后,汇报了近年来衡量自动评价方法的国际评测结果。最后,总结了自动评价的发展趋势和有待进一步解决的相关问题。 ",MESS201403012
TSRM藏文拼写检查算法,"珠杰1,2:28527554|李天瑞1:10222865|刘胜久1:28488833",7,藏文音节; 藏文规则; 拼写检查;,"拼写检查作为文本处理中的重要内容,在字处理软件、文字识别、语音识别、搜索引擎等领域具有广泛的应用。该文以藏文语音特性建立的字组织法为依据,以藏文音节规则为模型,提出了藏文音节规则模型(TSRM)的藏文音节拼写检查算法,并通过2组实验验证了算法的有效性。在没有考虑梵音转写藏文的情况下,拼写错误检查的准确率可以达到99.8%。 ",MESS201403013
基于FUG的藏语句法形式化描述,扎西加1:11131756|多拉2:11679097,5,藏语句法; 复杂特征集; 句子结构; 语义信息;,"针对藏语自然语言形式化的实际需求,分析了用复杂特征描述藏语句子的必要性,引入了复杂特征集和合一运算的概念。以形式化为出发点,以现代语言学理论为后盾,以实例举证的方式对藏语词汇、句法、语义的规则及句子合一运算提出了探索性的研究思路,并且采用框式表示的方法,力求从形式化的角度为藏语自然语言处理提供便利。 ",MESS201403014
藏文构件元素识别算法研究,边巴旺堆:09163661|卓嘎:09143915|陈延利:22670145|武强:10829816,8,藏文; 算法; 语法规则; 构件元素;,"要实现藏文排序算法,必须解决组成藏文音节的构件元素识别,然后由构件元素的优先级进行排序。本文通过对藏文的文字结构、书写规律以及文法规则的研究,设计了符合现代藏文的构件元素识别算法。在该算法中对藏文特殊音节的二义性、双元音和缩写等问题进行了处理。实验表明该算法能够满足实际藏文构件元素识别的需要。另外,为了在国家编码标准下输入的藏文词语也能利用本算法正确识别其构件元素,在算法中做了相应处理。 ",MESS201403015
一种维吾尔语联机手写识别系统,热依曼·吐尔逊:25205534|吾守尔·斯拉木:17705001,5,维吾尔文; 手写体; 词语建模; HMM; GMM;,"该文介绍一种维吾尔语联机手写体识别系统。其针对维吾尔语词语的书写特点采用了基于多分类器融合的系统和方法,分别使用混合高斯模型模拟整词的静态特征和隐马尔科夫模型模拟书写笔迹的动态特征,有效地提升了识别系统的准确率。在第一期实验中,整词识别率达到97%;第二期的实验中,整词识别率达到99%。 ",MESS201403016
基于能量变化率的汉语塞音检测算法,张连海:21149942|陈斌:26226407|屈丹:20534357|李弼程:20650975,7,塞音检测; 能量变化率; 发音特性; Seneff听觉模型;,"针对爆发谱特征不稳定的问题,论文提出了一种基于能量变化率的汉语塞音检测方法。该方法首先基于Seneff听觉谱提取了一组描述音段能量变化率特性的参数,然后采用Fisherface方法进行特征变换,变换后的特征采用K近邻(KNN)分类器进行分类,实现了塞音的检测,最后利用留一法对模型性能进行交叉验证。实验结果表明,干净语音塞音检测准确率可以达到96.39%,信噪比10dB的语音塞音检测准确率可达到88.07%,模型具有较好的稳定性和泛化性能。 ",MESS201403017
语音声学参数自动标注/提取系统简介,周学文:11049861|呼和:11147824,6,声学参数; 自动标注; 自动提取;,"该文重点介绍了一个实用的语音声学参数自动标注/提取软件系统。使用该系统能够极大地降低语音参数标注和采集的错误率,有效提高语音声学参数库研制效率,确保实验方法和实验数据的可重复性和可验证性,从而推动语音声学参数数据库研制和语音声学实验研究工作的规范化和标准化。 ",MESS201403018
话题转换方式和句子长度对边界声学参数的影响,吴倩:11420890|王蓓:25134863,7,话题转换方式; 句子长度; 韵律边界;,"该文研究了不同话题转换方式和句子长度对边界处停顿、边界前延长量及音高重置的影响。语料是由两个句子构成的小语篇,通过改变第二个句子控制两种句子长度(短和长)和三种话题转换方式(延续、精述和转折)。20位发音人的语音分析结果显示:(1)话题转换方式和句子长度对停顿及音高重置都有调节作用,但对边界前词的时长延长量没有显著影响。另外,两因素间没有交互作用。主要表现为:边界后句子越长,句间停顿越长,且边界处的音高重置越大。从话题延续、话题精述到话题转折,停顿时长呈增长趋势,且音高重置度增大;(2)停顿时长与边界前延长量存在较弱的负相关,与音高重置则存在较弱的正相关;(3)相较于男性发音人,女性发音人对话题转换方式更为敏感,且更倾向于用停顿和音高两种声学线索标记话题转换方式。句长效应则在男女发音人中都稳定存在。以上结果表明,句长对边界处声学参数的影响基于底层发音机制,而话题转换方式的影响则是语言中信息传递的需要。 ",MESS201403020
基于语义分类的比较句识别与比较要素抽取研究,周红照:26990839|侯明午:28150653|侯敏:10316023|滕永林:15395593,7,语义分类; 词典与规则; 比较句识别; 比较要素抽取;,"比较是人们常用的评估不同事物优劣、异同的表达方式,利用机器识别比较句并进一步抽取比较要素是语言信息处理领域一项新颖又有实用价值的课题。该文依据比较句与比较要素之间是一种""你中有我,我中有你""的共生关系,将比较句识别与比较要素抽取两个任务合二为一完成;根据词意分类,构建由领域词典、情感词典、标记词典、普通词典构成的词典系统;根据汉语比较句句义分类,构建比较句识别与比较要素抽取规则库。以第四届中文倾向性评测(COAE2012)发布的测试语料为实验对象,该系统取得了较好的实验(评测)结果。 ",MESS201403021
面向动态主题数的话题演化分析,"方莹1,2:27677931|黄河燕1:23136252|辛欣1:30369384|魏骁驰1:31367739|庄琨1:31367740",8,主题模型; 无参混合模型; 狄利克雷过程; 话题演化;,"话题演化用于自动分析话题变化趋势,具有较高的应用和研究价值。ILDA(Infinite Latent Dirichlet Allocation)模型在LDA(Latent Dirichlet Allocation)模型的基础上增加了狄利克雷过程,除了能获取隐变量,更重要的是能完成超参的动态更新和主题数的变动。而已有的话题演化研究中,话题的主题数需要事先指定且无法变动,基于ILDA模型的方法则可以针对性地解决该问题。构建的话题演化分析系统可实现如下功能:各周期内按不同主题分类、相邻周期间的主题进行关联、按时间顺序计算子话题强度。实验显示,基于ILDA模型的参数动态更新符合实际需求,话题演化分析过程完善可行。 ",MESS201403022
评价文本中意见分布规律研究,许延祥:33245902|罗铁坚:33244031|周佳:33244033|王竹:33245903,9,意见挖掘; 评价文本; 主观性; 主观句; 客观句;,"对评价文本的意见挖掘旨在提取由对象、特征、评价语和倾向构成的元组。当前方法主要依赖情感词和语言学启发信息获得主观句表达的意见,忽略了语义表达因素,导致意见召回率较低。该文以实际语料为数据基础,寻找意见表达方式的分布规律。文中明确了判别意见、主观句和客观句的准则,并对ChnSentiCorp语料集中12 000个句子进行了标注。统计结果表明,意见特征类别有限且领域差异大;特征呈随机分布,隐性特征占31.8%;客观句形式意见占36%;在表达方式上有5种主观句式、3种客观句式,意见在各句式上分布不平均。论文最后给出提升意见挖掘性能的5条策略。 ",MESS201403023
第十一届全国自然语言处理青年学者研讨会在乐山师范学院召开,,1, ,"<正>2014年5月15—16日,由中国中文信息学会主办,乐山师范学院承办的""第十一届全国自然语言处理青年学者研讨会""(YSSNLP2014)在四川乐山举行。开幕式上中国中文信息学会副理事长兼秘书长孙乐研究员,中国中文信息学会副理事长、""973""首席科学家孙茂松教授分别代表学会致辞。乐山师范学院校长胡丹教授致辞,并代表学校对各位专家、学者到校参会表示热烈欢迎。计算机科学学院院长金澎博士主持开幕式。 ",MESS201403006
中国中文信息学会在民政部组织的“社会组织评估”中获得4A等级,,1, ,"<正>社会组织评估是我国政府加强对社会组织规范管理的重要举措。评估内容包括基础条件、内部治理、工作绩效、社会评价等方面。评估结果等级从高到低依次为5A、4A、3A、2A、1A。自2013年4月接到上级主管单位中国科学技术协会转发的《民政部关于开展2013年度社会组织评估工作的通知》后,中国中文信息学会依据《社会组织评估管理办法》和全国性社会组织评估的相关规定,参加了民政部组织的社会组织评估 ",MESS201403019
商务印书馆即将推出“中国语言学书院·海外语言学博士论文文库”,,1, ,"<正>Rejceted Expectations:The Scalar Particles Cai and Jiu in Mandarin Chinese《预期之否认:汉语梯级算子""才""和""研究""》Huei-Ling Lai(赖惠玲)著本书是对现代汉语普通话副词""才""和""就""的语义研究提升到了新的高度,这是一本对相关语言事实描写充分、思路清晰、解释易懂 ",MESS201403024
中文信息处理的词法问题——以句本位语法图解树库构建为背景,"彭炜明1,2:30613113|宋继华3:06364557|俞士汶1,2:06272028",8,中文信息处理; 临时造词; 句本位语法; 图解树库;,"该文对比了句本位语法图解树库与中文信息处理现行词法规范在分词单位和词类标注两方面的差异,指出目前自动词法分析与句法分析的若干脱节之处,梳理了图解树库中关于临时造词、惯用语等特殊结构的标注策略和语言学理据,并探讨了""依句辨品""和""指称化""等汉语词类相关理论在中文信息处理中的实现方式。 ",MESS201402001
基于谓词及句义类型块的汉语句义类型识别,王倩:11277242|罗森林:06346792|韩磊:06349344|潘丽敏:06339684,9,句义类型识别; 句义类型; 语义分析; 自然语言处理;,"从现代汉语语义学角度,可将句义类型划分为简单句义、复杂句义、复合句义和多重句义4种。作为在整体上对句义结构进行描述的方式之一,句义类型识别是对汉语句子进行完整句义结构分析的重要步骤。该文基于谓词及句义类型块提出了一种汉语句义类型识别的方法,实现了4种句义类型的识别。该方法先通过句中谓词的个数进行初步识别判断出部分简单句,再对剩余的句子先用C4.5机器学习的方法得到句中谓词经过的最大句义类型块的个数,再结合句法结构中顶端句子节点进行判决,最终给出剩余句子的句义类型判定结果。实验采用BFS-CTC汉语标注语料库中10 221个句子进行开集测试,句义类型的整体识别准确率达到97.6%,为基于现代汉语语义学的研究奠定了一定的技术研究基础。 ",MESS201402002
基于功能连接词的隐式篇章关系推理,车婷婷:28039744|洪宇:25038035|周小佩:28039743|严为绒:30700879|姚建民:13898051|朱巧明:09891804,11,隐式篇章关系; 功能连接词; 论元概念模型;,"功能连接词是一种直接表述篇章单元内部语义关系、结构特性和语境发展趋势的词特征。借助功能连接词的这一优势,该文提出一种基于功能连接词的隐式篇章关系推理方法。该方法首先挖掘词级与短语级的功能连接词,划分功能连接词的篇章关系类别;其次,为每个功能连接词构建概念模型,借以描述由功能连接词连接的论元属性,并建立论元概念与篇章关系的映射体系;最后,利用统计策略识别待测论元的概念模型,并借助""概念—关系""映射体系,实现隐式篇章语义关系推理。实验结果显示,该文基于功能连接词构建概念模型的推理方法,相较于现有的基于监督学习的分类方法,系统性能获得显著提升。 ",MESS201402003
中文篇章级句间语义关系体系及标注,张牧宇:25206165|秦兵:06990821|刘挺:06994824,9,中文篇章级语义分析; 句间关系; 语义体系; 语料标注;,"篇章句间关系(Discourse Relation)是篇章级语义分析的重要内容,该文在英文篇章句间关系研究的基础上分析了中英文间的差异,总结了中文篇章级语义分析的特点,并在此基础上提出面向中文篇章句间关系的层次化语义关系体系,对句间关系类型进行详细描述。为了验证体系的合理性和完备性,我们在互联网新闻语料上进行了标注实践,分析了标注中遇到的难点并给出解决方案,为进一步的中文篇章级语义分析工作奠定基础。 ",MESS201402004
基于HNC理论的词语相似度计算,吴佐衍:30750877|王宇:06532281,8,概念层次网络; 语义相似度; 中文信息处理;,"该文运用自然语言处理的概念层次网络(Hierarchical Network of Concepts,HNC)理论提出了一种词语相似度计算方法。该方法利用HNC理论词汇层面联想的概念表述体系,根据HNC映射符号的编码规则和符号映射理论,综合概念内涵、概念外部特征、概念类别和组合符号来计算词语的相似度,并与基于知网的词语相似度算法和人工的主观判断的相似度进行了比较分析。实验结果表明,该方法能够较好地反映词语之间的语义差别,与人的直观判断基本一致,是一种有效可行的方法。 ",MESS201402006
依存树到串模型中引入双语短语的三种方法,谢军:22037543|刘群:09638994,7,统计机器翻译; 依存树到串模型; 泛化句法短语; 非句法短语;,"依存树到串模型使用基于HDR片段的翻译规则。HDR片段是由中心词及其所有依存节点组成的树片段。这种翻译规则可以较好地捕捉语言中的句子模式和短语模式等组合现象,但在捕捉非组合现象(如习惯用语或固定搭配)方面存在不足。这类非组合现象易于由短语捕捉。为了更好地改善依存树到串模型的性能,本文提出了三种引入双语短语的方法,分别为引入句法短语、引入泛化句法短语及引入非句法短语。实验结果表明,同时使用句法短语、泛化句法短语及非句法短语时,可以将依存树到串模型的性能显著提高约1.0BLEU值。 ",MESS201402007
一种基于改进隐马尔克夫模型的词语对齐方法,刘颖:08230768|姜巍:08173387,5,短语结构树距离; 隐马尔克夫模型; 词语对齐; BLEU值;,"该文在基本隐马尔克夫模型的基础之上,利用句法知识来改进词语对齐,把英语的短语结构树距离和基本隐马尔克夫模型相结合进行词语对齐。与基本隐马尔克夫模型相比,这个模型可以降低词语对齐的错误率,并且提高统计机器翻译系统BLEU值,从而提高机器翻译质量。 ",MESS201402008
判别式藏语文本词性标注研究,"华却才让1,2:28932271|刘群3:09638994|赵海兴1,2:31156614",5,词性标注; 感知机模型; 特征选择; 藏语词性标注;,"该文在分析了现有藏文词性标注方法的基础上,提出感知机训练模型的判别式藏语词性标注方法,重点研究了符合藏语词法特性的模型训练特征模板、模型训练和词性标注方法。并且在人工标注的测试集上获得了98.26%的词性标注精确率,可以实际应用到藏语自然语言处理中。 ",MESS201402009
基于判别式分类和重排序技术的藏文分词,"孙萌1,2:25200604|华却才让3:17628476|才智杰3:08166533|姜文斌1:23136246|吕雅娟1:13898594|刘群1:09638994",6,判别式; 藏文分词; 构词粒度; 重排序;,"本文提出一种基于判别式模型的藏文分词方法,重点研究最小构词粒度和分词结果重排序对藏文分词效果的影响。在构词粒度方面,分别考察了以基本字丁、基本字丁-音节点、音节为最小构词粒度对分词效果的影响,实验结果表明选定音节为最小构词粒度分词的F值最高,为91.21%;在分词结果重排序方面,提出一种基于词图的最短路径重排序策略,将判别式解码生成的切分结果压缩为加权有向图,图中节点表示音节间隔,而边所覆盖的音节作为候选切分并赋予不同权重,选择一条最短路径从而实现整句切分,最终分词结果的F值达到96.25%。 ",MESS201402010
基于词典和统计相结合的维吾尔语拼写检查方法,麦合甫热提1:31156615|艾山·吾买尔2:10775068|麦热哈巴·艾力2:26179697|吐尔根·伊布拉音2:22675986|张健3:25606224,6,维吾尔语; 拼写检查; 词典; N元语法;,"该文通过研究国内外相关的拼写错误查错和纠错方法的理论,再结合维吾尔语自身的特点,提出了基于词典和统计相结合的维吾尔语拼写查错方法。首先,提出基于词典的方法进行词库和词干提取的拼写检查;其次,提出基于N元语法的词缀连接有效性判断模型,对未登录词提出基于N元语法的拼写检查模型;最后,结合以上几种方法各自的优点提出基于混合策略的拼写检查方法,该方法在准确性和检查结果可靠性等方面得到了较显著的提高。 ",MESS201402011
基于特征耦合泛化的药名实体识别,何林娜1:29347689|杨志豪1:06523490|林鸿飞1:06504899|李彦鹏1:11595611|唐利娟2:29676955,6,药名识别; 机器学习; 特征耦合泛化; CRF;,"药名识别的直接目的是从生物医学文本中寻找药名。目前,药物相关研究不断出现,远远超出了维护人员更新药物信息数据库的速度,这就迫切需要一种自动提取药物信息的技术。该文采用了一种基于特征耦合泛化(FCG)的半监督学习方法生成药名词典,然后将药名词典和条件随机场结合进行药名实体识别。首先我们用模板的方法构造了一个药名词典,然后用FCG方法对词典去噪,最后将去噪后的词典用在测试集上进行药名实体识别,得到了76.73%的F值。 ",MESS201402012
多语种网络文本快速新词抽取,"刘冰洋1,2:31156616|刘倩1,2:29729450|张瑾1:22101466|刘欣然3:10628857|程学旗1:09559496",7,新词; 邻接类别; 字符串整体度; 后缀树; 多语言;,"从网络文本中提取新词是网络信息处理中的一个重要问题,在信息检索、文本挖掘、词典编纂、中文分词等领域中都有重要应用。本文提出了一种与语言无关的快速新词提取算法,首先针对后缀树的数据结构将多语言文本进行统一编码,然后使用改进的统计方法在双后缀树上以线性时间统计重复串与邻接类别,并计算字符串的整体度,同时通过剪枝大幅度减少计算量,在中、英文语料上较好地实现了新词的抽取及排序。 ",MESS201402013
基于PageRank的中文多文档文本情感摘要,林莉媛:30773777|王中卿:23843509|李寿山:27030929|周国栋:13898054,6,摘要; 情感; 多文档;,"文本情感摘要任务旨在对带有情感的文本数据进行浓缩、提炼进而产生文本所表达的关于情感意见的摘要。该文主要研究基于多文档的文本情感摘要问题,重点针对网络上存在同一个产品的多个评论产生相应的摘要。首先,为了进行关于文本情感摘要的研究,该文收集并标注了一个基于产品评论的中文多文档文本情感摘要语料库。其次,该文提出了一种基于情感信息的PageRank算法框架用于实现多文档文本情感摘要,该算法同时考虑了情感和主题相关两方面的信息。实验结果表明,该文采用的方法和已有的方法相比在ROUGE值上有显著提高。 ",MESS201402014
《同义词词林》在中文实体关系抽取中的作用,,9,中文实体关系抽取; 树核函数; 同义词词林; 语义信息;,"语义信息在命名实体间语义关系抽取中具有重要的作用。该文以《同义词词林》为例,系统全面地研究了词汇语义信息对基于树核函数的中文语义关系抽取的有效性,深入探讨了不同级别的语义信息和一词多义等现象对关系抽取的影响,详细分析了词汇语义信息和实体类型信息之间的冗余性。在ACE2005中文语料库上的关系抽取实验表明,在未知实体类型的前提下,语义信息能显著提高抽取性能;而在已知实体类型的情况下,语义信息也能明显提高某些关系类型的抽取性能,这说明《词林》语义信息和实体类型信息在中文语义关系抽取中具有一定的互补性。 ",MESS201402016
基于核心词和实体推理的事件关系识别方法,杨雪蓉:28523621|洪宇:25038035|马彬:28296695|姚建民:13898051|朱巧明:09891804,9,实体分布; 核心词分布; 虚拟相关事件; 事件关系;,"事件关系识别是一项面向文本信息流进行事件关系判定的自然语言处理技术。事件关系识别的核心任务是以事件为基本语义单元,通过分析事件的篇章结构信息及语义特征,实现事件逻辑关系的浅层检测(即判定任意事件之间是否存在逻辑相关性)。该文通过利用同一话题下事件的核心词及实体的分布特性,针对同一话题下事件关系识别任务,提出一种基于核心词和实体推理的事件关系识别方法。实验结果显示,该文方法明显优于基于事件语义依存线索的事件关系识别方法,F值获得了15.34%的提升。 ",MESS201402017
多特征文本蕴涵识别研究,"赵红燕1:14007104|刘鹏2:30823523|李茹3,4:08453268|王智强3:25200586",7,文本蕴含识别; 句法依存关系; FrameNet;,"文本蕴涵识别是解决自然语言中存在的同义异形问题的有效途径。虽然国内外学者已经提出了很多文本蕴涵识别模型,但影响文本蕴涵识别的因素错综复杂,识别准确率普遍不高。该文把文本蕴涵识别看作二元分类问题,抽取词汇特征、句法依存关系特征及FrameNet语义知识库特征的多种特征构造特征矩阵,训练SVM分类器,实现文本蕴涵识别。该方法在国际文本蕴涵识别技术评测RTE3的测试集上进行测试,蕴涵正例识别准确率达到了78.1%,高于RTE3评测2-ways的最高结果。 ",MESS201402018
基于偏斜数据集的文本分类特征选择方法研究,"刘振岩1,2,3,4:31156617|孟丹3:32902259|王伟平3:32902258|王勇4:06342871",6,文本分类; 偏斜数据集; 特征选择; 类别差异;,"对于不同类别样本数量差别很大的偏斜文本数据集,使用传统的特征选择方法所选出的特征绝大多数来自于大类,会使得分类器偏重大类而忽略小类,直接影响分类效果。该文首先针对偏斜文本数据集的数据特点,分析发现偏斜数据集中影响特征选择的两个重要因素,即特征项的类别分布和类间差异,其中类别分布因素反映的是特征项在整个数据集中的类别频率差异;而类别差异因素反映的是特征项在不同类别之间的相对文档频率差异。然后基于这两个重要因素构造形成一个新的尤其适用于偏斜文本分类的特征选择函数—相对类别差异(Relative Category Difference,RCD)。与传统的特征选择方法进行对比实验的结果表明,RCD特征选择方法对于偏斜文本分类效果更优。 ",MESS201402019
CICF:一种基于上下文信息的协同过滤推荐算法,鲁凯:28720671|张冠元:23769190|王斌:09559997,7,三协同过滤; 上下文信息; 隐参数模型;,"协同过滤能够满足用户的偏好,为用户提供个性化的指导,是当前互联网推荐引擎中的核心技术。然而,该技术的发展面临着严重的用户评分稀疏性问题。用户评分历史中包含着丰富的上下文信息,因此该文通过利用两种上下文信息对评分稀疏性问题进行了有益的探索:利用物品之间的层次关联关系挖掘用户的潜在喜好;对用户评分的短期时间段效应进行建模。并提出了基于两种上下文信息的统一模型CICF。通过在Yahoo音乐数据集上的实验表明,CICF相比传统协同过滤算法能够显著提高预测效果;并通过在不同稀疏度的训练集上的实验证实了CICF能够有效地缓解评分稀疏性问题。 ",MESS201402020
LDA-CF:一种混合协同过滤方法,廉涛1:31156618|马军1:08853996|王帅强2:28472941|崔超然1:28720668,8,推荐系统; 协同过滤; 主题模型;,"推荐系统是一种克服信息过载的重要工具,其中最流行的方法是协同过滤。该文提出一种结合潜在因素模型和邻域方法的混合协同过滤方法 LDA-CF。我们首先将评分矩阵转换成伪文档集合,使用LDA(Latent Dirichlet Allocation)主题模型发现用户和物品潜在因素向量;然后在低维潜在因素空间计算用户和物品相似度;最后采用邻域方法预测未知评分。在MovieLens 100k数据集上的实验表明:在评分预测任务中,LDA-CF取得的MAE性能指标优于传统的邻域方法。因此,LDA可以有效地从评分矩阵中发现对计算相似度十分有用的用户和物品低维特征表示,在一定程度上缓解了数据稀疏问题。 ",MESS201402021
一种基于作者建模的微博检索模型,"李锐1,2:27772468|王斌1:09559997",8,微博; 作者模型; 微博检索; 平滑;,"近年来,微博的发展令人瞩目,微博检索已经成为一个重要的研究课题。而微博具有文本内容短、更新快、融合社交网络等特点,这些特点使微博的检索不同于传统的web检索。该文首先分析了传统的向量空间模型、概率模型以及基本的语言模型直接用于微博检索将面临的问题;接着在语言模型框架下提出了利用作者信息对微博内容进行扩展的思想,即利用作者信息重新估计微博的语言模型;然后针对话题模型在短文档训练中存在的问题,提出了使用作者的文档话题模型来进一步扩展微博的内容;最后在TREC公开数据集上进行了实验。实验结果表明,可以通过合理使用作者信息来有效的提高微博检索的效果。 ",MESS201402022
基于移动互联网日志的搜索引擎用户行为研究,"万飞1,2:26297979|赵溪1:31156620|梁循1:25202919|潘登1:31156621|倪志豪1:30190215",7,移动搜索引擎; 搜索引擎日志; 用户行为分析;,"随着移动互联网的迅速发展,移动搜索用户大规模增加,移动搜索引擎用户行为分析对改进搜索引擎性能,提高用户体验具有重要意义。该文选取某移动搜索引擎2011年6月第一周的日志,对移动互联网用户搜索行为进行分析和研究。我们从查询词分析、会话分析以及用户点击分析3个角度出发,对查询词长度和频度、问题式查询和网址查询比例、会话内查询个数、查询词修改方式以及用户点击位置进行研究,并与互联网搜索引擎相应指标进行对比。相关分析结论对于移动搜索引擎算法改进与系统优化具有一定参考意义。 ",MESS201402023
基于转化的互联网广告技术研究,"顾智宇1,2:31156622|秦涛3:31156623|王斌1:09559997",8,互联网广告; 转化率; 按行动付费广告;,"基于转化的互联网广告方式根据用户在浏览广告后的购买等行为对广告效果进行衡量,极大利用了互联网广告的独特优势,成为了未来互联网广告发展的趋势。该文介绍了基于转化的互联网广告的运行方式,分析了其行业应用,进一步地总结了该领域的当前研究成果,包括基于转化的竞价机制设计、转化率预测、基于转化的广告排序等。最后在此基础上,分析了存在的问题并展望未来的研究方向。 ",MESS201402024
2014年《中文信息学报》征订启事,,1, ,"<正>《中文信息学报》是全国一级学会—社团法人中国中文信息学会和中国科学院软件研究所联合主办的学术性刊物,创刊于1986年10月,现为双月刊,大16开,每期158面,由商务印书馆出版,成为商务印书馆期刊方阵中的期刊之一,清华大学印刷厂印刷。《中文信息学报》是我国计算机、计算技术类83种刊物中的中 ",MESS201402005
中国中文信息学会战略研讨会在贵州贵阳成功召开,,1, ,<正>目前已经进入以互联网和大数据为主要标志的海量信息时代。计算机和互联网技术的快速发展对中文信息处理技术提出了许多新的挑战。2014年4月18-19日在贵州贵阳成功举办了中国中文信息学会2014战略研讨会。四十多位来自全国各地的中文信息处理领域的专家学者围绕我国中文信息处理事业当前发展 ,MESS201402015
语言计算的重要国际前沿,孙茂松1:08823738|刘挺2:06994824|姬东鸿3:09004523|穗志方4:06268960|赵军5:10891784|张钹1:05974610|吾守尔·斯拉木6:17705001|俞士汶4:06272028|朱军1:08189228|李建民1:08174290|刘洋1:45684033|王厚峰4:06274413|吐尔根·依布拉音6:17705003|刘群7:09638994|刘知远1:45671912,8,语言计算; 研究前沿; 评述; 中文信息处理;,"该文在互联网规模语言信息处理的语境下,从语言计算基础模型、语言分析、语言资源建设、机器翻译、文本内容理解与问答等多个方面,对国内外相关重要动态进行了评述,讨论了语言计算的若干前沿问题及其对中文信息处理近期研究工作所提出的要求。 ",MESS201401001
语言网络研究进展,韩普1:29454700|王东波2:28659628|路高飞3:27052031|苏新宁3:08041788,10,语言网络; 小世界现象; 无尺度分布;,"语言网络作为一个新的研究领域,其研究正在迅速崛起,目前已经吸引了不少领域的研究者们的关注。该文首先简要介绍了语言网络的特点、常用的统计特征以及相关的网络模型;其次,根据语言构成单位以及当前语言网络研究热点,将语言网络分为语音网络、共现网络、依存句法网络、概念语义网络,并详细介绍了各类语言网络研究的主要进展。最后总结了语言网络研究的现状并给出了展望。 ",MESS201401002
基于语言模型的有监督词义消歧模型优化研究,杨陟卓1:27362083|黄河燕2:23136252,7,数据稀疏; 模型优化; 有监督模型; 语言模型; 参数估计;,"词义消歧是自然语言领域中重要的研究课题之一。目前,有监督词义消歧方法已经是解决该问题的有效手段。但是,由于缺乏大规模的训练语料,有监督方法还不能取得满意的效果。该文提出一种基于语言模型的词义消歧优化模型,该模型采用语言模型优化传统的有监督消歧模型,充分利用有监督和语言模型两种模型的消歧优势,共同推导歧义词的词义。该模型可以在训练语料不足的情况下,有效的提高词义消歧效果。在真实数据上表明,该方法的消歧性能超过了参加SemEval-2007:task#5评测任务的最好的有监督词义消歧系统。 ",MESS201401003
多种语义特征在突发事件新闻中的共指消解研究,庞宁1:10891367|杨尔弘2:06429879,7,中文信息处理; 突发事件; 共指消解; 语义特征; 最大熵模型;,"提高突发事件应对的关键在于快速地收集和提取相关新闻报道中的有用信息,共指消解是信息提取研究的重要子任务。该文采用最大熵模型对汉语突发事件新闻报道中的共指现象进行消解,综合对比了语义类特征、语义角色特征,以及基于维基百科的语义相关特征,重定向特征及上下文特征在测试集上的效果。实验结果表明,除单纯使用语义角色特征会使系统F值下降1.31%以外,其余各种语义知识对共指消解模型的结果均有所提高。 ",MESS201401004
Weighted-Tau Rank:一种采用加权Kendall Tau的面向排序的协同过滤算法,孙建凯:30857637|王帅强:10664093|马军:08853996,8,协同过滤; 面向排序; 加权Kendall Tau; 舒尔茨方法;,"已知的面向排序的协同过滤算法主要有两个缺点:计算用户相似度时只考虑用户对同一产品对的偏好是否一致,而忽略了用户对产品对的偏好程度以及该偏好在用户间的流行度;进行偏好融合和排序时需要中间步骤来构建价值函数然后才能利用贪婪算法产生推荐列表。为解决上述问题:我们利用类TF-IDF加权策略对用户的偏好程度及偏好流行度进行综合考量,使用加权的Kendall Tau相关系数计算用户间的相似度;进行偏好融合与排序时则使用基于投票的舒尔茨方法直接产生推荐列表。在两个电影数据集上,本文提出的算法在评测指标NDCG上的效果要明显优于其他流行的协同过滤算法。 ",MESS201401006
基于吸收马尔可夫链的子话题发现方法,"魏明川1,2:30857638|朱俊杰1,2:30857640|张瑾1:22101466|张凯1:10348575|程学旗1:09559496|任彦3:22393034",7,子话题划分; 话题关键词; 吸收马尔可夫链;,"受互联网文本信息话题内容多元性,演化性等特点的影响,传统的话题检测模型对子话题粒度的选取和检测质量很难保证。针对该问题,该文提出一种基于吸收马尔可夫链的子话题划分算法,该算法对基于网页聚类生成的话题关键词进行组合生成子话题,并以吸收马尔可夫链对子话题进行吸收衍化,进行重排序生成结果子话题。实验结果表明,该算法能同时保证生成子话题的重要性和多样性。 ",MESS201401007
特定事件微博与新闻报道话题对比研究,周振宇:08554728|李芳:09595202,9,话题模型; 微博; 新闻报道; 对比;,"该文描述了基于特定事件的新闻报道和微博在话题层面的对比研究。首先利用LDA话题模型抽取两种媒体上关于特定事件的话题,然后提出了话题关注度、差异度、演化度的定义和计算公式,改进了不同媒体话题差异度的计算方法,最后,选取四个不同种类的事件,进行实验对比与分析,结果显示,关于同一事件,1)微博上评论性话题较多,话题关注度值比较接近;新闻报道上事实性话题较多,话题关注度值差异较大;2)微博与新闻报道对评论性话题词汇差异度大,事实性话题词汇差异度小;3)微博上评论性话题持续时间较长,内容变化较少;新闻报道上事实性话题持续时间较长,内容变化较少。 ",MESS201401008
社交网络中的社团结构挖掘,范超1:27711243|王厚峰2:06274413,8,社交网络; 社团结构; 社团挖掘; 人人网;,"社交网络已经成为现代人们在线交流并交换信息的重要途径之一。以国内的人人网为例,大量的年轻人,尤其是学生,以此为平台,相互讨论感兴趣的话题。人与人之间因为学习关系、工作关系、共同的兴趣等诸多因素关联起来;以大学生交流为主体的社交网则更有可能因为在相同院、系、所而关联在一起,从而呈现出社团结构。该文以人人网的真实数据,使用CNM算法来验证这一假设;同时,还利用社会网络的结构知识对CNM算法作了改进,提高了社团发现的精度。所挖掘的社团结构关系还表明,高校不同院系和学科形成的社团具有各自的特点。 ",MESS201401009
基于用户意图识别的查询推荐研究,罗成:08177211|刘奕群:08176974|张敏:08186086|马少平:08177513|茹立云:08823400|张阔:08835581,9,查询推荐; 用户意图挖掘; 摘要点击模型;,"信息检索的效果很大程度上取决于用户能否输入恰当的查询来描述自身信息需求。很多查询通常简短而模糊,甚至包含噪音。查询推荐技术可以帮助用户提炼查询、准确描述信息需求。为了获得高质量的查询推荐,在大规模""查询-链接""二部图上采用随机漫步方法产生候选集合。利用摘要点击信息对候选列表进行重排序,使得体现用户意图的查询排在比较高的位置。最终采用基于学习的算法对推荐查询中可能存在的噪声进行过滤。基于真实用户行为数据的实验表明该方法取得了较好的效果。 ",MESS201401010
搜索引擎用户行为与用户满意度的关联研究,刘健:08822484|刘奕群:08176974|马少平:08177513|张敏:08186086|茹立云:08823400|张阔:08835581,7,搜索引擎; 用户行为分析; 用户满意度;,"用户满意度是以用户为中心的搜索引擎性能评价的一个重要分支,区别于传统基于查询与文档相关性的评价方法,基于用户满意度的性能评价能够更加全面、客观地对搜索引擎性能进行评价。该文通过设计搜索实验平台,在尽量不影响用户正常搜索过程的前提下收集用户的搜索行为及其满意度评价,通过用户行为分析的方法挖掘用户群体行为特征与用户查询满意度之间的关联关系。相关结论对提高搜索引擎性能、改善用户查询体验具有一定的参考意义。 ",MESS201401011
一种基于内存的高效在线数据处理服务框架,"林祥辉1,2:30857641|张瑾1:22101466|黄康平1,2:30857642|许磊1:30857643|许洪波1:10348532|程学旗1:09559496|程工3:27764449",7,海量数据; 数据处理; 在线缓存; 发布/订阅;,"在海量数据处理环境下,传统的基于中心数据库的架构已经无法满足大规模的数据处理应用中高并发高数据读写的需求,而串行的工作模式也使得数据分析的时效性得不到有效的保证,已经严重地影响了用户体验。该文从应用架构的角度出发,提出了一种基于内存的高效在线数据处理服务框架,通过多索引的高效数据存取方法和基于发布/订阅模式的数据访问控制机制,在有效减少用户对中心数据库的读写请求的同时提高了数据处理的时效性。实验结果表明该文提出的基于内存的高效在线数据处理服务框架能够有效提高数据库的响应速度,缩短数据处理延时。 ",MESS201401012
引入集成学习的最大熵短语调序模型,何钟豪1:30857644|苏劲松2:10911517|史晓东1:09218694|陈毅东1:09193993|黄研洲1:30857645,7,最大熵; 短语调序; 不平衡分类; 集成学习;,"基于最大熵的括号转录语法模型具有翻译能力强、模型训练简单的优点,成为近些年统计机器翻译研究的热点。然而,该模型存在短语调序实例样本分布不平衡的缺点。针对该问题,该文提出了一种引入集成学习的短语调序模型训练方法。在大规模数据集上的实验结果表明,我们的方法能有效改善调序模型的训练效果,显著提高翻译系统性能。 ",MESS201401013
现代汉语常用动词释义对比研究——以《现代汉语词典》(第六版)和《重編國語辭典修訂本》为例,刘珺:30884547|徐德宽:07962449|马梦佳:30884548|陈淑梅:11227437,6,常用动词; 释义对比; 释义差异;,"动词在语言中的地位十分重要,而汉语更是一种动词性语言。了解动词的释义,是研究动词的一个重要途径。该文采用《现代汉语词典》(第六版)和《重編國語辭典修訂本》为对比研究的材料,参考新汉语水平考试大纲,选取三者共有的动词词条进行研究,着重对比两本词典对动词的释义,找出普通话和台湾地区所用标准语两者在动词方面的差异,减少两岸交流中因词义不同所产生的误会,更好地促进两岸交流。 ",MESS201401014
维吾尔语音素的声学特征分析,"王辉1:09255425|努尔麦麦提·尤鲁瓦斯1,2:28479964|吾守尔·斯拉木1,2:17705001",7,维吾尔语; 声学特征; 特征融合; 语速;,"该文对不同语速下,人工标注的维吾尔语连续语音语料中各音素进行共振峰频率、音长、音强的统计分析,并完成辅—元结构下的塞音、塞擦音的声学特征分析。该文通过美尔频率倒谱系数与共振峰频率等声学特征的融合及模型状态数的修改,对维吾尔语音素识别的声学模型进行了改进,并验证了不同声学特征对音素识别的影响。相比于基线系统,改进后声学模型的识别率取得一定提升。同时,利用语音学知识分析维吾尔语易混淆音素产生原因,为音素识别声学模型的进一步改进提供参考依据。 ",MESS201401015
最大熵和条件随机场模型相融合的藏文人名识别,加羊吉1:24688520|李亚超1:27243481|宗成庆2:10815045|于洪志1:09120080,6,藏文人名识别; 最大熵; 条件随机场;,"藏文人名识别是藏文信息处理领域研究的难点之一,其识别效果直接影响到藏文自动分词的精度和相关应用系统的性能,包括藏汉翻译、藏文信息检索、文本分类等。该文在分析藏文人名构成规律和特点的基础上,提出了一种最大熵和条件随机场相融合的藏文人名识别方法。实验表明,该方法可以获取较好的识别效果,在我们的测试集上F-测度值到达了93.08%。 ",MESS201401016
计算机识别藏语虚词的方法研究,高定国1:17403917|扎西加2:11131756|赵栋材1:11104246,5,识别; 藏语; 虚词;,"藏文虚词的研究是藏文信息处理技术中词、句及语义研究的基础,而计算机自动识别藏文虚词又是藏语虚词研究的前提。该文在论述藏语虚词在藏语文本中的作用和使用方法的基础上,分析了计算机识别藏语虚词的难度,提出了一个计算机识别藏语虚词的方法,并用2 525句典型藏文句子进行了验证,对结果进行分析发现藏文虚词识别的正确率高达97.076 8%。 ",MESS201401017
维吾尔文网页研究及Android维文浏览器的实现,邓俊:29401463|吾守尔·斯拉木:17705001|艾尼宛尔·托乎提:26201501|袁廷磊:29406909|赵志成:29401476,7,Android; 浏览器; WebKit; 维吾尔文; 网页;,"通过二次修改WebKit内核来定制浏览器功能是当前嵌入式应用开发的热点。在研究Android平台浏览器引擎WebKit的基础上,综合分析多款浏览器在访问维吾尔文网站时出现的显示问题,找出访问维文网页时显示异常的原因。最后根据维吾尔文文字特点进行研究、设计维文浏览器架构,提出在应用层开发维文网页渲染引擎,实现Android平台的维吾尔文浏览器。 ",MESS201401018
"内容丰富多彩,阐述深入浅出——评《统计自然语言处理》(第2版)",俞士汶:06272028,2, ,"<正>宗成庆博士著《统计自然语言处理》一书自2008年问世以来,已在计算语言学与自然语言处理学界产生了广泛影响,被很多大学、研究所指定为硕士生、博士生的必读参考书。该书第1版很快售罄。参照读者反馈的意见,作者对该书进行了增删、修改和磨砺,于2013年8月推出了第2版。在清华大学出版社组织出版的《中文信息处理丛书》中,这种情 ",MESS201401019
第十二届全国计算语言学学术会议(CCL2013)在苏州大学成功召开,,1, ,"<正>2013年10月10日至11日,第十二届全国计算语言学会议(CCL 2013)在苏州大学成功召开。会议主办单位是中国中文信息学会计算语言学专业委员会,组织单位是清华信息科学与技术国家实验室,承办单位是苏州大学。全国计算语言学会议是中国中文信息学会的旗舰会议,从1991年开始每两年举办一次。会议着重于中 ",MESS201401005
商务印书馆新书目录,,1, , ,MESS201401020
中国机器翻译研究的机遇与挑战——第八届全国机器翻译研讨会总结与展望,杜金华1:10187459|张萌1:29475618|宗成庆2:10815045|孙乐3:10352504,8,机器翻译理论; 机器翻译应用; 语音翻译; 少数民族语言; 机器翻译评测;,"随着统计方法逐渐成为机器翻译研究的主流,机器翻译系统评测的分值越来越高,人们对机器翻译的信心和期望逐渐增加,社会对机器翻译应用的需求也越来越大。然而,现有的机器翻译理论和方法在系统性能上提升的空间逐渐减小,而且距离用户实际需求仍有很长的路要走。那么,面对期望、面对需求,机器翻译之路应该如何走?为此,第八届全国机器翻译研讨会对当前机器翻译研究所面临的挑战和机遇进行了深入研讨。该文详细介绍了该次研讨会六个专题的讨论情况,对机器翻译研究面临的机遇和挑战进行了认真的分析和总结。 ",MESS201304002
基于对偶分解的词语对齐搜索算法,沈世奇:29475619|刘洋:45684033|孙茂松:08823738,7,词语对齐; 判别式模型; 搜索算法; 对偶分解;,"词语对齐旨在计算平行文本中词语之间的对应关系,对机器翻译、双语词典构造等多项自然语言处理任务都具有重要的影响。虽然近年来词语对齐在建模和训练算法方面取得了显著的进展,但搜索算法往往都采用简单的贪心策略,面临着搜索错误较大的问题。该文提出了一种基于对偶分解的词语对齐搜索算法,将复杂问题分解为两个相对简单的子问题,迭代求解直至收敛于最优解。由于对偶分解能够保证求解的收敛性和最优性,该文提出的搜索算法在2005年度863计划词语对齐评测数据集上显著超过GIZA++和判别式词语对齐系统,对齐错误率分别降低4.2%和1.1%。 ",MESS201304003
基于多粒度的英汉人名音译,于恒1:29475620|凃兆鹏1:29475621|刘群1:09638994|刘洋2:45684033,6,人名音译; 多粒度; 词图;,"音译是解决人名翻译的重要方法。在英汉人名音译问题中,翻译粒度问题一直是研究的重点之一。该文提出一种基于多粒度的英汉人名音译方法。将多种粒度的英文切分通过词图进行融合,并使用层次短语模型进行解码,从而缓解了由于切分错误而导致的音译错误,提高了系统的鲁棒性。实验结果表明基于多粒度的音译方法融合了基于各种粒度音译方法的优点,在准确率上提高了3.1%,在BLEU取得了2.2个点的显著提升。 ",MESS201304004
《中文信息学报》征稿简则,,1, ,<正>一、《中文信息学报》主要刊登中文信息的基础理论、应用技术、中文信息处理系统及设备、中文信息的自动输入和人工编码输入、汉字字形信息、自然语言处理、计算语言学及民族语言文字信息处理及网上信息处理等方面的研究论文、技术报告、综述、通讯、简报、国内外学术活动等。 ,MESS201304005
基于ListMLE排序学习方法的机器译文自动评价研究,李茂西:29475622|江爱文:26498557|王明文:08472511,8,机器译文评价; 排序学习; ListMLE方法; 人工评价; 自动评价;,"机器翻译译文质量的自动评价是推动机器翻译技术快速发展的一条重要途径。该文提出了基于List-MLE排序学习方法的译文自动评价方法。在此基础上,探讨引入刻画译文流利度和忠实度的特征,来进一步提高译文自动评价结果和人工评价结果的一致性。实验结果表明,在评价WMT11德英任务和IWSLT08BTEC CEASR任务上的多个翻译系统的输出译文质量时,该文提出的方法预测准确率高于BLEU尺度和基于RankSVM的译文评价方法。 ",MESS201304006
基于序列标注的中文分词、词性标注模型比较分析,刘一佳:29475623|车万翔:06987220|刘挺:06994824|张梅山:27030882,7,中文分词; 词性标注; Stacked Learning;,"该文对三种不同的分词词性标注模型进行了比较。这三种模型分别为一个序列标注串行模型,一个基于字分类的联合模型和一个将这两种模型使用Stacked Learning框架进行集成的融合模型。通过在《人民日报》、CoNLL09、CTB5.0和CTB7.0四个数据集上进行比较分析,最终实验结果表明分类联合模型能取得比较好的速度,融合模型能取得比较好的准确率,而普通串行模型处于速度和准确率的平衡位置。最后该文将准确率最好的融合模型和相关前沿工作在CTB5.0和CTB7.0上进行了对比,该融合模型均取得了最好的结果。 ",MESS201304007
基于主动学习的本体概念关系判断,张桂平:24679273|李文博:28999912|王裴岩:24679272,7,本体; 概念关系; 辅助判断; 主动学习;,"该文依据关系判断任务特点将主动学习应用到本体概念关系的辅助判断中,对边缘采样、熵采样、最不确信采样等主动学习查询生成策略进行了比较研究。在此基础上,从实际应用角度出发,讨论了在三种不同样本初始情况下主动学习技术的应用。对于初始样本正反例充足的情况,采用基于熵采样和边缘采样产生查询;对于初始样本仅有正例的情况,依据样本相似度主动的学习策略生成候选反例;对于缺乏初始样本的情况,使用概念在样本间距离等统计信息,同时生成候选正例和候选反例。从而,实现了在概念关系判定过程中对用户反馈信息的有效利用。 ",MESS201304008
基于词元语义特征的汉语框架排歧研究,"李国臣1,2:08407515|张立凡1:29475624|李茹1,3:08453268|刘海静2:29475625|石佼1:29475626",8,框架排歧; 汉语框架网语义资源; 自动特征选择; 词元语义特征;,"框架排歧指的是在一个给定的句子中,判断句中目标词激起的语义场景与该目标词可能激起的哪个框架一致,则将该框架分配给当前的目标词。框架排歧最重要的一个步骤就是特征选择,目前常用的方法是人工特征选择方法,但是这种方法不能有效地利用每个目标词的语义特征,而且大量实验表明,不同的目标词取得最好的结果时所用的特征模板是不同的。因此,该文为每个目标词设置一个特征模板,并提出了特征模板的自动选择算法,首先从语料中抽取特征构成特征集,然后利用打分机制,把特征集中得分最高的特征逐个加入到特征模板中,直到相邻两次的得分不再增加。该文借助汉语框架网语义资源,利用最大熵模型建模,使用自动特征选择算法选出特征模板,并进行5-fold交叉验证,平均精确率可达到84.46%。 ",MESS201304009
基于条件随机场的藏语自动分词方法研究与实现,李亚超1:27243481|加羊吉1:24688520|宗成庆2:10815045|于洪志1:09120080,7,藏语自动分词; 条件随机场; 紧缩词识别; 格助词;,"藏语自动分词是藏语信息处理的基础性关键问题,而紧缩词识别是藏语分词中的重点和难点。目前公开的紧缩词识别方法都是基于规则的方法,需要词库支持。该文提出了一种基于条件随机场的紧缩词识别方法,并在此基础上实现了基于条件随机场的藏语自动分词系统。实验结果表明,基于条件随机场的紧缩词识别方法快速、有效,而且可以方便地与分词模块相结合,显著提高了藏语分词的效果。 ",MESS201304010
藏语判断、存在动词识别策略,"李琳1,2:28907685|龙从军1,3:11531165",5,藏语; 判断动词; 存在动词; 自动识别;,"判断动词与存在动词在藏语中使用频度高,兼类现象频繁,在不同语境下具有不同的含义。既可以表示判断、存在和领有意义,也可作为语法标记表达复杂的体貌、示证意义。判断、存在动词的多功能性给藏文文本分词标注、句型识别等工作带来较大的困难。借助藏语语法的研究成果和真实藏文文本,我们对这两类词的上下文语境进行了分析和归纳,进而提出了辨别这两类词的方法。首先,考察判断动词和存在动词在不同语境下的左右特征词;然后,建立了识别规则库,从肯定与否定两个方面判别其词性并标注。 ",MESS201304011
基于中心语块扩展的汉藏基本名词短语对的识别,诺明花:15570459|刘汇丹:09573793|马龙龙:27055084|吴健:09573880|丁治明:11204381,7,藏文信息处理; 基本名词短语; 中心语块扩展;,"该文提出汉藏基本名词短语对齐框架。从汉语基本名词短语出发,找藏文正确译文过程中,参考英汉短语对齐的方法,针对藏语的特殊性,提出基于中心语块扩展的藏语基本名词短语识别方法。提出词典与自动词对齐结果相结合的方法和基于序列相交的方法抽取藏语中心语块,再以扩展可信度为依据扩展中心语块。实验结果表明,基于序列相交的方法所抽取的汉藏基本名词短语对能够节省人工校正的工作量,有效辅助于汉藏基本名词短语库的建设。 ",MESS201304012
基于依存语法的蒙古语语义角色分类及其标记研究,包晓荣:11704887|华沙宝:08639277|达胡白乙拉:07994523,4,蒙古语语料库; 依存语法; 语义角色;,"该文从蒙古文信息处理角度出发,着重参考了其他语言语义角色标注的理论方法和蒙古语语义角色相关研究成果,结合蒙古语依存句法树库的特征,通过手工标注分析研究,制定了基于依存语法的蒙古语语义角色分类及其标记。 ",MESS201304013
简繁对应关系与简繁转换,王立军1:06367769|王晓明2:10803294|吴健3:09573880,10,简化字; 繁体字; 简繁对应关系; 简繁转换;,"简繁转换系统的最根本问题是语言文字的应用问题。其核心是针对中国大陆、中国港澳台等不同应用环境的简繁汉字对应关系和术语对照表。这项工作是十分复杂的,不可能一蹴而就,需要分阶段逐步完成。首要工作是要做好大陆地区简繁对应关系的分解,研制出适用于大陆内部的简繁转换系统。这一系统应该包括六大步骤,其中""字境""概念的引入,为提高简繁转换的准确率提供了有力的支撑。 ",MESS201304014
基于混合相关的Markov网络信息检索扩展模型,甘丽新1:28803348|涂伟1:28803347|王明文2:08472511|石松3:28833330,7,混合相关; Markov网络; 查询扩展;,"查询扩展是提高检索性能的有效方法。为了弥补在数据集中由于词对没有直接出现而导致无法统计出词间关系进行查询扩展的缺陷,该文通过提取Markov网络中的词团信息来量化词间的混合相关性,将强化后的词间混合相关性应用于信息检索扩展模型中。实验表明:基于混合相关的Markov网络信息检索扩展模型的检索效果优于基于直接相关的查询扩展模型;此外,该文提出的模型在总体检索性能上略优于基于团的Markov网络信息检索模型,但在词团提取上大大减少了计算开销。 ",MESS201304015
基于用户生成内容的产品搜索模型,"王海雷1,2:28949962|章彦星3:24536794|赵海玉3:29475627|张铭3:06276534",7,产品搜索; MNL模型; 情感分析; 特征选取; 用户生成内容;,"以消费者行为分析和离散选择的相关理论为基础,通过对用户生成内容进行特征粒度的情感分析,同时从产品的客观数据和用户生成的主观内容中提取模型特征,使用有监督的学习训练MNL模型预测产品的消费者剩余作为搜索排序的依据,并实现了手机、笔记本电脑和数码相机类的产品搜索系统。双盲实验表明,该文提出的产品搜索模型搜索效果比基准算法有显著的提高。 ",MESS201304016
基于排序学习的微博用户推荐,彭泽环:29475628|孙乐:10352504|韩先培:26496192|石贝:29475629,7,排序学习; 用户推荐; 微博;,"该文在分析总结影响微博用户推荐的四大类信息,包括用户的内容信息、个人信息、交互信息和社交拓扑信息的基础上,提出一个基于排序学习的微博用户推荐框架,排序学习的本质是用机器学习中的分类或回归方法解决排序问题,该框架可以综合各类信息特征进行用户推荐。实验结果表明:(1)融合多个特征综合推荐通常可以取得更好的推荐效果;(2)基于用户个人信息、交互信息、社交拓扑信息的推荐效果均好于基于用户内容的推荐效果。 ",MESS201304017
维吾尔语评论文本主题抽取研究,禹龙1:09256058|田生伟2:09220503|黄俊3:27500740,10,主题抽取; 陈述级; 显式主题; 隐式主题; 维吾尔语;,"主题抽取是意见挖掘的核心任务之一。该文面向维吾尔语评论文本,针对显式主题和隐式主题,提出了一种陈述级的主题抽取方法。该方法采用GLR-Cascaded LDA模型抽取段落级的局部主题、篇章级的全局主题,建立全局—局部主题关系,并将这些关系对应到每个意见陈述中;然后运用Bootstrapping和模式匹配的方法进行显式陈述的主题抽取;最后使用隐式主题推断算法推断隐式陈述的主题。主题抽取的最终目标是为每个意见陈述建立意见陈述—主题四元组<OC,GT,LT,CT>。实验结果证明了该方法在主题抽取任务中的有效性。 ",MESS201304018
不平衡情感分类中的特征选择方法研究,王志昊:25189782|王中卿:23843509|李寿山:27030929|李培峰:09886822,6,情感分类; 不平衡数据; 特征选择;,"随着网络的发展,情感分类任务受到广大研究人员的密切关注。针对情感分类中的不平衡数据分布和高维特征问题,该文比较研究了四种经典的特征选择方法在不平衡情感分类中的应用。同时,该文提出了三种不同的特征选择模式并实验比较了这三种模式在分类和降维性能方面的表现。实验结果表明在不平衡数据的情感分类任务中,特征选择方法能够在不损失分类效果的前提下显著降低特征向量的维度。此外,特征选择方法中信息增益(IG)结合""先随机欠采样后特征选择""模式能够取得最佳的分类效果。 ",MESS201304019
一种启发式多标记分类器选择与排序策略,李哲:23489502|王志海:06323687|何颖婧:29475630|付彬:23494884,8,多标记分类; 文本分类; 数据挖掘;,"在多标记分类问题当中,多标记分类器的目的是为实例预测一个与其关联的标记集合。典型方法之一是将多标记分类问题转化为多个二类分类问题,这些二类分类器之间可以存在一定的关系。简单地考虑标记间依赖关系可以在一定程度上改善分类性能,但同时计算复杂度也是必须考虑的问题。该文提出了一种利用多标记间依赖关系的有序分类器集合算法,该算法通过启发式的搜索策略寻找分类器之间的某种次序,这种次序可以更好地反映标记间的依赖关系。在实验中,该文选取了来自不同领域的数据集和多个评价指标,实验结果表明该文所提出的算法比一般多标记分类算法具有更好的分类性能。 ",MESS201304020
商务印书馆推出《新华成语大词典》,,1, ,"<正>商务印书馆辞书研究中心编2013年1月出版定价:138.00元ISBN 978-7-100-06434-7《新华成语大词典》是一部大型成语辞书,500万字,收成语26 000余条。词 ",MESS201304021
汉语组块分析研究综述,"李业刚1,2:26776335|黄河燕1:23136252",8,中文信息处理; 浅层句法分析; 组块分析; 组块识别;,"组块分析作为浅层句法分析的代表,既可以满足很多语言信息处理系统对于句法功能的需求,又可以作为子任务,在词法分析和完全句法分析以及语义分析中间架起一座桥梁,为句子进行进一步深入分析提供有力的支持,因此众多的研究将注意力集中于组块分析上。该文主要对组块的定义和分类、组块识别方法、组块的标注和评测以及组块内部关系分析等几方面的研究进展进行详细的综述。最后,探讨了组块分析存在的问题并对未来的发展方向进行了展望。 ",MESS201303002
基于统计学习模型的句法分析方法综述,"吴伟成1:29246672|周俊生1:08116958|曲维光1,2:08112756",11,句法分析; 统计学习模型; 生成式模型; 判别式模型; 移进—归约决策; 面向数据的句法分析;,"句法分析是自然语言处理领域中重要的基础研究问题之一。近年来,基于统计学习模型的句法分析方法研究受到了广泛关注,多种模型与算法先后被提出。从采用的学习模型和算法类型着手,该文系统地对各种主流和前沿方法进行了归纳与分类,着重对各类模型和算法的思想进行了分析和对比,并对中文句法分析的研究现状进行了综述;最后,对句法分析下一步的研究方向与趋势进行了展望。 ",MESS201303003
篇章分析技术综述,,14,篇章; 篇章分析; 语料库; 评测;,"篇章作为词和句子之后的一种文本分析粒度在自然语言理解和自然语言生成中起到至关重要的作用。该文从计算语言学角度出发,对中英文篇章分析技术的研究现状进行了综述。介绍了中英文篇章分析技术在自然语言处理中的应用,并分别从篇章理论、篇章语料库及评测、篇章分析器的自动构建等方面详细阐述了中英文篇章分析技术。最后归纳出篇章分析技术后续研究的几个方向。 ",MESS201303004
叙事生成方法研究综述,"诸峰1,2:29246674|曹存根1:10348278",8,叙事生成; 故事生成; 叙事智能; 自然语言生成;,"随着人工智能和自然语言处理技术的飞速发展,近年来,关于叙事自动生成的研究逐渐被人们所关注和重视。该文介绍了叙事生成的相关概念、历史背景以及当前的研究现状,总结和归纳了目前主要的叙事生成研究方法,包括基于智能规划的方法、基于常识和知识本体的方法、基于故事文法的方法等。在此基础上,对各类方法的基本思想、相关工作及主要优缺点进行了深入的分析,并探讨了当前叙事生成研究中存在的不足及未来的发展趋势。 ",MESS201303005
现代汉字形声字声符在普通话中的表音度测查,胡韧奋1:24106271|曹冰2:29246675|杜健一3:29246676,7,现代汉字; 形声字; 声符; 表音度; 聚类分析;,"""形声""作为一种重要的造字方式,构筑了汉字家族中最为庞大的一支。造字之初,形声字以形符表义,以声符表音。随着时代的发展,声符的表音度渐渐发生变化,为人们准确地标音读字造成了一定困难。该文试采用聚类分析的方法,以普通话中3 500常用汉字为对象,结合语言学理论和计算机知识,依据声符表音程度相同、相似和不同制定详细分级标准,并得到每一层级的形声字表和百分数据,从而对现代汉字中形声字声符的表音度情况进行系统、直观而全面地呈现,以期为现代汉字规范的制定和汉语教学提供一定的参考和佐证。 ",MESS201303006
普通话发音评估性能改进,"齐欣1:29246677|肖云鹏1,2:23246664|叶卫平1:06374351",8,发音评估; PNCC; 模型拆分; HMM状态数;,"为减少噪声环境对评估性能的影响,该文将PNCC参数引入普通话发音评估。结果表明,其评分相关性在普通话测试实录音数据库上较传统MFCC参数提高了6.6%。在此基础上,对汉语声学模型拆分方法进行了研究,提出将声母介音+韵母模型拆分方法应用到发音评估中。使用这种拆分方式的评估系统总错误率降低5.6%,专家打分相关性则提高了0.056。该文还对模型最佳状态数的选取进行讨论,并提出模型状态数混合和不同配置综合评分两种混合评分方案,在相关性上较同等条件下3状态模型分别提高了0.021和0.017。 ",MESS201303007
基于输出概率分布的集外词拒绝,"黄石磊1,2:28020861|刘轶2:26182325|程刚2:23788353",5,语音识别; 关键词确认; 置信度;,"该文提出了一种基于音子HMM输出概率分布(OPD)计算集外词(OOV)拒绝的方法,该方法主要用于语音识别中的验证阶段。与动态垃圾模型中使用经过排序的概率数值的方法相比,OPD向量包含了更多的信息。每个音素的置信值都是以OPD向量为输入的支持向量机(SVM)分别计算出,并得到词的置信度,确定候选词被接受或拒绝。实验结果表明,所提出的方法在语音识别的验证任务中,与传统的动态垃圾模型相比,等错误率EER值相对降低了11.0%。 ",MESS201303008
语料对中文名词短语指代消解影响研究,高俊伟:28001083|孔芳:08865090|朱巧明:09891804|李培峰:09886822,8,指代消解; 名词短语; 无监督; 聚类; 语料;,"指代是自然语言中一种常见的语言现象,对简化语言,减少冗余有很大的作用。指代消解是用计算机找出这些指代现象的一个过程。近几年英文指代消解研究取得了很大的成就,然而,中文指代消解研究目前还较少,一方面是由于中文自然语言处理的研究起步较晚,相关的知识较少,另外一方面就是中文相关的语料库较少,目前已知的仅有ACE2005,OntoNotes等。为了探讨语料库对中文名词短语指代消解的影响,该文实现了一个基于有监督学习方法的中文名词短语指代消解平台和一个基于无监督聚类方法的中文名词短语指代消解平台,在此平台的基础上从语料库的数量和质量两个方面来探讨语料对中文名词短语指代消解的影响。 ",MESS201303009
基于层叠CRFs的中文句子评价对象抽取,郑敏洁1:06691397|雷志城2:28178751|廖祥文2:23769186|陈国龙2:06679915,8,评价对象; 层叠条件随机场; 降噪模型; 补充模型;,"中文句子评价对象抽取是指在中文句子中抽取评论所针对的对象或对象的属性。目前国内相关研究工作尚未能有效识别复合词评价对象和未登陆评价对象。针对以上两种情况,该文提出了一种基于层叠条件随机场的中文句子评价对象抽取方法。该方法首先通过低层条件随机场获得候选评价对象集,然后通过降噪模型对噪声进行过滤、补充模型对缺失的候选评价对象进行补充、合并模型对复合短语候选评价对象进行合并,最后由高层模型抽取出评价对象。实验结果显示,与基于线性链条件随机场的识别方法相比,该方法准确率、召回率和F1值分别提升1.62%、5.75%和4.17%,能有效地识别复合词评价对象和未登录评价对象,从而提高中文句子评价对象的识别精度。 ",MESS201303010
领域问答系统中的文本错误自动发现方法,"刘亮亮1,2:29246679|王石1:23246662|王东升1,2:29246680|汪平仄1,2:29246681|曹存根1:10348278",7,文本自动校对; 问答系统; 非词错误; 真词错误; 错别字对;,"文本自动校对是自然语言处理的一个挑战性的研究课题,也是一个难题。该文对中文的错误类型和原因进行分析,提出了一种基于领域问答系统用户问题日志的错别字自动发现方法。该方法首先对语料进行分词,然后对分词的结果中出现的散串进行合并,对分词中的多字词和合并的串进行相似词串聚类,对相似词串的上下文语境进行统计分析,从中自动获取错别字对。实验表明,该系统获得71.32%的召回率,82.6%的准确率。 ",MESS201303011
基于短语串实例的汉藏辅助翻译,"熊维1,2:27055082|吴健1:09573880|刘汇丹1,2:09573793|张立强1:25200613",7,机器翻译; 辅助翻译; 基于短语的机器翻译; 基于实例的机器翻译;,"目前汉藏机器翻译的研究主要集中在基于规则的方法上,主要原因在于汉藏的平行语料等基础资源相对匮乏,不方便做大规模的基于统计的汉藏机器翻译实验。该文依据汉藏辅助翻译项目的实际需求,在平行语料资源较少的情况下,提出了一种基于短语串实例的机器翻译方法,为辅助翻译提供候选译文。该方法主要利用词语对齐信息来充分挖掘现有平行语料资源信息。实验结果表明,该文提出的基于短语串实例方法优于传统基于句子实例的翻译,能够检索出任意长度的短语串翻译实例。在实验测试集上,该方法与默认参数下的Moses相比,翻译的BULE值接近Moses,短语翻译实例串的召回率提高了约9.71%。在平均句长为20个词的测试语料上,翻译速度达到平均每句0.175s,满足辅助翻译实时性的要求。 ",MESS201303012
URL模式与HTML结构相结合的平行网页获取方法,刘奇:11577923|刘洋:45684033|孙茂松:08823738,9,平行网页获取; 平行语料库; URL模式; HTML结构;,"平行语料库是对机器翻译、跨语言信息检索等应用技术具有重要支撑作用的基础数据资源。虽然互联网上的平行网页数量巨大且持续增长,但由于平行网站的异构性和复杂性,如何快速自动获取高质量的平行网页进而构造平行语料库仍然是巨大的挑战。该文提出了一种URL模式与HTML结构相结合的平行网页获取方法,首先利用HTML结构实现平行网页的递归访问,其次使用URL模式优化遍历平行网站的拓扑顺序,从而实现高效准确的平行网页获取。在联合国与香港政府①两个平行网站上的实验表明,该方法相对传统获取方法在获取时间上减少50%以上,准确率提高15%,并显著提高了机器翻译的质量(BLEU值分别提高1.6和0.7个百分点)。 ",MESS201303013
基于众包的词汇联想网络的获取和分析,丁宇:26962746|车万翔:06987220|刘挺:06994824|张梅山:27030882,7,众包; 语义相关性词典; 词汇联想网络;,"词典是汉语自然语言处理中非常重要的一类资源,它能为汉语词法句法以及语义分析等提供资源支撑。该文采用众包方法构建汉语语义相关性词典,该词典是通过触发词联想的方式间接获取的,因此又称为词汇联想网络。词汇联想网络相比传统词典具有以下特点:(1)获取代价低;(2)面向互联网,易扩展;(3)词语关系从人的认知角度来建立,符合人的直觉。该文详细介绍词汇联想网络的获取方法并对已获取的数据进行分析,另外,将词汇联想网络与《知网》、《同义词词林》以及微博文本ngram进行比较说明其上述特点。 ",MESS201303014
FrameNet中有定的零形式识别,"雷章章1:29246682|王宁1:22660717|李茹1,2:08453268|王智强1:25200586",7,FrameNet; 有定的零形式识别; 最大熵;,"在FrameNet,有定的零形式识别旨在发现框架语义标注语料中需要填充的零形式框架元素,有助于篇章理解能力的提高。针对该任务,该文提出一个简单的二级流水线的有定的零形式识别方法:第一级基于规则在语义角色标注的基础上检测出语料中的零形式,第二级使用最大熵分类器预测检测出来的零形式类别,以达到有定的零形式识别的目的。实验在SemEval-2010Task 10的测试集中的结果显示,零形式检测的召回率和分类准确率分别为60.1%和53.5%,接近于评测给出的最好结果。 ",MESS201303015
基于词义类簇的文本聚类, ,7,文档聚类; 文档表示; 话题模型;,"文档表示是文本聚类的重要组成部分,该文旨在通过改进文档表示改进文本聚类。同义词和多义词现象是文档表示所面临的重要挑战。为此该文提出了词义类簇模型(Sense Cluster Model,SCM),在词义类簇空间上表示文档。SCM首先构造词义类簇空间,然后将文档表示在词义类簇空间上,获得每篇文档在每个词义类簇的概率。在词义类簇空间构造这一步骤中,首先利用词义归纳技术从文本中自动发现词义,接着采用词义聚类技术识别相同或者相似的词义从而获得词义类簇。词义类簇空间构造后,该文首先进行词义消歧,然后利用词义消歧的结果将文档表示在词义空间上。实验表明,SCM在标准测试集上的性能优于基线系统以及经典话题模型LDA。 ",MESS201303016
基于集成学习的半监督情感分类方法研究,高伟:08845358|王中卿:23843509|李寿山:27030929,7,情感分类; 半监督; 集成学习;,"情感分类旨在对文本所表达的情感色彩类别进行分类的任务。该文研究基于半监督学习的情感分类方法,即在很少规模的标注样本的基础上,借助非标注样本提高情感分类性能。为了提高半监督学习能力,该文提出了一种基于一致性标签的集成方法,用于融合两种主流的半监督情感分类方法:基于随机特征子空间的协同训练方法和标签传播方法。首先,使用这两种半监督学习方法训练出的分类器对未标注样本进行标注;其次,选取出标注一致的未标注样本;最后,使用这些挑选出的样本更新训练模型。实验结果表明,该方法能够有效降低对未标注样本的误标注率,从而获得比任一种半监督学习方法更好的分类效果。 ",MESS201303017
商务印书馆新近推出北大版《现代汉语》(增订本),,1, ,<正>《现代汉语》(增订本)北京大学中文系现代汉语教研室编主持人:郭锐王理嘉陆俭明编者:绪论(王理嘉李小凡)、语音(王理嘉)、文字(苏培成)、词汇(符淮青万艺玲)、语法(陆俭明马真)、修辞(袁毓林)2012年8月出版开本:16开 ,MESS201303018
基于大规模语料库的汉语词义相似度计算方法,石静1:24703288|吴云芳1:06270718|邱立坤2:28907681|吕学强3:10724564,7,词义相似度; 上下文特征; 权值选择; 依存关系;,"词义相似度的计算是自然语言处理领域的关键问题之一,它在信息检索中的查询扩展、机器翻译中的模块识别,以及句法分析、词义消歧等任务中都发挥着重要的作用。该文研究了基于大规模语料库的汉语词义相似度计算方法,系统地比较分析了上下文特征权值的选择、向量相似度计算方法、基于窗口和基于依存关系的表征形式、新闻语体和网络语体的差异。实验结果表明,在网络语言语料上,基于窗口选取上下文特征,用互信息PMI来计算权值,采用cosine来计算相似度,取得了最好的词义相似度结果。 ",MESS201301000
一种基于搭配的中文词汇语义相似度计算方法,"王石1:23246662|曹存根1:10348278|裴亚军2:22640605|夏飞1,3:28907682",8,语义相似度; 词汇搭配; 相似度基准测试集;,"词汇间的语义相似度计算在自然语言处理相关的许多应用中有基础作用。该文提出了一种新的计算方法,具有高效实用、准确率较高的特点。该方法从传统的分布相似度假设""相似的词汇出现在相似的上下文中""出发,提出不再采用词汇在句子中的邻接词,而是采用词汇在二词名词短语中的搭配词作为其上下文,将更能体现词汇的语义特征,可取得更好的计算结果。在自动构建大规模二词名词短语的基础上,首先基于tf-idf构造直接和间接搭配词向量,然后通过计算搭配词向量间的余弦距离得到词汇间的语义相似度。为了便于与相关方法比较,构建了基于人工评分的中文词汇语义相似度基准测试集,在该测试集中的名、动、形容词中,方法分别得到了0.703、0.509、0.700的相关系数,及100%的覆盖率。 ",MESS201301001
基于双语依存关系映射的中英文词表构建研究,徐华:08849388|刘丹丹:08865739|钱龙华:08844995|周国栋:13898054,6,双语词表构建; 依存上下文模型; 依存关系映射;,"基于上下文的双语词表构建方法是比较流行的基于可比较双语语料库的双语词表构建方法。特别地,依存上下文模型从句子的依存树上抽取词语的上下文特征,由于依存关系更能体现词语之间的共现关系,因而这种方法提高了构建双语词表的性能。该文在此基础上,进一步提出了依存关系映射模型,即通过同时匹配依存树中的上下文词语、依存关系类型和方向来实现双语词表的构建。在FBIS语料库上的实验表明,该方法在中文—英文和英文—中文两个方向上的双语词表构建上均取得了较好的性能,这说明了依存关系映射模型在双语词表构建中的有效性。 ",MESS201301002
网页中商品“属性—值”关系的自动抽取方法研究,唐伟:13969171|洪宇:25038035|冯艳卉:25202917|姚建民:13898051|朱巧明:05968617,10,商品“属性—值”关系抽取; Web数据挖掘; 模板构建;,"商品属性及其对应值的自动挖掘,对于基于Web的商品市场需求分析、商品推荐、售后服务等诸多领域有重要的应用价值。该文提出一种基于网页标题的模板构建方法,从结构化网页中抽取完整的商品""属性—值""关系。该方法包含四个关键技术:1)利用商品网页标题构建领域相关的属性词包;2)基于预设分隔符细化文本节点;3)结合领域商品属性词包获取种子""属性—值""关系;4)结合网页布局信息和字符信息来筛选与构建模板。该文的实验基于相机和手机两个领域展开,获得94.68%的准确率和90.57%的召回率。 ",MESS201301003
事件超图模型及类型识别,"肖升1,2:27472016|何炎祥1:10133728",9,事件抽取; 事件类型识别; 超图; 有向超图; 事件超图模型; 事件相似度;,"为避免向量空间模型的独立性假设影响事件类型识别,该文提出了一种基于超图的事件类型识别方法。该方法首先用事件超图描写事件元素间的多元有序关系;然后用事件超图模型(由事件超图添加类型组件和层面组件后构成)描述某个(某类)事件在不同观测层面的属性及其结构;最后根据事件的属性及其结构计算其相似度,并借此完成事件类型识别。实验结果显示,此方法识别效率的平均F值达到83.0%,与基于向量空间模型的支持向量机方法和最大熵方法相比,此方法也具有一定优势。 ",MESS201301004
一种基于社会化标签的信息检索方法,"李鹏1,2:22045099|王斌1:09559997|晋薇3:27490694",9,社会化标注; 标签; 语言模型; 话题模型;,"社会化标签提供了网页信息的额外描述,直观上对搜索具有重要价值。该文提出一种新颖的利用社会化标签的分类属性进行检索的方法。该方法通过将群体的标注信息建模为高层类别来估计话题模型,然后基于该话题模型来对语言模型进行平滑。建模方法可以降低标注稀疏性的影响,有效地表达标签含义,从而提升检索效果。基于TREC评测构建的数据集上的实验结果表明,该方法优于基于LDA的检索方法以及现有其他基于标签数据的检索方法。 ",MESS201301005
中文博客多方面话题情感分析研究,傅向华:15492784|刘国:26281787|郭岩岩:28907683|郭武彪:28358179,9,多方面情感分析; 博客情感分析; LDA模型; HowNet词典;,"博客是Web环境中个人表达观点和情感的一种重要载体,一般涉及较宽泛的话题,蕴含丰富的舆情信息。现有针对有关社会事件的用户产生内容进行情感分析的研究多数以篇章级为处理粒度,尚不能满足博客文本深度情感分析的需求。该文提出一种基于LDA话题模型与Hownet词典的中文博客多方面话题情感分析方法。该方法首先利用数据语料训练LDA话题模型,然后以滑动窗口为基本处理单位,利用训练好的LDA模型对博客文本进行话题识别与划分;在此基础上,基于Hownet词典对划分后的话题段落进行情感倾向计算。该方法有助于同时识别博客文本所涉及的多方面子话题及每个子话题上的情感倾向。实验结果表明,该方法不仅能获得较好的话题划分结果,也有助于改善情感分析的准确率。 ",MESS201301006
第三届中文倾向性分析评测(COAE2011)语料的构建与分析,廖祥文1:23769186|许洪波2:10348532|孙乐3:10352504|姚天昉4:08576605,8,中文信息处理; 倾向性分析; 倾向性语料库; 文本编码规范;,"文本倾向性分析已成为自然语言处理领域研究的热点问题之一。为进一步推动中文倾向性分析的研究,中国中文信息学会信息检索专业委员会举办了第三届中文倾向性分析评测(COAE2011)。该次评测主要关注领域和上下文语境(Context)对中文倾向性分析的影响。该文主要介绍COAE2011评测语料的构建及其对评测的支撑:首先介绍了COAE2011语料的领域选取、媒介分布等获取过程,然后详细阐述语料的标注原则与方法,最后依据评测结果分析领域和上下文语境因素对倾向性的影响。COAE2011语料的建立将为中文倾向性分析提供强大的资源支持。 ",MESS201301007
统计机器翻译中一致性解码方法比较分析,"段楠1:21767412|李沐2:14788529|周明1,2:08920905",9,自然语言处理; 统计机器翻译; 一致性解码; 最小贝叶斯风险解码; 系统融合;,"该文对近年来统计机器翻译研究中出现的多种一致性解码方法进行比较与分析。根据现有一致性解码方法对(单个或多个)统计机器翻译系统输出结果使用方式的不同,首先将其归纳为两大类:基于翻译假设重排序的一致性解码方法和基于翻译假设重组合的一致性解码方法;然后,针对每类方法,分别回顾其最具代表性的研究工作;最后,通过在大规模中—英机器翻译评测数据上的对比实验,对该文中介绍的多种方法进行比较,并对该课题未来研究方向进行展望。 ",MESS201301008
BFS-CTC汉语句义结构标注语料库,刘盈盈:27354924|罗森林:06346792|冯扬:23149803|韩磊:06349344|陈功:06339094|王倩:11277242,9,自然语言处理; 语义标注; 句义结构; 语料库;,"句义结构分析是汉语语义分析中不可逾越的重要环节,为了满足汉语句义结构分析的需要,基于现代汉语语义学理论构建了一种层次化的汉语句义结构模型,定义了标注规范和标记形式,建设了一个汉语句义结构标注语料库BFS-CTC(Beijing Forest Studio-Chinese Tagged Corpus)。标注内容方面,基于句义结构模型的定义标注了句义结构句型层、描述层、对象层和细节层中所包含的各个要素及其组合关系,包括句义类型、谓词及其时态、语义格类型等信息,并且提供了词法和短语结构句法信息,便于词法、句法、句义的对照分析研究;语料库组织结构方面,该语料库包括四个部分,即原始句子库、词法标注库、句法标注库和句义结构标注库,可根据研究的需要,在词法、句法、句义结构标注的基础上进行深加工,在核心标注库的基础上添加更多具有针对性的扩展标注库,利用句子的唯一ID号进行识别和使用;语料来源和规模方面,语料全部来自新闻语料,经过人工收集、整理,合理覆盖了主谓句、非主谓句、把字句等六种主要句式类型,规模已达到10 000句。同其他语义标注库相比,BFS-CTC基于现代汉语语义学,提供了多层次的句义结构标... ",MESS201301009
基于统计的记叙文语句焦点的分布特点研究,"赵建军1,2:28048592|杨玉芳2:09646963|吕士楠3:10357466",5,记叙文; 焦点分布; 语义角色;,"该文通过20人对30篇汉语记叙文中语句焦点的标定结果,结合文本标注和统计分析,对焦点在词类和语义角色中的分布规律进行了探讨。结果主要发现,记叙文语篇中焦点词大约占实词总数的五分之一。形容词成为焦点的概率远高于其他词类。焦点在语义角色中分布的总体趋势是:客体论元的焦点化倾向最高,其次是外围论元,最低的是主体论元和谓词部分。 ",MESS201301010
基于组合核的蛋白质交互关系抽取,李丽双:06521783|刘洋:06528827|黄德根:06527360,8,蛋白质交互关系抽取; SVM; 树核; 组合核; 修剪策略;,"蛋白质交互关系(PPI)抽取是生物医学信息抽取领域的一个重要部分,具有很高的应用价值和实际意义。该文使用一种基于SVM的组合核方法进行蛋白质关系抽取,将基于特征的平面核和基于结构的卷积树核组合。一棵完整的句法解析树中包含了较多噪声,需对其修剪以提高PPI抽取效果。首先讨论不同的树的剪裁策略对实验结果的影响,分别使用完全树、最小完全树、最小树和最短路径闭包树进行实验,最短路径闭包树效果最好;然后在最短路径闭包树的基础上提出一种动态拓展树,该树取得了明显优于其他解析树的效果。最后基于组合核在AIMED上进行10倍交叉实验,精确率、召回率和F值分别达到了82.40%、51.30%和63.23%。 ",MESS201301011
“方言同音字汇”自动生成软件的设计及实现,"程南昌1,2:28220301|侯敏3:10316023",5,方言同音字汇; 竖排表; 自动生成; 设计原理;,"""方言同音字汇""整理是方言调查的基础性工作,靠手工制作十分繁难。该文论述了""方言同音字汇""自动生成软件的设计原理及实现过程。软件的主要功能是,根据用户事先给定的韵、声、调排序依据和排序顺序,对已经录入的方言字表进行排序,排序技术采用对应韵、声、调与字表所有字目的一个四重循环,最终生成""同音字汇竖排表""。此外,该文对软件的实用性能进行了分析,并对软件的应用进行了一定的说明。实践证明,该软件完全能够满足方言调查实用化的需求。 ",MESS201301012
针对发音质量评测的声学模型优化算法,严可1:23368356|魏思2:28360400|戴礼荣1:09539044,9,计算机辅助学习; 区分性训练; 普通话水平测试; 发音质量评测;,"在发音质量评测研究中,传统仅用发音标准的数据进行声学建模,难以描述实际测试面临的非标准发音,使得训练与测试的失配在所难免。针对上述问题,该文提出一种利用覆盖各种发音的数据,根据最小化机器分与人工分均方误差准则进行声学模型优化的算法。实验在普通话水平考试现场3 685份数据(其中498份测试,3 187份训练)上进行。实验表明采用优化算法得到的针对发音质量的评测声学模型相比传统建模方式得到的声学模型有显著的优势。 ",MESS201301013
新标准体系下蒙古文变形显现模型的设计与实现,"王震1,2:27055083|刘汇丹1,2:09573793|吴健1:09573880",7,国家标准; 蒙古文变形模型; OpenType字库; Qt4; Pango;,"国家标准GB 25914-2010的提出,为蒙古文变形规则提供了统一的可实施的标准。目前还缺乏完全符合该标准的蒙古文变形引擎和OpenType蒙古文字库。针对这一问题,该文提出了一种符合新标准的蒙古文变形模型,该模型具有高效率和通用性。我们利用蒙古文变形模型分别在KDE平台下的复杂文本布局引擎Qt4和GNOME平台下的Pango中实现了对蒙古文的变形支持。实验结果证明了该模型的有效性。其中,通过对Pango增加蒙古文变形支持,GNOME平台下的Firefox等应用程序也能正确显示蒙古文。该模型的实现,为研制符合新标准的以GNOME或者KDE为桌面环境的蒙古文操作系统奠定了基础。 ",MESS201301014
现代藏语助动词结尾句子边界识别方法,"赵维纳1,2:25200636|于新2:25200638|刘汇丹2,3:09573793|李琳1,4:28907684|王磊5:24196375|吴健2:09573880",5,藏语分句; 藏语句子边界识别; 藏语信息处理; 中文信息处理;,"藏语句子边界的正确识别是藏文文本处理首先要解决的问题。而藏语书面语中标点符号的特殊性是造成藏语句子边界识别困难的主要原因。该文主要对现代书面藏语中常见的以藏语助动词结尾的藏语句子边界识别进行研究,结合藏文标点符号的特点提出藏语助动词结尾句子边界识别方法。 ",MESS201301015
水书键盘输入系统研究与实现,陈笑蓉:06939837|杨撼岳:24273078|郑高山:24273077|黄千:26465974,9,水书; Unicode; 字库; 输入法;,"水族文字被称为水书。为了满足水书研究者和出版业界的需要,设计了水字字符集的Unicode编码,利用字体制作软件建立了水字TrueType字库。该文提出了一种基于笔形特征的编码方法,依据编码规则取水字3个角的笔形组成有序序列,为水字编码。利用Windows系统的IMM-IME机制,实现了水字笔形输入法。 ",MESS201301016
商务印书馆新书目录,,1, , ,MESS201301017
基于单层标注级联模型的篇章情感倾向分析,李本阳:25581078|关毅:06991644|董喜双:25202940|李生:06989058,7,情感倾向分析; 情感分类; 级联模型; 最大熵; 支持向量机;,"情感分类是目前篇章情感分析的主要方法,但该方法存在难以融入中文结构特征的问题。针对此问题,采用级联模型对篇章情感倾向进行分析,将篇章情感倾向分析分为两层:小句级和篇章级,对篇章情感倾向分析引入小句级的情感分析。该文使用最大熵模型处理小句级情感分类,小句级的输出作为上层篇章级的输入,并结合句型特征和句子位置等信息作为特征,采用支持向量机模型进行篇章级情感分类。同时对于级联模型中双层标注问题,基于交叉验证的思想提出了单层标注级联模型,避免了多层标注工作以及错误。实验结果表明,该方法的准确率较传统情感分类方法提高了2.53%。 ",MESS201204000
文本处理中的MapReduce技术,"李锐1,2:27772468|王斌1:09559997",12,文本处理; MapReduce; 分布式计算; 综述; Hadoop;,"用于文本处理的很多数据集已经达到TB、PB甚至更大规模,传统的单机方法难以对这些数据进行有效处理。近年来出现的MapReduce计算框架能够以简洁的形式和分布式的方案来解决大规模数据的并行处理问题,得到了学术界和工业界的广泛认可和使用。目前,MapReduce已经被用于自然语言处理、机器学习及大规模图处理等领域。该文首先对MapReduce做了简单的介绍,并分析了其特点、优势还有不足;然后对MapReduce近年来在文本处理各个方面的应用进行分类总结和整理;最后对MapReduce的系统和性能方面的研究也做了一些介绍与展望。 ",MESS201204001
微博文本处理研究综述,"张剑峰1,2:08243216|夏云庆1:10931903|姚建民2:13898051",8,微博文本; 语言分析; 文本处理;,"微博是一个基于关系的信息分享、传播以及获取平台。用户可以通过WEB、WAP以及各种客户端组件,以140字左右的文字更新信息,并实现即时分享。由于微博发展迅猛,微博文本已经形成了大规模积累,针对微博文本的研究已经成为了一个十分重要的课题。该文对微博文本进行了定义,阐述了微博文本研究的重要性,并从微博文本的不同应用领域出发,对微博文本的研究现状进行了综述,介绍了目前已经存在的微博文本数据集和应用系统。 ",MESS201204002
基于甲骨文字形动态描述库的甲骨文输入方法,"栗青生1,2,3:06215377|吴琴霞1,3:21990659|王蕾1,3:06214850",6,甲骨文字形; 字形描述; 输入; 编码;,"该文分析了目前常用的甲骨文字在编码和输入方面的问题和不足,给出了一种甲骨文字形动态描述的方法。该方法在现代汉字的编码和书写规范基础上,使用有向笔段和笔元对甲骨文进行描述,用扩展的编码区域和外部描述字形库相结合的方式,解决了甲骨文字特别是异体字和没有识别的甲骨文字的输入和输出问题。 ",MESS201204003
古汉语双字词自动获取方法的比较与分析,段磊:27772470|韩芳:06362190|宋继华:06364557,9,中文信息处理; 古汉语; 史记; 双字词; 统计模型;,"词汇的自动获取在自然语言生成、计算词典编纂、句法分析以及语料库语言学等领域均有着重要的研究价值。该文针对古汉语双字词的自动获取问题,以《史记》全文语料为例,分别应用基于频率、互信息、假设检验的统计方法获取古汉语双字词,并结合人工标注结果进行了详细的比较和分析,评价了各方法的优缺点及可靠性,为不同应用背景下的古汉语双字词自动获取提供了相应的解决方案。 ",MESS201204004
基于《知网》的中文信息结构消歧研究,张瑞霞1:15726650|庄晋林1:07518675|杨国增2:24549326,8,知网; 中文信息结构; 消歧; 图相容度; 语义相似度;,"《中文信息结构库》是《知网》的重要组成部分之一,可以作为中文语义分析的规则库,对其进行消歧是实际应用的基础之一。因此,该文首先对中文信息结构进行了形式化描述;接着对其进行优先级划分;然后根据其构成形式提出了四种不同的消歧方法:即词性序列消歧法、图相容匹配消歧法、图相容度计算消歧法、基于实例的语义相似度计算消歧法;最后针对不同优先级的中文信息结构集设计了不同消歧流程。实验结果证明消歧正确率达到了90%以上。 ",MESS201204005
汉语传统语法及其在中文信息处理中的应用展望,彭炜明1:24186788|宋继华2:06364557|王宁1:06365544|康明吉2:27772471,11,中文信息处理; 传统语法; 黎氏语法; 句本位; 句子格局; 句子成分;,"汉语传统语法首推黎锦熙《新著国语文法》为代表。黎氏语法是以讲句子成分和句子格局为主要特征的语法体系,被称为""句本位""的语法。该文首先简要回顾了汉语语法体系自《马氏文通》以来的变化发展历史,梳理了传统语法与结构语法两大流派的主要思想和理论特色。然后从汉语树库角度剖析了当前中文信息处理领域主流语法体系的优缺点,并将它们与传统语法体系做了深入的比较分析,得出将传统语法应用于中文信息处理的必要性。最后讨论传统语法在中文信息处理领域应用需要面对的几个关键问题。 ",MESS201204006
维吾尔语动词体范畴的有限状态自动机的构建,"阿孜古丽·夏力甫1,2:21835924|早克热·卡德尔3:22045086|吐尔根·依布拉音3:17705003",6,维吾尔语; 动词; 体范畴; 有限状态自动机; 形式化;,"维吾尔语动词的体范畴是维吾尔语动词语法范畴中极为复杂的范畴,也是维吾尔语信息处理中的难点问题之一,计算机对维吾尔语动词体范畴的处理是在对人称、时、否定等语法范畴处理之后才进行处理。但是难点就是体范畴重叠问题的解决。维吾尔语动词的体范畴词尾按照一定的规则连接在词干,这使得维吾尔语动词体范畴的重叠形式可用有限状态自动机形式化描述。因此它根据重叠规则构造从右向左的非确定自动机,之后把从右向左方向的自动机转换成从左向右的非确定自动机,最后把非确定自动机转换成确定自动机来实现维吾尔语动词体范畴的形式化描述。 ",MESS201204007
藏语机读音标SAMPA_ST的设计,于洪志:09120080|高璐:11557886|李永宏:09119993|郑文思:25583299,7,SAMPA_ST; 国际音标; 声母; 韵母; 声调;,"该文选取具有代表意义的藏语卫藏方言的拉萨话、安多方言的夏河话以及康方言的德格话进行语言调查;整理归纳藏语三大方言音系,包括单辅音、复辅音、单元音、复合元音和辅音韵尾,以及三大方言声调;依照SAMPA的规则建立适合于藏语三大方言的机读音标,并设计了SAMPA_ST的自动标注系统,实现文音转换功能,为语音的韵律特征分析和语音工程的研究提供依据。 ",MESS201204008
中文歧义研究25年——以《中文信息学报》论文为例,张禄彭1:20324255|易绵竹2:20301944|周云3:21079706,12,歧义; 消歧; 《中文信息学报》; 统计分析; 研究对象; 研究方法;,"过去的25年间中文信息处理领域的歧义研究取得了长足进步,涌现出大量科研成果。该文试图以中国中文信息学会会刊《中文信息学报》刊载的论文为例,着重从研究对象和研究方法两个方面观察探讨歧义研究的进展、特点和大体趋势。文章分时间段从多个角度对中文歧义研究进行定量统计分析,述评结合,针对歧义研究的现状提出了建议。 ",MESS201204009
基于随机特征子空间的半监督情感分类方法研究,苏艳:24217438|居胜峰:27030930|王中卿:23843509|李寿山:27030929|周国栋:13898054,6,情感分类; 半监督学习方法; 特征子空间;,"情感分类是目前自然语言处理领域的一个热点研究问题。该文关注情感分类中的半监督学习方法(即基于少量标注样本和大量未标注样本进行学习的方式),提出了一种新的基于动态随机特征子空间的半监督学习方法。首先,动态生成多个随机特征子空间;然后,基于协同训练(Co-training)在每个特征子空间中挑选置信度高的未标注样本;最后使用这些挑选出的样本更新训练模型。实验结果表明我们的方法明显优于传统的静态产生方式及其他现有的半监督方法。此外该文还探索了特征子空间的划分数目问题。 ",MESS201204010
评价对象及其倾向性的抽取和判别,顾正甲1:27772472|姚天昉2:08576605,7,评价对象; 倾向性; SBV极性传递法; 指代消解;,"基于主观性文本的意见挖掘技术是一种在多种领域都有广泛应用的语言技术。该文把评价性语素作为研究对象,在哈尔滨工业大学的语言技术平台(LTP)对语料处理结果的基础上,利用SBV极性传递法为核心,引入指代消解、ATT链算法和互信息法对语料中的评价对象进行抽取,并在对极性词进行倾向性判别时,充分考虑了不同类型的句子,以及副词、连词对极性的影响,尤其是对一般副词、贬义副词和副词""太""作了详细地探讨,最后提出了一个综合的解决方案。该方案结构层次清晰,易于理解,并且其算法复杂度较低。但由于利用的是较为浅层的句法分析结果和基于经验的语言模式方法,该文提出的方案对句法分析结果的依赖度较大。 ",MESS201204011
基于非完备信息系统的评价对象情感聚类,"王素格1,2:08454306|尹学倩3:27223970|李茹1,2:08453268|张杰3:14482626|吕云云1:27772473",6,非完备信息系统; 评价对象; 本体; 特征降维; 聚类;,"该文利用领域本体对产品评论文本中的评价对象进行抽取和整合,在此基础上,建立产品性能的非完备信息系统,将特征的情感倾向寓于特征的权重计算之中。对非完备信息系统,给出了基于差别矩阵的启发式特征约简方法,通过特征降维处理,达到了减少特征的冗余度和数据稀疏性的目的。对降维后的非完备信息系统采用K-Means聚类算法,实现了评价对象情感聚类。为了验证该文提出方法的有效性,在真实汽车评论文本数据上进行实验,实验结果表明,在对特征进行一定程度的降维后,仍表现出较好的聚类效果。 ",MESS201204012
基于情绪词的非监督中文情感分类方法研究,,6,情感分类; 情绪词; 非监督学习; 协同训练;,"情感分类任务旨在识别文本所表达的情感色彩信息(例如,褒或者贬,支持或者反对)。该文提出一种基于情绪词的中文情感分类方法,使用大规模未标记数据和少量情绪词实现情感分类。具体来讲,首先使用情绪词从未标注数据中抽取高正确率的自动标注数据作为训练样本,然后采用半监督学习方法训练分类器进行情感分类。实验表明,该文提出的方法在产品评论与酒店评论两个领域的情感分类任务中取得了较好地分类效果。 ",MESS201204013
微博客中转发行为的预测研究,张旸:27772474|路荣:25202906|杨青:13621884,7,微博客; 转发; 特征加权模型;,"在微博客中,转发对信息的传播有着至关重要的影响,各种各样的信息正是通过转发得以在微博客上广泛且迅速的传播。另外在很多领域中,例如,市场营销、政治选举和热点提取等,也都需要深入探讨转发的各种特性。该文中,我们以Twitter为例,通过预测一条tweet是否会被转发,研究微博客中的转发行为。为解决这个问题,我们使用机器学习中的分类算法,并通过对微博上不同特征的重要性进行分析,提出了基于特征加权的预测模型。实验表明,我们的特征加权模型很好的解决了微博客中的转发预测问题,大约86%的微博能被成功预测。 ",MESS201204014
采用数据挖掘的自动化推荐技术的研究,陈庆章:23331744|汤仲喆:26062414|王凯:26062413|姚敏:26062412|裴玉洁:27772475,7,自动化推荐系统; 自适应共振理论; 数据挖掘; 关联规则;,"随着网络的迅速发展,各种数据量变得庞大且分散,利用关键词检索数据的传统方式变得相当费时。为了减少用户在网络上的搜寻时间,提供用户更确切的内容信息,自动化推荐系统(Automatic Recommender System)应运而生。该研究将人工神经网络中的自适应共振理论(Adaptive Resonance Theory,ART)和数据挖掘技术结合起来,建构了一个可自动聚类族群特征且能挖掘出关联规则的自动化在线推荐机制。同时将用于用户聚类的ART算法进行了改进,提出了MART聚类算法,使由推荐系统得出的结果变得更加合理和灵活。 ",MESS201204015
基于幂律分布的网络用户快速排序算法,张玥:07004709|张宏莉:06998552|张伟哲:07004638,7,幂律; 入度; 集合划分; 快速排序;,"随着网络论坛、博客、微博的发展,引出社会网络中的用户排序问题。将在线网络论坛中用户映射为节点,用户评论过程中形成的回复关系映射为有向关联图,其节点度符合幂律分布。且论坛中用户的主题发布行为和回复关系符合Pagerank算法的互增强和随机游走特性,因此选用Pagerank算法排序用户影响力。该文提出的研究问题:如何提高用户排序应用中数据的存储和运行效率。天涯网络论坛中80%以上用户入度为0,据此,根据入度是否为0划分为两个集合,对入度为0集合按出度构造链接表,设计了基于集合划分的高效排序算法SD-Rank。SD-Rank时空复杂性为O(V′),V′为入度非0节点集。对天涯网络论坛真实用户数据的实验结果表明:SD-Rank算法时空复杂性优于Pagerank算法。 ",MESS201204016
商务印书馆语言学期刊方阵简介,,1, ,"<正>商务印书馆出版的《中国语文》《方言》《民族语文》《语言学论丛》《中国语言学报》等语言学刊物,在国内外语言学界产生了重要影响。随着语言学事业的迅速发展,商务印书馆秉承出版 ",MESS201204017
中文CCG树库的构建,宋彦1:23136254|黄昌宁2:08966779|揭春雨1:13898284,7,组合范畴语法; 树库; 中文句型; 动词子范畴框架;,"组合范畴语法(CCG)是一种类型驱动的语法,可以高度词例化(lexicalized)并兼顾句法和一定程度上语义的表达,可为深层次的文本分析提供有效支持。将CCG应用于真实文本分析需要编制大规模的词库,为了避免为此付出的昂贵人力和资源,一个经济有效的解决方案是利用现有短语句法树库来自动生成CCG树库。该文提出在清华中文树库的基础上自动生成CCG树库的方法,在预定义的中文句型和基于清华树库的动词子范畴框架的支持下,通过标准转换算法,得到一个包含32 737句、超过35万词次的中文CCG树库。该树库通过手工和自动评价验证,又与已有文献所报告的多语种CCG树库构建工作比较,均证明该文所述方法的有效性。 ",MESS201203002
面向移进—归约句法分析器的单模型系统整合算法,马骥:06565020|朱慕华:06581713|肖桐:11698781|朱靖波:06569435,7,句法分析; 系统整合; 移进—归约句法分析器;,"该文提出了一种面向移进—归约句法分析器的单模型系统整合算法。在训练阶段,该方法通过调整训练数据的分布,来构建用于整合的多个移进—归约句法分析器。在解码阶段,该方法首先使用各个移进—归约句法分析器对待分析的句子进行句法分析,然后利用一个线性模型对各句法分析器输出的句法树进行评分,从中选出得分最高的句法树作为最终结果。该文中的实验是在宾州英文树库上进行的。实验结果表明,该文中的方法能够显著改善基准系统的性能。 ",MESS201203003
最大生成树算法和决策式算法相结合的中文依存关系解析,周惠巍:13896094|黄德根:06527360|高洁:27030885|杨元生:06507781,6,中文依存关系解析; 最大生成树算法; 决策式算法;,"基于最大生成树解析算法和决策式解析算法的互补关系,提出了最大生成树解析算法和决策式解析算法相结合的中文依存关系解析方法。结合方法利用Nivre模型的依存关系解析结果和依存度修正最大生成树模型有向边的权重,再搜索最大生成树作为依存树。使用宾州中文树库中的4 500句语料作十折交叉测试,结合模型的依存关系正确率达到了86.49%。结果表明该文提出的结合方法有效地提高了的中文依存关系解析性能。 ",MESS201203004
基于特征结构的汉语主谓谓语句语义标注研究,"陈波1,2:27496100|姬东鸿2:09004523|吕晨2:27030890",6,特征结构; 主谓谓语句; 语义标注; 语义资源;,"建构大规模的汉语语义资源,是当前中文信息处理的重要任务之一。但是其中语义分析的传统方法存在一些问题,不能很好的反映汉语中各个词语或成分之间的语义关联。该文提出了基于特征结构的语义标注方法,并在此基础上建构了一个大规模的汉语语义资源。以汉语主谓谓语句为例,探讨了特征结构的标注方法。结果表明,特征结构分析解决了以往传统标注方法对汉语特殊句型无法表示的难题,包含更多的语义信息,其标注效率更高,标注精度也更高。 ",MESS201203005
基于统计方法的蒙古语依存句法分析模型,斯·劳格劳:07995395|华沙宝:08639277|萨如拉:23687301,6,蒙古文; 依存语法; 句法分析; 概率模型;,"蒙古语文信息处理已初步完成字、词处理阶段的基本任务,正在步入句处理阶段,并且在国家自然科学基金的资助下构建了蒙古语依存树库MDTB。该文以MDTB为训练和评测数据,设计实现了一种基于词汇依存概率的蒙古语依存句法分析模型。目前,该模型的无标记准确率、有标记准确率和核心词准确率分别达到了71.24%、61.42%和93.05%。 ",MESS201203006
基于不平衡数据的中文情感分类,王中卿:23843509|李寿山:27030929|朱巧明:05968617|李培峰:09886822|周国栋:13898054,6,情感分类; 不平衡分类; 集成学习;,"近些年来,情感分类在自然语言处理研究领域获得了显著的发展。然而,大部分已有的研究都假设参与分类的正类样本和负类样本一样多,而实际情况中正负类数据的分布往往是不平衡的。该文收集四个产品领域的中文评论文本,发现正类样本的数目远远多于负类样本。针对不平衡数据的中文情感分类,提出了一种基于欠采样和多分类算法的集成学习框架。在四个不同领域的实验结果表明,我们的方法能够显著提高分类性能,并明显优于目前主流的多种不平衡分类方法。 ",MESS201203007
基于语境歧义词的句子情感倾向性分析,宋艳雪:27030931|张绍武:06536175|林鸿飞:06504899,7,语境歧义词; 关联规则; 倾向性; 情感计算;,"该文从情感的角度研究语境歧义词的搭配,这种搭配对文本情感倾向性分析方面具有实际重要的意义。首先使用关联规则挖掘的方法确定语境歧义词候选搭配集,然后通过PMI过滤后判断每对搭配词是否具有情感倾向性,最终构建语境歧义词搭配词典。采用语义分析的方法,在构建的语境歧义词搭配词典基础上对句子进行情感倾向性分析。通过在COAE2008语料集和情感语料库上进行实验,证明了在判断句子情感倾向性时考虑到语境歧义词的重要性,其对句子进行情感倾向性判断的正确率有很大的影响。 ",MESS201203008
基于语义块的事件倾向性分析研究,韦向峰:09634466|张全:09634516|缪建明:13898607|池毓焕:09633771,5,倾向性; 语义块; 立场分析;,"事件的倾向性分析对网络舆情分析和事件趋势分析都具有重要意义。该文把影响倾向性分析的词语分为四类:对象词、褒贬词、逻辑词和程度词,建立了语句倾向性分析的二元模型和三元模型,在语句语义块分析的基础上实现对语句和篇章的倾向性获取。实验中首先确定三个事件实例的关键对象和立场,然后根据语句倾向性分析获得文章对于对象的褒贬态度和立场。实验表明语义块的范围限制有助于提高事件倾向性分析的准确性,立场分析则是事件倾向性分析的关键所在。 ",MESS201203009
规则和统计相结合的中文地址翻译方法,于淼:25200610|吕雅娟:13898594|苏劲松:25211837|李贤华:25200609,5,中文地址; 机器翻译; 地址单元;,"该文研究了一种规则和统计相结合的中文地址翻译方法。首先利用区划词典、关键字词典和模式表进行分词及词语类型标注,并根据词语类型划分地址单元;然后,以统计翻译模型为基础结合少量的翻译词典和人工模板对地址单元进行翻译;最后,将地址单元的翻译结果以逆序粘合在一起,形成最终译文。实验表明,利用该方法翻译中文地址能够取得较好地翻译效果。 ",MESS201203010
一种适用于机器翻译的汉语分词方法,,6,中文分词; 统计机器翻译; 对齐可信度;,"汉语分词是搭建汉语到其他语言的统计机器翻译系统的一项重要工作。从单语语料中训练得到的传统分词模型并不一定完全适合机器翻译[1]。该文提出了一种基于单语和双语知识的适应于统计机器翻译系统的分词方法。首先利用对齐可信度的概念从双语字对齐语料中抽取可信对齐集合,然后根据可信对齐集合对双语语料中的中文部分重新分词;接着将重新分词的结果和单语分词工具的分词结果相融合,得到新的分词结果,并将其作为训练语料,利用条件随机场模型训练出一个融合了单双语知识的分词工具。该文用该工具对机器翻译所需的训练集、开发集和测试集进行分词,并在基于短语的统计机器翻译系统上进行实验。实验结果表明,该文所提的方法提高了系统性能。 ",MESS201203011
基于“固结词串”实例的中文分词研究,"修驰1:27030881|宋柔1,2:05982879",6,中文分词; CRF; 固结词串; 分词歧义; 机器学习;,"近几年的中文分词研究中,基于条件随机场(CRF)模型的中文分词方法得到了广泛的关注。但是这种分词方法在处理歧义切分方面存在一定的问题。CRF虽然可以消除大部分原有的分词歧义,却会带来更多新的错误切分。该文尝试找到一种简单的、基于""固结词串""实例的机器学习方法解决分词歧义问题。实验结果表明,该方法可以简单有效的解决原有的分词歧义问题,并且不会产生更多新的歧义切分。 ",MESS201203012
基于词典信息的先秦汉语全文词义标注方法研究,"张颖杰1:24367271|李斌1,2:08031757|陈家骏1:08035597|陈小荷2:08109709",8,词义消歧; 义项标注; 古汉语; 自然语言处理;,"词义消歧是自然语言处理中的一项基础任务,古汉语信息处理也急需深层次的语义标注工作。该文针对先秦古汉语这一特殊的语言材料,在训练语料和语义资源匮乏的条件下,采用《汉语大词典2.0》作为知识来源,将其词条释义作为义类,每个义项的例句作为训练语料,使用基于支持向量机(SVM)的半指导方法对《左传》进行全文的词义标注。按照频度不同、义项数量不同的原则,我们随机选取了22个词进行了人工检查,平均正确率达到67%。该方法可以广泛用于缺乏训练语料的古汉语义项标注工作,能够在古汉语全文词义标注的起步阶段提供初始结果,为人工标注词语义项提供良好的数据底本,补正传统词典释义不全的问题,进一步丰富汉语史发展研究资料。 ",MESS201203013
基于隐最大熵原理的汉语词义消歧方法,张仰森:15552896|黄改娟:15551287|苏文杰:25606379,7,隐最大熵原理; 文本隐性特征; 义原搭配信息; 词义消歧;,"该文针对最大熵原理只能利用上下文中的显性统计特征构建语言模型的特点,提出了采用隐最大熵原理构建汉语词义消歧模型的方法。在研究了《知网》中词语与义原之间的关系之后,把从训练语料获取的文本上下文中的词语搭配信息转换为义原搭配信息,实现了基于义原搭配信息的文本隐性语义特征提取方法。在结合传统的上下文特征后,应用隐最大熵原理进行文本中多义词的词义消歧。实验结果表明,采用文中所提方法对十个多义动词进行词义消歧,正确率提高了约4%。 ",MESS201203014
基于电子商务用户行为的同义词识别,张书娟:26867493|董喜双:25202940|关毅:06991644,7,同义词识别; 用户行为; SimRank; Gradient Boost Decision Tree;,"该文研究了电子商务领域同义词的自动识别问题。电子商务领域的同义词是指对同一事物或概念的不同表达,即在商品描述和检索中可以相互替换的词,针对该领域新词多、错别字多、近义词多的特点,提出基于用户行为的同义词识别方法。首先通过并列关系符号切分商品标题和基于SimRank思想聚集查询两种方法获取候选集合,进而获取两词的字面特征以及标题、查询、点击等用户行为特征,然后借助Gradient Boost Decision Tree模型判断是否同义。实验表明同义词识别准确率达到56.52%。 ",MESS201203015
构建大规模的汉语事件知识库,"周强1,2:08836151|王俊俊3:27030897|陈丽欧3:27030898",7,事件内容分析; 事件语义标注资源; 汉语事件知识库;,"该文提出了一种静态知识库和动态标注库相结合的汉语事件知识库构建方法。在统一的设计框架下,将相关事件知识拆分成五个相对独立的知识子库,并通过各子库之间的内在联系使之互相参照互为补充。经过有效拆分和信息联动,增强信息的丰富性和可靠性,同时细化工作的粒度,具有较好的可操作性。以此为基础,开发完成一个汉语""存在拥有类""事件知识库,其中静态知识库覆盖72个情境和1 548个词语义项,动态标注库包含598个事件目标动词的10万句标注结果,取得了较好的实验效果。 ",MESS201203016
事件信息结构分析,杨尔弘1:06429879|曾青青1:22101471|李婷婷2:27497229,6,事件词; 事件信息结构; 主线信息链; 副线信息链;,"该文通过考察事件词在文本篇章结构中的分布方式,指出突发事件新闻报道文本中包含主线信息链和副线信息链。主线信息链中包含了文本的事件信息,是事件信息提取重点考虑的文本内容部分;副线信息链则由文本结构中的""评价""、""背景""以及""情节""部分的细节信息等组成,是事件信息提取时可以忽略的文本内容部分。事件信息的结构可以进一步分解为前核心事件链、核心事件链、次生事件链和后次生事件链。该文通过定义事件词,以其为触发,探索了事件信息结构的识别与获取,并借助《知网》(HowNet)提高了事件词对信息刻画的有效性和区分度。 ",MESS201203017
基于关联度的汉藏多词单元等价对抽取方法,"诺明花1,2:15570459|刘汇丹1,2:09573793|吴健1:09573880|丁治明1:11204381",6,藏文信息处理; 多词单元; 关联度;,"针对为汉藏辅助翻译系统建立汉藏多词单元翻译词典这一任务,该文提出了CMWEPM模型。该模型首先依据关联度和结合度来确定汉语语料中多词单元的边界,然后根据词对齐信息分别抽取严格和约束多词单元等价对,从而形成汉藏多词单元等价对。CMWEPM模型根据不同长度和频次对多词单元进行分类,并为不同类型设定不同阈值,最终提高了汉藏多词单元等价对的召回率,从而能够间接地提高汉藏辅助翻译系统的翻译质量。 ",MESS201203018
评论挖掘中产品属性归类问题研究,杨源:25955429|马云龙:22150717|林鸿飞:06504899,6,属性; 归类; SimRank; 半监督学习;,"该文主要把产品评论中属性的不同描述进行归类。在产品评论中,同类的属性会有不同的描述,例如,手机的""外形""和""设计""指的是同类属性。同类属性虽然有不同的描述,但是在句中却和相同的情感词搭配使用。该文首先抽取评论句中属性和情感词的搭配关系,形成一个二部图,然后用权重标准化SimRank计算不同属性之间的相似度,并把所得的结果与半监督学习中的贝叶斯分类器进行融合,得到了更好的分类结果。通过实验证明了此方法的有效性。 ",MESS201203019
中文维基百科的结构化信息抽取及词语相关度计算方法,"涂新辉1,2:07628856|张红春1,2:15583986|周琨峰1,2:27030910|何婷婷1,2:07640959",7,语义相关度; 中文维基百科; 结构化信息;,"维基百科作为一个以开放和用户协作编辑为特点的Web 2.0知识库系统,具有知识面覆盖度广,结构化程度高,信息更新速度快等优点。然而,维基百科的官方仅提供一些半结构化的数据文件,很多有用的结构化信息和数据,并不能直接地获取和利用。因此,该文首先从这些数据文件中抽取整理出多种结构化信息;然后,对维基百科中的各种信息建立了对象模型,并提供了一套开放的应用程序接口,大大降低了利用维基百科信息的难度;最后,利用维基百科中获取的信息,该文提出了一种基于链接所对应主题页面所属类别的词语语义相关度计算方法。 ",MESS201203020
基于依存关系的旅游景点评论的特征—观点对抽取,"王素格1,2:08454306|吴苏红3:27030917",6,特征-观点对; 依存关系; 组块;,"特征—观点对的抽取是观点挖掘中非常重要的研究课题之一。该文首先利用依存语法对句子进行了依存分析,在此基础上研究了旅游评论文本中特征-观点对的抽取。利用词对间的依存关系,构建了获取含有特征和观点词语的组块规则,并设计了候选特征的识别算法和特征—观点对的抽取算法。该文对山西旅游景点评论语料进行了实验,结果表明,特征—观点对的抽取整体的F1值达到了87.10%,验证了方法的有效性。 ",MESS201203021
基于多特征表示的本体概念挂载,徐立恒1:27030899|刘洋1:14495479|来斯惟1:27030900|刘康1:13898613|田野2:13536531|王渝丽2:13536534|赵军1:10891784,7,本体; 多特征; 概念挂载;,"该文研究了一种基于多特征表示的本体概念挂载方法。以中国大百科知识体系作为本体体系结构,抽取网络知识库条目作为本体概念,通过分析条目中文本内容、语义标签和半结构化信息获得本体概念间层级关系。该文将中国大百科知识体系扩展为百万级概念的多领域中文本体,为进一步抽取本体概念的属性、概念之间的非层级关系以及支持问答服务等应用建立了良好的基础。实验证明该方法相对于单一特征方法能够提高11.8%的挂载精度。 ",MESS201203022
中文论坛内容监测的方法研究,郝秀兰1:23893967|胡运发2:06698081|申情1:10872550,8,内容监控; 中文论坛; 特征提取;,"互联网上充斥着用户生成文档,如论坛中的帖子。如何对这些杂乱无章的内容进行监控是安全部门所关心的重点之一,话题识别与跟踪(Topic Detection and Tracking,TDT)是监控的有效手段之一。但是,网络论坛帖子的特点是回帖篇幅短、话题转移快,使得面向论坛的话题识别与跟踪变得异常困难。针对其特点,给出了三个TDT模型:首先给出一个基线模型;为了缓解""话题漂移""现象,提出了将一个话题表示为种子向量与后续向量的改进模型;在改进的模型上运用最新的命名实体(NE)权重调节策略。针对论坛帖子格式不规范及TDT系统对处理速度的要求,提出了一种特征提取方法。最后,在真实数据集上给出了所用TDT模型的实验结果,证实了所建模型及特征提取方法的有效性。 ",MESS201203023
商务印书馆“中国语言学文库”第三辑,,1, ,"<正>商务印书馆2002年斥资100万元人民币,设立语言学出版基金,主要资助""中国语言学文库""的出版。文库共分四辑,目前第三辑——中青年语言学者专辑是出版的重点。经基金资助已经出版的第三辑图书及相关信息见下表,另有部分入选图书即将出版。 ",MESS201203024
中文CCG树库的构建,宋彦1:23136254|黄昌宁2:08966779|揭春雨1:13898284,7,组合范畴语法; 树库; 中文句型; 动词子范畴框架;,"组合范畴语法(CCG)是一种类型驱动的语法,可以高度词例化(lexicalized)并兼顾句法和一定程度上语义的表达,可为深层次的文本分析提供有效支持。将CCG应用于真实文本分析需要编制大规模的词库,为了避免为此付出的昂贵人力和资源,一个经济有效的解决方案是利用现有短语句法树库来自动生成CCG树库。该文提出在清华中文树库的基础上自动生成CCG树库的方法,在预定义的中文句型和基于清华树库的动词子范畴框架的支持下,通过标准转换算法,得到一个包含32 737句、超过35万词次的中文CCG树库。该树库通过手工和自动评价验证,又与已有文献所报告的多语种CCG树库构建工作比较,均证明该文所述方法的有效性。 ",MESS201203002
统计与词典相结合的领域自适应中文分词,张梅山:27030882|邓知龙:27030883|车万翔:06987220|刘挺:06994824,5,中文分词; CRF; 领域自适应;,"基于统计的中文分词方法由于训练语料领域的限制,导致其领域自适应性能力较差。相比分词训练语料,领域词典的获取要容易许多,而且能为分词提供丰富的领域信息。该文通过将词典信息以特征的方式融入到统计分词模型(该文使用CRF统计模型)中来实现领域自适应性。实验表明,这种方法显著提高了统计中文分词的领域自适应能力。当测试领域和训练领域相同时,分词的F-measure值提升了2%;当测试领域和训练领域不同时,分词的F-measure值提升了6%。 ",MESS201202001
一种利用注疏的《左传》分词新方法,徐润华:24011438|陈小荷:08109709,6,先秦文献; 注疏文献; 自动对齐; 自动分词;,"先秦文献的注疏文献中包含有大量词汇语义知识,是先秦文献自动分词的重要依据。该文以篇幅最大的先秦文献《左传》为研究对象,在对《左传》及其注疏文献进行自动对齐的基础上,提出了一种利用注疏的《左传》分词新方法。分词实验的F值达到89.0%,较之baseline有明显提升。该方法无需训练语料,利用注疏文献辅助分词的思想也适合推广到其他先秦文献的自动分词任务中去。 ",MESS201202002
基于主动学习的中文依存句法分析,车万翔:06987220|张梅山:27030882|刘挺:06994824,5,主动学习; 依存句法; 不确定性度量; 委员会投票;,"目前依存句法分析仍主要采用有指导的机器学习方法,即需要大规模高质量的树库作为训练语料,而现阶段中文依存树库资源相对较少,树库标注又是一件费时费力的工作。面对大量未标注语料,该文将主动学习应用到中文依存句法分析,优先选择句法模型预测不准的实例交由人工标注。该文提出并比较了多种衡量依存句法模型预测可信度的准则。实验表明,一方面,与随机选择标注实例相比,当使用相同数目训练实例时,主动学习使中文依存分析性能最高提升0.8%;另一方面,主动学习使依存分析达到相同准确率时只需标注更少量实例,人工标注量最多可减少30%。 ",MESS201202003
树库中的歧义组合考察,李艳娇:25200594|杨尔弘:06429879,6,歧义组合; 语义关系; 树库;,"汉语树库是汉语信息处理的宝贵资源,其中包含了丰富的句子结构及成分组合信息,对树库中的词性串组合进行考察,是有效利用树库信息的基础工作。该文对汉语树库中的歧义组合进行考察,发现汉语中的结构歧义很大程度上要靠词语的语义特征来消解,仅仅依靠词语的语法特征(如词类信息)是无法解决的。 ",MESS201202004
基于序列标注的全词消歧方法,"周云1:21079706|王挺1:20633286|易绵竹2:20301944|张禄彭3:20324255|王之元1,4:21086624",7,全词消歧; 隐马尔可夫模型; 最大熵马尔可夫模型; 超大状态问题;,"全词消歧(All-Words Word Sense Disambiguation)可以看作一个序列标注问题,该文提出了两种基于序列标注的全词消歧方法,它们分别基于隐马尔可夫模型(Hidden Markov Model,HMM)和最大熵马尔可夫模型(Maximum Entropy Markov Model,MEMM)。首先,我们用HMM对全词消歧进行建模。然后,针对HMM只能利用词形观察值的缺点,我们将上述HMM模型推广为MEMM模型,将大量上下文特征集成到模型中。对于全词消歧这类超大状态问题,在HMM和MEMM模型中均存在数据稀疏和时间复杂度过高的问题,我们通过柱状搜索Viterbi算法和平滑策略来解决。最后,我们在Senseval-2和Senseval-3的数据集上进行了评测,该文提出的MEMM方法的F1值为0.654,超过了该评测上所有的基于序列标注的方法。 ",MESS201202005
基于HNC的汉语词语知识库改进,"王青海1:20626056|马海慧1,2:27030894|池毓焕3:09633771|李颖1:20119320|董凌冲4:27030895",5,汉语词语知识库; HNC理论; 关系数据库;,"汉语词语知识库是HNC知识库系统的重要组成部分,目前其结构设计简单,加大了对HNC符号解析的难度。该文在分析了HNC的编码特点的基础上,改进了汉语词语知识库模型,阐述了改进后汉语词语知识库实体属性的设计方法和知识库的填写原则,并用实例说明了改进后的词语知识库可以提高自然语言处理的效率。 ",MESS201202006
基于依存树距离识别论元的语义角色标注系统,王鑫:06260404|穗志方:06268960,6,论元识别; 基于依存树距离的方法; 语义角色标注;,"在基于依存的语义角色标注研究中,大多数系统采用机器学习方法进行论元识别和分类。该文分析了依存树的特点,发现论元集中分布于依存树上的特定局部范围内,因此提出一种基于依存树距离的论元识别方法。该方法将候选论元限制在与目标动词的依存树距离不超过3的范围内,通过制订规则,提取目标动词的最佳候选论元集合。在CoNLL2009中文语料上采用正确的依存树,识别出了98.5%的论元。在此基础上,结合基于机器学习的角色分类,系统F值达到89.46%,比前人的方法 (81.68%)有了较为显著的提升。 ",MESS201202007
基于FrameNet框架关系的文本蕴含识别,"张鹏1:08403344|李国臣1:08407515|李茹1,2:08453268|刘海静1:22045083|石向荣3:26746453",5,文本蕴含识别; FrameNet; 框架关系;,"文本蕴含识别是处理自然语言中广泛存在的同义异形现象的一种有效途径。该文基于FrameNet中框架及框架之间的八种关系,结合WordNet中词汇间的语义关系,提出了一种文本蕴含识别方法。在给定文本T和假设H中词元激起的框架基础上,该方法利用深度优先搜索,在FrameNet框架关系图中,查询T和H中框架之间的上下位关系;再使用WordNet中语义关系比较二者的框架元素是否一致或相似。实验对RTE2007中50个文本对进行了测试,达到了76.6%的准确率,略高于RTE2007评测的最优结果。 ",MESS201202008
服务于内容侧面发现的框架识别,王荀:27030887|李素建:06264429|宋涛:22641792|姜伯平:27030888,6,FrameNet语料库; 内容侧面发现; 框架识别;,"文本内容通常包含多个侧面,全面地识别这些内容侧面对自然语言处理有重要地意义。传统的统计方法使用简单特征难以识别出所有的内容侧面。以自动摘要为例,传统的抽取式方法多以词频为主要特征,一些重要的句子常因重复度不高被舍弃。要想全面地覆盖原始文本的重要信息,就要识别出文本描述的内容侧面。该文以框架语义学为指导,使用FrameNet语料库作为知识库,综合多种特征来标注文本描述的框架,在此基础上识别文本所包含的内容侧面。该方法在新闻语料上取得了较好地结果,达到了61%的正确率。 ",MESS201202009
基于CRFs的评价对象抽取特征研究,王荣洋:27033941|鞠久朋:24415406|李寿山:27030929|周国栋:13898054,6,情感分析; 评价对象抽取; 特征组合; 语义角色标注;,"评价对象是情感分析中情感信息的一个重要组成部分。该文基于条件随机场模型,研究多种特征在评价对象抽取任务中的表现,并将特征归纳为词法、依存关系、相对位置、语义四大类别。其中,重点引入语义角色标注新特征。在实验中,我们在三个不同的数据集上考查了各个特征及其组合对系统性能的影响,作了详细地比较研究。另外,实验结果表明新提出的语义角色标注特征对评价对象抽取有很好地指示作用。 ",MESS201202010
基于条件随机场与Web数据的缩略语预测,"焦妍1,2:27030884|王厚峰1:06274413|张龙凯1:27030925",7,缩略语; CRF模型; 网页数据;,"缩略语在自然语言中被广泛使用。因其是新词的重要来源之一,成为了自然语言处理领域的一大问题。该文以汉语为对象,研究了从完整形式预测缩略语形式的方法。首先,使用条件随机场模型对完整形式进行序列标注,生成缩略语候选集合。再利用搜索引擎获取网络数据,并通过不同策略利用网络数据对各候选依次评估,结合各项评估分数进行重排序,选择最终的缩略语结果。实验结果表明,增加Web信息之后,缩略语预测的准确率可以提高约五个百分点。 ",MESS201202011
基于双语平行语料的中文缩略语提取方法,"刘友强1:27030907|李斌1,2:08031757|奚宁1:22036023|陈家骏1:08035597",6,缩略语; 平行语料库; 短语抽取; 分类;,"汉语缩略语在现代汉语中被广泛使用,其研究对于中文信息处理有着重要地意义。该文提出了一种从英汉平行语料库中自动提取汉语缩略语的方法。首先对双语语料进行词对齐,再抽取出与词对齐信息一致的双语短语对,然后用SVM分类器提取出质量高的双语短语对,最后再从质量高的短语对集合中利用相同英文及少量汉语缩略—全称对应规则提取出汉语缩略语及全称语对。实验结果表明,利用平行语料的双语对译信息,自动提取出的缩略语具有较高地准确率,可以作为一种自动获取缩略语词典的有效方法。 ",MESS201202012
基于维基百科和模式聚类的实体关系抽取方法,"张苇如1,2:27030913|孙乐1:10352504|韩先培1:26496192",8,关系抽取; 维基百科; 模式聚类;,"该文提出了一种基于维基百科和模式聚类的方法,旨在从开放文本中抽取高准确率的中文关系实体对。首次使用从人工标注知识体系知网到维基百科实体映射的方式获取关系实例,并且充分利用了维基百科的结构化特性,该方法很好地解决了实体识别的问题,生成了准确而显著的句子实例;进一步,提出了显著性假设和关键词假设,在此基础上构建基于关键词的分类及层次聚类算法,显著提升了模式的可信度。实验结果表明该方法有效提升了句子实例及模式的质量,获得了良好的抽取性能。 ",MESS201202013
基于并列结构的概念实例和属性的同步提取方法,"李文杰1,2:06267527|穗志方1,2:06268960",6,并列结构; 搜索引擎; 实例提取; 属性提取; 上下文模式;,"在概念实例和属性的提取研究中,针对基于模式的方法召回率比较低的特点,该文提出了一种基于并列结构的概念实例和属性的同步提取方法。首先利用并列结构模式去网页集合中提取同类词语集合,然后再用基于种子的弱指导方法去学习实例和属性共现的上下文模式,最后再通过模式去提取候选实例或候选属性。在此过程中,每提取出一个候选,就将该候选所在的同类词语集合合并到候选集合中。实验结果表明,该文的方法在不降低准确率的基础上,能大大提高提取结果的召回率。 ",MESS201202014
商品品牌名称挖掘,何正焱:27030920|王厚峰:06274413,5,商品名挖掘; 半监督学习; 图算法;,"百度百科包含了大量的实体和丰富的链接与分类关系,在中文领域含有大量人类知识,能够弥补普通词典词汇覆盖面小的缺点。在商品品牌名称挖掘中,该文提出了发现新的品牌名称的基于图模型的半指导方法。利用百度百科中词条间的相关关系和开放分类,该文使用不同的准则计算词条间的相似度,结合词条和分类的关联性,分类与分类之间的关联性,使用标记传播算法,在130万个词条上进行了品牌名称的挖掘,取得了较好地效果。 ",MESS201202015
面向冗余度控制的中文多文档自动文摘,王红玲:08848649|周国栋:13898054|朱巧明:05968617,5,冗余度控制; 多文档自动文摘; 中文自动文摘;,"多文档自动文摘能够帮助人们自动、快速地获取信息,是目前的一个研究热点。相比于单文档自动文摘,多文档自动文摘需要更多考虑文档之间的相关性,以及文档信息之间的冗余性。因此如何控制信息冗余是多文档自动文摘的一个关键所在。该文在考虑文摘特性的基础上提出了一个冗余度控制模型,该模型通过计算文本单元在主题概率分布之间的相似度来决定句子的选择,从而达到控制冗余的目的。实验结果表明,该方法能够有效降低冗余度,且总体性能优于现有的自动文摘系统。 ",MESS201202016
文本摘要问题中的句子抽取方法研究,张龙凯:27030925|王厚峰:06274413,5,文本摘要; 句子抽取; 条件随机场;,"抽取式摘要是从正文中按照一定策略抽取重要句子组成摘要。该文提出了一种句子抽取方法。基本思想是将句子的抽取看作序列标注问题,采用条件随机场模型对句子进行二类标注,根据标注结果抽出句子以生成摘要。由于不在摘要中的句子的数量远大于摘要中的句子数量,标注过程倾向于拒绝将句子标注为摘要句,针对此问题该文引入了修正因子进行修正。实验表明该方法具有较好地效果。 ",MESS201202017
基于词汇评分的汉语作文自动评分,"彭星源1:25200624|柯登峰1:17244347|赵知1:27030938|陈振标1:11567167|徐波1,2:10983611",7,词汇评分; 作文自动评分;,"该文研究了通过作文词汇评分来实现汉语作文自动评分的新算法。在作文评分应与词汇评分高度相关的假设基础上,实现了这种关系的量化计算。该文从通用词表方法、常规方法以及提出的三种改进算法上进行方法性能的比较,并对比了E-rater作文评分系统中同样采用基于词汇方法的性能。实验结果表明,基于新的词汇评分的作文评分方法相关度①接近0.7的水平,高于E-rater中采用的基于词汇的方法的相关度。同时,这一方法的结果已经接近于人工作文评分的相关度。 ",MESS201202018
基于话题模型的科技文献话题发现和趋势分析,贺亮:27030928|李芳:09595202,7,话题模型; 趋势分析;,"自动挖掘科技文献话题,总结发展趋势及最新研究动态,有助于科技工作者的研究。该文提出一种话题发现和趋势分析的方法,该方法首先利用LDA话题模型抽取科技文献的话题,然后计算话题的强度和影响力,最后针对热门和冷门话题以及影响力高和影响力低的话题,进行了趋势分析。该文提出的话题强度和影响力计算方法,可以针对任何文集。对ACL论文集的实验,显示了计算语言学领域过去的发展状况。和其他方法的对比实验,也验证了该文提出的话题强度和影响力的计算方法是正确和可行的。 ",MESS201202019
基于跨语言广义向量空间模型的跨语言文档聚类方法, ,5,跨语言文档聚类; 跨语言广义向量空间模型; 文档聚类; 跨语言信息检索;,"跨语言文档聚类主要是将跨语言文档按照内容或者话题组织为不同的类簇。该文通过采用跨语言词相似度计算将单语广义向量空间模型(Generalized Vector Space Model,GVSM)拓展到跨语言文档表示中,即跨语言广义空间向量模型(Cross-Lingual Generalized Vector Space Model,CLGVSM),并且比较了不同相似度在文档聚类下的性能。同时提出了适用于GVSM的特征选择算法。实验证明,采用SOCPMI词汇相似度度量算法构造GVSM时,跨语言文档聚类的性能优于LSA。 ",MESS201202020
多信息融合的新闻节目主题划分方法,余骁捷1:27065185|吴及1:08239433|孔繁庭2:06715242|李树森1:27198005,7,新闻节目主题划分; 改进的SeLeCT算法; 信息融合;,"对新闻播报节目进行自动主题划分,可以有效地组织和利用新闻播报类数据。目前自动故事单元划分的研究以视频数据为主,音频的语音识别文本中包含丰富的语义信息,同时声音事件的转换也可以提供很多重要信息,能够有效的进行基于语义的主题划分。根据这些信息,该文提出了一种基于规则的多信息融合的方法,利用切分点邻域的音频类型信息来修正使用语义信息的切分结果,完成主题划分。实验表明根据规则进行特征融合后,新闻节目主题划分的F-估值为64.8%,错误概率Pk和WindowDiff分别达到18.3%和24.5%。 ",MESS201202021
“综合型语言知识库”获国家科技进步奖二等奖,,1, ,"<正>北京大学计算语言学研究所研制的综合型语言知识库(Comprehensive Language Knowledge Base,简称:CLKB)继近几年连续获得政府部门和全国性学术团体的奖励之后,更上一层楼,又获得 ",MESS201202022
动态自适应加权的多分类器融合词义消歧模型,张仰森:15552896|郭江:25928827,7,词义消歧; 分类器; 多分类器融合; 上下文特征;,"词义消歧一直是自然语言处理中的热点和难题。集成方法被认为是机器学习研究的四大趋势之一,在系统研究已有集成学习方法在汉语词义消歧中的应用后,借鉴模式识别领域集成分类器思想,提出了一种动态自适应加权投票的多分类器集成方法来构建融合分类器。实验结果表明,所提融合分类器模型对汉语文本自动消歧结果的准确率提高较大。 ",MESS201201002
结合结构下文及词汇信息的汉语句法分析方法,陈功:06339094|罗森林:06346792|陈开江:24808627|冯扬:23149803|潘丽敏:06339684,7,汉语句法分析; 概率上下文无关语法; 结构下文相关; 词汇信息; 分层分析;,"针对句法分析中上下文无关语法模型对句子信息利用的不足,通过融入结构下文和部分词汇信息,提出两种基于概率上下文无关语法模型的短语结构消歧方法,以达到消解结构歧义的目的;引入分层分析的算法,通过损失一定的时间效率使得在提高分析准确率的同时保证分析结果的全面性。实验结果表明,融入结构下文及词汇信息的汉语句法分析方法,利用了更多的句子信息,与上下文无关语法相比有着更强的消歧能力。 ",MESS201201003
基于《知网》的汉语未登录词语义相似度计算,张瑞霞1:15726650|杨国增2:24549326|吴慧欣1:16792904,6,《知网》; 语义相似度; 未登录词; 概念图;,"提出了一种基于《知网》的汉语未登录词语义相似度计算方法。该方法首先参照意合网络理论构造了语义关系匹配函数;接着在用概念图表示未登录词语义信息的基础上,根据节点在语义表示中的作用不同对其分类;然后应用匹配函数对弧、节点对及节点对集进行分类;最后设计了未登录词的整体相似度、不同类型节点对及节点对集相似度的计算方法。该方法能够合理分类未登录词的语义信息并能将其充分利用到计算过程中,实验结果证明此方法是有效的。 ",MESS201201004
第七届全国机器翻译研讨会机器翻译评测总结,赵红梅:22037542|吕雅娟:13898594|贲国生:26971704|黄云:26971705|刘群:09638994,9,机器翻译; 机器翻译评测; BLEU-SBP; WoodPecker评测;,"该文介绍了第七届全国机器翻译研讨会(CWMT2011)机器翻译评测的具体情况。本次评测重点关注各种语言到汉语的翻译,除了汉英、英汉、日汉三个语言对以外,评测还新增了五种民族语言(藏语、蒙古语、维吾尔语、哈萨克语、柯尔克孜语)到汉语的翻译评测。共有19家国内外单位的165个系统参加此次评测。除了介绍评测项目的设置、评测数据的准备、评测流程、参评单位等,本文还重点介绍了CWMT2011的评测结果,并对评测结果进行了分析,用实例说明了与评测结果相关的几个因素:源语言与目标语言是否相似、评测领域是否集中、测试集与训练及开发集语料是否相似、训练语料的规模、参评系统的技术和成熟度等。 ",MESS201201005
层次短语翻译模型的介词短语调序,冯洋1:22036015|张冬冬2:22036003|刘群1:09638994,6,统计机器翻译; 层次短语模型; 介词短语调序; 条件随机场;,"在不同的语言中,句法成分的相对位置往往不同,介词短语表现尤为明显,因此正确的对介词短语进行调序对提高翻译质量至关重要。层次短语模型借助于形式语法规则,具有较强的处理长距离调序的能力,但是其并不对短语的句法成分进行区分,这会导致规则的使用不当,从而引起翻译错误。该文在层次短语模型的基础上,针对介词短语进行处理。首先利用条件随机场模型识别出介词短语,然后抽取出带有介词短语的规则,构建一个新的同步上下文无关文法。解码的时候,在这个同步上下文无关文法定义的空间里搜索找到最优的译文。相对于层次短语模型,该方法在我们内部的英汉数据集上调高了0.8个BLEU百分点,在NIST 2008英汉翻译数据集上提高了0.5个BLEU百分点。 ",MESS201201006
面向层次短语翻译的词汇化调序方法研究,"肖欣延1,2:26971706|刘洋1:09638999|刘群1:09638994|林守勋1:09559596",6,统计机器翻译; 层次短语; 词汇化调序;,"词汇化信息在短语调序中有重要的作用。然而层次短语翻译模型调序时并不考虑变量所泛化的短语的词汇化信息,因此该模型调序的歧义性较大。为此该文提出面向层次短语模型的词汇化调序方法。我们定义变量与邻接词语的调序关系,并使用变量所泛化短语片段的边界词信息来指导调序。在大规模语料的汉语到英语翻译评测任务中,我们的方法在NIST 2003-2005测试数据上获得了0.6～1.2BLEU值的提高。 ",MESS201201007
基于同义实体扩展的冗余信息去重,姜孟晋:26656110|周雅倩:06710223|黄萱菁:06698167,9,信息抽取; 信息去重; 命名实体;,"冗余信息去重是信息抽取中的重要任务,对于多元素表示的信息,该文针对以往对各个元素统一处理所存在的问题,将信息元素进行分类,由各类元素的冗余判断难易出发,归纳相似度计算方法,并将各相似度作为特征,通过分类器判断信息间的冗余性。同时对最难判断的命名实体信息元素,该文从其他易判断相似性的信息元素出发,通过同义命名实体的自动扩展,提高信息去重的效果。 ",MESS201201008
基于词共现的文档表示模型,"常鹏1,2:15448169|冯楠1:09949573",7,文档建模; 词共现; 文档相似度; 文本挖掘;,"文档表示模型是文本自动处理的基础,是将非结构化的文本数据转化为结构化数据的有效手段。然而,目前通用的空间向量模型(Vector Space Model,VSM)是以单个的词汇为基础的文档表示模型,因其忽略了词间的关联关系,导致文本挖掘的准确率难以得到很大的提升。该文以词共现分析为基础,讨论了文档主题与词的二阶关系之间的潜在联系,进而定义了词共现度及与文档主题相关度的量化计算方法,利用关联规则算法抽取出文档集上的词共现组合,提出了基于词共现组合的文档向量主题表示模型(Co-occurrence Term based Vector SpaceModel,CTVSM),定义了基于CTVSM的文档相似度。实验表明,CTVSM能够准确反映文档之间的相关关系,比经典的文档向量空间模型(Vector Space Model,VSM)具有更强的主题区分能力。 ",MESS201201009
基于事件抽取的网络新闻多文档自动摘要,韩永峰:25622637|许旭阳:25427510|李弼程:20650975|朱武斌:26971708|陈刚:20402137,9,事件抽取; 中文信息处理; 分类; 新闻文档; 聚类; 自动摘要;,"目前,有代表性的自动摘要方法是根据文本片段进行聚类,较传统方法避免了信息冗余,但网络新闻文本中有些文本片段和主题无关,影响了聚类的效果,导致最终生成的摘要不够简洁。为此,该文引入事件抽取技术,提出了一种基于事件抽取的网络新闻多文档自动摘要方法。该方法首先通过二元分类器辨析出文本中的事件和非事件;然后通过聚类将文档原来以段落或句子为单位的物理划分转化为以事件为单位的内容逻辑划分,最后通过主旨事件抽取、排序及润色,生成摘要。实验结果表明,该方法是有效的,显著提高了生成摘要的质量。 ",MESS201201010
基于粗糙集与贝叶斯决策的不良网页过滤研究,孙艳:23227685|周学广:45696047,6,信息安全; 网页过滤; 粗糙集; 区分矩阵; 贝叶斯决策;,"不良网页过滤是一种两类网页分类问题。提出了一种基于粗糙集与贝叶斯决策相结合的不良网页分类过滤方法,首先利用粗糙集理论的区分矩阵和区分函数得到网页分类决策的属性约简;然后通过贝叶斯决策理论对网页进行分类与过滤决策。仿真实验表明,该方法在不良网页分类过滤系统中开销小,过滤准确度高,因而在快速过滤不良网页的应用中具有工程应用价值。 ",MESS201201011
基于层次结构的多策略中文微博情感分析和特征抽取,谢丽星1:23137767|周明2:10120319|孙茂松1:08823738,11,新浪微博; 情感分析; SVM;,"随着Web2.0时代的兴起,与微博相关的研究得到了学术界和工业界的广泛关注。该文使用新浪API获取数据,针对中文微博消息展开了情感分析方面的研究。我们对于三种情感分析的方法进行了深入研究,包括表情符号的规则方法、情感词典的规则方法、基于SVM的层次结构的多策略方法,实验表明基于SVM的层次结构多策略方法效果最好。其次,针对层次结构的多策略方法的特征选择进行了详细分析,包括主题无关、主题相关的特征。实验表明使用主题无关的特征时获得的准确率为66.467%。引入主题相关的特征后,准确率提升至67.283%。 ",MESS201201012
《中文信息学报》征稿简则,,1, ,<正>一、《中文信息学报》主要刊登中文信息的基础理论、应用技术、中文信息处理系统及设备、中文信息的自动输入和人工编码输入、汉字字形信息、自然语言处理、计算语言学及民族语言文字信息处理及网上信息处理等方面的研究论文、技术报告、综述、通讯、简报、国内外学术活动等。 ,MESS201201013
基于情感分布的微博热点事件发现,杨亮:14244075|林原:23136279|林鸿飞:06504899,8,微博; 热点事件; 情感分布语言模型;,"微博(Micro-Blog,Twitter)是互联网上的一种重要媒体,以简短、便捷的方式表达用户的观点,并实现多发布工具即时分享,已经成为热点事件产生和传播的重要场所,因此微博平台中热点事件发现等方面研究的重要性便突显出来了。该文依据热点事件的出现会使用户所发微博中情感词数量增多,情感发生变化,提出了情感分布语言模型,通过分析相邻时段间情感分布语言模型间的差异,实现对热点事件的发现。实验结果表明该文方法可以有效地从微博平台中发现热点事件,并且有助于对微博平台中热点事件的管理和监控。 ",MESS201201014
维吾尔语词法中音变现象的自动还原模型,"麦热哈巴·艾力1,2:26179697|姜文斌2:23136246|吐尔根·依布拉音1:17705003",6,维吾尔语; 词法分析; 维吾尔语变音现象;,"该文针对维吾尔语的音变现象,提出了一种自动还原模型。与以往方法不同的是,此模型中我们把音变现象泛化,先假设维吾尔语中所有语音都有音变现象,从而将还原问题转化为类似于词性标注问题,再利用标注的方法解决了还原操作。在新疆多语种信息技术重点实验室手工标注的《维吾尔语百万词词法分析语料库》上做了实验,还原模块作为维吾尔语词法分析器的一部分,把词法分析器功能的F值从84.1%提高到了91.4%,同时维吾尔语中词缀数目最多、变形情况最复杂的动词词干的还原正确率也达到了88.6%,实际应用中完全可以被接受。 ",MESS201201015
SegT:一个实用的藏文分词系统,"刘汇丹1,2:09573793|诺明花1,2:15570459|赵维纳3,4:25200635|吴健1:09573880|贺也平1:10352407",7,藏文分词; 格助词; 临界词识别; 词频统计; 藏文信息处理; 中文信息处理;,"在分析现有藏文分词方法的基础上,该文重点研究了藏文分词中的格助词分块、临界词识别、词频统计、交集型歧义检测和消歧等问题并提出了相应的方法。应用这些方法,设计实现了一个藏文分词系统SegT。该系统采用格助词分块并识别临界词,然后采用最大匹配方法分词,并进行紧缩词识别。系统采用双向切分检测交集型歧义字段并使用预先统计的词频信息进行消歧。实验结果表明,该文设计的格助词分块和临界词识别方法可以将分词速度提高15%左右,但格助词分块对分词效果没有明显提高或降低。系统最终分词正确率为96.98%,基本达到了实用的水平。 ",MESS201201016
基于能量分布和共振峰结构的汉语鼻音检测,陈斌:26226407|张连海:21149942|牛铜:23535784|王波:20225069,6,鼻音检测; 能量分布; 共振峰结构; Seneff听觉模型;,"该文提出了一种基于能量分布和共振峰结构的汉语鼻音检测方法,该方法首先基于Seneff听觉谱提取了一组描述音段能量分布和共振峰结构的特征参数,然后采用支持向量机模型进行检测和分类,得到候选的鼻音,最后根据音段持续时间、前端韵母能量、高低频能量差、中低频能量比等特征对候选的鼻音进行后处理,去除插入错误,提高鼻音检测的准确率。实验结果表明,干净语音鼻音检测准确率可以达到90.4%,信噪比10dB的语音鼻音检测准确率可达到84.4%以上。 ",MESS201201017
从实验语音学角度探析维吾尔语鼻音的声学特征,艾斯卡尔·艾木都拉:17704444,9,维吾尔语; 鼻音; 共振峰; 时长; 音强; 语音; 变体;,"该文根据语音合成与识别等语音应用研究的需求,从文本分析模块入手,利用""维吾尔语语音声学参数库"",选择了包含鼻音m、n和的单音节以及多音节词,提取它们的声学参数并进行统计分析,归纳了其共振峰、音强和时长分布模式,研究了鼻音的两个变体,从实验语音学的角度出发进一步探讨了鼻音的声学特性,并总结出了一系列结论。其目的是为了提高语音合成的自然度即更好的为自然语言处理服务。该项研究结果对维吾尔语语言乃至整个阿尔泰语系语言的韵律研究具有较高的参考价值。 ",MESS201201018
第二语言学习者汉语声调范畴浮现的模拟研究,陈默:10596525,9,声调范畴; 计算机模拟; 生长型树形结构自组织映射模型;,"第二语言学习者汉语声调范畴的习得一直是汉语学习的难点之一。为了深入研究声调范畴的认知机制,该研究采用动态的生长型树形自组织映射模型,模拟了英语母语者汉语声调范畴的认知发展过程。由于新发展的自组织模型既具有良好的拓扑映射性,又具有动态的容量扩展性,所以能很好地模拟英语母语者汉语声调范畴认知的动态发展过程。模拟结果跟行为实验结果呈现出非常好的一致性,这样既证明了行为实验中汉语声调范畴的动态发展过程,也为汉语声调认知范畴的机制研究提供了机理上的解释。通过对声调范畴习得过程中的一些模式和机制的研究,为声调教学提出了一些有益的建议。 ",MESS201201019
中国中文信息学会第七次全国会员代表大会暨学会成立30周年学术会议在北京成功召开,,1, ,"<正>2011年12月4—5日,中国中文信息学会第七次全国会员代表大会暨学会成立30周年学术会议在北京成功召开。在开幕式上,工业与信息化部杨学山副部长、国家语委副主任教育部语信司李宇明司长、学会支撑单位中国科学院软件研究所李玉成书记对学会成立30周年表示了热烈的祝贺,并对中文信息处理事业 ",MESS201201020
商务印书馆新书目录,,1, , ,MESS201201021
维吾尔语广播新闻敏感词检索系统的研究,"木合塔尔·沙地克1,2:26179677|李晓1:09602585|布合力齐姑丽·瓦斯力3:26179679",8,维吾尔语; 广播新闻; 敏感词识别; HMM; MATLAB;,"维吾尔语广播新闻敏感词检索系统是以HMM为基础。在MATLAB平台上设计实现的。该系统的特点包括:1.由于维吾尔语敏感词数量不多,该系统语音语料库很小。2.由于广播新闻中的发音较为标准规范,在识别中避免了说话人发音上的不规范,这有利于语音识别系统性能的提高。3.由于选择词素为识别基元,易于识别基元端点检测。 ",MESS201104002
西双版纳傣文新闻网站与数字报刊技术研究,殷建民1:23062859|刀福祥2:15891383|唐金宝1:26179680|玉康龙2:26179681,6,西双版纳傣文; 新闻网站; 数字报刊; 编码/显现字符集; 输入法;,"该文介绍了西双版纳傣文新闻网站与数字报刊系统的研究内容与关键技术,涉及西双版纳新老傣文编码/显现字符集、输入法和嵌入式字库的研究以及版面数字化技术、网站发布技术、新闻信息多渠道采集技术、多媒体共享稿库技术和中文新闻信息标准的应用。 ",MESS201104003
基于朴素贝叶斯分类器的朝鲜语文本分类的研究,周国强:26179682|崔荣一:09291242,4,朝鲜语; 朴素贝叶斯; 文本分类; TF-IDF;,"该文基于朴素贝叶斯分类器对朝鲜语文本分类进行了研究。首先,利用基于类别选择的特征选择方法对朝鲜语文本进行特征选择,并使用类TF-IDF估算方法计算权重;其次,构造朴素贝叶斯分类器;最后,利用分类器实现对朝鲜语文本的分类。实验表明,该方法在朝鲜语文本分类中具有较好的效果,为朝汉结合文本分类提供了一定的依据。 ",MESS201104004
基于栏目的藏文网页文本自动分类方法,"胥桂仙1,2:10091840|向春丞1:26179684|翁彧1,2:25428283|赵小兵1,2:22390615|杨国胜1:15485979",4,藏文信息处理; 文本分类; 藏文网页分类;,"该文提出了一种简单、快速的藏文网页文本分类方法。该方法利用网页栏目中词条的类别特征,结合网页文本提取技术,实现了快速、精确地将藏文网页文本归于预定义类别中。实验表明,该方法具有很高的网页文本分类正确率,对构建高质量多类别藏文语料库有重要作用。 ",MESS201104005
基于双语约束的蒙古语无监督依存分析,刘凯1:26179687|乌日力嘎2:23669877|斯钦图2:26179688|姜文斌1:23136246|刘群1:09638994,6,蒙古语; 无监督句法分析; 依存分析; 双语约束;,"句法分析在自然语言处理的实际应用中扮演着重要的角色。当前各少数民族语言包括蒙古语的句法分析研究还处在相对滞后的阶段。同时给其他相关研究带来了相应的困难。该文提出了一种基于双语约束的蒙语的无监督依存分析方法。能够在无需蒙语依存树库及蒙语句法的情况下,对蒙语进行无监督的依存句法分析。并且获得了较好的效果,在人工标注的测试集上有向及无向的正确率分别达到了67.2%及73.3%,可以实际应用到自然语言处理中了。 ",MESS201104006
蒙古语有向图形态分析器的判别式词干词缀切分,"姜文斌1:23136246|吴金星1,2:25034629|乌日力嘎1,2:26179689|那顺乌日图2:07984919|刘群1:09638994",5,蒙古语; 词法分析; 词性标注; 词干提取; 有向图; 判别式;,"蒙古语形态分析中,我们之前的有向图模型取得了较高的性能。这种建模方式以图状结构刻画句中词干和词缀之间的概率关系,从而借助上下文信息为每个词确定最佳的切分标注候选。为每个词尽可能地枚举出所有合法的切分标注候选,是有向图模型有效工作的前提。该文提出了一种基于判别式分类的词干词缀切分策略,与之前基于词干表和词缀表的枚举方案相比,该方法对于词中含有未登录词干的情形具有更好的泛化能力。以20万词规模的三级标注人工语料库为训练数据,采用判别式词干词缀切分的有向图形态分析器,对于含有未登录词干的情形,词级切分标注正确率提高了7个百分点。 ",MESS201104007
蒙古文停用词和英文停用词比较研究,巩政:08012143|关高娃:26179690,4,蒙古文停用词; 蒙古文信息检索; 英文停用词;,"该文采用联合熵算法(Union Entropy,UE)初步确定了蒙古文停用词,接着从初步确定的蒙古文停用词中去掉蒙古文实体名词及同形异义词,再通过对英文停用词和蒙古文停用词的词性比较,确定了蒙古文停用词表。最后用蒙古文停用词表和英文停用词表进行了文档信息检索的对比实验。实验结果表明,用该文所述方法确定的蒙古文停用词表进行蒙古文文档检索,比用英文停用词翻译成蒙古文进行蒙古文文档检索的准确率更高。 ",MESS201104008
最大熵和规则相结合的藏文句子边界识别方法,李响1:25670932|才藏太2:08163472|姜文斌1:23136246|吕雅娟1:13898594|刘群1:09638994,6,最大熵; 句子边界识别; 藏文信息处理;,"句子边界识别是藏文信息处理领域中一项重要的基础性工作,该文提出了一种基于最大熵和规则相结合的方法识别藏语句子边界。首先,利用藏语边界词表识别歧义的句子边界,最后采用最大熵模型识别规则无法识别的歧义句子边界。该方法有效利用藏语句子边界规则减少了最大熵模型因训练语料稀疏或低劣而导致对句子边界的误判。实验表明,该文提出的方法具有较好的性能,F1值可达97.78%。 ",MESS201104009
藏文语义本体中的上下位关系模式匹配算法,"邱莉榕1,2:26182132|翁彧1,2:25428283|赵小兵1,2:22390615",5,知识获取; 语义本体; 概念获取; 上下位关系;,"语义本体是共享概念模型显示的形式化规范说明,其目标是将杂乱无章的信息源转变为有序易用的知识源。目前语义本体还主要依赖于手工创建模式。上下位关系是一种基本的语义关系,常用于语义本体中概念的自动获取和验证。该文首先描述了藏文语义本体的创建方法,进而给出了藏文中的上下位关系模式以及模式匹配算法。上下位关系的模式可以辅助进行概念扩充,也可以作为建立和维护本体的辅助工具,这在一定程度上降低了创建和维护本体的成本。 ",MESS201104010
一种改进的维吾尔语句子相似度计算方法,卡哈尔江·阿比的热西提1:26179691|吐尔根·依布拉音2:17705003|姚天昉1:08576605|艾山·吾买尔2:10775068|艾山·毛力尼亚孜2:26179692,4,维吾尔语句子相似度计算; EBMT; 句子结构相似度;,"在基于实例的维吾尔语汉语机器翻译系统中维吾尔语相似度计算起重要作用。维吾尔语的黏着性特性要求对单词进行词干提取。本文提出的方法结合简单的句子结构相似度计算方法,通过对单词词干提取进行句子相似度计算。小规模实验结果比较接近人工评价的句子相似度。 ",MESS201104011
央金藏文分词系统,史晓东1:09218694|卢亚军2:10207616,3,藏文分词; 自然语言处理; HMM;,"藏文分词是藏文信息处理的一个基本步骤,该文描述了我们将一个基于HMM的汉语分词系统Segtag移植到藏文的过程,取得了91%的准确率。又在错误分析的基础上,进行了训练词性的取舍、人名识别等处理,进一步提高了准确率。 ",MESS201104012
基于词典的汉藏句子对齐研究与实现,"于新1,2:25200638|吴健1:09573880|洪锦玲1:26179693",6,汉藏句子对齐; 词典; 分词粒度; 平行语料库; 藏文信息处理;,"双语语料库加工的关键技术之一是对齐,构建句子级别的对齐语料是构建语料库最基本的任务。该文参考其他语言句子对齐的成熟的方法,针对藏文语言的特殊性,提出基于词典的汉藏句子对齐。整理了对齐所用双语词典,并对其词语覆盖率进行了评价。在汉藏句子对齐过程中发现汉语与藏文的分词粒度不同的问题,采用在藏汉词典中进一步查词并在汉语句子中比对的方法,使正确句对的得分增加,从而提高对齐正确率。采用该方法准确率为81.11%。 ",MESS201104013
基于WAMP的藏汉英互译在线词典的设计与实现,周毛先:25202339|头旦才让:25202338|才让加:08163475,3,藏文; 在线词典; WAMP; B/S结构; 数据库;,"根据目前在线藏汉英词典使用的实际需求,青海师范大学藏文信息处理省部共建教育部重点实验室设计实现了一种基于WAMP平台的藏汉英互译在线词典,并给出了词典数据库和查询页面的具体设计方法和关键代码。经测试,该在线词典根据用户的需要,输入单字和词就可以在藏汉英三语间交互查询并快速检索到对应的译词。词典采用B/S结构,它的实现有助于藏汉英三语间的交流和学习。 ",MESS201104014
藏语语料库TEI标记规范探讨,扎西加1:11131756|高定国2:17403917,6,藏语; 语料库; TEI标记;,"在语言信息处理过程中,大规模真实文本处理已成为一个研究热点。藏语语料库的标记在汉藏英机器翻译、信息检索、文本数据挖掘、词典编纂的研究工作中占很重要的地位。为了便于数据交换和共享,该文基于TEI编码的藏语语料,对藏语语料库中文本的属性信息和结构信息标记做了系统而全面的探讨。 ",MESS201104015
多民族语言本体知识库构建技术,"赵小兵1,2:22390615|邱莉榕1,2:26182132|赵铁军3:06997742",4,知识库; 语义本体; 词典扩充; 本体学习;,"语义本体是共享概念模型的显示的形式化规范说明,其目标是将杂乱无章的信息源转变为有序易用的知识源。语义本体知识库的构建是文本自动处理的一个重要环节,跨语言信息检索、信息抽取、自动翻译等领域中都有广泛的应用。该文旨在描述统一标准、统一接口的多民族语言本体知识库的创建思路,以及包含的若干问题,例如:多民族语言中共有概念的一般表示与各民族语言特有的事物表达方式的规律,基于词汇语义的、包括汉语、英语及少数民族语言在内的多民族语言语义本体的表示理论与方法等。 ",MESS201104016
面向形态丰富语言的多粒度翻译融合,"王志洋1,2:23136247|吕雅娟1:13898594|刘群1:09638994",7,形态丰富语言; 多粒度; 系统融合;,"形态丰富语言由于其复杂的形态变化,会导致大词汇量和数据稀疏问题,这给统计机器翻译带来了巨大挑战。该文通过将这类语言表示为不同的粒度,然后分别进行翻译;由于不同的粒度能表征语言不同层面的特点,通过对不同粒度的翻译结果进行词级系统融合,便可生成更好的译文。维吾尔语、蒙古语到汉语的两组翻译实验表明,这种多粒度系统融合方法改善了翻译效果,BLEU值比最好的单系统分别提高了+1.41%和+2.03%。 ",MESS201104017
维吾尔语中汉族人名的识别及翻译,"李佳正1:26179695|刘凯1:26179687|麦热哈巴·艾力1,2:26179696|吕雅娟1:13898594|刘群1:09638994|吐尔根·依布拉音2:17705003",6,语言模型; 名词词缀; 拼写规则; 人名识别及翻译;,"该文研究了一种维吾尔语中汉族人名的识别和翻译方法。该方法在词典等传统方法的基础上,运用语言模型实现维语中的汉族人名的识别和翻译。针对维语人名的构词和拼写特点,增加了名词词缀识别预处理模块,补充了维语字母到汉语拼音的映射规则,有效提高了人名识别的正确率及召回率。在1 000句含有汉族人名的维语语料上进行测试,汉族人名识别的正确率和召回率分别达到75.2%和91.5%。 ",MESS201104018
汉蒙统计机器翻译中的调序方法研究,王斯日古楞1:07999500|斯琴图2:08644763|那顺乌日图3:07984919,5,汉蒙统计机器翻译; 调序; 规则;,"在基于短语的汉蒙统计机器翻译系统的研究中,我们发现存在着严重的语序错误。该文在对汉语和蒙古语句子语序进行研究的基础上,提出了基于蒙古语语序的汉语句子调序方法;同时介绍了调序规则和调序算法的设计;最后给出了具体实验。实验证明这种方法明显提高了现有汉蒙机器翻译系统的性能。 ",MESS201104019
蒙古语标准音辅音组合的协同发音研究,包桂兰1:10768932|呼和2:11147824,9,蒙古语标准音; 辅音组合; 协同发音;,"该文在以往实验研究的基础上,利用美国KAY公司6300型电子腭位仪(EPG)、3700Multi-Speech和南开大学""桌上语音工作室""(MiniSpeechLab)等生理和声学分析仪器和软件,通过观察辅音组合的声学语图、动态腭位图和LCV曲线图,比较系统地描述和归纳了蒙古语辅音组合中相邻音段之间的协同发音规律。 ",MESS201104020
蒙古文编码向拉丁转写转换和分音节算法实现,孟和吉雅1:08012943|山丹2:26179698,4,蒙古文; 音节; 拉丁转写;,"在蒙古文单词拼写中有很多型同音异词,从字面上难以辨别和区分型同字符的差异,这对蒙古文信息处理方面都带来了一定的困难。但在蒙古文的文字信息处理过程中,解决型同音异词,确定其编码是一项重要研究内容。该文重点讨论如何实现蒙古文的拉丁转写和切分音节,来确定那些型同音异词中的型同字符的问题。 ",MESS201104021
LPC及F0参数组合基于GMM电话语音说话人识别,"伊·达瓦1,2,3:25209182|吾守尔·斯拉木1,2:17705001|匂坂芳典3:15456015",5,电话语音; 说话人识别; LPC; F0; GMM;,"该文报告了组合LPC参数以及基频F0的高斯混合模型(GMM)电话语音说话人自动识别技术的实验研究结果。该研究在基线试验中GMM使用16混合共分散对角矩阵,特征量为LPC倒谱系数。而在开发系统测试中分别利用语音的全发话区间和有声区间两部分参数增加基频参数进行试验,并给出实验比较结果。在50人电话通话开放集自动切分语音流实验中正确识别率为76.97%,而提案方法为80.29%,改善率为3.32%。接近人工切分语音流时的识别率82.34%。 ",MESS201104022
藏语句子相似度算法的研究,安见才让:25280800,6,自然语言处理; 语料库; 连续单词序列; 藏语; 句子相似度;,"该文提出了一种藏语句子相似度的计算方法,即采用散列单词倒排索引和基于句长相似度粗选的算法,快速从语料库中筛选出候选句子的集合,散列单词倒排索引能够有效提高算法的查找速度;再采用基于词形和连续单词序列相似度的多策略精选算法,可以有效衡量两个藏语句子的相似程度。实验结果证明算法是有效的。 ",MESS201104023
框架元素语义核心词自动识别研究,康旭珍:25202923|李茹:08453268|李双红:23136261,7,框架元素; 框架核心依存图; 条件随机场; 最大熵模型; SVM模型;,"该文基于汉语框架网,利用框架核心依存图形式化地表示一个汉语句子,使得对句子能够进行深层语义理解。为了得到框架核心依存图,需要提取其中框架元素的语义核心词。该文较为系统地描述了框架元素的语义核心词的识别问题。我们利用条件随机场模型、最大熵模型和支持向量机模型来识别框架元素语义核心词,并分别对这三种不同的模型所选的特征集进行了分析,且通过构造不同的特征模板进行对比实验,选取其中较优的特征模板和模型。结果表明,条件随机场模型具有较好的识别性能,在对其特征模板做进一步改进的基础上,识别效率也得到一定的提高。其中对简单型和复合型短语类型框架元素语义核心词识别的平均正确率分别达到了97.34%和94.03%。 ",MESS201104024
基于短语统计机器翻译模型蒙古文形态切分,"李文1,2:25202347|李淼1:10347203|梁青3:25610475|朱海1,2:23693822|应玉龙1,2:22674752|乌达巴拉1:21963300",7,形态学; 形态切分; 机器翻译; 统计模型;,"该文结合最小上下文构成代价模型,借鉴并利用统计机器翻译的方法,尝试解决蒙古文形态切分问题。基于短语的统计机器翻译形态蒙文切分模型和最小上下文构成代价模型分别对词表词和未登录词进行形态切分。前者选取了短语机器翻译系统中三个常用的模型,包括短语翻译模型、词汇化翻译模型和语言模型,最小上下文构成代价模型考虑了一元词素上下文环境和词缀N-gram上下文环境。实验结果显示:基于短语统计机器翻译形态切分模型对词表词切分,最小上下文构成代价模型对未登录词处理后,总体的切分准确率达到96.94%。此外,词素融入机器翻译系统中后,译文质量有了显著的提高,更进一步的证实了本方法的有效性和实用性。 ",MESS201104025
中国术语学建设书系,,1, ,"<正>审定科技术语,搞好术语学建设,实现科技术语规范化,是一个国家科技发展和文化传承中的重要的基础工作,是实现科技现代化的支撑性的系统工程。""中国术语学建设书系""是全国科技名词审定委员会和商务印书馆联合推出的一系列术语学专著和译著,该书系不仅为那些有志于术语学研究的人士提供丰富的学术食粮,而且大大加强了我国术语学理论研究和学科建设。 ",MESS201104026
自动构建时间基元规则库的中文时间表达式识别,邬桐:24703721|周雅倩:06710223|黄萱菁:06698167|吴立德:06705247,8,计算机应用; 中文信息处理; 时间表达式识别; 时间基元; Timex2; 错误驱动; 正则表达式;,"该文提出一种基于正则文法的时间表达式识别算法:它基于""时间基元""①进行规则构建,提高了时间表达式识别的召回率;同时使用基于错误驱动思想的规则剪枝算法,削减了从训练语料带来的噪声,提高了识别的正确率,两者搭配有效提高了系统整体性能。在ACE07中文语料上的实验结果显著超过了现有水平,F-score达到89.9%。该文提出的算法具有很好的通用性和扩展性,加以改进将可以有更广泛的应用。 ",MESS201004000
基于卷积树核的无指导中文实体关系抽取研究,"黄晨1,2:22495481|钱龙华1:08844995|周国栋1:13898054|朱巧明1:05968617",7,计算机应用; 中文信息处理; 实体关系抽取; 卷积树核; 无指导学习; 层次聚类;,"该文提出了一种基于卷积树核的无指导中文实体关系抽取方法。该方法以最短路径包含树作为关系实例的结构化表示形式,以卷积树核函数作为树相似度计算方法,并采用分层聚类方法进行无指导中文实体关系抽取。在ACE RDC 2005中文基准语料库上的无指导关系抽取实验表明,采用该方法的F值最高可达到60.1,这说明基于卷积树核的无指导中文实体关系抽取是行之有效的。 ",MESS201004001
融合字特征的平滑最大熵模型消解交集型歧义,任惠:17380942|林鸿飞:06504899|杨志豪:06523490,7,计算机应用; 中文信息处理; 分词; 交集型歧义; 融合丰富字特征; 最大熵模型; 平滑技术;,"交集型歧义的切分问题是分词阶段需要解决难点之一。该文将交集型歧义的消解问题转化为分类问题,并利用融合丰富字特征的最大熵模型解决该问题,为了克服最大熵建模时的数据稀疏问题,该文引入了不等式平滑技术和高斯平滑技术。我们在第二届国际分词竞赛的四个数据集上比较了高斯平滑技术、不等式平滑技术和频度折扣平滑技术,测试结果表明:不等式平滑技术和高斯平滑技术比频度折扣技术有显著提高,而它们之间不分伯仲,但是不等式平滑技术能使特征选择无缝嵌入到参数估计过程中,显著压缩模型规模。该方法在四个测试集上最终获得了96.27%、96.83%、96.56%、96.52%的消歧正确率,对比实验表明:丰富的特征使消歧性能分别提高了5.87%、5.64%、5.00%、5.00%,平滑技术使消歧性能分别提高了0.99%、0.93%、1.02%、1.37%,不等式平滑使分类模型分别压缩了38.7、19.9、44.6、9.7。 ",MESS201004002
网络新闻口语评论文本中人物对象识别方法,林琛:20451712|李弼程:20650975|周杰:24234286,7,计算机应用; 中文信息处理; 网络舆情; 口语评论; 人物对象; 频繁项挖掘;,"网络新闻口语评论文本中的人物对象是网络舆情的重要内容,是口语评论情感倾向性分析的基础。该文结合新闻口语评论中人物对象特点,提出了一种有效的人物对象自动识别方法。该方法首先在分词基础上,采用多频率综合判别对单字作为人物对象的可靠度进行评估,以获得稳定的识别线索;其次,根据线索划定处理窗口,利用改进频繁项挖掘算法,从窗口中提取候选人物对象;最后,对结果中存在的冗余进行优化处理。实验结果表明,新方法能够完整、有效地识别网络新闻口语评论文本中的人物对象。 ",MESS201004003
Nave Bayes分类器制导的专业网页爬取算法,韩国辉:24703716|陈黎:09785238|梁时木:15609805|唐小棚:15610813|王亚强:24703717|于中华:08759534,8,计算机应用; 中文信息处理; 搜索引擎; 专业爬虫; Nave Bayesian Classifier; 链接前后文;,"从Web中快速、准确地检索出所需信息的迫切需求催生了专业搜索引擎技术。在专业搜索引擎中,网络爬虫(Crawler)负责在Web上搜集特定专业领域的信息,是专业搜索引擎的重要核心部件。该文对中文专业网页的爬取问题进行了研究,基于KL距离验证了网页内容与链接前后文在分布上的差异,在此基础上提出了以链接锚文本及其前后文为特征、Nave Bayes分类器制导的中文专业网页爬取算法,设计了自动获取带链接类标的训练数据的算法。以金融专业网页的爬取为例,分别对所提出的算法进行了离线和在线测试,结果表明,Nave Bayes分类器制导的网络爬虫可以达到近90%的专业网页收割率。 ",MESS201004004
一种新的面向领域的鲁棒性文本分析算法,陶县俊1:21692817|邬晓钧2:08182995|王晓东1:07252209|郑方2:08188525,5,计算机应用; 中文信息处理; 线图分析方法; 鲁棒性; 错误推测;,"在自然语言处理的应用中,特别是在对口语文本、网络文本的处理中,待分析的文本经常会包含字词和句式上的错误。该文描述了一种基于线图分析方法改进的鲁棒性文本分析算法。该算法利用当前活动弧和规则库中的终结符,对基于领域词表的分词过程无法识别的语句串进行错误推测,将无法识别的语句串纠正为可能的正确文字。实验结果表明,在采用拼音的同音匹配进行推测纠错的情况下,该文所设计的鲁棒性文本分析算法相对于燕方法,分析度提高了14.78%,而语句平均分析循环次数增长为9.363%。 ",MESS201004005
词义标注一致性检验系统的设计与实现,乔剑敏:24703718|张仰森:15552896,8,计算机应用; 中文信息处理; 词义标注; 一致性检验; 《知网》; 语料; 语句相似度;,"词义消歧是自然语言处理领域的一个重要研究课题。词义标注的一致性将直接影响语料库的建设质量,进而直接或间接影响到其相关的应用领域。由于语言本身的复杂性与发展性以及算法设计的难点和缺陷,目前各种词义标注的算法与模型还不能百分之百正确地标注词义,即不能保证词义消歧的正确性与一致性。而人工校验在时间、人力方面的投入是个难题。该文在对《人民日报》语料、语句相似度算法和语义资源《知网》研究的基础上,提出了对《人民日报》语料词义标注进行一致性检验的方法。实验结果表明,此方法是有效的。 ",MESS201004006
社会标注及其在信息检索中的应用研究综述,"靳延安1,2:24703719|李瑞轩1:07588637|文坤梅1:07593221|辜希武1:11215394|卢正鼎1:05964823|段东圣1:24703720",11,计算机应用; 中文信息处理; 社会标注; 信息检索; 社区发现; 分类;,"社会标注作为一种新型的网络资源管理和组织形式,在互联网和企业网中已经成为一种普遍的网络服务。社会标注具有标引、分类、资源发现和语义特性,这些特性可以帮助用户找到预期的信息。因此,可以利用社会标注来进行信息检索。该文首先对社会标注及标注对象和标注方法进行了概述。然后,从社会标注的分类特性、社区发现以及社会标注与语义搜索等方面进行综述评论。最后,讨论社会标注研究领域存在的挑战,并指出未来可能的研究方向。 ",MESS201004007
极性相似度计算在词汇倾向性识别中的应用,"宋乐1,2:23136308|何婷婷1,2:07640959|王倩1,2:07646946|闻彬1,2:23136306",5,计算机应用; 中文信息处理; 极性义原; 极性相似度; 极性值;,"该文提出了一种新的基于HowNet相似度计算的词汇倾向性识别方法。该方法首先利用HowNet中的""良""、""莠""极性义原进行一种新的相似度——极性相似度的计算,再计算出词汇的极性值,进而识别出词汇的极性倾向。大量实验证明了该方法能够有效地区分词汇的极性,并且在第一届中文倾向性分析评测(COAE2008)比赛中取得了很好的效果。 ",MESS201004008
基于高斯混合模型的生物医学领域双语句子对齐,陈相:21963301|林鸿飞:06504899|杨志豪:06523490,6,计算机应用; 中文信息处理; 句子对齐; 高斯混合模型; 迁移学习; 锚信息;,"双语术语词典在生物医学跨语言检索系统中有着非常重要的地位,而双语句子对齐是构建双语词典的第一步工作。为了构想面向生物医学领域的双语词典,该文将分类思想和迁移学习方法引入汉英句子对齐任务中,将句子对齐任务看成一个多类分类任务,考虑生物医学领域双语摘要的锚信息,利用高斯混合模型完成分类目标。同时,在模型训练过程中,该文引入了迁移学习的思想,结合无噪音的《新概念英语》双语语料对模型的句子长度特征进行训练,使得模型在测试语料上句子对齐的正确率得到较大提高。 ",MESS201004009
机器翻译系统融合技术综述,李茂西:22036021|宗成庆:10815045,12,人工智能; 机器翻译; 系统融合; 最小贝叶斯风险解码; 混淆网络解码; 词对齐;,"该文对机器翻译研究中的系统融合方法进行了全面综述和分析。根据在多系统输出结果的基础上进行融合的层次差异,我们将系统融合方法分为三类:句子级系统融合、短语级系统融合和词汇级系统融合。然后,针对这三种融合方法,该文分别介绍了它们各自具有代表性的研究工作,包括实现方法、置信度估计和解码算法等,并着重阐述了近年来使用广泛的词汇级系统融合方法中用于构造混淆网络的词对齐技术。最后,该文对这三类系统融合方法进行了比较、总结和展望。 ",MESS201004010
加入调型信息的汉语孤立词识别研究,王鹏:09508763|胡郁:09540699|戴礼荣:09539044|刘庆峰:09575724,6,计算机应用; 中文信息处理; 汉语信息处理; 汉语语音识别; 调型信息; 调型建模; 双流建模;,"汉语是一种有调语言,因此在汉语语音识别中,调型信息起着非常关键的作用。在现有的隐马尔可夫模型(Hidden Markov Model)框架下,如何有效地利用调型信息是有待研究的问题。现有的汉语语音识别系统中主要采用两种方式来使用调型信息:一种是基于Embedded Tone Model,即将调型特征向量与声学特征向量组成一个流去训练模型;一种是Explicit Tone Model,即将调型信息单独建模,再利用此模型优化原有的解码网络。该文将两种方法统一起来,首先利用Embedded Tone Model采用双流而非单流建模得到Nbest备选,再利用Explicit ToneModel对调进行左相关建模并对Nbest得分重新修正以得到识别结果,从而获得性能提升。与传统的无调模型相比,该文方法的识别率的平均绝对提升超过了3.0%,在第三测试集上的绝对提升达到了5.36%。 ",MESS201004011
基于语音知识的音节切分,汤霖1:10672747|黄建中1:14699690|尹俊勋2:05973851,5,计算机应用; 中文信息处理; 音节切分; 语音信号处理; 普通话水平测试;,"在充分利用普通话水平测试试卷的文本信息、同一人的声母时长在常规语速下基本稳定、同一人的声母之间以及韵母之间的相对时长基本保持比例关系等先验知识的基础上,使用经小波变换后再重构的3个语音信号分量的累计能量特征为参数,提出了利用话者语音统计信息的两级音节切分算法,使音节切分精度达98.3%以上。 ",MESS201004012
普通话韵律结构对声韵母时长影响的分析,梅晓1:23788346|熊子瑜2:20272256,8,计算机应用; 中文信息处理; 声母时长; 韵母时长; 韵律结构;,"该研究基于大规模语音数据库,通过建立普通话连续语流中的声韵母时长预测模型,考察声韵母时长的影响因素,探讨普通话声韵母在连续语流中的时长变化类型与话语韵律结构之间的关系。初步研究结果表明:话语的韵律结构对声母时长的影响较小,而对韵母时长的影响较为显著,这种影响主要体现为:韵律单元末音节的韵母时长是否发生显著延长与话语的韵律结构密切相关,韵律大短语和语调短语末尾的音节通常会发生显著的韵母延长,韵律词内以及韵律词末尾的音节通常不会发生韵母延长;韵律小短语末尾的音节在韵母时长方面的表现比较混乱,规律性不明显,可能需要进一步做分化处理。 ",MESS201004013
普通话测试信息分析,"王璐1,2:06373854|赵欣如1:06370561|谢簪2:24156858|严志宇2:24156857|谭军华1:24156860|肖云鹏2:23246664|李峤2:24156859|张学波2:24703722|叶卫平2:06374351",7,计算机应用; 中文信息处理; 普通话水平测试; 方言背景; 学科背景; 易错音; 分数相关性;,"该文以普通话测试数据统计结果为依据,分析了方言背景和学科背景对普通话水平的影响,发现文学类学科普通话水平较高,其他学科不相上下;该文考察了普通话测试中的易错音节,分析了普通话测试的主要失分因素和普通话学习难点,如平舌擦音,翘舌擦音,舌面擦音,鼻韵母和上声声调;该文对测评员主观评分的相关性统计表明,不同测评员主观测评之间相关度较高,分数客观。 ",MESS201004014
超大规模语料库精深加工及应用研讨会会议报道,金澎:08550970,1, , ,MESS201004015
哈萨克文信息处理的现状和发展方向,木合亚提·尼亚孜别克1:23837637|古力沙吾利2:17616780,3,计算机应用; 中文信息处理; 哈萨克文; 信息处理; 关键概念;,"在信息日趋网络化的时代,作为中文信息处理中的子项哈萨克文信息处理技术也开始一步一步地进入研究当中,该文介绍了哈萨克文信息处理技术的现状、研究发展方向和一些关键概念、基本要素以及今后哈萨克文信息处理技术发展中存在的和需解决的问题。 ",MESS201004016
维吾尔语框架语义知识库的概念设计,阿里甫·库尔班1:22675985|吾买尔江·库尔班2:09255957|尼加提·阿不都肉苏力1:24703723,5,计算机应用; 中文信息处理; 维吾尔语; 框架语义; 概念设计; 实体—联系;,"该文对维吾尔语的框架语义描述体系及内容进行了初步探讨和尝试,建立了维吾尔语框架语义文档的树型结构。根据维吾尔语框架语义知识库的描述内容及框架语义网络自身的特点,该文在数据库中以维吾尔语框架语义为核心进行信息存储,设计了语义知识库的概念模型。为创建基于认知的维吾尔语框架语义知识库建设探索了一条可行的技术路线、方法和思路。 ",MESS201004017
维吾尔语、哈萨克语、柯尔克孜语在图书馆编目系统的应用,吾守尔·斯拉木1:17705001|曹锦梅2:45681534|朱雪莲3:10248060|陈少鸿4:24703724,4,计算机应用; 中文信息处理; 维吾尔语; 哈萨克语; 柯尔克孜语; 数据库; 图书馆;,"针对开发维吾尔语、哈萨克语、柯尔克孜语图书馆编目软件中出现的问题,以UNICODE5.0的UTF-8编码为核心,详细给出了维、哈、柯文字统一化处理的策略,通过整体规划提出了分层管理和分层实现的思路。此项研究总结了开发我国新疆维吾尔语、哈萨克语、柯尔克孜语数字图书馆系统的技术路线,各民族语言与汉字等同编程等关键问题。该项研究为各少数民族图书馆数字化事业的发展提供了具有现实意义的实施方案。 ",MESS201004018
面向新疆双语教学的远程教学系统的设计与实现,依皮提哈尔·买买提1:22265050|吾守尔·斯拉木2:17705001,6,计算机应用; 中文信息处理; 双语教学; 远程教学系统; 双语化; Unicode标准;,"新疆是多民族的自治区,使用的主要民族语言文字有汉语和维吾尔语,考虑到这个特殊性,在深入研究国内优秀远程教学软件的基础上,本文提出了面向新疆双语教学的维汉双语远程教学系统的总体框架,分析了维汉双语远程教学系统的体系结构以及模块功能,论述了该系统主要模块中支持维汉双语、系统界面双语显示与切换等关键技术的实现。 ",MESS201004019
商务印书馆语言学出版基金简介,,1, , ,MESS201004020
基于加权SimRank的中文查询推荐研究,"李亚楠1,2:13898593|许晟1,2:23770994|王斌1:09559997",8,计算机应用; 中文信息处理; 搜索引擎; 查询推荐; SimRank; WSimRank;,"查询推荐是搜索引擎系统中的一项重要技术,其通过推荐更合适的查询以提高用户的搜索体验。现有方法能够找到直接通过某种属性关联的相似查询,却忽略了具有间接关联的语义相关查询。该文将用户查询及查询间直接联系建模为查询关系图,并在图结构相似度算法SimRank的基础上提出了加权SimRank(简称WSimRank)用于查询推荐。WSimRank综合考虑了查询关系图的全局信息,因而能挖掘出查询间的间接关联和语义关系。然而,WSimRank复杂度太高而难以实用,该文将WSimRank转换为一个状态层次图的遍历和计算过程,进而采用动态规划、剪枝等策略对其进行优化从而可以实际应用。在大规模真实Web搜索日志上的实验表明,WSimRank在各项评价指标上均优于SimRank和传统查询推荐方法,其MAP指标接近0.9。 ",MESS201003000
中文交互式问答用户问题相关检测研究,伍大勇:21828101|张宇:06997645|刘挺:06994824,8,计算机应用; 中文信息处理; 交互式问答; 问题; 相关检测; 二元分类;,"交互式问答是具备处理系列相关问题以及与用户进行对话式交互的问答技术,是近年来国际上问答技术研究的一个热门方向,但是目前在中文问答领域几乎没有开展相关的研究。实现交互式问答系统首先要判别用户系列问题之间的相关性。该文探讨了提取问题中不同特征对中文交互式问答问题相关检测的作用,并且根据识别出的有效特征采用基于二元分类方法分别对翻译成中文的TREC QA问题集语料和真实的交互式问答语料进行问题相关检测实验,实验结果显示该文的方法获得了较好的问题相关检测效果。 ",MESS201003001
一种基于文档相似度的检索结果重排序方法,周博:08244552|岑荣伟:13897550|刘奕群:08176974|张敏:08186086|金奕江:08169589|马少平:08177513,6,计算机应用; 中文信息处理; 相关反馈; 文档重排序; 信息检索;,"对相关反馈问题的研究已有近30年的历史,相关反馈也被证明可以大程度稳定地提升检索系统的性能。当前网络环境下相关反馈的应用以及用户提供反馈信息的方式已经发生了明显的变化,因此相关反馈研究又一次引起了研究界的注意。该文提出了一种基于文档相似度的搜索结果重排序方法,该方法同时利用了反馈信息中的相关文档与不相关文档。在大规模网络信息检索标准实验数据上的实验结果表明:该方法不仅可以稳定地提高系统的检索性能,并且相较于经典的查询扩展方法有着明显的优势。 ",MESS201003002
一种基于语境的词语相似度计算方法,蔡东风:08670703|白宇:11329492|于水:22045104|叶娜:23769209|任晓娜:23769210,5,计算机应用; 中文信息处理; 语境; 模糊重要度; 词语相似度; 隶属函数;,"词语相似度计算是机器翻译、信息检索等自然语言处理领域的关键问题之一。传统的词语相似度计算方法,未能很好地考虑上下文信息对词语语义的约束,从而不能对语境变换带来的词语间相似度的差异进行有效的区分。该文引入模糊数学中隶属函数的概念计算词语上下文信息的模糊重要度,并结合基于《知网》的语义相似度计算方法,提出一种基于语境的词语相似度计算方法。实验表明,该算法可以根据语境有效地区分语义相近的词语。 ",MESS201003003
面向网络论坛的突发话题发现,"陈友1,2:09596159|程学旗1:09559496|杨森1,2:23769179",8,计算机应用; 中文信息处理; 突发话题; 网络论坛; 时间序列;,"每天有大量的信息涌现在论坛上,用户可以通过论坛获知目前国际国内正在发生的一些突发事件。如何使用机器自动化的方法检测论坛中的突发话题已经成为搜索引擎以及网络挖掘系统的一项基础任务。话题检测与跟踪模型(TDT)可以很好的解决话题发现问题,但是TDT处理的对象是新闻语料,与论坛内容相比,新闻语料更准确、严谨、规范。TDT中使用的方法不适合用语随意的论坛。因此在网络论坛这种噪音环境下的话题检测面临着一定的困难与挑战。文中提出一种基于噪音过滤的话题发现模型,它从内容和用户参与度两个角度来检测论坛话题。在""水木社区""的""水木特快""上进行了相关的实验,实验结果表明该文提出的模型不仅可以检测突发话题,而且可以检测与这些话题相对应的用户社区。 ",MESS201003004
面向话题的新闻评论的情感特征选取,陶富民:23769452|高军:06259529|王腾蛟:06260341|周凯:06278726,7,计算机应用; 中文信息处理; 情感分析; 特征选取; 特征扩展;,"情感特征的提取是进行文本情感分析的一个非常重要的步骤,也是影响其结果好坏的主要因素。在该文中,作者提出一种新的特征提取方法来解决新闻评论的情感分析问题。在该方法中,首先根据评论和新闻的对比分析获得候选情感特征,然后经过相关的扩充和验证操作得到通用的情感特征,并将其用于新闻评论的情感分析。对新闻进行话题划分后进行更细粒度的情感分析:根据新闻话题信息,设计相应的话题相关的特征对比和验证过程,选取出面向话题的情感特征,最后用面向话题的情感特征对相应话题进行情感分析。实验证明,这种情感特征提取方法,对于新闻评论这种语句短、评论对象相对分散的评论,情感分析效果有较大的改进。 ",MESS201003005
COLING 2010即将在北京召开,,1, , ,MESS201003006
面向用户互联网访问日志的异常点击分析,王倩:08182194|刘奕群:08176974|马少平:08177513|茹立云:08823400,6,计算机应用; 中文信息处理; 用户行为分析; 互联网访问日志; 异常点击;,"随着互联网用户人数的日益增长,用户行为分析已经成为互联网技术领域重要的研究方法之一。在日志中去除异常点击,对于准确挖掘用户行为的意图和习惯十分重要。该文采用某公司提供的真实用户互联网访问日志,对日志中的连续点击,单IP多用户以及单用户多IP等可能的异常点击,从访问集中度,用户平均访问量等方面进行了分析。我们认为对于连续点击,用户行为分析研究人员可以分情况滤去多余点击或该用户所有点击,而对于单IP多用户和单用户多IP的点击,我们建议不做处理。 ",MESS201003007
基于日志挖掘的搜索引擎用户行为分析,岑荣伟:13897550|刘奕群:08176974|张敏:08186086|茹立云:08823400|马少平:08177513,6,计算机应用; 中文信息处理; 用户行为分析; 搜索引擎; 网络信息检索;,"随着网络搜索用户的大规模增加,网络用户行为分析已成为网络信息检索系统进行架构分析、性能优化和系统维护的重要基石,是网络信息检索和知识挖掘的重要研究领域之一。为更好理解网络用户的搜索行为,该文基于7.56亿条真实网络用户行为日志,对用户行为进行分析和研究。我们主要考察了用户搜索行为中的查询长度、查询修改率、相关搜索点击率、首次/最后一次点击位置分布以及查询内点击数分布等信息。该文还基于不同类型的查询集合,考察用户在不同查询需求下的行为差异性。相关分析结果对搜索引擎算法优化和系统改进等都具有一定的参考意义。 ",MESS201003008
基于检索历史上下文的个性化查询重构技术研究,宋巍:21774529|张宇:06997645|刘挺:06994824|李生:06989058,7,计算机应用; 中文信息处理; 个性化检索; 隐式反馈; 查询重构;,"基于检索历史隐式地学习用户偏好是个性化检索研究的热点,而根据用户检索历史重构新的查询输入是其中主要的研究内容。已有的研究在利用检索历史进行查询重构时,通常不区分检索历史中的内容是否与当前查询相关,而是将全部检索历史视为整体,因而使重构后的查询含有较多噪声。该文基于相关词语在上下文中大量共现的特征,将用户历史检索结果的网页摘要作为上下文语境,结合用户点击,选择检索历史中与当前查询共现程度最高的词语重构查询模型。对初始检索结果重排序的实验表明,该方法可以有效地选择相关词语,减少噪声。用p@5和NDCG两种指标评价,比最好的基准系统分别相对提高12.8%和7.2%,比初始排序结果相对提高26.0%和11.4%。 ",MESS201003009
基于版块的论坛增量搜集策略,杜言琦:23769181|马军:08853996,7,计算机应用; 中文信息处理; 增量搜集; 论坛爬虫; 延迟;,"该文研究论坛的增量搜集问题。由于在论坛中同一主题通常分布在多个页面上,而传统增量搜集技术的抓取策略通常是基于单个页面,因此这些技术并不适于对论坛增量搜集。该文通过对许多论坛中版块变化规律的统计分析,提出了基于版块的论坛增量搜集策略。该策略将属于同一版块的所有页面看做一个整体,以它做为抓取的基本单位。同时该策略利用版块权重和局部时间规律确定抓取频率和抓取时间点。实验结果表明本策略对新增和新回复帖子的平均召回率为99.3%,并且与平均调度方法相比系统总延迟最高可减小42%。 ",MESS201003010
基于混合语言信息的词语搭配倾向判别方法,"王素格1,2:08454306|杨安娜1:17668082",6,计算机应用; 中文信息处理; 词语搭配; 搭配模式; 情感倾向判别; 概率潜在语义模型;,"具有较强褒贬倾向的词语搭配对于文本的情感分析具有重要的价值。该文提出了一种混合语言信息的词语搭配的倾向判别方法。该方法首先根据词语搭配六种模式的特点,确定出各模式的概率潜在语义模型,然后利用这些语义模型判别搭配的情感倾向。最后对部分包含情感词的搭配再利用规则修正其先前标注的情感倾向。基于汽车语料的实验结果表明,基于混合语言信息的词语搭配情感倾向判别方法优于单纯基于概率潜在语义模型或规则的方法。 ",MESS201003011
基于博主背景的博客倾向性检索归一化策略,廖祥文1:23769186|许洪波2:10348532|钟尚平1:11430018,7,计算机应用; 中文信息处理; 博客倾向性检索; 博主背景模型; 归一化策略;,"博客倾向性检索的目标是检索出不仅与特定查询主题相关而且包含针对该主题的评论的博文单元,并依据倾向性强度进行排序。目前大多数研究工作仅仅通过单个博文单元包含的主题倾向性强弱对博文进行排序。然而,博客是博主表达自己观点情感的媒介,博主的个性风格很大程度上影响着倾向性强度,忽略博主因素仅仅使用单个博文单元获取倾向性评分,会给倾向性评分带来偏差。针对这个问题,该文首先分析博主背景因素对倾向性评分的影响并建立博主背景模型,然后提出基于博主背景的博客倾向性检索归一化策略,最后使用该策略对基于概率推理模型的博客倾向性检索算法进行归一化。实验结果表明,基于博主背景的倾向性检索归一化策略能够更加合理地对博主单元进行排序。 ",MESS201003012
一种基于空间映射及尺度变换的聚类框架,"曾依灵1:23769166|许洪波1:10348532|吴高巍1:09639476|程学旗1:09559496|白硕1,2:09596143",8,计算机应用; 中文信息处理; 文本聚类; 空间映射; 尺度变换; 模型不匹配;,"传统聚类算法通常建立在显式的模型之上,很少考虑泛化模型以适应不同的数据,由此导致了模型不匹配问题。针对此问题,该文提出了一种基于空间映射(Mapping)及尺度变换(Rescaling)的聚类框架(简称M-R框架)。具体而言,M-R框架首先将语料映射到一组具有良好区分度的方向所构建的坐标系中,以统计各个簇的分布特性,然后根据这些分布特性对各个坐标轴进行尺度变换,以归一化语料中各个类簇的分布。如上两步操作伴随算法迭代执行,直至算法收敛。该文将M-R框架应用到K-means算法及谱聚类算法上以验证其性能,在国际标准评测语料上的实验表明,应用了M-R框架的K-means及谱聚类在所有语料集上获得了全面的性能提升。 ",MESS201003013
结合属性分布特征的模式匹配算法,"王宇1,2:23769169|方滨兴1:15197689|吴博1,2:23769170|宋林海1,2:23769171|郭岩1:09559534",8,计算机应用; 中文信息处理; 属性对互斥; 属性对共现; Web模式匹配; 约束聚类;,"该文提出了一种结合属性分布特征的Web模式匹配算法,属性分布特征包括属性对互斥特征和属性对共现特征。属性对互斥特征由属性对的互斥性和出现次数计算得出,这个特征隐含了属性对的语义相似程度。为了充分利用传统的属性名、属性值相似性特征,该文通过机器学习方法结合属性对互斥特征与相似性特征进行属性匹配。并以潜在的匹配属性对为基础,引入有约束的属性聚类方法进行Web模式匹配,聚类方法的约束条件来自属性对共现特征。实验结果表明,相对于仅使用相似性特征的方法,在不同的实验设置下,结合属性分布特征的Web模式匹配算法将F值提高了0.13到0.55。 ",MESS201003014
文本分类中特征权重因子的作用研究,张爱华1:23769195|靖红芳1:22045087|王斌1:09559997|徐燕2:23372621,8,计算机应用; 中文信息处理; 文本分类; 权重表示; 权重因子作用; VSM;,"在传统的基于向量空间的文本分类中,特征权重计算与特征选择过程完全割裂,特征选择函数的得分能反映特征的重要性,却未被纳入权重表示,造成特征表示不精确并影响分类性能。一些改进方法使用特征选择函数等修改TFIDF模型,提高了分类性能,但没有探究各权重因子如何影响分类的性能。该文以词频、逆文档频率及特征选择函数分别作为衡量特征的文档代表性、文档区分性及类别区分性的因子,通过实验测试了它们对分类性能的影响,得到文档代表性因子能使分类效果峰值最高但抵抗噪音特征能力差、文档区分性因子具有抗噪能力但性能不稳定、而类别区分性因子抗噪能力最强且性能最稳定的结论。最后给出权重表示的四点构造原则,并通过实验验证了其对分类性能的优化效果。 ",MESS201003015
基于改进潜在语义分析的跨语言检索,宁健:23769212|林鸿飞:06504899,7,计算机应用; 中文信息处理; 改进潜在语义分析; 语义空间; 跨语言检索; SVD; NMF;,"该文采用基于SVD和NMF矩阵分解相结合的改进潜在语义分析的方法为生物医学文献双语摘要进行建模,该模型将英汉双语摘要映射到同一语义空间,不需要外部词典和知识库,建立不同语言之间的对应关系,便于在双语空间中进行检索。该文充分利用医学文献双语摘要语料中的锚信息,通过不同的k值构建多个检索模型,计算每个模型的信任度,使得多个模型都对查询和文本的相似度做出贡献。在语义空间上进行项与项、文本与文本、项与文本之间的相似度计算,实现了双语摘要的跨语言检索,取得了较好的实验效果 ",MESS201003016
面向专利文献的中文分词技术的研究,张桂平:09719392|刘东生:23769216|尹宝生:08654455|徐立军:08654443|苗雪雷:08670807,5,计算机应用; 中文信息处理; 中文分词; 专利文献; 上下文信息;,"针对专利文献的特点,该文提出了一种基于统计和规则相结合的多策略分词方法。该方法利用文献中潜在的切分标记,结合切分文本的上下文信息进行最大概率分词,并利用术语前后缀规律进行后处理。该方法充分利用了从大规模语料中获取的全局信息和切分文本的上下文信息,有效地解决了专利分词中未登录词难以识别问题。实验结果表明,该文方法在封闭和开放测试下分别取得了较好的结果,对未登录词的识别也有很好的效果。 ",MESS201003017
一种基于大知识库的亲属关系自动推理模型,陈振宇1:11540519|袁毓林1:06263991|张秀松1:15612229|周强2:08836151,7,计算机应用; 中文信息处理; 亲属关系; 自动推理; 认知模型; 知识库; 逆判断; 传递路径;,"我们采用""大知识库—小运算""的技术路线,提出一个汉语亲属关系的自动推理模型。首先,在充分研究汉语亲属关系的词汇—语法表达的基础上,给汉语常见的亲属关系及其情景语义建立认知模型。然后,据此构造大型的汉语亲属关系知识库,包括外围知识库和核心知识库两种。前者详尽列举亲属名词和称呼动词所涉及的各种句式,并给出相应的语义表达式;后者包括三个子库:性质库(刻画亲属关系中的性别、长幼等属性)、逆判断库(刻画""父—子""等反对称关系对子)和传递库(刻画通过中介人把称呼人与被称呼人联系起来的各种路径,共计3 600余条)。在此基础上,形成了一个汉语亲属关系自动推理模型,可以在已知ABC三边关系的任意两边时快速地推导出未知的另一边关系。 ",MESS201003018
信息处理用藏文分词单位研究,关白:22662822,5,计算机应用; 中文信息处理; 藏文分词; 分词单位; 信息处理; 分词原则;,"分词单位作为分词系统的基本单位,是研究分词理论的基础,要确立分词单位就必须有相应的理论体系。该文结合藏文已有的语法著作和汉语语义分类体系建立与分词单位相应的词类划分体系;参照《资讯处理用中文分词规范》和《信息处理用现代汉语分词规范》等标准,从藏文文本语料出发,建立切分分词单位的九项基本原则和三项辅助原则,以此词类划分体系和切分原则为理论依据对藏文的分词单位进行详细说明。 ",MESS201003019
全球华语词典,,1, , ,MESS201003020
文本蕴涵的推理模型与识别模型,袁毓林1:06263991|王明华2:09385613,11,计算机应用; 中文信息处理; 文本蕴涵; 推理模型; 蕴涵型式; 识别模型; 词汇概率; 句法语义;,"该文首先介绍一个逼近文本蕴涵关系的推理模型,它由带有推理规则集的蕴涵型式知识库和相关的概率评价构成。接着介绍习得推理规则和蕴涵型式及其概率的几种方法,包括从平行或单一语料库中学习和从网络文件中学习。然后介绍基于词汇概率的蕴涵识别模型,包括通过构建词汇蕴涵的概率模型和基于词汇所指的语义匹配模型来逼近文本蕴涵的几种方法。最后介绍基于句法的语义分析模型,包括基于依存树节点匹配、论元结构或原子命题匹配等处理模型。 ",MESS201002000
中文词汇网络:跨语言知识处理基础架构的设计理念与实践,"黄居仁1,2:23136241|谢舒凯3:24194389|洪嘉馡4:23137760|陈韵竹1:24194390|苏依莉1:24194391|陈永祥5:24194392|黄胜伟1:24194393",10,计算机应用; 中文信息处理; 中文词汇网络; 全球词汇网络网格; 知识本体; 多语处理; 跨语言整合;,"中文词汇网络(Chinese WordNet,简称CWN)的设计理念,是在完整的知识系统下兼顾词义与词义关系的精确表达与语言科技应用。中文词义的区分与词义间关系的精确表征必须建立在语言学理论,特别是词汇语义学的基础上。而词义内容与词义关系的发掘与验证,则必须源自实际语料。我们采用的方法是分析与语料结合。结合的方式则除了验证与举例外,主要是在大量语料上平行进行词义标记,以反向回馈验证。完整、强健知识系统的建立,是兼顾知识本体(ontology)的完备规范(formal integrity)和人类语言系统内部的完整知识。我们采用了上层共享知识本体(SUMO)来提供知识的规范系统表征。 ",MESS201002001
书讯,,1, , ,MESS201002023
基于篇章的中文地名识别研究,唐旭日:22101470|陈小荷:08109709|许超:08078123|李斌:08075606,9,计算机应用; 中文信息处理; 篇章地名关系; 条件随机场; 地名性判断;,"该文介绍了以篇章为单位的中文地名识别方法和系统实现。地名识别包括简单地名识别和复杂地名识别两个阶段。简单地名识别由基于条件随机场的识别模块和基于篇章地名关系的识别模块顺序构成,以原始文本为输入,直接利用地名内部结构和相邻字信息进行地名识别和文本分词,然后利用篇章地名关系和地名性判断进一步处理。复杂地名识别以简单地名识别结果为输入,采用条件随机场识别。系统在封闭测试和开放测试中F-1值分别达到92.87%和89.76%。研究发现,在地名性判断中地名确信度低的字串对于地名识别干扰性较大,篇章地名关系能够在不降低识别精确度的情况下有效提高召回率,综合利用地名短距离和长距离依存关系可以有效提高地名识别效果。 ",MESS201002002
商务印书馆国际汉语新书目录,,1, , ,MESS201002024
《资治通鉴》历史领域本体构建及其应用研究,彭炜明:24186788|宋继华:06364557,6,计算机应用; 中文信息处理; 领域本体; 构建方法; 本体工程;,"该文分析了目前领域本体构建过程中存在的一些问题,特别是""实例""在本体框架中的定位问题。在此基础上提出了《资治通鉴》历史领域本体工程和与之相适应的领域本体构建方法,即采用模式驱动的方式,自底向上构建领域本体,并用此方法实现了工程的先秦部分——先秦史本体。最后从SPARQL语言的本体查询和TouchGraph可视化两方面的应用评价了这个本体。 ",MESS201002003
基于CRF的先秦汉语分词标注一体化研究,石民:21774532|李斌:08075606|陈小荷:08109709,7,计算机应用; 中文信息处理; 先秦汉语; 分词; 词性标注; 左传; 条件随机场模型;,"该文探索了古代汉语,特别是先秦文献的词切分及词性标注。首先对《左传》文本进行了词汇处理(分词和词性标注)和考察分析,然后采用条件随机场模型(CRF),进行自动分词、词性标注、分词标注一体化的对比实验。结果表明,一体化分词比单独分词的准确率和召回率均有明显提高,开放测试的F值达到了94.60%;一体化词性标注的F值达到了89.65%,比传统的先分词后标注的""两步走""方法有明显提高。该项研究可以服务于古代汉语词汇研究和语料库建设,以弥补人工标注的不足。 ",MESS201002004
文本中人物性别识别研究,唐琴:17658229|林鸿飞:06504899,6,计算机应用; 中文信息处理; 性别倾向性特征词; 性别倾向性描述词; 性别倾向性称谓词; 性别识别;,"对文本中人物进行性别识别时除了利用其人名本身的用字特征外,可以从整个篇章出发,考虑篇章中描述不同性别时的两性特征差异。该文根据描述男女人物不同方面时存在的两性差异自动获取大量具有明显性别差异的性别倾向性特征词:性别倾向性描述词和性别倾向性称谓词。通过性别识别实验发现,性别倾向性描述词相对于性别倾向性称谓词具有更好的性别指示作用。另外,性别倾向性描述词结合性别倾向性称谓词和姓名的用字特征相对于仅利用人名进行性别识别的效果更好。 ",MESS201002005
《汉字键盘输入技术发展与成果》出版,,1, , ,MESS201002006
基于贝叶斯估计的概念语义相似度算法,吴奎1:15588053|周献中2:05971977|王建宇1:08740083|赵佳宝2:08721657,7,计算机应用; 中文信息处理; 本体; 语义相似度; 贝叶斯估计; Beta分布;,"传统的基于语义距离的概念语义相似度算法不能兼顾客观统计数据,基于信息量的相似度算法又难以获得权威统计样本,针对这些不足,该文提出一种基于贝叶斯估计的概念语义相似度算法。该算法首先假定概念出现概率是符合Beta分布的随机变量,然后基于语义距离的相似度算法计算先验参数,并根据统计样本计算该先验分布下基于最小风险的贝叶斯估计后验参数。随后利用基于信息量的语义相似度算法,便可获得主观经验与客观事实相结合的概念语义相似度。结合WordNet的实验分析表明,该算法与人为主观经验之间具有最大的相关系数。 ",MESS201002007
基于最大频繁项集的搜索引擎查询结果聚类算法,苏冲:24186789|陈清才:06983666|王晓龙:06993266|孟宪军:06996828,10,计算机应用; 中文信息处理; 搜索引擎; 网页聚类; 频繁项集;,"现有的搜索引擎查询结果聚类算法大多针对用户查询生成的网页摘要进行聚类,由于网页摘要篇幅较短,质量良莠不齐,聚类效果难以有较大的提高(比如后缀树算法,Lingo算法);而传统的基于全文的聚类算法运算复杂度较高,且难以生成高质量的类别标签,无法满足在线聚类的需求(比如KMeans算法)。该文提出一种基于全文最大频繁项集的网页在线聚类算法MFIC(Maximal Frequent Itemset Clustering)。算法首先基于全文挖掘最大频繁项集,然后依据网页集合之间最大频繁项集的共享关系进行聚类,最后依据类别包含的频繁项生成类别标签。实验结果表明MFIC算法降低了基于网页全文聚类的时间,聚类精度提高15%左右,且能生成可读性较好的类别标签。 ",MESS201002008
基于网页布局相似度的Web论坛数据抽取,王允:24186790|李弼程:20650975|林琛:20451712,8,计算机应用; 中文信息处理; Web论坛; 数据抽取; 相似度;,"Web论坛中蕴含着丰富的信息资源,充分利用这些信息资源依赖于论坛数据抽取技术。该文解决了从Web论坛抽取什么数据和如何抽取的问题,提出了一种基于网页布局相似度的Web论坛数据抽取方法,有效弥补了目前方法的自动化程度低,或准确率低的不足。该方法充分利用Web论坛网页布局结构上的特点,采用分级处理的方式,先识别出主题信息块、再利用待抽取数据的统计规律在主题信息块中完成抽取,整个过程不需要任何人工干预。实验结果表明,新方法对不同的BBS站点有很好的通用性,且具有较高的准确率和召回率。 ",MESS201002009
“综合型语言知识库”再次获奖,,1, , ,MESS201002010
高性能中文垃圾邮件过滤器,齐浩亮1:10930693|程晓龙1:24186791|杨沐昀2:06996935|何晓宁3:24186792|李生2:06989058|雷国华1:07283187,8,计算机应用; 中文信息处理; 中文垃圾邮件过滤; 在线学习; 逻辑回归模型; 字节级n元文法; TONE;,"设计并实现了基于在线过滤模式高性能中文垃圾邮件过滤器,能够较好地识别不断变化的垃圾邮件。以逻辑回归模型为基础,该文提出了字节级n元文法提取邮件特征,并采用TONE(Train On or Near Error)方法训练过滤器。在多个大规模中文垃圾邮件过滤公开评测数据上的实验结果表明,该文过滤器的性能在TREC 06C数据上优于当年评测的最好成绩,在SEWM07立即反馈上1-ROCA值达到了0.000 0%,并明显优于SEWM08评测在线过滤任务中的所有其他方法。 ",MESS201002011
《中文信息学报》征稿简则,,1, , ,MESS201002012
OHR:一种基于本体的个性化混合服务推荐模型,"潘拓宇1,2:24186793|朱珍民1,2:09640517|滕吉1,2:24186795|叶剑1:09597009|曾庆峰1:24186796",7,计算机应用; 中文信息处理; 服务本体; 混合个性化服务推荐模型; 项目协同过滤; 概率计算;,"随着网络信息量的日益增加,为用户提供个性化服务是一种趋势。该文通过建立一个通用的服务本体模型,将项目集合划分到多个服务子类中,经过概率计算得到用户的兴趣分布,并在此基础上提出了一个结合内容过滤和项目协同过滤的个性化混合服务推荐模型(OHR)。实验结果表明了该模型在服务推荐上具有较高的准确率和发现用户新兴趣的能力。 ",MESS201002013
动词次范畴英汉论元对应关系获取,朱聪慧1:24166219|赵铁军1:06997742|韩习武2:07287984|郑德权1:06997784,6,人工智能; 机器翻译; 动词次范畴化; 跨语言论元对应关系; 自动获取; 统计机器翻译;,"动词次范畴是根据句法行为对动词的进一步划分,它是由核心动词和一系列论元组成。其相关研究在英汉等多种语言方面都取得了较好的成果,但跨语言之间的研究还很少。该文提出了一种基于主动学习策略的英汉动词次范畴论元对应关系自动获取方法,这种方法可以在双语平行语料上,几乎不需要任何先验的语言学知识的情况下,自动获取英汉论元的对应关系。然后我们将这些对应关系加入了统计机器翻译系统。实验结果表明,融合了英汉动词次范畴论元对应关系的SMT系统在性能上有明显的提升,证明了自动抽取的对应关系的有效性,也为SMT提供了新的研究方向。 ",MESS201002014
基于统计的汉语格律诗生成研究,"何晶1,2:11172436|周明2:10120319|蒋龙2:23136249",8,人工智能; 机器翻译; 统计机器翻译; 诗歌生成; 绝句评测;,"古代中文诗歌的巅峰——中文格律诗,包括律诗和绝句,是中国古典诗词的奇葩。该文从已有的古今名诗中自动学习作诗知识,实现了一个中文格律诗的自动生成系统。该系统接收用户选择的表达其思路的若干个关键词作为输入,首先,利用相关词汇数据库和语言模型,实现了根据用户选定的关键词自动生成诗歌的第一句。其次,我们独创性地将格律诗的上下句关系映射为源语言到目标语言的翻译关系,设计了一个基于短语的统计机器翻译模型,从而把诗歌的第N-1句作为输入用以生成第N句。并提供了一个用户交互式的系统,使得用户可以在每一步都选择一个最佳诗句。最后,我们还精心设计了一套翔实的格律诗评测标准,并通过单句实验和全诗实验证明,该方法是诗歌产生的一个较好的方法。 ",MESS201002015
倒谱形状规整在噪声鲁棒性语音识别中的应用,杜俊:09539138|戴礼荣:09539044|王仁华:09578638,6,计算机应用; 中文信息处理; 鲁棒性语音识别; 形状规整;,"该文提出了一种新的用于鲁棒性语音识别的特征规整方法。我们观察到在噪声环境下语音特征分布的形状相比于干净环境变化很大,因此提出了一种称为倒谱形状规整的新方法,它是利用引入一个指数因子来达到对倒谱分布形状进行规整的目的。这种方法被证明在噪声环境下非常有效,特别是在低信噪比情况下。实验结果表明此新方法在au-rora2和aurora3两个标准数据库上比经典的均值方差规整算法在词错误率方面分别有38%和25%的相对降低,并且倒谱形状规整也好于其它传统方法,比如直方图均衡和高阶倒谱矩规整方法。 ",MESS201002016
普通话发音错误自动检测技术,张峰1:10949262|黄超2:15585743|戴礼荣1:09539044,6,计算机应用; 中文信息处理; 发音错误自动检错; 说话人自适应训练; 选择性最大似然线性回归; 话者归一化;,"统计语音识别框架是现在发音错误检测系统的主流框架,而声学模型则是统计语音识别的基础。该文一方面为了获得对于发音错误检测更好的声学模型,引入了说话人自适应训练(SAT)和选择性最大似然线性回归(SMLLR)技术;另一方面,由于字发音检错中存在严重的信息量不足问题和专家对于不同水平说话人的评价标注不一样,在后端上加入了话者得分归一化技术。在包含40个不同水平说话人的8 000个字的数据库上的实验结果表明,文中提出的方法有效的提高了系统性能,召回率为30%时,正确率从45.8%升到了53.6%,召回率为10%时,正确率从64.6%升到了79.9%。 ",MESS201002017
甲骨拓片字形图像复原方法,顾绍通:14634866,6,计算机应用; 中文信息处理; 甲骨拓片; 自适应阈值; 统计分形; 分形维数; 压缩变换; 字形图像复原;,"提出了一种基于自适应阈值和分形几何的甲骨拓片字形图像复原方法。文章分析了甲骨拓片噪声的特点以及字形图像边缘的分形特征,通过计算自适应阈值对噪声区域进行填充。采用统计的方法计算甲骨拓片字形图像边缘的分形维数特征,对字形图像边缘进行压缩变换,进而对甲骨拓片字形图像边缘进行平滑。实验结果显示,这一方法的图像复原效果是比较明显的。 ",MESS201002018
维吾尔语元音的声频特性分析和识别,王昆仑1:11447500|张贯虹1:21724197|吐尔洪江·阿布都克力木2:23788331,7,计算机应用; 中文信息处理; 语音识别; 声频特性; 共振峰频率; 元音; 维吾尔语;,"维吾尔语属阿尔泰语系突厥语族,由于其构词法的特点,八个元音的声频特性在语音识别中,尤其是识别基元选取中有重要作用,其共振峰频率参数也是语音识别和语音合成的重要依据。运用实验语音学的基本理论和方法,在维吾尔语综合语音数据库的办公环境语料条件下,对维吾尔语八个元音进行了声频特性统计分析,给出了维吾尔语元音共振峰频率参数和分布规律,并通过八个元音的语音识别实验结果,验证了其共振峰频率分布规律的正确性。实验证明:维吾尔语在排除元音和谐情况下,其声频特性具有很强的可区分性,对于实现语音信息的传送接受正确性很高。 ",MESS201002019
《语言学名词》即将问世,,1, , ,MESS201002020
基于词边界分类的中文分词方法,李寿山:23136242|黄居仁:23136240,5,计算机应用; 中文信息处理; 中文分词; WBD方法; 在线学习;,"该文研究和探讨一种新的分词方法:基于词边界分类的方法。该方法直接对字符与字符之间的边界进行分类,判断其是否为两个词之间的边界,从而达到分词的目的。相对于目前主流的基于字标注的分词方法,该方法的实现和训练更加快速、简单和直接,但却能获得比较接近的分词效果。更显著的是我们可以很容易地从词边界分类方法获得在线分词学习方法,该方法能够使我们的分词系统非常迅速地学习新的标注样本。 ",MESS201001002
基于最大间隔马尔可夫网模型的汉语分词方法,李月伦:23136341|常宝宝:06253581,7,计算机应用; 中文信息处理; 最大间隔马尔可夫网模型; 汉语分词; 机器学习;,"分词是汉语自然语言处理研究中非常重要的一个环节,在早先的研究中,最大熵模型和条件随机场(CRF)模型已经广泛运用到汉语自动分词的工作中。最大间隔马尔可夫网(M3N)模型是近年来由B.Taskar等[1]人提出的一种新型结构学习模型。该文尝试将这一模型用于汉语分词建模并进行实验,实验结果显示,基于给定的训练语料与测试语料,分词精度可以达到95%,表明基于最大间隔马尔科夫网的汉语分词方法可以取得较高的分词精度,是一种有效的汉语分词方法。 ",MESS201001003
归一化的邻接变化数方法在中文分词中的应用,"何赛克1:21262688|王小捷2:06430796|董远1,3:22462446|张韬政2:23136244|白雪2:23136245",5,计算机应用; 中文信息处理; 无监督分词; 条件随机场; 归一化的邻接变化数方法;,"该文提出了一种无监督和有监督相结合的中文分词方法:将邻接变化数(Accessor Variety,AV)引入基于条件随机场的中文分词系统中。针对邻接变化数在处理较少的训练数据时存在的缺陷,提出了一种归一化的改进方法,以减轻计算AV值时产生的波动。基于Bakeoff-4的中文分词实验表明,归一化的邻接变化数方法无论对于封闭测试,还是开放测试,都带来了性能的提升。 ",MESS201001004
SSD模型及其在汉语词性标注中的应用,"邢富坤1,2:23136253|宋柔1:05982879|罗智勇1:17635790",5,计算机应用; 中文信息处理; SSD模型; HMM; 词性标注;,"该文提出了一种以符号解码与数值解码并举的SSD(Symbol-and-Statistics Decoding Model)模型,该模型被用于汉语词性标注任务,其标注正确率在封闭测试中达到97.08%,开放测试中达到95.67%,较二阶HMM的95.56%和94.70%都有较为显著提高。SSD模型的正确率虽然不及最大熵模型和CRF模型,但它的训练时间远少于后者,说明SSD模型在处理自然语言中的特定任务时是一种较强的实用模型。 ",MESS201001005
基于依存句法分析的中文语义角色标注,,6,计算机应用; 中文信息处理; 语义角色标注; 依存关系; 最大熵分类器;,"依存句法是句法分析的一种,相比于短语结构句法分析,依存句法具有更简洁的表达方式。该文采用英文语义角色标注的研究方法,实现了一个基于中文依存句法分析的语义角色标注系统。该系统针对中文依存关系树,采用有效的剪枝算法和特征,使用最大熵分类器进行语义角色的识别和分类。系统使用了两种不同的语料,一种是由标准短语结构句法分析(CTB5.0)转换而来,另一种是CoNLL2009公布的中文语料。系统分别在两种语料的标准谓词和自动谓词的基础上进行实验,在标准谓词上取得的F1值分别为84.30%和81.68%,在自动谓词上的F1值为81.02%和81.33%。 ",MESS201001006
基于多词块的框架元素语义核心词自动识别研究,李双红:23136261|李茹:08453268|钟立军:22101454|郭伟昱:23980573,7,计算机应用; 中文信息处理; 框架元素; 语义核心词; 多词块;,"抽取一个句子的核心依存图是对句子进行语义理解的有效途径。在CFN自动标注的基础上,只能得到框架依存图,为了把框架依存图转换成框架核心依存图需要提取每个框架元素的语义核心词。该文提出了基于多词块标注的框架元素语义核心词识别和提取方法,通过对比分析,给出了多词块和框架元素的融合策略,并建立了在多词块标注基础上提取框架元素语义核心词的规则集。在6 771个框架元素上的实验结果显示,采用该文的方法和规则集提取框架元素核心词的平均准确率和覆盖率分别为95.58%和82.91%。 ",MESS201001007
基于柱搜索的高阶依存句法分析,李正华:17457974|车万翔:06987220|刘挺:06994824,5,计算机应用; 中文信息处理; 柱搜索; 高阶特征; 依存分析;,"该文提出使用所有的孙子节点构成祖孙特征的高阶依存模型,并且使用柱搜索策略限制搜索空间,最终找到近似最优依存树。另外,该文以较小的时间复杂度为代价,使用了丰富的依存关系特征,并且允许模型在解码的过程中进行依存关系选择。作者参加了CoNLL 2009年多语依存句法分析和语义角色标注国际评测,最终获得联合任务总成绩第一名,依存句法分析总成绩第三名。 ",MESS201001008
现代汉语句系系统的构建和研究,亢世勇:10882043|许小星:10845167,6,计算机应用; 中文信息处理; 语料库; 句型; 句模; 句干; 句系系统;,"在""现代汉语句法语义信息语料库""的基础上,我们将相对独立的句型系统、句模系统和句干系统有机整合在一起,建立了一个有层级体系的句系系统。并将[P]、[SP]、[SPO][、PO]定义为基础句型,利用解析法,考察了基础句型对应的高频句模在复杂句模生成机制中的主体作用,此外还考察了补语、状语同语义成分的对应情况。通过寻求简单句型和复杂句型、简单句模和复杂句模之间的组合映射规律,从而找到句型句模对应机制研究的一个新的突破点。 ",MESS201001009
中文核心领域本体构建的一种改进方法,谌贻荣:23136270|陆勤:09238733|李文捷:09208617|崔高颖:23136271,6,计算机应用; 中文信息处理; 本体构建; 领域核心本体; 上位本体; 领域本体; 上位关系;,"核心本体对最基本的领域知识建模,并在上位本体和领域本体之间建立联系。上位本体是领域无关的而核心本体是领域相关的,因此在自动创建中文核心本体过程中,映射中文核心术语到上位本体概念有很多的错误。本文提出的改进方法首先找到共享后缀术语集内被共享的术语条数更多、与各术语的意义更接近的上位概念;然后用其来改进词集中的核心术语和概念之间的映射。实验证明,该方法有效的提高了核心本体自动创建的精确度。 ",MESS201001010
基于Web弱指导的本体概念实例及属性的同步提取,"康为1,2:23136353|穗志方1,2:06268960",6,计算机应用; 中文信息处理; Web; 概念实例提取; 属性提取; 弱指导; 上下文模式;,"该文提出了一种基于Web弱指导的本体概念实例和属性的同步提取方法,利用小规模的种子实例和属性集,该文从Web上自动获取实例和属性共现的上下文模式,并利用种子实例和属性的关联性来评价这些模式。进一步,根据上下文模式提取候选概念实例和属性后,该文提出两种方法来评价提取的候选实例和属性。第一,利用概念实例和属性的关联性来互相评价对方的准确度;第二,利用候选实例或候选属性与种子实例或属性在上下文模式分布上的相似度来评价准确度。在疾病类实验结果表明,人工确认候选实例的准确率在前500个结果达到94%,前1 000个结果的准确率也高达93%。 ",MESS201001011
基于知网的中文结构排歧工具——VXY,董强:23987264|郝长伶:23987265|董振东:23987266,5,计算机应用; 中文信息处理; 语义; 排歧工具; 强支配; 中文句法结构; 知网;,"该文介绍了基于知网的中文结构排歧工具系列中的一种—VXY。VXY采取了一种独到的排歧技术,对于语言难点采取""定点清除""的策略。它用来解决""V+N+的+N""类型的结构性歧义。VXY是一个自足的、可以现场考核检验的并可以真正付诸实用的系统,而不是仅仅某种方法论的表演或举例性的""游戏""。该文简要地介绍了VXY的组成部分,说明了它的意义计算的原理。同时,该文就如何更有效地利用知网进行结构和语义排歧,如何开辟不同于当前语言信息处理中的""三部曲""(语料标注、现成的计算、应试性的评测)的语言技术等问题进行讨论。 ",MESS201001012
语法信息与韵律结构的分析与预测,王永鑫:08833229|蔡莲红:00009725,6,计算机应用; 中文信息处理; TTS; 韵律结构; 语法结构; 语义;,"韵律结构的自动预测是高自然度文语转换(TTS)系统的关键组成部分,直接影响到合成语音的自然度和表现力。该文建立了一个同时具有语法信息与韵律结构标注的汉语语料库。在这一语料库的基础上,对汉语的韵律结构组成、韵律结构与语法语义之间的关系进行了分析,并进行了预测试验。研究发现,汉语的韵律结构虽与语法结构不同,但是有着密切的联系,韵律结构可以通过语法结构进行预测。韵律结构除与语法结构有关之外,还要受到语句语义的制约。 ",MESS201001013
基于用户查询日志的命名实体挖掘,翟海军1:14202823|郭嘉丰2:14336892|王小磊2:22101464|许洪波2:10348532,7,计算机应用; 中文信息处理; 分开命名实体; 用户查询日志; 话题模型;,"针对大规模查询日志中丰富的命名实体的挖掘是数据挖掘领域中的重要研究课题。已有的研究工作提出了一种基于种子实体的抽取框架,利用实体间的分布相似度进行挖掘。然而该工作只有当种子实体仅属于单个语义类别时才能取得好的结果,实际上命名实体往往可能从属于多个类别。该文通过引入一个弱指导话题模型,利用少量的人工指导信息,很好地解决了实体的类别模糊性,提高了挖掘的有效性。实验表明该文提出的方法在实体挖掘性能上显著优于已有的方法。 ",MESS201001014
跨领域倾向性分析相关技术研究,"吴琼1,2:21889485|谭松波1:09596688|张刚1:09560075|段洣毅1:22046073|程学旗1:09559496",7,计算机应用; 中文信息处理; 跨领域; 倾向性分析; 图排序; EM算法;,"该文主要研究文本的倾向性分析问题,即判断文本中的论断是正面还是负面的。已有的研究表明,监督分类方法对倾向性分析很有效。但是,多数情况下,已有的标注数据与待判断倾向性的数据不属于同一个领域,此时监督分类算法的性能明显下降。为解决此问题,该文提出一个算法,将文本的情感倾向性与图排序算法结合起来进行跨领域倾向性分析,该算法在图排序算法基础上,利用训练域文本的准确标签与测试域文本的伪标签来迭代进行倾向性分析。得到迭代最终结果后,为充分利用其中倾向性判断较为准确的测试文本来提高整个测试集倾向性分析的精度,将这些较准确的测试文本作为""种子"",进一步通过EM算法迭代进行跨领域倾向性分析。实验结果表明,该文提出的方法能大幅度提高跨领域倾向性分析的精度。 ",MESS201001015
评价对象抽取及其倾向性分析,刘鸿宇:23136304|赵妍妍:11639065|秦兵:06990821|刘挺:06994824,6,计算机应用; 中文信息处理; 情感分析; 评价对象; 倾向性判断; 句法分析;,"情感分析近年来已经成为自然语言处理领域的热点问题,该文对情感分析中的两项关键技术——评价对象抽取和倾向性判断进行了深入研究。在评价对象抽取阶段,首先使用句法分析结果获取候选评价对象,继而结合基于网络挖掘的PMI算法和名词剪枝算法对候选评价对象进行筛选。在倾向性判断阶段,通过分析情感句句型,归纳相应的分析规则,使用无指导的方法完成评价对象在情感句中的倾向性判断。该系统参加了COAE2008任务三的评测,取得了较好成绩。 ",MESS201001016
面向特定领域的产品评价对象自动识别研究,"宋晓雷1:23136302|王素格1,2:08454306|李红霞1:09165685",5,计算机应用; 中文信息处理; 产品评价对象; 产品名称; 产品属性; 模板; K均值聚类; 双向Bootstrapping方法;,"产品评价对象的自动识别是文本观点信息抽取和倾向性分析中的重要研究课题之一。该文针对汽车评论,提出了一种不依赖外部资源的无指导评价对象自动识别方法。该方法首先综合使用词形模板和词性模板,采用模糊匹配方法和剪枝法抽取候选评价对象。然后,从候选对象集中,采用双向Bootstrapping方法识别出产品评价对象。最后,通过采用K均值聚类方法对产品评价对象进行聚类,实现从评价对象中自动抽取产品名称和产品属性。实验结果表明,该方法对产品评价对象识别的F值达到58.5%,产品名称识别的F值达到69.48%。 ",MESS201001017
基于领域类别信息C-value的多词串自动抽取,李超:06577102|王会珍:06579162|朱慕华:06581713|张俐:06574957|朱靖波:06569435,5,计算机应用; 中文信息处理; 多词串抽取; 多类别C-value; 领域信息;,"该本的多词串抽取是自然语言处理领域一项重要的研究内容。该文提出了一种多类别C-value(Multi-Class C-value)方法,利用多词串在不同领域的分布信息改善领域相关的多词串抽取的性能。在汽车、科技和旅行三个领域的数据上进行实验,评价多词串的准确率,在top-100级别上,较传统的C-value方法在三个领域中分别提高了12、12和13个百分点。实验结果验证了方法的有效性。 ",MESS201001018
基于情感向量空间模型的歌词情感分析,夏云庆1:10931903|杨莹2:22086807|张鹏洲2:09484794|刘宇飞3:23980572,5,计算机应用; 中文信息处理; 文本情感分析; 情感向量空间模型; 情绪压力;,"音频信号在歌曲情感分析中难以奏效,所以该文提出以歌词作为歌曲情感分析的依据,采取基于情感单元的情感向量空间模型(s-VSM)进行歌词情感分析。该模型较好地解决了基于词汇的向量空间模型(w-VSM)在文本表示效率、歧义、情感功能和数据稀疏性等方面的不足。同时,该文将情感词词频与Thayer二维情感压力模型相结合,提出了""轻松""、""压抑""之外的""复杂""、""含蓄""两类新的情感压力类别。实验证明:(1)s-VSM模型在歌词情感分类中优于传统方法;(2)四类情感压力模型对歌词情感分析很有帮助。 ",MESS201001019
统计机器翻译中多分词结果的融合,马永亮:22036007|赵铁军:06997742,6,人工智能; 机器翻译; 统计机器翻译; 中文分词; 翻译模型特征插值; 多策略特征融合;,"汉英统计机器翻译中,汉语语料通常需要使用中文分词将句子切分成词序列。然而中文分词不是为统计机器翻译而开发的技术,它的分词结果不能保证对统计机器翻译的优化。近些年,一些研究试图改进中文分词方法从而达到对统计机器翻译的优化。在该文中,从另外的角度研究中文分词对统计机器翻译的影响。基本思想是利用多分词结果作为额外的语言知识,提出一种简单而有效的方法使这些知识为统计机器翻译所用,使用了一系列策略融合多分词结果,并将融合结果应用在统计机器翻译系统中。实验结果表明这种方法比没有使用多分词结果融合的系统提高1.89个BLEU分数。 ",MESS201001020
面向统计机器翻译的重对齐方法研究,肖桐:11698781|李天宁:22036010|陈如山:22036009|朱靖波:06569435|王会珍:06579162,7,人工智能; 机器翻译; 统计机器翻译; 词对齐; 重对齐; IBMmodels;,"词对齐是统计机器翻译中的重要技术之一。该文提出了一种重对齐方法,它在IBM models获得的正反双向词对齐的基础上,确定出正反双向对齐不一致的部分。之后,对双向词对齐不一致的部分进行重新对齐以得到更好的对称化的词对齐结果。此外,该文提出的方法还可以利用大规模单语语料来强化对齐结果。实验结果表明,相比在统计机器翻译中广泛使用的基于启发信息的词对齐对称化方法,该文提出的方法可以使统计机器翻译系统得到更高的翻译准确率。 ",MESS201001021
基于规则和统计的日语分词和词性标注的研究,"姜尚仆1,2:23136356|陈群秀1,2:08164877",6,人工智能; 机器翻译; 日汉机器翻译系统; 日语分词; 日语词性标注; 联合分词;,"日语分词和词性标注是以日语为源语言的机器翻译等自然语言处理工作的第一步。该文提出了一种基于规则和统计的日语分词和词性标注方法,使用基于单一感知器的联合分词和词性标注算法作为基本框架,在其中加入了基于规则的词语的邻接属性作为特征。在小规模测试集上的实验结果表明,这种方法分词的F值达到了98.2%,分词加词性标注的F值达到了94.8%。该文所采用的方法已经成功应用到日汉机器翻译系统中。 ",MESS201001022
汉语块分析评测任务设计,周强:08836151|李玉梅:23136343,6,计算机应用; 中文信息处理; 基本块; 功能块; 事件描述小句; 块标注库;,"该文主要介绍了目前中文信息学会句法分析评测CIPS-ParsEval-2009中的三项块分析评测任务:基本块分析、功能块分析和事件描述小句识别的设计理念、判定标准和相关资源构建方法。然后给出了这三项目前的主要评测结果并对相关内容进行了简要分析。最后通过相关统计数据分析和国内外相关研究评述,总结了这三项评测任务的主要特色。 ",MESS201001023
中文信息学报第四届编辑委员会,,1, , ,MESS200904001
基于规则的中文阅读理解问题回答技术研究,李济洪1:08401319|杨杏丽2:23136258|王瑞波3:13897708|张娜1:13897711|李国臣3:08407515,7,计算机应用; 中文信息处理; 阅读理解; 问答系统; 规则; 正交表;,"该文针对中文阅读理解问答中的时间、人物、地点、数值、实体、描述六类问题,制定了各类问题回答的启发式规则集。对规则集中每条规则赋予一个相应权值,利用正交表对各规则所对应的权值进行了调优选取,给出了各候选答案句基于相应规则的得分计算方法。该文方法在山西大学自主开发的中文阅读理解语料库CRCC v1.1上进行了实验,在整个语料库上得到了83.09%的HumSent准确率。为了与文献[10]中的最大熵方法比较,该文在与文献[10]中完全相同的训练集上调优规则的权值,在相同的测试集上测试,最终得到HumSent准确率81.13%,比最大熵的方法高大约1%,且在全部的六类问题上,该文方法的HumSent准确率都不低于最大熵方法。 ",MESS200904004
汉语零形回指研究综述,黄娴1:22101639|张克亮2:21027033,6,计算机应用; 中文信息处理; 零形回指; 语言学; 语言信息处理;,"回指研究一直是语言学研究的一个热点,回指解析则是文本信息处理中亟待解决的问题之一。传统语言学从句法、语用、篇章、认知角度出发对汉语零形回指进行了广泛的研究。在自然语言处理领域,针对汉语零形回指也有一些颇有影响的研究,如基于向心理论的零形回指解析算法,基于HNC理论的零形回指处理方法,以及基于DRT理论和语义分析等方法提出的汉语零形回指解析方法。该文从语言学角度对这些理论研究进行介绍,旨在指出语言信息工作者在注重工程实践的同时,应关注并借鉴语言学基础理论研究的成果,而从事中文信息处理的语言学家也应加强语言形式化的研究。 ",MESS200904005
基于SVMTool的中文词性标注,王丽杰:23246659|车万翔:06987220|刘挺:06994824,6,计算机应用; 中文信息处理; 词性标注; SVMTool; 未登录词; 偏旁部首;,"SVMTool是建立在支持向量机(SVM)原理上的序列标注工具,具有简单、灵活、高效的特点,可以融入大量的语言特征。该文将SVMTool应用于中文词性标注任务,将基于隐马尔科夫模型的基线系统准确率提升了2.07%。针对未登录词准确率不高的问题,该文加入了中文字、词的特征,包括构成汉字的部首特征和词重叠特征,并从理论上分析了这两个特征的可行性,实验显示加入这些特征后,未登录词标注的准确率提升了1.16%,平均错误率下降了7.40%。 ",MESS200904006
SMS-2008标注中文短信息库,马旭1:22150152|徐蔚然2:06420468|郭军2:06426169|胡日勒3:23246660,5,计算机应用; 中文信息处理; 中文短信息; 标注语料库;,"随着短信息应用的普及,用户、运营商及政府管理部门均迫切需要智能短信处理工具。语料库是研究算法,开发系统,测试性能等必不可少的基础资源。但受到技术、版权保护、隐私权利等种种原因,目前还没有公开的标准短信息语料库。SMS-2008标注短信息库是本项目组在国内外率先建立的多用途中文短信息语料库,它包括原始语料库、预处理语料库、隐私标注语料库、内容标注语料库、错误标注语料库等。该语料库可用于短信语言现象研究、短信分类过滤算法研究、隐私保护算法研究、自动纠错算法研究等。 ",MESS200904007
多文档文摘中基于时间信息的句子排序策略研究,徐永东:06995681|王亚东:07001164|刘杨:11316540|王伟:07000803|权光日:06997211,7,计算机应用; 中文信息处理; 多文档自动文摘; 句子排序; 中文时间信息处理;,"文摘句排序是多文档自动文摘中的一个关键技术,直接影响到文摘的流畅程度和可读性。文本时间信息处理是影响排序算法质量的瓶颈技术,由于无法获得准确的时间信息,传统的句子排序策略均回避了这一问题,而且均无法获得稳定的高质量的排序效果。对此该文从文本时间信息处理入手,首先提出了中文文本时间信息抽取、语义计算以及时序推理算法,并在此算法基础上,借鉴传统的主成分排列的思想和句子相关度计算方法,提出了基于时间信息的句子排序算法。实验表明该算法的质量要明显好于传统的主成分排列算法和时序排列算法。 ",MESS200904008
话语标记的语体特征研究及应用,孟晓亮:23246661|侯敏:10316023,6,计算机应用; 中文信息处理; 话语标记; 语体特征; 语体度; 相似度; 文本分类;,"话语标记作为一种常见的话语现象,已成为话语分析研究的重要课题。由于研究角度不同,人们对于话语标记的认识和分类至今仍存在较大差异。该文从语体的角度提出假设,认为话语标记具有一定的语体特征。为准确描写话语标记的语体特征,提出了""语体度""的概念。通过对采样话语标记在不同语体的语料中分布情况进行定量分析,证实了相当一部分话语标记具有明显的语体特征,并根据分析结果选择特征向量,采用Rocchio分类法对开放文本进行自动语体分类实验,正确率达到82.9%。事实证明话语标记的语体特征对文本分类具有一定的参考价值。 ",MESS200904009
中文搜索引擎查询与反馈词语特征研究,赖茂生:06263616|屈鹏:10827398,8,计算机应用; 中文信息处理; 中文搜索引擎; 用户搜索行为; 语言使用; 日志挖掘; 问卷调查; 对比实验;,"查询式是网络用户搜索时表达其信息需求的主要方式,系统提示的相关词则是用户改善查询的有效工具,该文以这二者为研究对象,从用户的使用行为入手对这二者的特征进行刻画和分析。首先使用日志挖掘的方法,对查询式进行总体的定量描述;进而通过定性分类将查询式中的高频词分为主体词和辅助词两大类,并比照问卷调查的研究结果,发现网络用户在搜索时大量地使用辅助词,主体词的内容相对集中,查询式的长度较短,结构相对简单。在对相关词的研究中,综合问卷调查和对比实验研究结果,发现被试者对搜索引擎提示的相关词认同程度高而应用程度低。该文为理解网络用户搜索时的语言使用提供了实证研究结果,并对搜索引擎索引的改善有一定的参考意义。 ",MESS200904010
一种基于随机森林的多视角文本分类方法,田宝明:17481622|戴新宇:08061509|陈家骏:08035597,7,计算机应用; 中文信息处理; 文本分类; 向量空间模型; 隐含狄利克雷分配; 集成分类; 随机森林;,"基于词的向量空间模型是文本分类中的传统的表示文本的方法。这种表示方法的一个缺点是忽略了词之间的关系。最近一些使用潜在主题文本表示的方法,如隐含狄利克雷分配LDA(Latent Dirichlet Allocation)引起了人们的注意,这种表示方法可以处理词之间的关系。但是,只使用基于潜在主题的文本表示可能造成词信息的损失。我们使用改进的随机森林方法结合基于词的和基于LDA主题的两种文本表示方法。对于两类特征分别构造随机森林,最终分类结果通过投票机制决定。在标准数据集上的实验结果表明,相比只使用一种文本特征的方法,我们的方法可以有效地结合两类特征,提高文本分类的性能。 ",MESS200904011
用宋词实现高嵌入率文本信息隐藏,余振山:22690300|黄刘生:09505041|陈志立:22690301|李凌君:22690302|杨威:09581445|赵欣欣:22690303,8,计算机应用; 中文信息处理; 信息隐藏; 文本隐写; 嵌入率; 语义安全; 宋词; 词牌;,"文本信息隐藏是将秘密信息隐藏到文本中的一种技术。与加密后的密文通常是无意义的一串编码不同,文本隐藏生成的隐写文本看起来与普通文本无异,不容易引人怀疑。但是因为文本本身的冗余度低,与图像、视频等载体相比,文本隐藏算法较少且容量偏低。该文提出了一个新的利用宋词的文本隐藏算法,并设计实现了由编码器、解码器、词典和词牌模板组成的系统。秘密信息被隐藏到在字数、行数、句子形式、格律和韵脚等方面符合某个词牌的隐写宋词中。系统在保证良好安全性的同时,嵌入率达到了16%。据我们所知,这是第一个利用特殊体裁的文本信息隐藏算法。 ",MESS200904012
WNCT:一种WordNet概念自动翻译方法,"王石1,2:23246662|曹存根1:10348278",9,人工智能; 机器翻译; WordNet翻译; 词汇翻译; 翻译消歧; 中文词汇知识库; 中文信息处理;,"WordNet是在自然语言处理领域有重要作用的英语词汇知识库,该文提出了一种将WordNet中词汇概念自动翻译为中文的方法。首先,利用电子词典和术语翻译工具将英语词汇在义项的粒度上翻译为中文;其次,将特定概念中词汇的正确义项选择看作分类问题,归纳出基于翻译唯一性、概念内和概念间翻译交集、中文短语结构规则,以及基于PMI的翻译相关性共12个特征,训练分类模型实现正确义项的选择。实验结果表明,该方法对WordNet 3.0中概念翻译的覆盖率为85.21%,准确率为81.37%。 ",MESS200904013
基于Level Set方法的西夏字轮廓提取,柳长青:08178933,6,人工智能; 模式识别; 西夏文信息处理; Level set方法; 西夏字; 轮廓提取; 紧致差分;,"随着国内外对西夏研究的不断深入,收藏于世界各地的大批西夏古籍文献通过影印方式陆续出版。如何将这些西夏古籍文献进行数字化、文本化则有着极其重要的意义。首先利用平滑和细化算法对西夏影印文献进行了预处理,然后利用Level set方法对影印文献中的西夏字进行了轮廓提取。Level Set演化函数在空间方向上采用了四阶紧致差分逼近式离散,计算过程中加入了窄带算法及全局优化方法。实验表明,算法在不增加计算时间的基础上可以得到较精确的西夏字轮廓。 ",MESS200904014
因子分析在基于GMM的自动语种识别中的应用,付强:09539211|宋彦:09508171|戴礼荣:09539044,5,计算机应用; 中文信息处理; 自动语种识别; 高斯混合模型; 因子分析;,"在自动语种识别中,测试语音中说话人和信道的差异,会对系统性能产生很大的影响。针对于此,该文通过引入因子分析技术,根据语种识别的特点,建立了描述该差异(说话人差异和信道差异)的子空间的数学模型,并分别从特征域和模型域两个方面尝试消除该差异的影响。在最新的NIST LRE2007的测试任务中,相对于GMM-UBM基线系统,该文方法有效地提高了系统识别性能。在30s时长的测试中,等错误率(EER)相对降低36.5%。 ",MESS200904015
汉语韵律短语的时长与音高研究,"倪崇嘉1,2:21963310|刘文举1:11459454|徐波1:10983611",6,计算机应用; 中文信息处理; 主要韵律短语; 次要韵律短语; 时长; 音高;,"语句和篇章的韵律结构和信息结构的分析及模型化是提高语音合成的自然度、降低自然语言识别错误率的关键。该文在带有韵律标注ASCCD语料库的基础上对韵律短语的时长和音高特性进行了研究,得到并验证了如下一些结论:(1)韵律短语边界对音节时长有明显的延长作用,不同声调对音节的时长延长作用不同,并且不同的重音级别对音节时长的延长作用也不同。(2)韵律短语边界处中断的时长在较小的韵律边界表现的更为明显。韵律短语的边界处发生了明显的音高重置现象,韵律短语的音高低线总是下降的,而音高高线只是在重音后下降,并且重音处的音域大而且音高高线的位置高。 ",MESS200904016
基于自适应频率规整的鲁棒说话人辨认研究,李燕萍:10888310|唐振民:08740008|张燕:08097227|丁辉:08092463,7,计算机应用; 中文信息处理; 说话人辨认; 自适应频率规整; 鉴别性特征; 鲁棒性;,"该文提出了一种基于自适应频率规整的鉴别性特征提取算法。该方法通过对语音频谱的各个频带的鉴别性分析及其量化结果对各个频域进行自适应的频率规整,进行非均匀子带滤波设计提取鉴别性特征;同时在噪声环境下,在特征提取前端进行了预增强处理,解决了测试语音与训练语音失配的问题,保证了特征的正确提取。实验证明,该特征原理简单,稳定性好,对语音内容不存在依赖性,有良好的抗噪性能,并且结合预增强处理是有效的,能够进一步提高辨认系统的识别率和鲁棒性。 ",MESS200904017
错音检测及其在语音教学中的应用综述,万济萍:06373757|肖云鹏:23246664|叶卫平:06374351,8,计算机应用; 中文信息处理; 自动发音错误检测; 计算机辅助语言学习; 计算机辅助发音训练; 发音评估; 语音识别;,"在学习语音的过程中,找出学习者发音的错误并加以改进是非常重要的。错音检测技术就是自动诊断语流中错误发音的技术,也是计算机辅助发音训练研究的主要内容之一。该文总结了错音检测技术的研究和应用现状,分别介绍了基于语音识别、基于错音网络和基于声学语音学的错音检测技术。在此基础上又介绍了错音检测技术在计算机辅助发音训练系统中的应用,以及汉语自动发音评估技术的发展。文章最后给出了作者的分析和建议。 ",MESS200904018
书讯,,1, , ,MESS200904019
维吾尔语单音节词复辅音声学分析,哈妮克孜·伊拉洪1:23246665|祖丽皮亚·阿曼2:22674756|艾斯卡尔·艾木都拉2:17704444,4,计算机应用; 中文信息处理; 维吾尔语; 复辅音; 声学分析; 声学参数;,"为了提高语音合成的自然度该文从文本分析模块入手,利用""维吾尔语语音声学参数库"",选择了带复辅音的63个单音节词的声学参数,包括辅音时长和辅音强度,通过语音分析软件研究了维吾尔语复辅音的组合规律和声学规律,复辅音中两个辅音声学特征之间的声学区别等问题。从语言类型学的角度看,在现代维吾尔语带复辅音的单音节词中前辅音比后辅音短且前辅音比后辅音强是固定声学特征。可是复辅音的组合不是固定的,因为组成复辅音的音素有可能再增加。 ",MESS200904020
藏语语料库词语分类体系及标记集研究,才让加:08163475,6,计算机应用; 中文信息处理; 语料库; 藏语词语; 分类体系; 标记集;,"青海师范大学藏文信息处理与机器翻译省级重点实验室已完成1 000万字的藏语语料库的加工实验,加工的主要目的是使计算机能够对藏语语料库中的藏语词语进行自动切分和自动标注。该文在对大规模藏语语料库进行自动切分和人工分析的基础上提出了一个藏语词语分类体系和标记集。根据藏语语料库和计算机自动切分和标注的实际需要,在藏语词语分类体系的构建上,采用先分虚实,再确定大类,在大类的基础上分出小类,再分出不同深度的子类。在藏语语料库加工实验中的应用表明,该分类方法和标记集是一个比较合理和实用的。 ",MESS200904021
维普资讯网简介,,1, ,"<正>重庆维普资讯有限公司前身为中国科技情报所重庆分所数据库研究中心。作为中国数据库产业的开拓者,公司自1993年成立以来,一直致力于电子信息资源的研究、开发和应用。公司的业务范围包括数据库出版发行、电子期刊出版发行、网络信息服务、网络广告推广、文献资料数字化加工等多种个性化服务。 ",MESS200904022
面向信息处理的藏文分词规范研究,扎西加:11131756|珠杰:10216645,6,计算机应用; 中文信息处理; 分词规范; 藏文; 信息处理;,"自动分词是藏文信息处理领域的一项基础课题,也是智能化藏文信息处理的关键所在。在藏文信息处理""字词处理""层面上,需要解决词的切分问题,而词类划分的标准和词的正确切分是进行藏文文本处理的必要条件。为了便于计算机对自动分词、词性标注的辨认,该文首先要确定满足藏文信息处理中词类的需求,并根据藏文自身的词汇特点与构词规律,提出了较为系统、适用的分词规范。 ",MESS200904023
基于ISO/IEC 10646标准的藏文编码转换的设计与实现,张青1:08166740|黄鹤鸣2:08224122|章登义3:09036578,6,计算机应用; 中文信息处理; 藏文; 字符集标准; 编码转换; 分表分组技术;,"目前,国内少数民族地区的书报印刷行业大多使用北大方正、华光藏文排版系统。这些软件的编码各异,致使有限的藏文资源无法实现交换和共享,造成这种现象的原因是各种软件编码体系不一致。解决这个问题的根本途径是将各种不同体系的藏文编码转换为符合国际标准的编码。该文以华光Windows藏文字符编码为例,首先对每个藏文字符进行构字分析,然后采用分表分组技术构造出每个字符符合ISO/IEC 10646标准的编码序列,最后采用hash技术优化查询算法,实现非标准的藏文字符编码向标准编码序列转换。 ",MESS200904024
EBMT中高效的维吾尔语单词散列表构造算法,田生伟1:09220503|吐尔根·依布拉音1:17705003|禹龙2:09256058,5,计算机应用; 中文信息处理; EBMT; 散列; 平均查找长度; 次优树;,"基于实例的机器翻译(EBMT)是一种高效的机器翻译方法,如何快速地从海量实例模式库中找出与待翻译句子相似的候选实例,是EBMT研究的关键技术之一。统计分析维吾尔语单词字母的分布特征,构造了基于维吾尔语单词的倒排索引散列表,在等概率条件下,平均查找长度为1.59;依据散列冲突的同义词在维吾尔语料中出现的频率作为权值,提出了一种新颖的解决散列冲突的算法:同义词次优树算法。实验显示,算法的性能比传统的顺序查找和二分查找算法分别高出了27.5%,21.8%,证明了该算法在EBMT中有较高的检索效率。 ",MESS200904025
商务印书馆语言学出版基金简介,,1, ,"<正>商务印书馆2002年斥资100万元人民币,设立语言学出版基金。商务印书馆语言学出版基金用于资助对汉语、汉字或中国境内其他语言文字的现状或历史进行调查研究有贡献的中国学者。特别提倡汉语研究与理论探索相结合,汉语本体研究与应用研究相结合,汉语的共时研究与历时研究相结合,标准语研究与方言研究相结合,汉语研究与非汉语研究相结合,汉语研究和跨语言研究相结合。提倡扎实、严谨、科学和创新的学风,鼓励学术争鸣。尤其重视发现人才、培养人才,特别是培养年轻人。 ",MESS200904026
集成多种背景语义知识的共指消解,郎君:06993481|忻舟:22045084|秦兵:06990821|刘挺:06994824|李生:06989058,8,计算机应用; 中文信息处理; 共指消解; 背景语义知识; WordNet; 维基百科;,"共指消解是信息抽取中一个重要子任务。近年来,许多学者尝试利用统计机器学习的方法来进行共指消解并取得了一定的进展。背景知识作为新的研究热点已经被越来越多地利用在自然语言处理的各个领域。该文集成多种背景语义知识作为基于二元分类的共指消解框架的特征,分别在WordNet、维基百科上提取背景知识,同时利用句子中的浅层语义关系、常见文本模式以及待消解词上下文文本特征。并利用特征选择算法自动选择最优的特征组合,同时对比同样的特征下最大熵模型与支持向量机模型的表现。在ACE数据集上实验结果表明,通过集成各种经过特征选择后的背景语义知识,共指消解的结果有进一步提高。 ",MESS200903002
一种基于谱聚类的共指消解方法,谢永康:22045071|周雅倩:06710223|黄萱菁:06698167,7,计算机应用; 中文信息处理; 共指消解; 谱聚类; 最大熵模型;,"该文针对中文共指消解的具体任务,提出采用谱聚类的方法进行共指消解。首先,在待消解项对上抽取特征,使用最大熵模型判断两个待消解项存在共指关系的概率;然后,以此概率值作为相似度进行谱聚类;最后,得到若干实体,实现共指消解。该方法能从全局的角度进行实体划分,有效地提高准确率。在ACE 2007标准数据集上的Diagnostic实验结果表明该方法的ACE Value比baseline方法有了2.5%的提高,Unweighted Precision值有5.4%的提高。 ",MESS200903003
基于可信度的中文完整词自动识别,"王芳1,2,3:11438514|万常选1,2:07848038",7,计算机应用; 中文信息处理; 中文分词; 互信息; 可信度; 自动识别;,"中文自动分词是中文信息检索中预处理工作的一部分,也是中文信息检索技术中的重要问题之一。针对在信息检索中完整词整体表达更有意义、更能体现用户查询目的的问题,结合完整词的成词特点,将互信息和完整词前后缀的计算,与组成完整词的可信度相关联,提出基于可信度的三种中文完整词自动识别方法,分别构成基于全信度、偏信度,以及前两者加权平均的混信度的完整词识别方法,设计及实现了基于可信度的三种完整词自动识别中文分词原型系统。最后给出了对第二届SIGHAN(2005)北京大学测试集语料的各项实验测试结果和分析,结果表明该原型系统的识别性能良好,且能同时满足多种性能的需求。 ",MESS200903004
基于统计信息的未登录词的扩展识别方法,韩艳:10702780|林煜熙:13898043|姚建民:13898051,8,计算机应用; 中文信息处理; 未登录词识别; 左右邻信息; 最频繁左邻比; 最频繁右邻比; 候选OOV扩展;,"该文提出一种基于网络资源的未登录词的扩展识别方法。该方法以左右邻信息判断未登录词边界为基础对已识别出的二元候选未登录词种子进行扩展,从而得到不限长度的语义更完整的未登录词。实验证明该文方法可行有效。 ",MESS200903005
面向主题爬取的多粒度URLs优先级计算方法,陈竹敏1:10697484|马军1:08853996|韩晓晖1:14257058|雷景生2:07028915,8,计算机应用; 中文信息处理; 主题爬取; 优先级计算; 网页分块; 相关度计算;,"垂直检索系统中主题爬虫的性能对整个系统至关重要。在设计主题爬虫时需要解决两个问题:一是计算当前页面与给定主题的相关度,二是计算待爬取URLs的访问优先级。对第一个问题,给出利用页面的主题文本块和相关链接块的相关度计算方法;对第二个问题,给出基于主题上下文和四种不同的粒度(即站点级、页面级、块级和链接级)的优先级计算方法。在此基础上,提出基于上述方法的主题爬取算法。实验证明,新算法在不增加时间复杂度的前提下,在查准率和信息量总和方面明显优于其他三种经典的爬取算法。 ",MESS200903006
基于“VASE”特征词的网络查询分类研究,"王俞霖1,2:22045094|孙乐1:10352504|李文波1:09659441",6,计算机应用; 中文信息处理; 网络查询分类; “VASE”特征词; 网络扩展; 加权特征词;,"网络查询分类对提高搜索引擎的搜索质量有重要的意义。该文通过对真实用户查询日志的分析和标注,发现四种特征词(称之为""VASE""特征词)对查询分类起决定性作用。我们提取特征词并构造了一个特征词倒排索引,用于对查询进行主题分类。在此基础之上,提出了基于网络扩展和加权特征词的方法改善分类的效果。实验结果显示,基于此分类方法的正确率和召回率分别达到78.2%和77.3%。 ",MESS200903007
基于向量距离的词序相似度算法,董刊生:22045102|方金云:09638901,6,计算机应用; 中文信息处理; 手机POI搜索; 简拼搜索; 词序相似度; 向量距离;,"手机POI搜索已经成为手机搜索的主要应用之一。该文结合手机搜索的特点以及POI数据的结构性特征采用简拼进行POI搜索。由于词序相似度是影响简拼搜索排序结果的主要因素,该文提出了基于向量距离计算词序相似度的算法。该算法采用空间向量模型作为简拼的表示方法,将提取的公共简拼映射为位置向量,进而利用位置向量间的距离计算词序相似度。通过理论分析,该算法相比基于逆序数的词序相似度算法,将时间复杂度由O(nlogn)降为O(n),空间复杂度由O(n)降为O(1)。实验结果表明,基于向量距离的词序相似度算法有效地保证了准确性,可以满足手机POI简拼搜索的应用需求,并在性能上将词序相似度的计算效率提高16.88%。 ",MESS200903008
一种面向流分类的特征选择算法,"李文法1,2:15089575|段洣毅1:22046073|刘悦1:09639001|孙春来3:10528571",8,计算机应用; 中文信息处理; 流分类; 特征选择; 快速模拟退火; 决策树;,"流分类技术在网络安全监控,QoS,入侵检测等方面起着重要的作用。流分类器处理的数据含有大量的相关与冗余特征,这不仅增加了分类器的计算复杂性,同时也影响了分类器的分类效果。针对高维特征空间,特征选择一方面可以提高分类精度与效率,另一方面可以找出富含信息的特征子集。该文提出一种wrapper型特征选择算法VFSA-C4.5来构建轻量级的流分类器。该算法采用快速模拟退火VFSA搜索策略对特征子集空间进行随机搜索,然后以提供的数据在C4.5上的分类正确率作为特征子集的评价标准,来获取最优特征子集。在流数据集上进行的大量实验结果表明,基于VFSA-C4.5的流分类器在不影响分类性能的情况下能够提高分类速度。 ",MESS200903009
人机互助的交互式口语翻译方法,刘鹏:22036025|宗成庆:10815045,7,人工智能; 机器翻译; 口语翻译; 基于短语的统计机器翻译; 人机交互; 模糊匹配;,"基于短语的统计翻译模型是目前机器翻译领域广泛使用的模型之一。但是,由于在解码时采用短语精确匹配的策略,造成了严重的数据稀疏问题,短语表中的大量短语无法得到充分利用。为此,该文提出了人机互助的交互式翻译方法。对于翻译短语表中找不到的短语,首先通过模糊匹配的方法,在短语表中寻找与其相似的短语。然后利用组合分类器,判断哪些相似短语可能提高句子的翻译质量。最后,通过人机交互的方法,选择可能提高翻译质量且保持原句语义的短语。在口语语料上的实验结果证明,这种方法可以有效地提高翻译系统的译文质量。 ",MESS200903010
汉英词语对齐规范,赵红梅1:22037542|刘群1:09638994|张瑞强2:22446503|吕雅娟1:13898594|隅田英一郎3:22037549|吴翠玲3:22037550,23,人工智能; 机器翻译; 汉英词语对齐规范; 手工词语对齐; 真对齐; 伪对齐; 强对齐; 弱对齐; 对齐和标注一致性;,"该文介绍了一个新的汉英词语对齐规范。该规范以现有的LDC汉英词语对齐规范为基础,对其进行了较大的改进和扩展,特别是提出了一种全新的对齐标注方法——将词语对齐区分为真对齐和伪对齐,真对齐又分为强对齐和弱对齐。这种细化的标注方法能够更好地刻画词语对齐的特点。该规范已经实际应用于大规模的人工词语对齐标注中。我们对对齐标注的一致性进行了评价。结果表明,在该规范的指导下,标注者内部和标注者间的对齐都取得了比较理想的一致性,两组强、弱、伪三种对齐的Kappa值分别为0.99、0.98、0.93和0.96、0.83、0.68。最后,一个简单的实验初步证实了该规范在统计机器翻译中的有效性。 ",MESS200903011
北京大学计算语言学教育部重点实验室建设计划通过论证,王厚峰:06274413,1, , ,MESS200903012
一种错误敏感的词对齐评价方法,黄书剑:11520226|奚宁:22036023|赵迎功:22036024|戴新宇:08061509|陈家骏:08035597,7,人工智能; 机器翻译; 统计机器翻译; 词对齐; 评价标准; AER; 错误敏感;,"对齐错误率(Alignment Error Rate,AER)是目前通用的词对齐评价标准。近年来的研究表明,AER虽然在一定程度上能够反映词对齐的质量,但它与机器翻译最终结果BLEU得分的相关性并不好。该文针对基于短语的机器翻译系统(PBSMT)分析了AER可能存在的一些问题,并根据词对齐结果中存在的不同类型的错误,提出了一种错误敏感的词对齐评测方法ESAER(Error-Sensitive Alignment Error Rate)。实验表明,该文提出的ES-AER与BLEU的相关性要远远好于AER。 ",MESS200903013
隐喻字面语义表示与生成,"王金锦1:22441633|杨芸1:09222501|周昌乐1,2:10232529",8,计算机应用; 中文信息处理; 隐喻字面语义; 隐喻计算; 无嵌套隐喻; 嵌套隐喻; 隐喻角色依存表示语言;,"在隐喻理解中,隐喻字面语义表示是隐喻深层语义表示的前提;确切地说,隐喻字面语义表示语言作为隐喻计算的输入语言直接影响到隐喻的最终释义,因此隐喻字面语义表示对隐喻的机器理解有着重要的影响作用。但在国内学术界,还鲜有这方面的研究。鉴于此,该文结合汉语隐喻特点,从隐喻字面语义表示的角度出发,将汉语隐喻分为无嵌套隐喻和嵌套隐喻两种。并在分析隐喻字面语义(浅层语义信息和隐喻信息)的基础上,提出了隐喻角色依存表示语言作为隐喻字面表示语言,最后给出隐喻角色依存表示语言生成算法。实验表明,该方法引入到汉语隐喻解释机制中是富有成效的。 ",MESS200903014
具有焦点标记作用的“是”字句重音分布研究,贾媛1:15657123|李爱军2:22444554|马秋武1:08773157|熊子瑜2:22444555,7,计算机应用; 中文信息处理; “是”字句; 焦点; 重音; 焦点和重音的关系;,"本研究以汉语中标记焦点的结构""[是[…XP…]]""为研究对象,通过声学和感知实验,系统地考察了这一句式所标记的焦点成分的重音位置及其声学表现。实验结果显示,该句式所标记的焦点位置,以韵律词为单位,音高的音域被整体拉大,后面的成分的音阶被陆续压低,被标记的焦点成分后面通常存在中间短语边界,而在第二个焦点标记前面,通常有语调短语边界。以实验结果为基础,本研究进一步讨论了语法学界争论较多的,关于焦点和重音关系的问题,研究指出,汉语中有标记的焦点位置通常有重音分布,有重音的位置一般伴有语调(音高音域)的变化,但重音和语调的变化不是确定焦点位置的依据。 ",MESS200903015
基于文档语义图的中文多文档摘要生成机制,宋锐:11438265|林鸿飞:06504899,6,计算机应用; 中文信息处理; 文档语义图; 编辑距离; PageRank; ROUGE; 中文多文档摘要;,"从文档集合的语义结构理解文档集合可以提高多文档摘要的质量。本文通过抽取中文多文档摘要文档集中的主-述-宾三元组结构构建文档语义图,再对语义图中的节点利用编辑距离进行语义聚类,并应用Page-Rank排序算法对语义图进行权重计算后,选取包含权重较高的节点及链接关系的三元组生成文档集合的多文档摘要。在摘要的评测阶段,将基于句子抽取的多文档摘要结果和基于文档语义图生成的多文档摘要分别与由评测员人工生成的摘要进行ROUGE相关度评测,并对利用编辑距离对语义图进行语义聚类前后的结果进行了比较。实验结果表明,基于文档语义图生成的多文档摘要与人工生成的摘要结果重叠度更高,而利用编辑距离对语义图进行聚类则进一步改进了摘要的质量。 ",MESS200903016
基于知识图的汉语词汇语义相似度计算,张瑞霞1:15726650|朱贵良1:07508376|杨国增2:10728174,5,计算机应用; 中文信息处理; 知识图; 知网; 语义相似度;,"提出了一种基于知识图的汉语词汇相似度计算方法,该方法以《知网》2005版为语义知识资源,以知识图为知识表示方法,在构造词图的基础上,以知网中的语义关系为依据对词汇概念中的义原进行分类,通过计算不同类型义原的相似度得到概念的相似度;为了对词汇相似度计算方法进行客观评价,设计了词汇相似度计算方法的量化评价模型;采用该模型对所提出的计算方法进行评价,试验结果证明此方法的有效度为89.1%。 ",MESS200903017
基于小世界模型的复合关键词提取方法研究,"马力1,2:09040096|焦李成1:05964057|白琳2:11313136|周雅夫2:10829797|董洛兵3:10829742",8,计算机应用; 中文信息处理; 小世界网络; 词语网络; 平均最短路径变化量; 聚类系数变化量; 复合关键词;,"该文提出了一种新的基于小世界网络特性的关键词提取算法。首先,利用K最邻近耦合图构成方式,将文档表示成为词语网络。引入词语聚类系数变化量和平均最短路径变化量来度量词语的重要性,选择重要性大的词语组成候选关键词集。利用侯选关键词集词语位置关系和汉语词性搭配关系,提取出复合关键词。实验结果表明该方法是可行和有效的,获取复合关键词比一般关键词所表达的含义更便于人们对文本的理解。 ",MESS200903018
商务印书馆出版新时期中国少数民族语言使用情况研究丛书,,1, , ,MESS200903019
《汉英机器翻译若干关键技术研究》由清华大学出版社出版,,1, , ,MESS200902020
命名实体识别、排歧和跨语言关联,赵军:10891784,15,计算机应用; 中文信息处理; 命名实体识别; 命名实体排歧; 命名实体跨语言关联;,"命名实体是文本中承载信息的重要语言单位,命名实体的识别和分析在网络信息抽取、网络内容管理和知识工程等领域都占有非常重要的地位。有关命名实体的研究任务包括:实体识别、实体排歧、实体跨语言关联、实体属性抽取、实体关系检测等,该文重点介绍命名实体识别、排歧和跨语言关联等任务的研究现状,包括难点、评测、现有方法和技术水平,并对下一步需要重点解决的问题进行分析和讨论。该文认为,命名实体识别、排歧和跨语言关联目前的技术水平还远远不能满足大规模真实应用的需求,需要更加深入的研究。在研究方法上,要突破自然语言文本的限制,直接面向海量、冗余、异构、不规范、含有大量噪声的网页信息处理。 ",MESS200902002
基于最大熵的依存句法分析,辛霄:22045076|范士喜:22045074|王轩:07000849|王晓龙:06993266,5,计算机应用; 中文信息处理; 句法分析; 最大生成树; 最大熵;,"该文提出并比较了三种基于最大熵模型的依存句法分析算法,其中最大生成树(MST)算法取得了最好的效果。MST算法的目标是在一个带有权重的有向图中寻找一棵最大的生成树。有向图的每条边都对应于一个句法依存关系,边的权重通过最大熵模型获得。训练和测试数据来源于CoNLL2008 Share Task的公用语料。预测的F1值在WSJ和Brown两个测试集上分别达到87.42%和80.8%,在参加评测单位中排名第6。 ",MESS200902003
基于语法分析和统计方法的答案排序模型,李波:06705506|高文君:22189154|邱锡鹏:06699441,6,计算机应用; 中文信息处理; 自动问题回答; 语法关键路径; 答案排序; 支持向量机;,"该文描述了一种构建问答式检索系统中答案排序模型的新方法。该方法结合了基于密度方法的度量特征和外部知识库,并且引入了基于语法分析方法的语法关键路径的新特征,使用支持向量机回归模型训练评估函数。实验证明,引入了上述语法关键路径特征后的新答案排序模型的排序性能有了明显提高。 ",MESS200902004
面向协作式问答的问题理解技术研究,张宇:06997645|赵鑫:07005468|刘挺:06994824,6,计算机应用; 中文信息处理; 协作式问答; 问题理解; 句法分析;,"问题理解是问答系统中的重要组成部分,尤其对于协作式问答。在协作式问答中用户对所提出的问题进行了详细的说明和描述。如何利用这些描述信息来提高系统的性能,是一个很重要的问题。该文提出了一种基于词典和句法分析的方法,来对用户的问题进行分析,从中提取出有价值的关键词,以提高包含候选答案网页的召回率。通过实验对比分析,该方法的MPP值和MAP值都有了较大的提高。 ",MESS200902005
基于汉语框架网的旅游信息问答系统设计,"李茹1,2:08453268|王文晶1:22045081|梁吉业1,2:08408575|宋小香1:22045082|刘海静1:22045083|由丽萍2,3:10812947",7,计算机应用; 中文信息处理; 汉语框架网; 本体; 问答系统;,"该文借助汉语框架网(Chinese Frame Net,简称CFN)在语义表达方面的独特优势,探讨用本体描述语言建立面向特定领域的汉语框架语义知识库,并且以旅游交通领域中问答系统设计为例分析方法的有效性。方法中首先利用TREC分类与本体分类相结合的方式为查询问句分类,然后提出基于CFN的问句分析策略,通过CFN语义分析得到问句中三元组:语义谓词、语义主体和语义客体,在问句分析的基础上从旅游本体知识库中对答案进行抽取并对答案处理,同时用本体编辑工具Protégé编码,实验证实方法是有效的。 ",MESS200902006
基于字符语言模型的垃圾邮件过滤,苏绥:22045125|林鸿飞:06504899|叶正:11547826,7,计算机应用; 中文信息处理; 垃圾邮件过滤; 语言模型; 朴素贝叶斯; 支撑向量机; n-Gram;,"基于内容的过滤是当前解决垃圾邮件问题的主流技术之一。该文先简单综述了当前基于内容的垃圾邮件过滤中采用的各种技术,在此基础上提出将基于字符的语言模型应用于垃圾邮件过滤任务中,并通过实验对比了该方法与Na ve Bayes、SVM和基于词的语言模型方法的性能差异,以及不同n值、不同特征选择方式对过滤结果的影响。实验结果表明,基于字符的语言模型实现简单且具有很高的性能,能较好地满足大规模在线邮件系统的需要,具有很高的实用价值。 ",MESS200902007
基于核偏最小二乘分类的垃圾邮件过滤,岑芳明:22045116|王明文:08472511|王鹏鸣:14183848|戴玉娟:22045117,6,计算机应用; 中文信息处理; 垃圾邮件过滤; 非线性; 核偏最小二乘; 回归; 分类; 潜在语义;,"垃圾邮件是Internet上亟待解决的问题,目前许多垃圾邮件过滤技术已经被使用。基于偏最小二乘的方法可以解决垃圾邮件的内容中普遍存在的数据稀疏性、高特征维数和多重相关性问题。但邮件内容之间的内在联系往往不是线性的,该文通过在偏最小二乘方法上引入核函数,去解决这一类的非线性问题。Enron-Spam垃圾数据集实验表明,同PLSR等方法比较,模型表现出了较好的过滤性能。 ",MESS200902008
网页搜索引擎查询日志的Session划分研究,张磊:15215084|李亚楠:13898593|王斌:09559997|李鹏:22045099|蒋在帆:22045100,8,计算机应用; 中文信息处理; 网络信息检索; 查询日志; session划分;,"搜索引擎查询日志中的session(以下简称session)是指某特定用户为得到某个信息需求而在一段时间内的搜索行为的连续序列。Session的正确划分是进行用户搜索行为分析等一系列工作的重要基础,目前尚没有关于session的系统研究工作。本文针对相关研究工作的问题重新统一定义了session的概念并进行探索和比较研究,得出结论:(1)统计语言模型因数据稀疏问题不适合做session划分;(2)利用多种属性的决策树方法可以得到比较理想的结果,以session为单位进行评价,F值达到了78.6%。 ",MESS200902009
基于人工标注的个性化检索系统评测的研究,张宇:06997645|范基礼:13896475|郑伟:07004292|邹博伟:13896483|刘挺:06994824,8,"计算机应用; 中文信息处理; 个性化信息检索,以用户为中心,评价方法;","个性化信息检索可以根据用户的检索兴趣返回个性化的检索结果。该文构建了个性化检索标注系统和个性化检索评测系统,生成个性化检索系统所需的语料集;并提出了以用户为中心的基于人工标注的个性化检索评价方法。个性化检索评测系统采用了NIST所建立的评价体系,根据用户的标注结果对个性化检索系统的性能进行自动评价,并给出量化、直观的性能指标。 ",MESS200902010
潜在语义索引中特征优化技术的研究,季铎:13897919|郑伟:11051921|蔡东风:08670703,8,计算机应用; 中文信息处理; 潜在语义索引; 共现特征; 奇异值分解; 特征选择;,"潜在语义索引被广泛应用于信息检索、文本分类、自动问答等领域中。潜在语义索引是一种降维方法,它把共现特征映射到同一维空间上,而非共现特征映射到不同的空间上。在潜在语义索引的语义空间中,共现特征通过文档内部以及文档之间的特征传递关系获得。该文认为这种特征传递关系会引入一些不存在的共现特征,从而降低潜在语义索引的性能,应该对这种特征传递关系进行一些选择,削除不存在的共现特征信息。该文采用文档频率对文档集合进行特征选择,用Complete-Link聚类算法在两个公开语料上进行三个实验,实验结果显示,保留文档频度的10%~15%时,其F1值分别提高了6.577 0%,1.992 8%和3.361 4%。 ",MESS200902011
一种新的基于中间语义的跨语言信息检索模型,黄国斌:22046064|王明文:22046065|叶浩:22046066,6,计算机应用; 中文信息处理; 跨语言信息检索; 中间语义; 潜在语义对; 偏最小二乘; TREC;,"目前的跨语言信息检索能够使用的方法有四种:查询词翻译的方法、文档翻译的方法、中间语言翻译方法和非翻译的方法。该文对这四种方法进行了简要介绍,提出它们的优缺点,并且提出了一种新的非翻译的方法——基于中间语义的方法。我们对提出来的方法进行了TREC跨语言语料库的试验,并且与单语言的信息检索模型进行了比较。试验证明我们的方法具有很好的性能和健壮性。 ",MESS200902012
基于后缀树的Web检索结果聚类标签生成方法,骆雄武:22045096|万小军:06262876|杨建武:06276703|吴於茜:06261494,6,计算机应用; 中文信息处理; 检索结果聚类; 聚类标签生成; 后缀树;,"对检索结果进行聚类能够方便用户从搜索结果中快速地找到自己需要的信息,当前已有各种聚类方法和系统被广泛使用,但是,现有大部分方法由于聚类标签的可读性和描述性较差,难以达到预期效果。该文提出了一种新的思路,注重于如何在聚类之前就产生好的标签,在生成了标签的基础上,再进行检索结果聚类。对于搜索引擎返回的结果,我们先统一建立一棵后缀树,然后计算后缀树中各个短语的得分,选取得分最高的若干短语作为候选标签。得到标签后,将搜索引擎返回的各个结果项分配到它所包含的标签对应的分类中,形成最后的聚类。实验表明,我们的方法是比较有效的。 ",MESS200902013
基于用户兴趣的寻找虚拟社区核心成员的方法,"陈海强1,2:13962326|程学旗1:09559496|刘悦1:09639001",7,计算机应用; 中文信息处理; 虚拟社区; 核心成员; 兴趣相似性;,"发现虚拟社区中的核心成员对于社区数据挖掘等应用问题有着相当重要的应用价值。为解决该问题,作者首先分析了一些虚拟社区中成员的兴趣相似性分布情况,从中发现核心成员间的兴趣存在相对较高的相似性。据此,作者提出了基于兴趣集中性的核心成员求解算法,并在豆瓣网的虚拟社区中进行了实验分析,实验结果证明了算法的有效性。 ",MESS200902014
基于目的分析的作弊页面分类,余慧佳:11444250|刘奕群:08176974|张敏:08186086|马少平:08177513|茹立云:08823400,7,计算机应用; 中文信息处理; 网络作弊; 目的分析; 作弊页面分类;,"随着互联网的飞速发展,因网络作弊而产生的垃圾页面越来越多,严重影响了搜索引擎的检索效率和用户体验。反作弊已经成为搜索引擎所面临的最重要挑战之一。但目前的反作弊研究大都是基于页面内容或链接特征的,没有一个通用可行的识别方法。本文主要基于作弊目的的分析,给出作弊页面另一种体系的分类,为基于目的的作弊页面识别起到良好的导向作用。 ",MESS200902015
中文比较句识别及比较关系抽取,宋锐:11438265|林鸿飞:06504899|常富洋:22045079,7,计算机应用; 中文信息处理; 中文比较句识别; 比较关系抽取; 中文比较模式库; 条件随机域;,"比较是一种具有一定说服力的评估方式,利用机器进行比较句的识别以及比较关系的抽取可以对观点挖掘、信息推荐等应用提供重要的依据。该文通过构建中文比较模式库以实现中文比较句的自动识别。在此基础上,该文通过选取比较主体、比较客体及其上下文的词、词性、位置、语义以及比较属性的领域知识等特征,利用条件随机域模型进行中文比较关系抽取。实验结果表明,中文比较模式库的构建有助于比较句的自动识别,而在词、词性、位置等Baseline特征中融入语义、领域知识及启发式规则特征后,基于条件随机域的比较关系抽取结果有了显著的提高。 ",MESS200902016
基于Wikipedia的语义元数据生成,韩先培:13898612|赵军:10891784,7,计算机应用; 中文信息处理; 元数据; 语义元数据; 数据处理; 语料库构建; 语义标注;,"语义元数据提供数据的语义信息,在数据的理解、管理、发现和交换中起着极为重要的作用。随着互联网上数据爆炸式的增长,对自动元数据生成技术的需求也就变得更加迫切。获得目标语义元数据及得到足够的训练语料是使用自动生成技术的两个基本问题。由于获得目标语义元数据需要专家知识,而获得足够的训练语料需要大量的手工工作,这也就使得这两个问题在构建一个成功的系统时至关重要。该文基于Wikipedia来解决这两个问题:通过分析一个类别中条目的目录表(table-of-contents)来抽取目标语义元数据,通过对分析文档结构和赋予目标结构正确的语义元数据来构建训练语料库。实验结果表明,该文的方法能够有效地解决这两个问题,为进一步的大规模的语义元数据应用系统打下了坚实的基础。 ",MESS200902017
词汇间语义相关关系量化计算方法,"钟茂生1,2:09606446|刘慧1:09596881|刘磊1:08518760",8,计算机应用; 中文信息处理; 词汇间语义关系; 相关关系; 互信息; 二分图; 量化方法;,"词汇间语义关系的定量化研究是自然语言处理任务中一个重要的基础性工作。词汇间语义关系总体上分为等同关系、上下位关系、相关关系,现有的语义关系定量化工作主要集中于词汇间语义的等同关系(相似性)量化研究。该文研究和提出了量化词汇间语义相关关系的基本思路和新方法,即构造词汇相关关系二分图来求解和量化词汇间间接相关关系,该方法能够解决在统计语料中没有出现的词汇对的相关关系量化求解问题。实验结果表明,该文提出的方法比单纯用互信息来计算和量化词汇间语义相关关系更为可行。同时,对于一个特定词汇而言,该文的方法能够得到一个相关关系量化的相对合理的趋势性结果。 ",MESS200902018
汉语意见型主观性文本标注语料库的构建,宋鸿彦:21774539|刘军:09596900|姚天昉:08576605|刘全升:21774537|黄高辉:21774538,6,计算机应用; 中文信息处理; 主观性文本; 汉语意见型主观性文本; 语料库;,"汉语意见型主观性文本是目前自然语言处理中的一个研究热点。该文介绍了汉语意见型主观性文本标注语料库构建方面的一些经验,讨论了设计和建设语料库方面的几个重要问题,包括语料的选取、标注、存储、检索和统计,以及语料库相关工具的设计等。汉语意见型主观性文本标注语料库与普通的语料库相比,其特点在于深度标注了主观性文本的词性、句法、语义和意见元素等信息,忠实记录了主观性文本的语言现象。汉语意见型主观性文本标注语料库的构建为人们分析和研究汉语主观性文本提供了有力的资源支持。 ",MESS200902019
中国语言资源开发应用中心成立,,1, , ,MESS200902021
基于知识管理和智能控制的协同翻译平台——知识管理和机器翻译的融合,张桂平:09719392|蔡东风:08670703,9,人工智能; 机器翻译; 知识管理; 用户模型; 协同翻译平台;,"在对机器翻译发展艰难历程总结和反思的基础上,提出了以用户模型为核心的知识管理与机器翻译技术融合的新思想。2008年7月该成果通过了中国中文信息学会在京组织的鉴定,鉴定委员会一致认为:""研制单位基于其所承担的国家863课题机器翻译和知识管理技术的融合研发的基于知识管理和智能控制的协同翻译平台已圆满完成。该项研究在利用知识管理技术实现人机双向协同翻译方面达到国际领先水平。""本文对平台研制的思想与方法、设计与实现、分析与应用、历程与展望进行了阐述。 ",MESS200805000
句法与词义相结合的中文代词消解,宋巍:21774529|秦兵:06990821|郎君:06993481|刘挺:06994824,6,计算机应用; 中文信息处理; 代词消解; 依存句法; 句法角色; 词义相似;,"句法知识对代词消解有很大的帮助。近年来依存句法由于其利于描述语言中词与词之间的关系、突出核心词的特点日益得到重视。该文提出了一种中文第三人称代词消解方法,直接利用依存句法分析器的结果,构建有效的句法角色特征和名词短语的支配词之间的词义相似和词语相关特征,采用支持向量机作为分类器,在ACE2005语料上的实验证明了这些特征的有效性。 ",MESS200806001
短语结构树库向依存结构树库转化研究,李正华:17457974|车万翔:06987220|刘挺:06994824,6,计算机应用; 中文信息处理; 短语结构树库; 依存结构树库; 依存句法分析;,"汉语依存树库的建设相对其他语言如英语,在规模和质量上还有一些差距。树库标注需要付出很大的人力物力,并且保证树库质量也比较困难。该文尝试通过规则和统计相结合的方法,将宾州汉语短语树库PennChinese Treebank转化为哈工大依存树库HIT-IR-CDT的体系结构,从而增大现有依存树库的规模。将转化后的树库加入HIT-IR-CDT,训练和测试依存句法分析器的性能。实验表明,加入少量经转化后的树库后,依存句法分析器的性能有所提高;但加入大量树库后,性能反而下降。经过细致分析,作为一种利用多种树库提高依存句法分析器性能的方法,短语转依存还存在很多需要深入研究的方面。 ",MESS200806002
基于最大熵原则的汉语语义角色分类,丁伟伟:21774530|常宝宝:06253581,8,计算机应用; 中文信息处理; 语义角色分类; 最大熵; 特征; 上下文; 窗口; 贪心策略;,"语义角色标注是近些年来兴起的自然语言处理的一个新的研究领域。与英语方面的研究相比,汉语方面的工作还不是很充分。该文在参考已有工作的基础上,基于最大熵原则,对汉语语义角色标注中的一个方面———语义角色分类进行了深入的研究。在提出了一些新的特征之后,该文还充分利用了语义角色之间的相关性,提取语义角色的上下文特征,从而提高标记的准确率;此外,通过对不同特征的单独研究,笔者发现了不同特征取得最优值时的窗口大小差别很大。发现这一现象后,笔者设计了一种基于贪心策略的选择算法,对不同的特征选择不同的窗口大小,使得标记结果进一步提高。在综合采用了以上的策略之后,笔者的汉语语义角色分类系统可以达到95.00%的准确率,比前人有较为显著的提升。从而证明了笔者的方法是有效的。 ",MESS200806003
“像”的明喻计算,李斌1:08075606|于丽丽1:21774531|石民1:21774532|曲维光2:08112756,6,计算机应用; 中文信息处理; 隐喻计算; 明喻; 明喻识别;,"汉语隐喻计算是一项难度很大的工作,明喻由于带有明显的标志(比喻词)成为计算机自动识别的基础类型。该文着力于典型的比喻词""像""的比喻义及相关比喻成分的自动识别。首先,人工标注了1 586句语料,分析了明喻句的基本特点。然后,使用最大熵模型对""像""的比喻义和非比喻义进行分类,开放测试F值达到了89%。最后,用条件随机场模型识别出比喻的本体、喻体和相似点,F值分别达到了73%、86%和83%。 ",MESS200806004
基于句间关系的汉语语义块省略恢复,"贾宁1,2:09584513|张全2:09634516",5,计算机应用; 中文信息处理; 省略; 语义块共享; 句间关系;,"语义块是句子的语义构成单位,句子内发生的省略现象可以归结为语义块的省略。该文在句类分析的基础上,从小句间语义块共享关系的角度分析语义块的省略。将语义块的省略分为语义块整块共享形成的省略和语义块部分共享形成的省略,分析了两种情况的特点,并给出了相应的处理算法。测试表明,该算法对于两种省略均有很好的处理效果。 ",MESS200806005
基于语言模型验证的词义消歧语料获取,郭宇航:21774533|车万翔:06987220|刘挺:06994824,5,计算机应用; 中文信息处理; 词义消歧; 语言模型; 噪声过滤;,"作为一种稀缺资源,人工标注语料的匮乏限制了有指导词义消歧系统的大规模应用。有人提出了利用目标词的单义同义词在生语料中自动获取词义消歧语料的方法,然而,在某些上下文当中,用目标词替换这些单义的同义词并不合适,从而带来噪声。为此,笔者使用语言模型过滤这些噪声,达到净化训练数据,提高系统性能的目的。笔者在Senseval-3国际评测中文采样词词义消歧数据集上进行了实验,结果表明经过语言模型过滤的词义消歧系统性能明显高于未经过滤的系统。 ",MESS200806006
《中国语言生活状况报告》中成语与习语的调查与思考,"曾小兵1:21774534|张志平1:21774535|刘荣1,2:21774536|杨尔弘1:06429879|张普1:06432471",7,计算机应用; 中文信息处理; 中国语言生活; 成语与习语; 语言规律; 词汇规范;,"成语与习语的调查是《中国语言生活状况报告》在2007年的新增项目,这表明成语与习语使用情况引起了人们更多的关注。成语与习语的研究在语言应用中有广泛而深刻的意义。该文在基于大规模真实语料调查的基础之上,对成语与习语的使用情况做出了""单字差异""等比较,从中发现一些语言现象并提出了自己的思考,以期对汉语语言事实的发现、语言规律的总结、语言词汇的规范化等方面有所裨益。 ",MESS200806007
《中文信息学报》征稿简则,,1, , ,MESS200806008
以关键词抽取为核心的文摘句选择策略,"马亮1,2:21776039|何婷婷1,2:07640959|李芳1,2:07645444|陈劲光1,2:21340272|邵伟1,2:17388772",5,计算机应用; 中文信息处理; 多文档文摘; 关键词抽取; 文摘句选择;,"针对面向查询的多文档自动文摘,该文提出了一种以关键词抽取为核心的文摘句选择策略。通过查询扩展的相关技术得到相关多文档集中词语的查询相关性特征,利用最大似然估计法得到语料中词语的话题相关性特征,并将这两个特征值进行特征融合得到词语的重要度以确定关键词。然后通过关键词的重要度来给候选句打分,进一步利用改进的MMR(Maximal Marginal Relevance)技术来调整候选句的得分,最后生成文摘。该文将特征融合引入到词语层面,在DUC2005的语料中测试取得了较好的效果。 ",MESS200806009
基于最大熵模型的中文阅读理解问题回答技术研究,李济洪1:08401319|王瑞波2:13897708|王凯华1:13897707|李国臣2:08407515,8,计算机应用; 中文信息处理; 阅读理解; 问答系统; 最大熵模型; 主成分;,"该文基于山西大学自主开发的中文阅读理解语料库CRCC v1.1版,根据问句和候选答案句的对应关系,构建了词层面以及句法层面共计35个特征,基于最大熵模型对中文阅读理解问题回答进行了建模,在35个特征全部加入最大熵模型的情况下,测试集上得到了75.46%的HumSent准确率。考虑到特征取值之间的相关性对权重估计的影响,笔者先对35个特征观测值矩阵进行主成分降维,选择适当的主成分个数重构特征,然后再使用最大熵模型进行建模,在测试集上的HumSent准确率达到80.18%.实验结果表明,在阅读理解问答系统中,采用特征的主成分降维方法,能有效融合全部特征信息,回避了最大熵模型中特征筛选的过程,并且提高了阅读理解系统的准确率。 ",MESS200806010
汉语意见型主观性文本类型体系的研究,刘全升:21774537|姚天昉:08576605|黄高辉:21774538|刘军:09596900|宋鸿彦:21774539,6,计算机应用; 中文信息处理; 主观性文本; 类型体系; 意见挖掘;,"主观性文本是一种描述个人想法、情感和意见等的非约束性文本。它与主要描述以事实为主的客观性文本在内容和结构上有很大的不同。意见型文本是包含有意见元素(意见持有者、意见陈述范围、意见主题和意见情感)的一种主观性文本,它大量出现在网上的电子公告板、论坛和博客等媒介中,受到广泛的关注,并成为研究意见挖掘方法和技术的语料。该文介绍了主观性文本的定义及其与客观性文本的差异,同时着重讨论了意见型文本的定义、特点、类型体系及其在意见挖掘技术中的应用。 ",MESS200806011
一种基于WWW的Ontology属性值自动提取方法,赵庆亮:21774540|穗志方:06268960,6,计算机应用; 中文信息处理; 因特网; 互动方法; 属性值提取;,"属性值是描述Ontology中类的重要信息,但是当前关于属性值的自动提取的研究并不多。该文提出一种基于WWW的Ontology属性值自动提取方法。论文首先提出了一种在小规模属性值种子集的基础上,包含属性值的句子的选择与属性值提取互动的方法。这种方法利用互联网信息的冗余性,自动抽取并扩充目标属性值集合。然后,为避免人工构造属性值种子集,提出种子集自动生成的方法。我们设计实验来计算提取结果的正确率和召回率,此外,我们还通过将填充后的Ontology信息用于网页正文提取任务来展示Ontology自动扩充结果的有效性。 ",MESS200806012
基于联合权重的多文档关键词抽取技术,"杨洁1:21774541|季铎1:13897919|蔡东风1:08670703|林晓庆1,2:16302248|白宇1:11329492",5,计算机应用; 中文信息处理; ATF×PDF; 联合权重; 多文档; 语义相似度;,"该文提出一种多文档关键词抽取方法,该方法提出ATF×PDF(Average Term Frequency×ProportionalDocument Frequency)来计算词语权重,并根据候选关键词之间的语义相似度,采用联合权重方法重新计算候选关键词的权重来抽取关键词。该方法综合考虑了词语的频率,词性以及词语之间的语义相似性等信息,实验表明,该方法能有效抽取多个文档的关键词,同基于关键词的聚类标记方法相比,其准确率提高3%,召回率提高7%,F-measure提高4.4%。 ",MESS200806013
网络热点事件发现系统的设计,"刘星星1,2:14906783|何婷婷1,2:07640959|龚海军1,2:17387367|陈龙1,2:21360943",6,计算机应用; 中文信息处理; 事件发现; 凝聚聚类; Single-pass聚类; 热度计算;,"该文设计了一个热点事件发现系统。该系统面向互联网新闻报道流,能自动发现任意一段时间内网络上的热点事件,并给出描述事件发展过程的曲线图。针对网络新闻语料具有数据规模大和时间特征明显两个特性,系统将语料按时间(天)分组,对每天的语料采用凝聚聚类得到微类,选取某段时间内的所有微类,再做Single-pass聚类得到事件列表,利用事件热度计算公式,把候选事件按热度进行排序。采用该系统对2007年新闻语料进行实验,结果表明该系统能取得较好的效果。 ",MESS200806014
基于统计特征的垃圾博客过滤,刘玮1:15034678|廖祥文1:09596594|许洪波1:10348532|王丽宏2:13575038,6,计算机应用; 中文信息处理; 内容分析; 垃圾博客过滤; 统计特征; 词频特征; 泛化能力;,"该文根据垃圾博客和正常博客在统计特征上的差异,对多种针对博客分类有效的统计特征进行了分析,提出基于博客页面统计特征的过滤方法。在Blog06数据集上的实验表明,该方法的过滤准确性达到97%,比基于词频特征的过滤方法提高了约7%,在不同规模训练集上的准确性保持在95%左右,具有更好的泛化能力。 ",MESS200806015
基于用户日志挖掘的搜索引擎广告效果分析,陈磊:08168605|刘奕群:08176974|茹立云:08823400|马少平:08177513,6,计算机应用; 中文信息处理; 搜索引擎; 用户行为分析; 竞价排名广告;,"随着搜索引擎市场的飞速发展,竞价排名广告以其有效、低风险、灵活等特点逐渐受到中小企业用户的青睐,成为搜索引擎稳定的收益增长点。然而竞价排名广告是否会影响用户体验,从而削弱其宣传效果并且影响用户对于搜索引擎的忠实度成为了企业及搜索引擎所担忧的问题。该文从网络用户日志中挖掘出网络用户对于广告的实际交互行为,并给出了各大搜索引擎竞价排名广告方面的统计数据。对于企业用户如何更有效地利用竞价排名广告以及搜索引擎如何平衡广告的经济效益和用户体验之间的关系都有较高的指导意义。 ",MESS200806016
机器学习的查询扩展在博客检索中的应用,王秉卿:21774820|张奇:06708764|吴立德:06705247|黄萱菁:06698167,6,计算机应用; 中文信息处理; 信息检索; 查询扩展; 机器学习;,"该文介绍一种新的查询扩展方法,该方法结合了查询扩展技术和机器学习理论。通过机器学习的方法挑选出查询扩展词,以此提高检索结果的性能。对于输入的查询项,首先通过伪反馈技术生成候选扩展词集合,然后使用支持向量机对输入的候选词评分,挑选得分较高的候选词和原始查询项组成一个新的查询项。由于训练这个支持向量机的训练数据较难获得,我们利用评测会议的检索结果和检索工具自动地生成训练数据。这套查询扩展方法的优点在于通过对训练语料的学习,能够对候选扩展词作出更合理的选择。在TREC评测会议组织的观点检索任务中,相对于不采用任何扩展技术的基准系统,该方法提高了MAP指标33.1%。 ",MESS200806017
一种有效的基于Web的双语翻译对获取方法,郭稷1:21774542|吕雅娟2:13898594|刘群2:09638994,7,计算机应用; 中文信息处理; 双语翻译对; 统计判别模型; 网络挖掘;,"命名实体和新词、术语的翻译对机器翻译、跨语言检索、自动问答等系统的性能有着重要的影响,但是这些翻译很难从现有的翻译词典中获得。该文提出了一种从中文网页中自动获取高质量双语翻译对的方法。该方法利用网页中双语翻译对的特点,使用统计判别模型,融合多种识别特征自动挖掘网站中存在的双语翻译对。实验结果表明,采用该模型构建的双语翻译词表,TOP1的正确率达到82.1%,TOP3的正确率达到94.5%。文中还提出了一种利用搜索引擎验证候选翻译的方法,经过验证,TOP1的正确率可以提高到84.3%。 ",MESS200806018
中心词驱动的汉语统计句法分析模型的改进,何亮1:08061509|戴新宇1:08030596|周俊生2:08116958|陈家骏1:08035597,7,计算机应用; 中文信息处理; 中心词驱动PCFG概率模型; 基本名词短语; N-Best词性序列; 汉语句法分析;,"在对Dan Bikel基于Collins中心词驱动概率句法分析模型实现的句法分析器进行深入研究分析的基础上,对其进行了两个方面的改进。一是通过提供N-best词性候选序列,改进原模型在词性方面的处理,改善了句法分析的结果;二是在该模型中引进单独的基本名词短语识别,从而降低句法分析的复杂度,提高了效率,其中,针对中文的特点,通过对BaseNP的概念进行一系列的扩展,深入研究了基于不同层次概念的BaseNP对句法分析的影响并探讨更适合中文句法分析的BaseNP定义。利用改进的句法分析模型进行中文句法分析实验,实验结果表明,改进模型可以缩短分析时间26%,提高F值4.4个百分点,交叉括号平均减少18%。 ",MESS200804000
汉语交集型歧义切分字段关于专业领域的统计特性,乔维:11601517|孙茂松:08823738,9,计算机应用; 中文信息处理; 汉语自动分词; 专业领域语料库; 交集型歧义切分字段; 伪歧义; 真歧义;,"交集型分词歧义是汉语自动分词中的主要歧义类型之一。现有的汉语自动分词系统对它的处理能力尚不能完全令人满意。针对交集型分词歧义,基于通用语料库的考察目前已有不少,但还没有基于专业领域语料库的相关考察。根据一个中等规模的汉语通用词表、一个规模约为9亿字的通用语料库和两个涵盖55个专业领域、总规模约为1.4亿字的专业领域语料库,对从通用语料库中抽取的高频交集型歧义切分字段在专业领域语料库中的统计特性,以及从专业领域语料库中抽取的交集型歧义切分字段关于专业领域的统计特性进行了穷尽式、多角度的考察。给出的观察结果对设计面向专业领域的汉语自动分词算法具有一定的参考价值。 ",MESS200804001
汉语篇章修辞结构的标注研究,乐明:09330471,6,计算机应用; 中文信息处理; 汉语语料库; 篇章标注; 修辞结构理论;,"汉语篇章修辞结构标注项目CJPL采用大陆主要媒体的财经评论文章为语料,依据修辞结构理论(Rhetor-ical Structure Theory,RST),定义了以标点符号为边界的篇章修辞分析基本单元和47种区分核心性单元的汉语修辞关系集,并草拟了近60页的篇章结构标注工作守则。这一工作目前完成了对97篇财经评论文章的修辞结构标注,在较大规模数据的基础上检验了修辞结构理论及其形式化方法在汉语篇章分析中的可移用性。树库所带有的修辞关系信息以及三类篇章提示标记的篇章用法特征,可以为篇章层级的中文信息处理提供一些浅层语言形式标记的数据。 ",MESS200804002
中医药古文献语料库设计与开发研究,刘耀1:17375155|段慧明2:09152456|王惠临1:08444886|周扬3:17374697|王振国3:06260916|李宏展2:09512639,7,计算机应用; 中文信息处理; 自然语言处理; 语料库; 中医药古文献; 知识工程;,"专业领域语料库是对专业领域文献进行自然语言处理的重要的不可或缺的基础,是对专业文本内容与意图进行深层把握的必由之路。通过对研究背景的分析,进一步明析了专业文献进行自然语言处理的必要性,并在对专业文献语料库的研究特点进行分析的基础上,深入探讨了专业语料库的设计思想及原理,同时,对语料库词类的标注信息进行了深入研究。成功地开发了针对专业领域语料库的辅助加工系统,为专业领域语料库建设提供了理论指导和技术支撑。 ",MESS200804003
农业古籍断句标点模式研究,黄建年:14247086|侯汉清:00019656,8,计算机应用; 中文信息处理; 农业古籍; 古农书; 古籍整理; 断句; 标点; 模式匹配;,"农业古籍的整理已经引起了众多学者和专家的注意,但是,对于农业古籍的自动断句、标点模式的研究仍付之阙如。本研究探索并总结出部分农业古籍断句、标点识别模式。首先采用句法特征词断句法、同义语标志词法进行初步断句;进而利用反义复合词、引书标志、时序、数量词、重叠字词、动名结构及比较句法进一步对子句进行断句、标点;最后使用农业用语和禁用模式表进一步提高断句、标点后农业古籍的可读性和准确性。经测试表明,断句、标点的平均准确率分别达到48%和35%,证明本方法具有一定的正确性和可行性。 ",MESS200804004
语义对立度及其计算模型的研究,麦范金1:45669457|王挺2:06963261,4,计算机应用; 中文信息处理; 语义; 相似度; 对立度; 反义词;,"人类的思维离不开语言,联想思维主要通过相关、相似和对立三种方式。现阶段有关语义的相关和相似的研究已比较多,而有关对立的研究却比较少。文章把负值引入到相似度计算中,提出对立度等概念和相关的计算模型,将它们运用到语义对立程度的计算中,并通过仿真试验论证了这些概念模型和计算方法的可行性和有效性。 ",MESS200804005
基于词法分析的维吾尔语元音弱化算法研究,,5,计算机应用; 中文信息处理; 维吾尔语; 弱化现象; 语音规律; 词法结构;,"重点研究维吾尔语中弱化现象及处理算法,并分析了维吾尔语词法结构,音节结构,词干—词缀连接形式等技术。处理弱化问题时,要根据词干库检查弱化属性,并根据语音和谐规律分析是否正确连接。该算法在文本检索、词频统计、文本校对等研究领域得到很好的应用。运行结果表明该算法具有可行性和有效性,并在实践中不断完善。 ",MESS200804006
基于混淆网络解码的机器翻译多系统融合,,7,人工智能; 机器翻译; 多系统融合; 最小贝叶斯风险解码; 多特征混淆网络; GIZA-TER;,"在对当前几种较流行的统计机器翻译多系统融合方法分析的基础上,提出了一种改进的多系统融合框架,该框架集成了最小贝叶斯风险解码和多特征混淆网络解码两种技术。融合过程如下:(1)从多个翻译系统输出的-best结果中,利用最小贝叶斯风险解码器选择一个风险最小的假设作为对齐参考;(2)将其余的-best假设结果与该参考对齐,从而构建混淆网络。多特征混淆网络基于对数线性模型,引入了更多有效的知识源参与最优路径选择,融合后的BLEU得分比融合前最好的单系统BLEU得分提高了2.19%。在对齐方法上,我们提出了一种改进的翻译错误率(Translation Error Rate,TER)准则——GIZA-TER准则,该准则可以对CN网络进行更有效的短语调序。实验中的显著性检验证明了本文方法的有效性。 ",MESS200804007
一种命名实体翻译等价对的抽取方法,陈怀兴:17373698|尹存燕:08035597|陈家骏:08045864,6,人工智能; 机器翻译; 命名实体; 翻译等价对; HMM; 对齐模型;,"有关命名实体的翻译等价对在多语言处理中有着非常重要的意义。在过去的几年里,双语字典查找,音译模型等方法先后被提出。另一种极具价值的方法是从平行语料库中自动抽取有关命名实体的翻译等价对,现有的方法要求预先对双语语料库的两种语言文本进行命名实体标注。提出了一种只要求对语料库中源语言进行命名实体标注,目标语言不需标注,然后利用训练得到的HMM词对齐结果来抽取有关命名实体翻译等价对的方法。在实验中,把中文作为源语言,英文作为目标语言。实验结果表明用该方法,即使在对齐模型只是部分准确的情况下,也得到了较高正确率的命名实体翻译等价对。 ",MESS200804008
双向聚类迭代的协同过滤推荐算法,王明文1:11195370|陶红亮1:08472511|熊小勇2:10897127,6,计算机应用; 中文信息处理; 协同过滤; 聚类; 交叉迭代; 平均绝对偏差;,"协同过滤是电子商务推荐系统中广泛采用的技术,然而数据稀疏性会影响协同过滤的推荐质量。针对数据稀疏问题提出一种双向聚类迭代的协同过滤推荐算法,对初始得到的用户聚类和项目聚类进行交叉迭代调整,使得聚类簇达到较为稳定的状态。调整后聚类簇的内聚性更强,类之间的区分度更大。实验表明,在调整后的聚类簇中查找邻居将更加准确,可以有效解决数据稀疏问题的影响,有利于提高推荐的准确性。 ",MESS200804009
文档检索中句法信息的有效利用研究,,9,计算机应用; 中文信息处理; 信息检索; 词项依存; 句法分析; 词项近邻;,"利用词项依存关系来改进词袋模型,一直是文本检索中一个热门话题。已有的定义词项依存的方法中,有两类主要的方法:一类是词汇层次的依存关系,利用统计近邻信息来定义词项依存关系,另一类是句法层次的依存关系,由句法结构来定义词项依存关系。虽然已有的研究表明,相对于词袋模型,利用词项依存关系能够显著地提高检索性能,但这两类词项依存关系却缺乏系统的比较:在利用词项依存关系来改进文档和查询的表达上,如何有效地利用句法信息,哪些句法信息对文本检索比较有效,依然是个有待研究的问题。为此,在文档表达上,比较了利用近邻信息和句法信息定义的词项依存关系的性能;在查询表达上,对利用不同层次的句法信息所定义的词项依存关系的性能进行了比较。为了系统地比较这些词项依存关系对检索性能的影响,在语言模型基础上,以平滑为思路,提出了一个能方便融入这两类词项依存关系的检索模型。在TREC语料上的实验表明,对于文档表达来说,句法关系较统计近邻关系没有明显的差别。在查询表达上,基于名词/专有词短语的部分句法信息较其他的句法信息更加有效。 ",MESS200804010
Web检索查询意图分类技术综述,张森:09559997|王斌:13898598,8,计算机应用; 中文信息处理; 自动查询分类; 查询意图分类; 分类方法; 数据集; 特征提取; 机器学习;,"查询分类是近年来信息检索领域的研究热点,并且在很多领域得到了广泛地关注。主要讨论根据查询的意图进行分类的研究工作,从查询分类的诞生背景、关键技术、所使用的分类方法和评价方法方面进行综述评论,提出了查询意图分类面临的问题和挑战。认为缺乏权威的评测标准、在大规模数据集上的未经全面测试的性能、如何准确地获取查询的特征以及如何证明分类体系的完备性和独立性是目前查询意图分类研究的关键问题。 ",MESS200804011
一种中文文档的数学公式定位方法,,5,人工智能; 模式识别; 中文文档; 字符识别; 数学公式; 高斯混合模型;,"为了从中英文混排的中文文档中定位数学公式,提出了一种基于中文字符识别和公式符号识别的数学公式定位方法。该方法主要由中文字符提取、内嵌公式提取和独立公式定位三个部分组成。在中文字符提取中,首先提取字符块信息:中文字符识别结果、公式符号识别结果和字符块的几何特征,然后使用决策树的方法区分中文字符和非中文字符。在内嵌公式提取中,使用公式符号的语义信息、符号间的角标关系和公式的语义信息等从非中文字符中定位内嵌公式。在独立数学公式定位中,对包含较多内嵌公式符号且不包含中文字符的文字行提取版式结构特征,并使用高斯混合模型区分独立公式和普通文字行。在148幅文档图像共包含3 690个公式组成的测试集上取得了91.19%的公式定位正确率。 ",MESS200804012
基于韵律信息的连续语流调型评测研究,潘逸倩:09578638|魏思:10894587|王仁华:17375468,6,计算机应用; 中文信息处理; 语音评测; 调型评测; 调型识别; 韵律词; MSD-HMM;,"汉语连续语流中的调型评测是汉语语音评测的一个重要环节,利用连续语流中韵律耦合效应和韵律结构紧密相关这一特性,以韵律词为基本建模单元,建立基于多空间概率分布的HMM调型模型(MSD-HMM),使得汉语普通话水平评测系统针对标准连续语流的调型识别率从82.0%提升至84.6%;针对有方言背景的非标准发音,机器评分与专家评分的相关度绝对提升超过3.0%。 ",MESS200804013
一种结构受限的异方差线性判别分析,陈思宝:09578638|胡郁:15584952|王仁华:09540699,6,计算机应用; 中文信息处理; 语音识别; 特征变换; HLDA; 结构受限;,"异方差线性判别分析(HLDA)因在语音识别中起到了巨大的特征去相关作用而被广泛利用。然而在训练数据不足或特征维数较高时,HLDA易出现不稳定性和小样本问题。根据特征的矩阵表示形式,提出了一种结构受限的HLDA。首先用二维线性判别分析(2DLDA)压缩矩阵形式的特征,然后作一维的HLDA。通过分析我们指出,二维的特征变换实际上是一种结构受限的一维特征变换。在RM库上的实验,受限HLDA对常规HLDA的词识别错误相对下降12.39%;在TIMIT库上的实验,受限HLDA对常规HLDA的音素识别错误相对下降4.43%。 ",MESS200804014
基于音素及其特征参数的维吾尔语音合成技术,姑丽加玛丽·麦麦提艾力:09219516|艾斯卡尔·艾木都拉:09253880,5,计算机应用; 中文信息处理; 语料库; 参数调整; 语音合成; 时域平滑;,"首先建立了由维吾尔语中的单音素、双音素所构成的小规模语音语料库,设计了相应的拼接单元挑选算法,利用参数调整算法对拼接单元语音信号的时长、基频和短时能量等特征参数进行调整,并利用时域平滑算法对拼接点处的语音参数进行调整,从而进一步提高了合成语音的自然度。用C Sharp编程语言实现了上述算法,试验结果表明研究思路和技术方案的可行性。该系统具有语料库小,合成语音的可懂度和自然度较高等优势。 ",MESS200804015
《中国科技术语》创刊十周年,,1, , ,MESS200804016
在通用字符集中藏文编码模式的研究与应用,欧珠:11626402,4,计算机应用; 中文信息处理; UCS; 藏文编码; 组合; 排序; 重排;,"藏文软件开发者在现代计算机系统中处理藏文数据时必须所具备的知识之一是藏文在通用字符集(Uni-versal Character Set,UCS)中是如何进行编码。在设计藏文网页内容时UCS藏文数据的整理、设计藏文应用软件时藏文文本的处理操作或者在设计藏文OpenType或AAT字库时、UCS藏文编码模式应用等都要首先去理解UCS藏文编码模式。因此,理解和掌握UCS藏文编码模式是软件制作商首选目标。详细介绍了UCS藏文编码模式的组织结构和设计方法,以便于使用OpenType来支持复杂藏文文本的显示。 ",MESS200804017
基于DUCET的藏文排序方法,黄鹤鸣1:08224122|契嘎·德熙嘉措2:10879018,5,计算机应用; 中文信息处理; 藏文字符串; 藏文音节; DUCET; 排序;,"DUCET为每个藏文字符规定了排序码,但藏文音节的拼写复杂性使得藏文排序不能直接应用这些排序码,提出了基于DUCET的藏文音节排序方法,主要思想是:首先,将二维的藏文音节转化成一维的字母串;其次,从DUCET中查出每个字母的排序码,得到藏文音节对应的排序码串;最后,通过比较排序码串实现藏文音节间的排序。还讨论了藏文音节与一般藏文字母串以及藏文字符串与外文字符串间的比较规则。 ",MESS200804018
基于Web Service的数字化民俗博物馆的研究与实现,,5,计算机应用; 中文信息处理; 数字民俗博物馆; Web Service; ASP.NET;,"为增强世界各族人民对新疆少数民族民俗文化的了解,并实现各个大学数字博物馆之间的无间访问,提出了基于Web Service的英、汉、维三语数字化民俗博物馆的建设方案,文中分析设计了数字化民俗博物馆的总体结构,讨论了Web Service关键技术与ASP.Net技术,并结合Web服务与ASP.Net技术,初步实现了数字民俗博物馆的建设,利用这两种技术的优点,提高了客户端的浏览速度,为用户提供了更方便、更透明的信息服务,并为不同用户提供了英、汉、维三种语言的选择。 ",MESS200804019
藏文编码字符集的优化研究,,4,计算机应用; 中文信息处理; 藏文编码; 基本集; 上加字;,"《信息交换用藏文编码字符集基本集》奠定了研究藏文信息处理技术的基础,非常重要,但随着藏文信息处理技术研究的深入,也逐渐发现了《基本集》没能反映藏文构件的基本特征,增加了研究有关藏文工作的难度,同时,在使用中还存在藏文编码歧义等缺陷。针对上述问题提出了增加三个上加字的编码到BMP中,使得藏文编码能正确地反应藏文的构件特征,还提出用""界定藏文编码的使用方法""来消除《基本集》应用中存在的歧义以及正确理解几个字符的属性等问题。 ",MESS200804020
《统计自然语言处理》由清华大学出版社出版,,1, , ,MESS200804021
基于字形拓扑结构的甲骨文输入编码研究,,6,计算机应用; 中文信息处理; 拓扑结构; 甲骨文; 输入; 编码;,"分析了甲骨文字形的拓扑结构特征,考虑了甲骨文字形、读音等因素,制作了甲骨文输入法的字形码表和拼音码表,设计了一种简便、有效的甲骨文输入编码方案,开发了甲骨文输入法程序,利用该程序可以通过两种途径来输入甲骨文字形,即拆分取码方法和现代汉字拼音方法,从而解决了从通用甲骨文字库中调出所需字形的问题。 ",MESS200804022
商务印书馆语言学出版基金简介,,1, , ,MESS200804023
语义资源建设的最新趋势和长远目标——通过映射对比、走向统一联合、实现自动推理,袁毓林:06263991,13,计算机应用; 中文信息处理; 语义资源; 映射关系; 论元结构; 命题结构; 事件关系; 回指关系;,"本文首先介绍WordNet、VerbNet、PropBank和FrameNet这几个主流语义资源的结构,并分析其各自的缺陷;然后,介绍怎样在不同的资源之间建立起映射关系(包括义项映射和框架映射),达到语义资源的统一和整合,形成词汇语义资源的连接和互补;最后,介绍面向自动推理的更加深层的语义关系的表示和标注的趋向:从动词的论元结构走向句子的命题结构,不同动词和句子所表达的事件及其关系,不同词类范畴(动词和事件名词等)所表示的相关事件及其关系,指代词、空语类跟有关表示事件的先行语之间的回指关系。 ",MESS200803002
“综合型语言知识库”获教育部科技进步奖一等奖,,1, , ,MESS200803003
词义标注语料库建设综述,金澎:11712467|吴云芳:06270718|俞士汶:06272028,8,计算机应用; 中文信息处理; 词义消歧; 词义标注语料库; 平行语料库; bootst rapping;,"词义消歧的关键问题是缺少大规模、高质量的词义标注语料库。本文分别从语料选取、词典选择、标注规模和标注质量等方面介绍已经建成的较有影响的若干词义标注语料库。在自动构建词义标注语料库的方法中,本文集中介绍bootstrapping策略在语料库建设方面的应用以及利用双语对齐语料库开展的相关研究。最后,针对词义标注语料库建设存在的问题提出自己的分析和思考。 ",MESS200803004
分层次的汉语功能块描述库构建分析,,9,计算机应用; 中文信息处理; 部分分析; 功能块; 分层次描述;,"现有功能块分析器对于不同长度和不同结构功能块的分析性能研究表明,长的结构复杂的功能块正是功能块自动分析的难点所在。由此,我们设计了新的分层次的功能块体系,并从清华句法树库TCT中自动生成了新的功能块语料库。通过对新的功能块语料库长度分布、内部结构分布分析,以及与单层次功能块语料库的相互关系的研究,我们证实了新的分层次功能块描述体系具有结构简单、长度短且分布均匀的优良特点。这些性质对功能块分析器的性能提高将会有很大的帮助。 ",MESS200803005
一种基于无监督学习的词变体识别方法,王宝勋:10837628|王晓龙:06993266|刘秉权:06988938|李鹏:06995102,6,计算机应用; 中文信息处理; 词变体; 缩略词; 最小编辑距离; 系统相似模型;,"本文提出了一种生物医药领域词变体的识别策略。首先使用最小编辑距离算法和字符匹配算法从语料中分别获得特定目标词的形态学变体和缩略词,并将其作为候选词变体。本文采用系统相似模型获得每个词变体上下文语义的量化评价。本文的方法不需要任何语言学知识和精细加工的语料资源,实验表明,该方法可以在保证准确率的同时显著地提高词变体识别的召回率。 ",MESS200803006
名词隐喻相似度及推理识别研究,王治敏:11255396,7,计算机应用; 中文信息处理; 隐喻识别; 相似度推理; 最大熵;,"本文考察了汉语名词隐喻的相似性特点,尝试利用隐喻相似度推理、词典信息等多种方法实现n+n隐喻表达的发现和提取。隐喻相似度推理,首先运用人机互助方法对中文概念词典(CCD)进行合理剪裁,建立了一个词语对应一个语义类的词典格式,为后续的推理实验提供了保证。同时也验证了名词隐喻知识库的有效性。实验证明,最大熵方法、隐喻相似度、词典知识等多种方法大大提高了识别效果。 ",MESS200803007
语言学组合特征在语义关系抽取中的应用,奚斌:15583207|钱龙华:08844995|周国栋:13898054|朱巧明:09891804|钱培德:08866518,7,计算机应用; 中文信息处理; 语义关系抽取; 支持向量机; 组合特征;,"语义关系抽取是信息抽取中的一个重要的研究领域。目前基于特征向量的语义关系抽取已经很难通过发掘新的特征来提高抽取的性能。本文提出了一种特征组合方法,通过在各种词法、语法、语义的基本特征内部及特征之间进行合理的组合形成组合特征,使用基于支持向量机的学习方法,使得关系抽取的准确率和召回率得到了提高。在ACE2004语料库的7个关系大类和23个关系子类抽取实验中F值分别达到了66.6%和59.50%。实验结果表明通过对基本语言学特征进行组合所得到的组合特征能够显著地提高语义关系抽取的性能。 ",MESS200803008
基于高斯分布的簇间距离计算方法,季铎:13897919|王智超:13897921|蔡东风:08670703|张桂平:09719392,6,计算机应用; 中文信息处理; 层次聚类; 簇间距离计算; 文本聚类;,"凝聚的层次聚类算法是一种性能优越的聚类算法,该算法通过不断合并距离相近的簇最终将数据集合划分为用户指定的若干个类别。在聚类的过程中簇间距离计算的准确性是影响算法性能的重要因素。本文提出一种新的基于高斯分布的簇间距离的计算方法,该方法通过簇自身的大小、密度分布等因素改进算法的计算准确性,在不同文本集合上与现有的簇间距离计算方法进行了对比实验,实验结果表明该方法有效地改进了层次聚类算法的性能。 ",MESS200803009
搜索引擎中的聚类浏览技术,,8,计算机应用; 中文信息处理; 搜索引擎; 文档聚类; 信息检索; 聚类标识;,"搜索引擎大多以文档列表的形式将搜索结果显示给用户,随着Web文档数量的剧增,使得用户查找相关信息变得越来越困难,一种解决方法是对搜索结果进行聚类提高其可浏览性。搜索引擎的聚类浏览技术能使用户在更高的主题层次上查看搜索结果,方便地找到感兴趣的信息。本文介绍了搜索引擎的聚类浏览技术对聚类算法的基本要求及其分类方法,研究分析了主要聚类算法及其改进方法的特点,讨论了对聚类质量的评价,最后指出了聚类浏览技术的发展趋势。 ",MESS200803010
网络文本主题词的提取与组织研究,,8,计算机应用; 中文信息处理; 主题词提取; 未登录词识别; 切分词拼接; 主题词聚类;,"网络信息的指数爆炸给人们获取与掌控信息带来了困扰,为了挖掘海量信息中的关键因子并以恰当的方式进行组织,本文设计了网络文本主题词提取和组织算法。该算法基于多级滤噪的切分词拼接,利用特定的噪音库与滤噪策略严格控制拼接过程,在合理收录策略的挑选下,算法提取出了能够准确反映海量网络数据中关键因子的主题词串。为清晰地组织主题词,建立主题词与网络事件的有机联系,设计了新的词聚类策略对主题词提取结果进行处理,使表达同一热点的主题词合理地组织在一起,共同描述同一事件。在以实际网络文本为语料的实验中,算法表现出令人满意的性能。 ",MESS200803011
文本意见挖掘综述,,10,计算机应用; 中文信息处理; 意见挖掘; 主观性文本; 综述;,"意见挖掘是针对主观性文本自动获取有用的意见信息和知识,它是一个新颖而且十分重要的研究课题。这种技术可以应用于现实生活中的许多方面,如电子商务、商业智能、信息监控、民意调查、电子学习、报刊编辑、企业管理等。本文首先对意见挖掘进行了定义,然后阐述了意见挖掘研究的目的,接着从主题的识别、意见持有者的识别、陈述的选择和情感的分析四个方面对意见挖掘的研究现状进行了综述,并介绍了几个成型的系统。此外,我们针对汉语的意见挖掘做了特别的分析。最后对整个领域的研究进行了总结。 ",MESS200803012
自动文摘评价方法综述,,8,计算机应用; 中文信息处理; 文本挖掘; 自动文摘; 自然语言处理; 多文档文摘; 文摘评价方法;,"评价是自动文摘领域长期关注的焦点,对自动文摘技术的发展起着积极的促进作用。本文首先介绍了自动文摘评价方法的应用背景和面临的困难;然后对自动文摘评价方法进行了简单介绍和评价;接着在了解国内外研究现状的基础上详细分析了文摘评价方法的关键技术;最后对自动文摘评价方法未来的发展趋势进行了展望。 ",MESS200803013
生物医学文本挖掘技术的研究与进展,王浩畅:11451320|赵铁军:06997742,10,计算机应用; 中文信息处理; 生物信息学; 文本挖掘; 信息抽取; 机器学习;,"生物医学研究是二十一世纪最受关注的研究领域之一,该领域发表了巨量的研究论文,已经达到年平均60万篇以上。如何在规模巨大的研究文献中有效地获取相关知识,是该领域研究者所面临的挑战。作为生物信息学分支之一的生物医学文本挖掘技术就是一项高效自动地获取相关知识的新探索,近年来取得了较大进展。这篇综述介绍了生物医学文本挖掘的主要研究方法和成果,即基于机器学习方法的生物医学命名实体识别、缩写词和同义词的识别、命名实体关系抽取,以及相关资源建设、相关评测会议和学术会议等。此外还简要介绍了国内研究现状,最后对该领域近期发展作了展望。 ",MESS200803014
采用支持向量机的说话者确认中的样本平衡,龙艳花:09539044|郭武:22013935|戴礼荣:09539908,6,计算机应用; 中文信息处理; 支持向量机; 冒认者;,"支持向量机在与文本无关的话者确认系统中已经取得了广泛的应用,但是在实际应用系统中获得的目标说话人样本与冒认者样本数量比一般在几千分之一,因此存在很严重的样本非平衡问题,冒认者样本选择的好坏直接影响到整个系统的性能。本文提出了两种挑选冒认者样本的方法。实验证明这些方法能有效地解决上述问题,性能比随机挑选冒认者样本的方法有了提升,经过在2004年NIST说话人识别数据库上进行测试,等错误率由9.3%降低到6.8%,错误率相对下降了26.9%。 ",MESS200803015
维吾尔语动词附加语素的复杂特征研究,阿孜古丽·夏力甫:10239618,5,计算机应用; 中文信息处理; 动词; 附加语素; 复杂特征;,"本文以复杂特征理论为指导思想,对维吾尔语动词附加语素的多样性进行了初步的研究。维吾尔语附加语素可分为构词语素、构形语素和构词—构形语素等三种类型。这些附加语素在分类、语法形式、体、时、人称、数、附加条件等方面形成了不同的复杂特征。动词附加语素与词根或词干连接时有不同的附加规则。本文主要论述动词附加语素及其变体的多种分类、附加条件、动词附加语素的复杂特征的分类及表现形式,以动词直接陈述式一般过去时的附加语素为例进行特征结构之间的合一。 ",MESS200803016
基于最小编辑距离的维语词语检错与纠错研究,玛依热·依布拉音:15593887|米吉提·阿不里米提:09255276|艾斯卡尔·艾木都拉:09219516,5,计算机应用; 中文信息处理; 维语尔语; 词法分析; 纠错; 最小编辑距离;,"拼写错误的发现和候选词选取是文本分析中的一个重要的技术问题。本文结合维吾尔语的语音和词语结构特点,列出了文本中常见的拼写错误类型,详细分析了解决方法,利用最小编辑距离(minimume ditdistance)算法实现了维吾尔语文本拼写错误分析中的查错和纠错功能,并以此为基础,结合维吾尔语构词规则,进一步提高了建议候选词的准确率和速度。该算法已被成功地应用到了维吾尔语文字自动校对和多文种文本检索等领域中。在以新疆高校学报为语料的测试中,词语查纠率达到85%以上。 ",MESS200803017
一种面向构形计算的汉字字形形式化描述方法,,9,计算机应用; 中文信息处理; 汉字字形; 形式化描述; 网格字形; 特征计算;,"目前汉字字形描述方法存在的主要问题是缺少能涵盖一切可能汉字的可计算的字形形式化描述体系,从而造成汉字处理应用中的一系列障碍。本文给出了一种汉字网格字形描述方法,实验表明,该方法具有描述一切可能汉字字形(包括错字)骨架的能力,支持不同颗粒度的构字元素、结构关系等字形特征的自动提取和计算,为字形特征的自动分析处理提供了一种有效的手段,从而也为基于字形计算的各种应用建立了可靠的基础。 ",MESS200803018
藏文字库标准符合性自动检测方案设计与实现,刘瀚猛1:15593551|芮建武1:14056745|白真龙2:15591900|吴健1:09573880,5,计算机应用; 中文信息处理; 藏文; 字库; 标准符合性; 测试;,"软件产品的标准符合性测试是衡量产品质量与性能的重要方法。本文根据藏文字符集标准与字型标准,按软件产品的可用性原则,分析与定义了藏文字库标准符合性检测的含义与内容。本文提出了实施藏文字库标准符合性测试的方案与算法,实现了藏文字库测试程序。测试结果表明本文的检测方案可行、完整,也为其他文字的字库标准符合性检测提供了很好的途径。 ",MESS200803019
网络时代的人工智能,,7,人工智能; 不确定性人工智能; 认知物理学; 数据场; 云模型; 网络化智能;,"五十多年来,人工智能在模式识别、知识工程、机器人等领域已经取得重大成就,但是离真正的人类智能还相差甚远。本文强调在当今的网络时代,作为信息技术的先导,人工智能科学有着非常值得关注的研究方向,要在学科交叉研究中实现人工智能的发展与创新。要关注认知科学、脑科学、生物智能、物理学、复杂网络、计算机科学与人工智能之间的交叉渗透,尤其是重视认知物理学的研究;自然语言是人类思维活动的载体,是人工智能研究知识表示无法回避的直接对象,要对语言中的概念建立起能够定量表示的不确定性转换模型,发展不确定性人工智能;要利用现实生活中复杂网络的小世界模型和无尺度特性,把网络拓扑作为知识表示的一种新方法,研究网络拓扑的演化与网络动力学行为,研究网络化了的智能,从而适应信息时代数据挖掘的普遍要求,迎接人工智能科学与应用新的辉煌。 ",MESS200802002
中文词法分析与句法分析融合策略研究,,8,计算机应用; 中文信息处理; 中文句法分析; 中文词法分析; 融合策略; 基于转换的错误驱动学习; 条件随机场;,"利用外部资源是提升句法分析性能的一种有效方法。本文利用中文词法分析器这一外部资源,提出了一种通用转换方法将中文词法分析器与句法分析器有机地融合在一起。通过基于转换的错误驱动学习和条件随机场解决不同切词、词性标注标准间的转换问题。在句法分析方面,本文提出了多子模型句法分析器,将中心词驱动模型和结构上下文模型有效结合在一起。融合后的中文句法分析性能在宾州中文树库1.0版①测试集上F1值达到了82.5%的最好水平。 ",MESS200802003
基于加权投票K—近邻法的生物医学缩略语消歧,于中华:10743036|陈蓉:08759534|胡俊锋:10731390|陈源:08726745,6,计算机应用; 中文信息处理; 生物医学信息抽取; 缩略语消歧; 加权投票K—近邻法;,"生物医学文献信息抽取对充分挖掘利用生物医学领域取得的重要成果,促进生物医学的进一步发展具有重要意义。本文针对生物医学缩略语的分析理解问题,提出了基于加权投票K—近邻法的生物医学缩略语消歧算法。该算法基于""One Sense Per Discourse""假设自动生成带类标实例数据,消歧特征选用能表达文本主题的全局特征词,分类算法采用加权投票K—近邻法。在包含177762篇Medline摘要的真实语料上进行的实验表明,本文所提出的算法明显优于相关工作中的算法。此外,实验还表明,对于缩略语消歧,加权投票K—近邻法与经典K—近邻法相比,不但具有高的预测准确率,而且性能更加稳定。 ",MESS200802004
基于最大熵模型的共指消解研究,庞宁1:10891367|杨尔弘2:06429879,5,计算机应用; 中文信息处理; 最大熵模型; 共指消解;,"共指是突发事件新闻报道中的常见现象。良好的处理共指现象,是进行信息提取的基本必要过程。本文采用最大熵模型对汉语突发事件新闻报道中的共指现象进行消解,目的是提取出突发事件新闻报道中指向同一实体的名词、代词和名词短语。根据问题特点,算法选择了8类特征作为模型的特征,该模型在20万字的新闻语料上进行训练,在10万字规模的语料上进行测试,最终的测试得到系统的F值为64.5%。 ",MESS200802005
基于句法的统计机器翻译综述,,12,人工智能; 机器翻译; 统计机器翻译; 基于句法的统计机器翻译; 树到串; 树到树; 依存语法;,"本文对基于句法的统计机器翻译进行了综述。按照模型所基于的语法不同,将基于句法的统计机器翻译分为两大类:基于形式化语法和基于语言学语法。对这两个不同类别,我们分别介绍它们代表性的工作,包括模型的构建、训练和解码器的设计等,并对比了各个模型的优点和缺点。最后我们对基于句法的统计机器翻译进行了总结,指出设计句法模型时要注意的问题,并对未来的发展趋势进行了预测。 ",MESS200802006
基于信息检索方法的统计翻译系统训练数据选择与优化,,7,人工智能; 机器翻译; 统计机器翻译; 平行语料库; 信息检索; 数据选择;,"双语平行语料库是构造高质量统计机器翻译系统的重要基础。与传统的通过扩大双语平行语料库规模来提高翻译质量的策略不同,本文旨在尽可能地挖掘现有资源的潜力来提高统计机器翻译的性能。文中提出了一种基于信息检索模型的统计机器翻译训练数据选择与优化方法,通过选择现有训练数据资源中与待翻译文本相似的句子组成训练子集,可在不增加计算资源的情况下获得与使用全部数据相当甚至更优的机器翻译结果。通过将选择出的数据子集加入原始训练数据中优化训练数据的分布可进一步提高机器翻译的质量。实验证明,该方法对于有效利用现有数据资源提高统计机器翻译性能有很好的效果。 ",MESS200802007
基于派生文法的日—蒙动词短语机器翻译研究,,8,人工智能; 机器翻译; 派生文法; 日语附加成分的分析; 语音规则; 短语生成;,"本文探索了源语为日语,目标语为蒙古语的动词短语机器翻译系统的实现方式。基于主张日语不活用的派生文法,重新分析日语附加成分。将日语的词干和附加成分转换到蒙古语的词干和附加成分之后,运用蒙古语的语音规则来处理并生成动词短语。在此基础上试做了日—蒙动词短语机器翻译系统。对30篇日文报道的403个动词短语进行测试,取得了95.78%的正确率。 ",MESS200802008
中文观点挖掘中的主观性关系抽取,章剑锋:13896210|张奇:06708764|吴立德:06698167|黄萱菁:06705247,6,计算机应用; 中文信息处理; 观点挖掘; 关系抽取; 最大熵;,"本文所针对的具体任务是抽取评价词和目标对象之间的关联关系。所采用的方法是将同一句子中共现的评价词与评价对象作为候选集合,应用最大熵模型并结合词、词性、语义和位置等特征进行关系抽取。我们将关系抽取引入观点挖掘,所提出的方法一定程度上解决了指代消解以及评价对象遗漏的问题。实验结果表明该方法的F值比取最近评价对象的Baseline方法有了15%的提高,并且发现程度副词能够帮助提高主观性关系抽取的性能。 ",MESS200802009
一种快速说话人搜索算法,,4,计算机应用; 中文信息处理; 说话人识别; 说话人搜索; 两遍搜索;,"随着音频数据的不断增加,说话人识别已经变得越来越困难。本文提出了一种新颖的方法,在已有的说话人识别系统(GMM-UBM系统)的基础上,综合利用Index和Simulation,以很小的代价,极大地提高了说话人识别的速度,从而使说话人搜索成为可能。具体而言,就是采用两遍搜索策略,首先通过建立索引,在索引空间,比较索引间的欧氏距离,粗略地筛选出一定量的候选说话人目标;然后在此基础上,通过更精细的Simulation模型匹配,找出最佳的识别结果。实验结果显示我们的方法能以很小的代价,显著地提高说话人识别的速度。 ",MESS200802010
基于多示例学习的图像检索方法, ,6,计算机应用; 中文信息处理; 多示例学习; 自适应分割; 基于内容的图像检索;,"由于多示例学习能够有效处理图像的歧义性,因此被应用于基于内容的图像检索(CBIR)。本文提出一种基于多示例学习的CBIR方法,该方法将图像作为多示例包,基于高斯混合模型和改进的EM算法全自动分割图像,并提取颜色、纹理、形状和不变矩等区域信息作为示例向量生成测试图像包。根据用户选择的实例图像生成正包和反包,使用多种多示例学习算法进行学习,实现图像检索和相关反馈,得到了较好的效果。 ",MESS200802011
半监督学习和主动学习相结合的浅层语义分析,陈耀东:20404373|王挺:20633286|陈火旺:05964648,6,计算机应用; 中文信息处理; 浅层语义分析; 半监督学习; 直推式支持向量机; 主动学习;,"语义分析是基于内容的文本挖掘领域的重要技术和研究难点。有监督机器学习方法受限于标注语料的规模,在小规模标注样本中难以获取较高性能。本文面向浅层语义分析任务,采用一种新颖的半监督学习方法——直推式支持向量机,并结合其训练特点提出了基于主动学习的样本优化策略。实验表明,本文提出的浅层语义分析方法通过整合主动学习与半监督学习,在小规模标注样本环境中取得了良好的学习效果。 ",MESS200802012
基于用户兴趣分析的网页生命周期建模,王勇1:08177513|刘奕群1:08833231|张敏1:08186086|马少平1:21742528|茹立云2:08176974,5,计算机应用; 中文信息处理; 用户行为分析; 网页生命周期; 网络日志挖掘;,"网页在其生命周期内的活跃程度会随时间发生变化。有的网页只在特定的阶段有价值,此后就会过时。从用户的角度对网页的生命周期进行分析可以提高网络爬虫和搜索引擎的性能,改善网络广告的效果。利用一台代理服务器收集的网页访问量信息,我们对网页的生命周期进行了研究,给出了用户兴趣演变的模型。这个模型有助于更好地理解网络的组织与运行机理。 ",MESS200802013
企业内部邮件中话题讨论检索研究,富羽鹏:10967361|张敏:08186086|马少平:08177513,6,计算机应用; 中文信息处理; 企业信息检索; 邮件检索; 话题讨论检索;,"随着信息技术的发展,企业检索已成为人们越来越关注的一个新的应用领域。作为企业检索的一个典型任务,企业内部的邮件检索是在企业中常常遇到的一个问题。企业内部存在着大量的可以公开访问的电子邮件,这些是企业重要的信息资源,如何高速有效地从这些邮件中检索到需要的信息具有很大意义。本文根据电子邮件本身具有的格式化特征和语义拓扑结构提出了基于电子邮件特征的检索模型。实验表明,该模型对电子邮件可以进行有效的检索,并且使用该模型在TREC2006电子邮件话题检索评测中取得了优异的性能成绩。 ",MESS200802014
基于自动句对齐的相似古文句子检索,郭锐:14357194|宋继华:06364557|廖敏:14358390,6,计算机应用; 中文信息处理; 古今汉语平行语料库; 句子对齐; 相似句子; 基于实例的机器翻译;,"随着语料库语言学的兴起,基于实例的机器翻译(EBMT)得到越来越多的研究。如何快速准确地构建大规模古今汉语平行语料库,以及从大量的对齐实例(句子级)中检索和输入句子最相似的源句子是基于实例的古今汉语机器翻译必须解决的问题。本文综合考虑句子长度、汉字字形、标点符号三个因素提出了古今汉语句子互译模型,基于遗传算法、动态规划算法实现了古今汉语的自动句对齐。接着为古文句子建立全文索引,基于汉字的信息熵,本文设计与实现一种高效的最相似古文句子检索算法。最后给出了自动句对齐和最相似古文句子检索的实验结果。 ",MESS200802015
基于字单元分析的中文辅助阅读系统,方高林:11428550|于浩:11579584|孟遥:11567301|邹纲:11577051,7,计算机应用; 中文信息处理; 词法分析; 新词发现; 术语翻译; Web挖掘; 辅助汉语学习;,"辅助汉语学习研究作为一个重要的研究领域,已经在自然语言处理领域激发起越来越多人的兴趣。文中提出一个基于字分析单元的辅助阅读系统,它可以为汉语学习者提供即时的辅助翻译和学习功能。系统首先提出基于字信息的汉语词法分析方法,对汉语网页中文本进行分词处理,然后利用基于组成字结构信息的方法发现新词。对于通用词典未收录的新词(例如:专业术语、专有名词和固定短语),系统提出了基于语义预测和反馈学习的方法在Web上挖掘出地道的译文。对于常用词,系统通过汉英(或汉日)词典提供即时的译文显示,用户也可通过词用法检索模块在网络上检索到该词的具体用法实例。该系统关键技术包括:基于字信息的汉语词法分析,基于组成字结构信息的新词发现,基于语义预测和反馈学习的新词译文获取,这些模块均以字分析单元的方法为主线,并始终贯穿着整个系统。实验表明该系统在各方面都具有良好的性能。 ",MESS200802016
一种基于区分性准则的模型结构优化方法,鄢志杰:09540699|胡郁:14361022|王仁华:09578638,7,计算机应用; 中文信息处理; 自动语音识别; 声学模型; 模型结构优化;,"本文提出了一种基于区分性准则的模型结构优化方法,用以调整HMM自动语音识别系统中声学模型各状态混合高斯核成分数量的分配。通过优化选定的准则,声学模型可以在使用相同参数数量的情况下得到更好的识别性能,也可以在保持相当性能的前提下降低所需要的模型参数。相对于传统的基于似然度及复杂度惩罚的模型结构优化准则来讲,基于区分性准则的优化方法能够更直接地提高模型的区分度和鉴别力,从而得到更好的识别效果。在一个面向嵌入式系统的中文连续数字串识别任务上的实验结果证明,基于最大互信息量准则的模型结构优化能够得到比传统的、基于模型似然度及复杂度的方法更好的识别效果。 ",MESS200802017
中文语音确认中子词置信度性能的研究,,5,计算机应用; 中文信息处理; 语音确认; 置信度; 似然比检验; 最小分类错误;,"本文提出了一种基于最小分类错误准则(MCE)的子词权重参数估计算法,通过MCE训练得到子词的权重系数。子词对词级置信度贡献量的研究表明:韵母的确认能力显著好于声母,在置信性能方面比声母更加稳定和可靠,区分能力优于声母。在130个关键词的关键词检测系统实验表明,采用不同子词贡献权重比等贡献权重时等错误率下降3.05%。 ",MESS200802018
语音合成系统中高质量的韵律生成, ,6,计算机应用; 中文信息处理; 韵律参数生成; 音长预测; 基频预测; 决策树;,"本文对富士通中文语音合成系统尤其是其中的韵律生成部分进行了描述。该系统是一个以音节为基本合成单元,在韵律参数生成结果即音长和基频预测结果的指导下,从音库中搜寻全局最优的合成单元,然后采用PSOLA算法进行波形调整的拼接合成系统。从提高合成语音韵律的角度出发,本文围绕音长预测和基频预测部分对该系统进行了详细的描述。最后,给出了韵律评测和系统评测的结果。 ",MESS200802019
基于依存句法分析的汉语韵律层级自动预测技术研究,邵艳秋1:14359483|穗志方1:06270718|韩纪庆2:06268960|吴云芳1:06985293,8,计算机应用; 中文信息处理; 语音合成; 韵律层级; 句法结构; 依存分析; 停顿指数;,"不同的韵律层级可以将文本划分成适合朗读与理解的韵律组块,从而保证合成语音能够以自然的节奏表现出来。目前对韵律层级预测所采用的特征绝大多数是较为浅层的特征,如词性、词长等,但这些浅层特征对有的韵律层次如韵律短语的预测能力比较弱。实际上,句法结构同韵律层级之间有着非常紧密的联系,二者相互影响,相互制约。本文根据依存句法分析的结果,抽取出若干同韵律层级相关的深层句法特征对韵律层级进行预测。实验证明,其中内弧跨度和内弧类型等特征,对浅层特征较难解决的类似韵律短语这种中间层次的韵律单元划分问题,可以起到很大的提高作用,使韵律短语标注的综合F值提高了11%。 ",MESS200802020
基于词图的音素识别及在语种识别中的应用,王士进:14360276|郑榕:10983611|徐波:11602010,5,计算机应用; 中文信息处理; 语种识别; 基于词图的并行音素识别方法;,"本文介绍了一种基于词图的并行音素识别方法的自动语种识别系统,基于词图的并行音素识别方法是并行音素识别方法的一个扩展,它用识别产生的词图来描述声学候选结果空间,比并行音素识别方法中用最佳路径音子序列包含更丰富的信息。通过真实环境广播语音测试表明,该方法比并行音素识别方法识别性能提升了约6%,在每个语种约4小时的训练数据下,跟其他的几种语种识别方法也有可比的性能。 ",MESS200802021
中文事件抽取技术研究,赵妍妍:11639065|秦兵:06990821|车万翔:06987220|刘挺:06994824,6,计算机应用; 中文信息处理; 事件抽取; 事件类别识别; 事件元素识别;,"事件抽取是信息抽取领域一个重要的研究方向,本文对事件抽取的两项关键技术——事件类别识别以及事件元素识别进行了深入研究。在事件类别识别阶段,本文采用了一种基于触发词扩展和二元分类相结合的方法;在事件元素识别阶段,本文采用了基于最大熵的多元分类的方法。这些方法很好的解决了事件抽取中训练实例正反例不平衡以及数据稀疏问题,取得了较好的系统性能。 ",MESS200801002
基于多向量和实体模糊匹配的话题关联识别,张晓艳:21156545|王挺:20633286|陈火旺:05964648,6,计算机应用; 中文信息处理; 话题关联识别; 多向量表示模型; 命名实体模糊匹配;,"本文在对新闻报道理论分析及实验验证的基础上,提出一种多向量表示模型,使其在尽量不丢失信息的情况下,对特征集合尽可能细地划分。基于该模型,本文设计了一种模糊匹配的方法用于计算命名实体子向量之间的关联度,它们和多个向量相似度一起用支持向量机进行整合,形成报道模型间的相似度。本文选用TDT4中文语料作为测试语料,将上述模型及模糊匹配技术用于话题关联识别。实验表明,多向量模型能够改进话题关联识别的性能,模糊匹配技术也在一定程度上弥补了精确匹配带来的性能损失。 ",MESS200801003
基于布局特征与语言特征的网页主要内容块发现,韩先培:13898612|刘康:13898613|赵军:10891784,7,计算机应用; 中文信息处理; 网页清理; 主要内容块发现; 网页切分; 布局特征; 语言特征;,"本文综合分析了网页内容块各方面的特征,提出了一个联合使用布局特征和语言特征的网页主要内容块发现方法,有效地解决了以往模型中通用性与高准确率不能共存的缺点。该方法使用网页视觉块树表示网页,对网页内容块的布局特征和语言特征分别建立了独立的分类器,然后组合这两个分类器来进行网页内容块分类。实验结果表明,在保持非噪音块召回率在90%以上的同时,组合分类器的准确率达到85%,比只使用布局特征的分类器提高5个百分点,比只使用语言特征的分类器提高15个百分点;在5个站点上的分类结果表明组合分类器在不同站点上性能稳定,具有良好的通用性。 ",MESS200801004
一种全自动生成网页信息抽取Wrapper的方法,,8,计算机应用; 中文信息处理; 网页信息抽取; 网页结构分离; 包装器;,"Web网页信息抽取是近年来广泛关注的话题。如何最快最准地从大量Web网页中获取主要数据成为该领域的一个研究重点。文章中提出了一种全自动化生成网页信息抽取Wrapper的方法。该方法充分利用网页设计模版的结构化、层次化特点,运用网页链接分类算法和网页结构分离算法,抽取出网页中各个信息单元,并输出相应Wrapper。利用Wrapper能够对同类网页自动地进行信息抽取。实验结果表明,该方法同时实现了对网页中严格的结构化信息和松散的结构化信息的自动化抽取,抽取结果达到非常高的准确率。 ",MESS200801005
中文网页信息检索测试集的构建、分析及应用,李静静:13895880|闫宏飞:06276313,7,计算机应用; 中文信息处理; CWT; 信息检索; 评测; 测试集; 文档集;,"随着WWW的迅速发展,Web信息检索技术成为研究者广泛关注的话题,但缺少合适的测试评测机制制约了中文网页信息检索技术的发展。参考国外测试集的构建经验,我们构建了大规模中文网页信息检索测试集CWT,并组织了SEWM中文网页检索评测,希望在国内外各个研究小组的共同参与下建立并完善CWT,一起推动中文网页信息检索技术的发展。本文在调研和分析国内外现有研究进展的基础上,详细介绍了CWT的构建原则和方法,并对CWT进行了有效的统计分析和实验研究。本文提出的构建测试集的方法为以后的研究提供了参考。 ",MESS200801006
基于推拉策略的文本分类增量学习研究,,7,计算机应用; 中文信息处理; 增量学习; 推拉策略; 文本分类; 中心法;,"学习算法是否具有增量学习能力是衡量其是否适合于解决现实问题的一个重要方面。增量学习使学习算法的时间和空间资源消耗保持在可以管理和控制的水平,已被广泛应用于解决大规模数据集问题。针对文本分类问题,本文提出了增量学习算法的一般性问题。基于推拉策略的基本思想,本文提出了文本分类的增量学习算法ICCDP,并使用该算法对提出的一般性问题进行了分析。实验表明,该算法训练速度快,分类精度高,具有较高的实用价值。 ",MESS200801007
知识增益:文本分类中一种新的特征选择方法,徐燕:11391371|王斌:09559997|李锦涛:05976441|孙春明:11650699,7,计算机应用; 中文信息处理; 文本分类; 特征选择; 粗糙集; 信息检索;,"特征选择在文本分类中起重要的作用。文档频率(DF)、信息增益(IG)和互信息(MI)等特征选择方法在文本分类中广泛应用。已有的实验结果表明,IG是最有效的特征选择算法之一,该方法基于申农提出的信息论。本文基于粗糙集理论,提出了一种新的特征选择方法(KG算法),该方法依据粗糙集理论关于知识的观点,即知识是分类事物的能力,将知识进行量化,提出知识增益的概念,得到基于知识增益的特征选择方法。在两个通用的语料集OHSUMED和NewsGroup上进行分类实验发现:KG算法均超过IG的性能,特别是在特征空间的维数降到低维时尤其明显,可见KG算法有较好的性能; ",MESS200801008
改进的OPTICS算法及其在文本聚类中的应用,,6,计算机应用; 中文信息处理; OPTICS算法; 密度聚类; 文本挖掘;,"基于密度的OPTICS聚类算法以可视化的结果输出方式直观呈现语料结构,但由于其结果组织策略在处理稀疏点时的局限性,算法实际性能未能得到充分发挥。本文针对此缺陷提出一种有效的结果重组织策略以辅助稀疏点的重新定位,并针对文本领域的特点改变距离度量方法,形成了OPTICS-Plus文本聚类算法。在真实文本分类语料上的实验表明,我们的结果重组织策略能够辅助算法产生更为清晰反映语料结构的可达图,与K-means算法的比较则证实了OPTICS-Plus具有较为良好的聚类性能。 ",MESS200801009
基于查询空间的分布式文档集合划分算法,张刚:09560075|刘悦:09639001|程学旗:09559496,5,计算机应用; 中文信息处理; 分布式信息检索; 文档集合划分; 聚类;,"合理的文档集合划分能够有效的提高分布式信息检索的效果,本文针对分布式信息检索中的集合划分问题,提出了一种基于查询空间的文档集合划分算法。与传统的基于文档空间的划分算法相比,该算法从一种全新的角度看待和理解文档集合划分问题,给出了一种针对大规模海量信息的文档集合划分解决方案。实验表明该算法在算法效果和算法效率方面都有很大的提高。 ",MESS200801010
基于聚类语言模型的生物文献检索技术研究,文健1:20646564|李舟军2:05979723,7,计算机应用; 中文信息处理; 主题语言模型; 信息检索; 聚类;,"近年来研究表明使用主题语言模型增强了信息检索的性能,但是仍然不能解决信息检索存在的一些难点问题,如数据稀疏问题,同义词问题,多义词问题,对文档中不可见项和可见项的平滑问题。这些问题在一些领域相关文献检索中显得尤其重要,比如大规模的生物文献检索。本文提出了一种新的基于聚类的主题语言模型方法进行生物文献检索,这主要包括两个方面工作,一是采用本体库中的概念表示文档,并在此基础上进行模糊聚类,把聚类的结果作为数据集中的主题,文档属于某个主题的概率由文档与聚类的模糊相似度决定。二是采用EM算法来估计主题产生项的概率。把上述方法集成到语言模型中就得到本文的语言模型。本文的语言模型能够准确描述项在不同主题中的分布概率,以及文档属于某个主题的概率,并且利用本体中概念部分地解决了同义词问题,而且项可以由不同的主题产生,这也能够部分解决词的多义问题。本文的方法在TREC 2004/05 Genomics Track数据集上进行了测试,与简单语言模型以及现有主题语言模型相比,检索性能得到一定的提高。 ",MESS200801011
基于多过滤器集成学习的在线垃圾邮件过滤,刘伍颖:20783249|王挺:20633286,7,计算机应用; 中文信息处理; 垃圾邮件过滤; 机器学习; 集成学习; 支持向量机;,"垃圾邮件过滤就是在线对邮件做出Spam(垃圾)或Ham(非垃圾)的判断,这是一种根据客户反馈不断自学习的过程。本文抽取邮件的语言特征和行为特征构建多个简单过滤器,然后采用集成学习方法组合这些简单过滤器,获得了比简单过滤器更高的性能。实验表明单一特征学习的计算复杂性低、速度较快,而集成学习的效果更好。本文提出的将SVM集成学习用于邮件过滤的方法,在各种集成学习方法中效果最好。 ",MESS200801012
基于偏最小二乘特征抽取的垃圾邮件过滤,王鹏鸣:14183848|吴水秀:07878314|王明文:08472511|黄国斌:14183845,6,计算机应用; 中文信息处理; 垃圾邮件过滤; 偏最小二乘; 特征抽取;,"随着垃圾邮件逐渐成为网络用户的一大困扰,垃圾邮件过滤技术的研究显得越来越重要。针对电子邮件存在数据极度稀疏性、高特征维数和多重相关性等特点,本文提出了一种基于偏最小二乘原理的特征抽取方法,可以通过对原始特征进行线性组合抽取出既可反映邮件内容又可反映邮件类型的潜在语义特征,并可解决多重相关性问题。在Enron-Spam邮件数据集上的实验结果表明,同χ2特征选择方法相比,该方法在较低维数上可以获取良好的邮件过滤性能。 ",MESS200801013
基于浅层语义树核的阅读理解答案句抽取,张志昌:13896482|张宇:06997645|刘挺:06994824|李生:06989058,7,计算机应用; 中文信息处理; 阅读理解; 答案句抽取; 浅层语义; 树核;,"阅读理解系统是通过对一篇自然语言文本的分析理解,对用户根据该文本所提的问题,自动抽取或者生成答案。本文提出一种利用浅层语义信息的英文阅读理解抽取方法,首先将问题和所有候选句的语义角色标注结果表示成树状结构,用树核(tree kernel)的方法计算问题和每个候选句之间的语义结构相似度,将该相似度值和词袋方法获得的词匹配数融合在一起,选择具有最高分值的候选句作为最终的答案句。在Remedia测试语料上,本文方法取得43.3%的HumSent准确率。 ",MESS200801014
面向中文新闻领域的移动摘要系统,宋锐:11438265|林鸿飞:06504899|杨志豪:06523490,6,计算机应用; 中文信息处理; 移动摘要; 最大重复串; 编辑距离; 层次型摘要;,"面向移动终端的自动摘要技术,对摘要本身提出了更严格的字数要求。本文设计了一个面向中文新闻领域的移动摘要系统,提取网页中的最大重复串作为文档的关键词集合,利用编辑距离生成适于在移动终端上显示的摘要。对于含有子标题的文档,采用层次型的摘要结构,以提高摘要的覆盖率,并用基于Q&A的评测方法验证了层次型摘要结构对该类文档的有效性。实验结果表明,生成的移动摘要在字数、可读性和完整性具有很好的效果。 ",MESS200801015
《中文信息学报》征稿简则,,1, , ,MESS200801016
一种新的层次化结构问题分类器,李方涛:11540948|张显:13897570|孙建树:13897563|朱小燕:08187758,6,计算机应用; 中文信息处理; 问题分类; 自动问答系统; 问题词; 中心词;,"问题分类是自动问答系统中关键技术之一,而问题中的关键词语是问题分类的重要依据。本文主要探讨问题词和中心词在问题分类中所起的作用,提出一种基于问题词和中心词的层次化结构问题分类器。分类器首先利用问题词将句子集分为三类,然后对于每个类别分别建立相应的分类器,对于what型问题,本文构造了基于关联规则的中心词分类器。本文实现的层次化结构分类器在TREC 2007 QA问题集和UIUC数据集上精度分别达到了90.6%和84.0%,充分显示了问题词和中心词在问题分类中至关重要的作用。 ",MESS200801017
基于本体的数字图书馆个性化用户模型表示, ,5,计算机应用; 中文信息处理; 本体; 用户模型; 个性化服务; 数字图书馆;,"本文针对当前个性化服务中基于关键词的用户兴趣表示方法在语义上的不足,结合本体语义信息丰富的特点,提出了一种基于本体的用户模型表示方法。在数字图书馆领域内,介绍了本体形式化描述并构建了数字图书馆领域本体,给出了用户模型的表示方法。并以个性化信息检索为例,说明了利用用户兴趣本体表示中的同义,上下位等关系给用户提供服务的方法。实验表明基于本体的表示方法能够给用户提供更加个性化的信息。 ",MESS200801018
基于单字提示特征的中文命名实体识别快速算法,,7,计算机应用; 中文信息处理; 中文命名实体识别; 条件随机场; 自然语言处理; 机器学习;,"近年来条件随机场(CRF)模型在自然语言处理中的应用越来越广泛。标准的线性链(Linear-chain)模型一般采用L-BFGS参数估计方法,收敛速度慢。本文在分析模型复杂度的基础上提出了一种改进的快速CRF算法。该算法通过引入小规模单字特征降低特征的规模,并通过在推理过程中引入任务相关的人工知识压缩Viterbi和Baum-Welch格搜索空间,提高了训练的速度。在中文863命名实体识别评测语料和SIGHAN06语料集上进行的实验表明,该算法在不影响中文命名实体识别精度的同时,有效地降低了模型的训练代价。 ",MESS200801019
基于伪相关反馈模型的领域词典生成算法,,5,计算机应用; 中文信息处理; 有意串; 领域词典; 大规模语料; 伪相关反馈;,"本文提出了一种基于伪相关反馈模型的领域词典自动生成算法。将领域词典生成过程视为领域术语的检索过程:假设初始检索出来的前若干个字符串与领域相关,将这些字符串加到领域词典中,重新检索,如此迭代,直到生成的领域词典达到预先设定的规模。实验表明,本算法经过若干次迭代后生成的领域词典准确率高于已有领域词典生成算法。 ",MESS200801020
情感语料库的构建和分析,徐琳宏:11554092|林鸿飞:06504899|赵晶:06508715,7,计算机应用; 中文信息处理; 情感语料库; 文本编码规范; 一致性检查; 情感迁移;,"本文介绍了情感语料库构建方面的一些经验,讨论了在设计和建设情感语料库中的几个基本问题:制定标注规范、选择标注集、设计标注工具以及标注过程中的质量监控。目前已经标注完成近4万句,100万字的语料。在完成这些已标注语料的基础上,进一步给出了语料库的情感分布,情感迁移规律等统计数据,分析了情感语料库的特点及应用。它的建成将为文本情感计算提供更加强大的资源支持。 ",MESS200801021
基于层叠CRFs模型的句子褒贬度分析研究,刘康:13898613|赵军:10891784,6,计算机应用; 中文信息处理; 句子褒贬度分析; 褒贬分类; 褒贬强度分析; 冗余标记; 层叠式条件随机场;,"本文研究句子的褒贬度分析问题。针对传统的基于分类的句子褒贬度分析方法不能考虑上下文信息的问题,以及基于单层模型的句子褒贬度分类方法中的由于标记冗余引起的分类精度不高问题,本文提出了基于层叠式CRFs模型的句子褒贬度分析方法。该方法利用多个CRFs模型从粗到细分步地判断句子的褒贬类别及其褒贬强度,其中层叠式框架可以考虑句子褒贬类别与褒贬强度类别之间的层级冗余关系,而CRFs模型可以利用上下文信息对于句子褒贬类别和强度的影响。该方法在有效识别句子褒贬度的同时,提高了句子褒贬强度判别的准确度。实验证明相对于传统分类方法和单层CRFs模型,本文的方法取得了良好的效果。 ",MESS200801022
话题检测与跟踪的评测及研究综述,洪宇:06987907|张宇:06997645|刘挺:06994824|李生:06989058,17,计算机应用; 中文信息处理; 综述; 话题检测与跟踪; 自然语言处理; 事件; 新闻报道;,"话题检测与跟踪是一项面向新闻媒体信息流进行未知话题识别和已知话题跟踪的信息处理技术。自从1996年前瞻性的探索以来,该领域进行的多次大规模评测为信息识别、采集和组织等相关技术提供了新的测试平台。由于话题检测与跟踪相对于信息检索、信息挖掘和信息抽取等自然语言处理技术具备很多共性,并面向具备突发性和延续性规律的新闻语料,因此逐渐成为当前信息处理领域的研究热点。本文简要介绍了话题检测与跟踪的研究背景、任务定义、评测方法以及相关技术,并通过分析目前TDT领域的研究现状展望未来的发展趋势。 ",MESS200706014
建设综合型语言知识库的理念与成果的价值,俞士汶:06272028,10,计算机应用; 中文信息处理; 综合型语言知识库; 多语言信息处理; 计算语言学; 自然语言处理; 现代汉语语法信息词典; 治学心得;,"积20余年之努力与锤炼,北京大学计算语言学研究所完成的一项科研成果""综合型语言知识库""于2007年2月通过了教育部组织的技术鉴定。鉴定结论认为""其规模、深度、质量和应用效果在我国语言工程实践中是前所未有的。该成果是以汉语为核心的多语言知识库建设中最全面、最重要的研究成果,总体上达到了国际领先水平""。本文在介绍以《现代汉语语法信息词典》为基础的综合型语言知识库的规模、构成、内容、品质和发展历程之后,陈述建设综合型语言知识库的理念,期望与读者分享在计算语言学和自然语言处理这一交叉学科领域内治学的心得与研发的经验。同时也对这项成果的应用实例进行分析,评估它的应用潜力,期望它在以汉语为核心的多语言信息处理事业的发展中起到铺路填坑或者投石问路的作用。 ",MESS200706002
信息,,3, , ,MESS200706003
基于语境信息的汉语组合型歧义消歧方法,冯素琴:09248017|陈惠明:10238426,5,计算机应用; 中文信息处理; 自然语言处理; 汉语自动分词; 组合型切分歧义; 对数似然比; 语境信息;,"组合型歧义切分字段一直是汉语自动分词的难点,难点在于消歧依赖其上下文语境信息。本文采集、统计了组合型歧义字段的前后语境信息,应用对数似然比建立了语境计算模型,并考虑了语境信息的窗口大小、位置和频次对消歧的影响而设计了权值计算公式。在此基础上,1.使用语境信息中对数似然比的最大值进行消歧;2.使用语境信息中合、分两种情况下各自的对数似然比之和,取值大者进行消歧。对高频出现的14个组合型分词歧义进行实验,前者的平均准确率为84.93%,后者的平均准确率为95.60%。实验证明使用语境信息之和对消解组合型分词歧义具有良好效果。 ",MESS200706004
中文组织机构名称与简称的识别, ,5,计算机应用; 中文信息处理; 组织机构名称识别; 组织机构简称识别; 规则匹配; 贝叶斯概率模型;,"本文提出了一种基于规则识别中文组织机构全称和简称的方法。全称的识别首先借助机构后缀词库获得其右边界,然后通过规则匹配并借助贝叶斯概率模型加以决策获得其左边界。简称的识别是在全称的基础上应用其对应的简称规则实现的。在开放性测试中,该方法的总体查全率为85.19%,查准率为83.03%,F Measure为84.10%;简称的查全率为67.18%,查准率为74.14%。目前该方法已应用于中文关系的抽取系统。 ",MESS200706005
基于分类信心重排序的中文共指消解研究,,7,计算机应用; 中文信息处理; 中文共指消解; 提及配对共指分类信心; 信息抽取; 自然语言处理; 机器学习; 聚类算法;,"共指消解是自然语言处理的核心问题之一。本文针对分步消解中分类器全局信息的不足,依据分类信心对全体提及配对进行排序,优先根据可靠的分类结果对提及进行聚集或分离。实验表明,该算法在多个学习框架下显著地改善了系统的整体性能。 ",MESS200706006
中文阅读理解语料库构建技术研究,郝晓燕1:08401319|李济洪2:10812947|由丽萍2:08408610|刘开瑛2:08870131,7,计算机应用; 中文信息处理; 阅读理解问答系统; 中文阅读理解语料库; 汉语框架语义知识库;,"阅读理解问答系统指的是能够自动分析一个自然语言文章,并且根据文中的信息为每个问题生成一个答案的系统,具有很高的研究价值。然而,缺乏中文阅读理解语料库已经成为制约汉语阅读理解问答系统发展的主要障碍。本文对于中文阅读理解语料库的构建过程进行了详细的介绍,包括语料选材、编写问句,标注答案句、语料加工和评测机制,尤其是基于汉语框架语义知识库对语料进行了框架元素、短语类型和句法功能三个层面标注的深加工技术。 ",MESS200706007
基于配价的维吾尔语框架语义知识库的构建,吾买尔江·库尔班1:10814221|阿里甫·库尔班2:10239609,7,计算机应用; 中文信息处理; 框架网; 维吾尔语; 配价;,"本文阐述了以配价作为基本描写法、真实语料为事实依据的维吾尔语框架语义知识库(简称框架网Frame Net)的构建,该知识库在构建维吾尔语词汇及其所属框架的语义词典等诸多领域有着广阔的应用空间和发展前景。提出了研究维吾尔语中句法功能和概念结构(也就是语义结构)之间的关系,以及建立用于自然语言处理的维吾尔语网上词汇知识库的意义。在维吾尔语的研究中引入了框架语义知识库(框架网)。框架语义知识库作为一种网上词汇语料库,包括对每个词位(lexeme)的各个涵义的句法、语义信息的详尽描述。本文为维吾尔语框架语义知识库中各个框架元素的句法、语义特征的说明等自然语言信息处理研究提出新的研究思路,对基于配价的维吾尔语框架语义知识库构建的方法进行了探讨。 ",MESS200706008
信息检索中一种基于词语—主题词相关度的语言模型,,9,计算机应用; 中文信息处理; 语言模型; 主题词; 词语—主题词相关关系; 词语—文档—主题词归属关系; 词语—主题词共现关系;,"本文提出一种基于词语-主题词相关关系的语言模型TSA-LM(Term-Subject Association Based Language Model),它的基本思想是把一篇文档分成两个文档块,一部分是由领域主题词表中的主题词构成的主题词文档块,另一部分是由非主题词构成的非主题词文档块,分别计算两个文档块和查询的似然程度。对非主题词文档块,假设词语间独立无关,沿用经典的语言模型计算;对主题词文档块,把查询词语和主题词相关关系引入语言模型中来估计该文档块和查询的似然程度。词语-主题词相关关系采用词语-主题词相关度来衡量。词语-主题词相关度的计算除了来源于对文档中词语-主题词共现性的观察外,还来源于宏观上对词语-文档-主题词归属关系的观察。公开数据集上的检索实验结果表明,基于词语-主题词相关关系的语言模型可以有效提高检索效果。 ",MESS200706009
《中文信息学报》征稿简则,,1, , ,MESS200706010
汉语词同现网络的小世界效应和无标度特性,刘知远:45671912|孙茂松:08823738,7,计算机应用; 中文信息处理; 词的同现; 复杂网络; 小世界; 无标度; 核心词典;,"人类语言的某些重要方面可以通过复杂网络来刻画。本文基于不同规模和类型的语料库,建立了汉语词同现网络,并从复杂网络的角度对这些网络进行了系统的实验考察。实验结果表明汉语词同现网络具有复杂网络的两个基本性质:(1)网络的平均最短路径为2.63-2.75,聚合系数远大于相同参数下的随机网络,这揭示了汉语同现网络的小世界效应;(2)网络中词的度大体上呈幂律分布,表明汉语同现网络具有无标度特性。本文还对实验中所得到的汉语核心词典进行了定量分析。 ",MESS200706011
中文信息检索系统的模糊匹配算法研究和实现,王静帆:10931903|邬晓钧:08182995|夏云庆:08188525|郑方:16693649,6,计算机应用; 中文信息处理; 模糊匹配; 过滤算法; 动态规划;,"在现代中文信息检索系统中,用户输入的字符串和实际数据库中的条目往往存在局部偏差,而基于关键词匹配的检索技术不能很好地解决这一问题。本文参考并改进了Tarhio和Ukkonen提出的过滤算法[1],针对汉字拼音输入法中常出现的同音字/近音字混用现象,将算法进一步扩展到广义的Edit Distance上。实验表明,本文提出的算法能有效提高中文信息检索系统的召回率,在实际应用中可达到""子线性""的效率。 ",MESS200706012
基于COSA算法的中文文本聚类,谷波1:08407332|李济洪2:08401319|刘开瑛1:08408610,6,计算机应用; 中文信息处理; 文本聚类; COSA算法; K-means算法;,"传统聚类算法在计算两个对象间的距离时,每个属性对距离的贡献相同。COSA(Clustering On Subsets of Attributes)算法[1]认为在不同的分组中,每个属性对计算距离所起的作用可能并不相等,因为不同分组中的对象可能在不同的属性子集上聚集。文献[1]在此基础上定义了新的距离,并提出了两种COSA算法:COSA1算法是一种分割的聚类算法;COSA2算法是一种层次聚类算法。为了对比COSA距离和传统的欧氏距离在文本聚类中的表现,本文对中文文本进行了分割聚类和层次聚类的实验。实验结果显示出COSA算法较基于欧氏距离的聚类算法有更好的性能,而且对于属性数的变化,COSA算法更加稳定。 ",MESS200706013
基于监督学习的中文情感分类技术比较研究,,8,计算机应用; 中文信息处理; 情感分类; 文本分类; 语言模型;,"情感分类是一项具有较大实用价值的分类技术,它可以在一定程度上解决网络评论信息杂乱的现象,方便用户准确定位所需信息。目前针对中文情感分类的研究相对较少,其中各种有监督学习方法的分类效果以及文本特征表示方法和特征选择机制等因素对分类性能的影响更是亟待研究的问题。本文以n-gram以及名词、动词、形容词、副词作为不同的文本表示特征,以互信息、信息增益、CHI统计量和文档频率作为不同的特征选择方法,以中心向量法、KNN、Winnow、Na ve Bayes和SVM作为不同的文本分类方法,在不同的特征数量和不同规模的训练集情况下,分别进行了中文情感分类实验,并对实验结果进行了比较,对比结果表明:采用Bi Grams特征表示方法、信息增益特征选择方法和SVM分类方法,在足够大训练集和选择适当数量特征的情况下,情感分类能取得较好的效果。 ",MESS200706015
使用机器学习方法进行新闻的情感自动分类,徐军:16866137|丁宇新:15906222|王晓龙:06993266,6,计算机应用; 中文信息处理; 文本分类; 情感分析; 贝叶斯; 最大熵;,"本文主要研究机器学习方法在新闻文本的情感分类中的应用,判断其是正面还是负面。我们利用朴素贝叶斯和最大熵方法进行新闻及评论语料的情感分类研究。实验表明,机器学习方法在基于情感的文本分类中也能取得不错的分类性能,最高准确率能达到90%。同时我们也发现,对于基于情感的文本分类,选择具有语义倾向的词汇作为特征项、对否定词正确处理和采用二值作为特征项权重能提高分类的准确率。总之,基于情感的文本分类是一个更具挑战性的工作。 ",MESS200706016
基于HowNet的VSM模型扩展在文本分类中的应用研究,孙宏纲1:06242969|陆余良1:20561655|刘金红1:20166791|龚笔宏2:20136069,8,计算机应用; 中文信息处理; HowNet; VSM模型; 文本分类;,"在采用VSM模型进行文本分类时,如果特征向量维数相差悬殊,会给分类结果产生很大负面影响。为了解决这一问题,本文引入了特征向量扩展的思想,同时定义了有效原始信息浓度的概念。特征向量扩展以HowNet语义词典为依据,对高维和低维特征向量采用不同的扩展策略,从而减小了不同类别语料间有效原始信息浓度的差值,进而改善复杂语料的分类结果。实验表明该方法在复杂语料情况下,通过对特征向量进行HowNet语义扩展,可以较好的改善分类结果。 ",MESS200706017
利用上下文提高文本聚类的效果,,7,计算机应用; 中文信息处理; 文本聚类; 上下文; 词语权重; 本体论词典;,"传统文本聚类的向量空间模型中,认为词的权重只和词频有关,而与词语出现的上下文无关。本文介绍了如何借助按词语之间关系组织的本体论词典对文章进行上下文分析,得到文章中词语之间意义上的相互关系,进而用相关词语的词频以及关系的权重量化地给出一个词语受到上下文的支持程度,所以在衡量词语权重时不仅考虑其词频,而且考虑上下文的支持情况。文章还介绍了如何用自动构建的方法得到本文所需的词典,使得在本体论词典资源还不太丰富的汉语中也能应用上面的方法。实验数据表明,本文的方法能有效的消除噪音,提高文本聚类的效果。 ",MESS200706018
普通话声调的客观评测,,9,计算机应用; 中文信息处理; 声调; 客观评测; 语音处理; 普通话水平测试;,"声调在普通话中起着构词辨义的作用,声调的准确程度是决定普通话水平的重要因素。声调的客观评测是普通话水平客观评测系统的重要子系统之一。在分析普通话声调特点的基础上,提出了能消除语速影响和音节间相互影响的建模方法。选择了能反映声调特点的5个基频比值与归一化的基频共同作为声调评测参数,利用高斯混合模型对60人的实测语音数据进行了测试,结果表明:客观测试同主观测试的符合率达到88.24%。 ",MESS200706019
古维吾尔文(察合台文)及转写符号的智能输入法研究,地里木拉提·吐尔逊:09253832|瓦依提·阿不力孜:10814217|吐尔根·伊布拉音:10240109,4,"计算机应用; 中文信息处理; 古维吾尔文(察合台文),数字化整理,智能输入法,撰写符号,UNICODE;","作为古维吾尔文(察合台文)文献数字化整理系统的关键技术,本文研究了察合台文和转写符号的智能输入方法,此模块的功能最终直接影响到察合台文与现代维吾尔文之间的转写效果。通过测试,本文提出的察合台文智能输入法和察合台文转写符号的智能输入法,具有较高的准确性、稳定性、易用性等优点。 ",MESS200706020
分词规范亟需补充的三方面内容,李玉梅1:08966779|陈晓1:10334001|姜自霞1:09502158|易江燕1:10985277|靳光瑾1:11185391|黄昌宁2:11223400,5,计算机应用; 中文信息处理; 语料库; 分词规范; 分词歧义消解;,"本文认为,为提高语料库的分词标注质量应在分词规范中补充三个内容:①命名实体(人名、地名、机构名)标注细则;②表义字串(日期、时间、百分数等)标注细则;③歧义字串的消解细则。因为一方面命名实体和表义字串已被不少分词语料库视为分词单位,另一方面在以往的分词规范中几乎从不谈及歧义消解问题。其实人们对歧义字串的语感往往是不同的。因此有必要在规范中对典型的歧义字串予以说明。实践表明,在规范中交待清楚以上三方面内容,就可以在很大程度上避免标注的错误和不一致性。 ",MESS200705002
基于有效子串标注的中文分词,,6,计算机应用; 中文信息处理; 中文分词; 基于子串标注的分词;,"由于基于已切分语料的学习方法和体系的兴起,中文分词在本世纪的头几年取得了显著的突破。尤其是2003年国际中文分词评测活动Bakeoff开展以来,基于字标注的统计学习方法引起了广泛关注。本文探讨这一学习框架的推广问题,以一种更为可靠的算法寻找更长的标注单元来实现中文分词的大规模语料学习,同时改进已有工作的不足。我们提出子串标注的一般化框架,包括两个步骤,一是确定有效子串词典的迭代最大匹配过滤算法,二是在给定文本上实现子串单元识别的双词典最大匹配算法。该方法的有效性在Bakeoff-2005评测语料上获得了验证。 ",MESS200705003
基于双字耦合度的中文分词交叉歧义处理方法,,5,计算机应用; 中文信息处理; 中文分词; 双字耦合度; t-测试差;,"本文提出了一种利用双字耦合度和t-测试差解决中文分词中交叉歧义的方法:首先利用词典找出所有的交叉歧义,然后用双字耦合度和t-测试差的线性叠加值来判断各歧义位置是否该切分。实验结果表明,双字耦合度和t-测试差的结合要优于互信息和t-测试差的结合,因此,用双字耦合度和t-测试差的线性叠加值来消除交叉歧义是一种简单有效的方法。 ",MESS200705004
汉语功能块自动分析,周强:08836151|赵颖泽:11259072,7,计算机应用; 中文信息处理; 汉语功能块; 边界识别模型; 序列标记模型; 模型融合;,"汉语功能块描述了句子的基本骨架,是联结句法结构和语义描述的重要桥梁。本文提出了两种不同功能块分析模型:边界识别模型和序列标记模型,并使用不同的机器学习方法进行了计算模拟。通过两种模型分析结果的有机融合,充分利用了两者分析结果的互补性,对汉语句子的主谓宾状四个典型功能块的自动识别性能达到了80%以上。实验结果显示,基于局部词汇语境机器学习算法可以从不同侧面准确识别出大部分功能块,句子中复杂从句和多动词连用结构等是主要的识别难点。 ",MESS200705005
基于动作建模的中文依存句法分析,段湘煜:10983611|赵军:10891784|徐波:10975495,6,计算机应用; 中文信息处理; 中文依存句法分析; 决策式依存分析; 动作建模;,"决策式依存句法分析,也就是基于分析动作的句法分析方法,常常被认为是一种高效的分析算法,但是它的性能稍低于一些更复杂的句法分析模型。本文将决策式句法分析同产生式、判别式句法分析这些复杂模型做了比较,试验数据采用宾州中文树库。结果显示,对于中文依存句法分析,决策式句法分析在性能上好于产生式和判别式句法分析。更进一步,我们观察到决策式句法分析是一种贪婪的算法,它在每个分析步骤只挑选最有可能的分析动作而丢失了对整句话依存分析的全局视角。基于此,我们提出了两种模型用来对句法分析动作进行建模以避免原决策式依存分析方法的贪婪性。试验结果显示,基于动作建模的依存分析模型在性能上好于原决策式依存分析方法,同时保持了较低的时间复杂度。 ",MESS200705006
基于大规模语料库的句法模式匹配研究,,5,计算机应用; 中文信息处理; 句法分析; 模式匹配; 句法树库;,"通过大量记录的正确处理实例的分析过程和结果,在句法分析时,搜寻近似实例或片段,匹配相似语言结构和分析过程,这样的句法分析体现了""语言分析依赖经验""的思想。基于这样的思想,本文提出了一种基于模式匹配的句法分析的方法,即从大规模标注语料树库中抽取出蕴含的句法模式,构建模式、子模式及其规约库,句法分析的过程转化为模式匹配和局部模式转换的过程。实验表明句法分析的各项指标都比较理想,尤其是处理效率很高,平均句耗时0.46秒(CPU为Intel双核2.8G,内存为1G)。 ",MESS200705007
基于依存分析和错误驱动的中文时间表达式识别,贺瑞芳:06989058|秦兵:06990821|刘挺:06994824|潘越群:11325949|李生:10935625,5,计算机应用; 中文信息处理; 时间表达式识别; 触发词; 依存分析; 错误驱动学习;,"时间表达式识别是进行时间表达式归一化的基础,其识别结果的好坏直接影响归一化的效果。本文提出一种基于依存分析和错误驱动识别中文时间表达式的新方法。首先以时间触发词为切入点,据依存关系递归地识别时间表达式,大大地提高了识别效果;然后,采用错误驱动学习来进一步增强识别效果,根据错误识别结果和人工标注的差异自动地获取和改进规则,使系统的性能又提高了近3.5%。最终在封闭测试集和开放测试集上,F1值达到了76.38%和76.57%。 ",MESS200705008
基于分解转移矩阵的PageRank迭代计算方法,刘松彬:10974717|都云程:10612775|施水才:11259437,5,计算机应用; 中文信息处理; PageRank; 搜索引擎; Markov状态转移矩阵; 矩阵分解;,"本文提出了一种基于分解转移矩阵的PageRank的迭代计算方法。该方法对PageRank理论模型进一步推导,把其Markov状态转移矩阵进行了分解,从而降低存储开销和计算复杂度,减少I/O需求,使得PageRank计算的工程化实现更为简单。实验表明1 700多万的网页2.8亿条链接,可以在30秒内完成一次迭代,内存需求峰值585MB,可以满足工程化应用的需求。 ",MESS200705009
面向信息检索的概念关系自动构建,胡熠:09596881|陆汝占:08516982|刘慧:05969178,5,计算机应用; 中文信息处理; 文本检索模型; 概念关系构建; bootstrapping;,"概念之间的依存分析是提高信息检索性能的关键。相比概念关系的强弱而言,识别关系的类型更有意义。本文在Bootstrapping框架下,以""(地理)领属"",""(实体)功能""和""(动作)对象""三种语义关系类型为例,获得了构建上下文中两个概念特定关系的语义模板,并开发了一个名为SPG的系统。本文的工作:(1)引入了生物信息计算中序列比对的方法两两生成相似上下文的模板;(2)定义了新的模板评价机制估计模板的置信度。就这三种概念关系的识别而言,SPG获得的模板集合相比DIPRE系统获得了更高的正确率和覆盖能力。 ",MESS200705010
首届汉语语汇学学术研讨会在太原举行,,1, , ,MESS200705028
基于多重冗余标记CRFs的句子情感分析研究,王根:10891784|赵军:10947674,6,计算机应用; 中文信息处理; 句子情感分析; 序回归; 条件随机场; 冗余标记;,"本文提出了一种基于多重冗余标记的CRFs并将其应用于情感分析任务。该方法不仅能够有效地解决有序标记的分类问题,还能够在保证情感分析中各子任务能够使用不同特征的前提下,将情感分析中的主客观分类、褒贬分类和褒贬强弱分类任务统一在一个模型之中,在多个子任务上寻求联合最优,制约分步完成时误差的传播。实验证明,该方法有效地提高了句子情感分析任务的准确率。在理论上,该方法也为基于最大似然训练的算法解决序回归问题提供了一条途径。 ",MESS200705011
面向文本分类的基于最小冗余原则的特征选取,张希娟:06569435|王会珍:06579162|朱靖波:11074835,5,计算机应用; 中文信息处理; 条件独立性假设; 最小冗余原则; 特征选取; 文本分类;,"在文本分类中,为了降低计算复杂度,常用的特征选取方法(如IG)都假设特征之间条件独立。该假设将引入严重的特征冗余现象。为了降低特征子集的冗余度,本文提出了一种基于最小冗余原则(minimal RedundancyPrinciple,MRP)的特征选取方法。通过考虑不同特征之间的相关性,选择较小冗余度的特征子集。实验结果显示基于最小冗余原则方法能够改善特征选取的效果,提高文本分类的性能。 ",MESS200705012
中文歌词的统计特征及其检索应用,郑亚斌:08823738|刘知远:11140453|孙茂松:45671912,7,计算机应用; 中文信息处理; 歌词; 齐夫定律; k-近邻; 节奏;,"我们在歌词上做了一些传统的自然语言处理相关的实验。歌词是歌曲语义上的重要表达,因此,对歌词的分析可以作为歌曲音频处理的互补。我们利用齐夫定律对歌词语料库的字和词进行统计特征的考察,实验表明,其分布基本符合齐夫定律。利用向量空间模型的表示,我们可以找到比较相似的歌词集合。另外,我们探讨了如何利用歌词中的时间标注信息进行进一步的分析:例如发现歌曲中重复片段,节奏划分,检索等。初步的实验表明,我们的方法具有一定的效果。 ",MESS200705013
基于链接分析的重要Blog信息源发现,杨宇航:07003704|赵铁军:06997742|郑德权:07003021|于浩:06997784,5,计算机应用; 中文信息处理; 重要Blog信息源; 链接分析; 评价指标; 相关性分析;,"本文提出了一种基于链接分析的对Blog信息源进行量化评估的方法,在此基础之上发现重要Blog信息源,既体现了Blog信息的特点,又在一定程度上减小了作弊链接对链接分析结果的影响,能为用户阅读信息提供方便,并可望为Blog信息检索提供一种新的思路。为了证明该评估方法的有效性,本文还提出了Blog信息源重要性的评价指标,对比了重要Blog信息源量化评估方法和评价指标的评分结果,通过相关性分析,表明此方法和评价指标存在高度的一致性。 ",MESS200705014
汉语语句主题语义倾向分析方法的研究,姚天昉:08576605|娄德成:11130998,7,计算机应用; 中文信息处理; 意见挖掘; 主题; 语义倾向;,"本文介绍了如何识别汉语语句主题和主题与情感描述项之间的关系以及如何计算主题的语义倾向(极性)。我们利用领域本体来抽取语句主题以及它的属性,然后在句法分析的基础上,识别主题和情感描述项之间的关系,从而最终决定语句中每个主题的极性。实验结果显示,与手工标注的语料作为金标准进行比较,用于识别主题和主题极性的改进后的SBV极性传递算法的F度量达到了72.41%。它比原来的SBV极性传递算法和VOB极性传递算法的F度量分别提高了7.6%和2.09%。因此,所建议的改进的SBV极性传递算法是合理和有效的。 ",MESS200705015
现代汉语语义资源用于短语歧义模式消歧研究,王锦:08164877|陈群秀:10986898,7,计算机应用; 中文信息处理; 现代汉语语义知识库; 搭配词典; 短语歧义排歧;,"现代汉语存在着许多歧义短语结构,仅依靠句中词性标记无法获得词与词之间正确的搭配关系。本文研究了大量包含歧义的短语实例,分析了计算机处理汉语结构时面临的定界歧义和结构关系歧义问题,在已有短语结构规则的基础上归纳出了七种结构歧义模式,提出了分析歧义模式的关键是四种基本搭配信息的判断,并实现了基于语义知识和搭配知识的消歧算法。对887处短语进行排歧的实验结果表明,处理短语结构的正确率由82.30%上升到87.18%。 ",MESS200705016
基于分层语块分析的统计翻译研究,,5,人工智能; 机器翻译; 基于分层语块分析的统计翻译模型; 条件随机场; CKY算法;,"本文描述了一个基于分层语块分析的统计翻译模型。该模型在形式上不仅符合同步上下文无关文法,而且融合了基于条件随机场的英文语块分析知识,因此基于分层语块分析的统计翻译模型做到了将句法翻译模型和短语翻译模型有效地结合。该系统的解码算法改进了线图分析的CKY算法,融入了线性的N-gram语言模型。目前,本文主要针对中文-英文的口语翻译进行了一系列实验,并以国际口语评测IWSLT(International Workshopon Spoken Language Translation)为标准,在2005年的评测测试集上,BLEU和NIST得分均比统计短语翻译系统有所提高。 ",MESS200705017
基于“松弛尺度”的短语翻译对抽取方法,何彦青1:11194208|周玉1:11181882|宗成庆1:10815045|王霞2:11134711,5,人工智能; 机器翻译; 短语对抽取; 统计机器翻译; 松弛尺度;,"短语对抽取是基于短语统计机器翻译方法的关键技术。当前广泛使用的Och提出的短语对抽取方法,过于依赖词对齐结果,因而只能抽取与词对齐完全相容的短语对。本文给出一种基于""松弛尺度""的短语抽取方法,对不能完全相容的短语对,结合词性标注信息和词典信息来判断是否进行抽取,放松""完全相容""的限制,可以保证为更多的源短语找到目标短语。实验表明,该抽取方法的性能比Och的方法有明显的改善和提高。 ",MESS200705018
汉语框架语义知识库及软件描述体系,郝晓燕1:08870131|刘伟2:08408610|李茹2:08453268|刘开瑛2:08408623,6,计算机应用; 中文信息处理; 汉语框架网络; 框架语义; 描述体系; 软件;,"汉语框架网络工程是以框架语义学为理论基础的基于语料库的计算词典编纂工程,用于语言学、计算语言学研究及自然语言处理研究。该工程的结果包括两部分:汉语框架语义知识库(即词典资源)和相关软件。其中,汉语框架网络知识库包括框架库、句子库和词元库三部分,相关软件主要包括汉语框架语义知识库管理系统和基于Web的展示系统。本文介绍了汉语框架语义知识库的语义描述体系以及软件描述体系。 ",MESS200705019
基于加权二部图的汉日词对齐,,6,计算机应用; 中文信息处理; 词对齐; 二部图; 匹配;,"高效的自动词对齐技术是词对齐语料库建设的关键所在。当前很多词对齐方法存在以下不足:未登录词问题、灵活翻译问题和全局最优匹配问题。针对以上不足,该文提出加权二部图最大匹配词对齐模型,利用二部图为双语句对建模,利用词形、语义、词性和共现等信息计算单词间的相似度,利用加权二部图最大匹配获得最终对齐结果。在汉日词语对齐上的实验表明,该方法在一定程度上解决了以上三点不足,F-Score为80%,优于GIZA++的72%。 ",MESS200705020
现代汉语虚词知识库的研究,昝红英1:10310465|张坤丽1:09467924|柴玉梅1:09463011|俞士汶2:06272028,5,计算机应用; 中文信息处理; 虚词; 语言知识库; 用法属性; 规则库;,"现代汉语虚词在句法中所起的作用比较复杂,其个性较强,用法各异。目前已有的虚词研究成果大都是面向人用的,对虚词个性的描写难以避免主观性和模糊性,很难直接应用于自然语言处理的研究。本文从计算语言学的观点出发,根据目前已有的虚词研究成果以及对真实语料中虚词用法规律的考察,着力构建面向机器的现代汉语虚词用法信息词典和虚词用法规则库,旨在为现代汉语虚词用法的机器识别打下一定的数据基础。 ",MESS200705021
基于双语语料库的短语复述实例获取研究,李维刚:06994824|刘挺:06993862|李生:06989058,6,计算机应用; 中文信息处理; 复述实例; 复述获取; 短语复述; 双语语料库;,"本文提出一种基于双语语料库的短语复述实例获取方法,尤其能够很好的抽取歧义短语的复述实例。该方法通过输入一个双语短语对约束短语的语义,利用词对齐的双语语料库,构造一个双向抽取模型从中抽取双语对的复述实例。双向抽取模型通过比较每一个候选复述短语和输入短语之间的语义一致性,来确定每个候选是否成为最终的复述实例。实验结果表明,本文短语复述实例获取方法的综合准确率达到了60%,获取了较好的性能。 ",MESS200705022
语言学与统计方法结合建立汉语动词SCF类型集,冀铁亮:11041944|孙薇薇:06268960|穗志方:06244170,8,计算机应用; 中文信息处理; 动词子语类框架; 类型集; 语言学与统计方法结合;,"动词子语类框架(Subcategorization Frame以下简称SCF)在句法分析、语义角色标注等方面的研究中具有不可或缺的重要作用。在子语类框架信息的获取过程中,首先要建立标准完备的子语类框架类型集。目前英语研究已经建立了获得普遍共识的子语类框架类型集。而汉语方面还没有标准的动词子类框架类型集。本文提出一种语言学知识与统计方法相结合的汉语动词子语类框架类型集的半自动获取方案。初步建立起既符合统计结果又基本符合语言学理论的汉语动词子语类框架类型集。实验证明,加入语言学理论的子语类框架类型集降低了对语料的依赖程度,比完全由分析语料产生的类型集更完备。 ",MESS200705023
基于多层次特征集成的中文实体指代识别,张海雷:06579162|曹菲菲:06581014|陈文亮:06577453|任飞亮:06569435|王会珍:11074585|朱靖波:11321557,5,计算机应用; 中文信息处理; 实体指代识别; 多任务标注; 条件随机场模型; ACE评测;,"实体指代识别(Entity Mention Detection,EMD)是识别文本中对实体的指代(Mention)的任务,包括专名、普通名词、代词指代的识别。本文提出一种基于多层次特征集成的中文实体指代识别方法,利用条件随机场模型的特征集成能力,综合使用字符、拼音、词及词性、各类专名列表、频次统计等各层次特征提高识别性能。本文利用流水线框架,分三个阶段标注实体指代的各项信息。基于本方法的指代识别系统参加了2007年自动内容抽取(ACE07)中文EMD评测,系统的ACE Value值名列第二。 ",MESS200705024
否定词跨标点句管辖的判断,,5,计算机应用; 中文信息处理; 否定词; 标点句; 管辖; 共享;,"现代汉语中基本否定词""不""以及扩充词""从不""、""很不""、""不能""、""不会""等的否定辖域受到学术界重视,但前人研究一般局限于句内,且主要局限于基本否定词,其实否定辖域也涉及多个标点句,否定词的管辖判断也涉及到扩充的否定词。跨标否定词跨标点句管辖的判断和否定词共享问题是整个跨标点句句法共享问题的一个重要组成部分。本文从形式上找到了一些否定词跨标点句的共享规律,即着重从形式角度讨论了否定词跨标点句的辖域问题,对现代汉语长句句法分析有重要作用,并对汉外机器翻译有实用价值。 ",MESS200705025
ACL2007会议观感,刘群:09638994|刘洋:09638999,3, , ,MESS200705026
商务印书馆语言出版基金简价,,1, , ,MESS200705027
自然语言处理的计算模型,张钹:05974610,5,人工智能; 自然语言处理; 计算模型; 分析模型; 概念统计模型; 混合模型; 不适定问题;,"本文讨论自然语言处理的计算模型。目前已经存在有各种类型的语言计算模型,如分析模型、概率统计模型、混合模型等,这些模型各具特色,并存在其自身的局限性。自然语言处理作为一个不适定问题,我们将讨论求解这类问题的本质困难,面临的挑战,以及解决这些困难的途径。 ",MESS200703000
中文分词十年回顾,黄昌宁1:10922471|赵海2:08966779,12,计算机应用; 中文信息处理; 中文分词; 词语定义; 未登录词识别; 字标注分词方法;,"过去的十年间,尤其是2003年国际中文分词评测活动Bakeoff开展以来,中文自动分词技术有了可喜的进步。其主要表现为:(1)通过“分词规范+词表+分词语料库”的方法,使中文词语在真实文本中得到了可计算的定义,这是实现计算机自动分词和可比评测的基础;(2)实践证明,基于手工规则的分词系统在评测中不敌基于统计学习的分词系统;(3)在Bakeoff数据上的评估结果表明,未登录词造成的分词精度失落至少比分词歧义大5倍以上;(4)实验证明,能够大幅度提高未登录词识别性能的字标注统计学习方法优于以往的基于词(或词典)的方法,并使自动分词系统的精度达到了新高。 ",MESS200703001
第二届“‘语言与国家’高层论坛”在绍兴举行,,1, , ,MESS200703002
有关“理解和分词孰先孰后”的反思,吴安迪:16785122,1, , ,MESS200703003
汉语基本块描述体系,,7,计算机应用; 中文信息处理; 基本块; 部分分析; 语料库标注; 词汇知识获取;,"块分析是自然语言处理研究中的重要技术,其处理基础是设计一套合理有效的块描述体系。本文在吸收和总结前人研究成果和经验的基础上,提出了一套基于拓扑结构的汉语基本块描述体系。它通过引入词汇关联信息确定基本拓扑结构,形成了很好的基本块内聚性判定准则,建立了句法形式与语义内容的有机联系桥梁。这套描述体系大大简化了从现有的句法树库TCT中自动提取基本块标注语料库和相关词汇关联知识库的处理过程,为进一步进行汉语基本块自动分析和词汇关联知识获取互动进化研究打下了很好的基础。 ",MESS200703004
单纯形算法在统计机器翻译Re-ranking中的应用,,6,人工智能; 机器翻译; discriminative re-ranking; 单纯形算法; 统计机器翻译;,"近年来,discriminative re-ranking技术已经被应用到很多自然语言处理相关的分支中,像句法分析,词性标注,机器翻译等,并都取得了比较好的效果,在各自相应的评估标准下都有所提高。本文将以统计机器翻译为例,详细地讲解利用单纯形算法(Simplex Algorithm)对翻译结果进行re-rank的原理和过程,算法的实现和使用方法,以及re-rank实验中特征选择的方法,并给出该算法在NIST-2002(开发集)和NIST-2005(测试集)中英文机器翻译测试集合上的实验结果,在开发集和测试集上,BLEU分值分别获得了1.26%和1.16%的提高。 ",MESS200703005
双语知识库中关联实例的多策略提取机制,,6,人工智能; 机器翻译; 双语知识库; 关联实例; 多策略提取机制; 翻译记忆;,"双语库是翻译记忆系统最重要的组成部分之一。从有限规模的双语库中提取更多的符合用户当前翻译需要的关联实例是翻译记忆技术研究的主要内容,本文首先对当前基于单一方法的实例检索算法存在的局限性进行了分析,并在对双语库进行知识化表示的基础上,提出了基于多策略的关联实例提取机制,即综合运用句子句法结构匹配、句子编辑距离计算、句子短语片段匹配、词汇语义泛化、基于扩展信息(如:句子来源、所属专业、应用频度等信息)的优选等策略进行关联实例提取。试验结果表明,该方法有效提高了关联实例的召回数量和质量,明显改善了对用户的辅助效果。 ",MESS200703006
汉语述语形容词机器词典机器学习词聚类研究,王锦:08164877|陈群秀:10986898,7,人工智能; 机器翻译; 机器学习; 词聚类; 搭配对; Kendallτ系数法; 字面相似度; 路径权值;,"本文提出了一个基于现代汉语述语形容词机器词典以及平衡语料库的形容词多信息聚类算法。聚类的过程根据形容词的语料提取了三重信息(所修饰的名词,同义近义词以及反义词),从而使形容词与形容词之间构成网络关系。本文重点描述了如何根据三重信息分别建模计算形容词的相似性并通过计算字面相似度以及路径权值这些辅助信息修正每两个形容词之间的相似度,从而在某种程度上缓解了数据稀疏的问题,实验结果显示该算法是有效的。 ",MESS200703007
2007年中文信息处理国际会议(ICCC2007)征稿通知,,1, , ,MESS200703008
基于层次聚类的自适应信息过滤学习算法,洪宇:11221644|张宇:07004292|刘挺:06989058|郑伟:06987907|龚诚:06994824|李生:06997645,7,计算机应用; 中文信息处理; 自适应信息过滤; 用户模型; 相关反馈; 阈值; 层次聚类;,"本文采用一种基于层次聚类的自适应学习策略,从系统反馈的信息流中,动态提取一类最优信息的质心更新用户模型,有效屏蔽了阈值失真和初始信息稀疏造成的大量反馈噪声,并且能够近似模仿人工反馈,完善自适应学习机制的智能性。 ",MESS200703009
一种基于紧密度的半监督文本分类方法,郑海清:06699265|林琛:11072934|牛军钰:10999624,7,计算机应用; 中文信息处理; 文本分类; 半监督机器学习; 支持向量机; 紧密度;,"自动的文本分类已经成为一个重要的研究课题。在实际的应用情况下,很多训练语料都只有一个数目有限的正例集合,同时语料中的正例和未标注文档在数量上的分布通常也是不均衡的。因此这种文本分类任务有着不同于传统的文本分类任务的特点,传统的文本分类器如果直接应用到这类问题上,也难以取得令人满意的效果。因此,本文提出了一种基于紧密度衡量的方法来解决这一类问题。由于没有标注出来的负例文档,所以,本文先提取出一些可信的负例,然后再根据紧密度衡量对提取出的负例集合进行扩展,进而得到包含正负例的训练集合,从而提高分类器的性能。该方法不需要借助特别的外部知识库来对特征提取,因此能够比较好的应用到各个不同的分类环境中。在TREC’05(国际文本检索会议)的基因项目的文本分类任务语料上的实验表明,该算法在解决半监督文本分类问题中取得了优异的成绩。 ",MESS200703010
基于信息增益的中文文本关联分类,,8,计算机应用; 中文信息处理; 信息增益; 关联分类; 文本分类;,"关联分类是一种通过挖掘训练集中的关联规则,并利用这些规则预测新数据类属性的分类技术。最近的研究表明,关联分类取得了比传统的分类方法如C4.5更高的准确率。现有的基于支持度-置信度架构的关联分类方法仅仅是选择频繁文字构建分类规则,忽略了文字的分类有效性。本文提出一种新的ACIG算法,结合信息增益与FoilGain在中文文本中选择规则的文字,以提高文字的分类有效性。实验结果表明,ACIG算法比其他关联分类算法(CPAR)有更高的准确率。 ",MESS200703011
中国辞书学会辞书编纂现代化专业委员会第二届年会暨学术研讨会征文,,1, , ,MESS200703012
基于小世界模型的中文文本主题分析,,7,计算机应用; 中文信息处理; 主题分析; 小世界模型; 文本分割; 词汇聚类;,"本文旨在研究如何基于小世界模型进行文本分割,确定片段主题,进而总结全文的中心主题,使文本的主题脉络呈现出来。为此首先证明由文本形成的词汇共现图呈现短路径,高聚集度的特性,说明小世界结构存在于文本中;然后依据小世界结构将词汇共现图划分为“簇”,通过计算“簇”在文本中所占的密度比重识别片段边界,使“簇”与片段对应起来;最后利用短路径,高聚集度的特性提取图“簇”的主题词,采取背景词汇聚类及主题词联想的方式将主题词扩充到待分析文本之外,尝试挖掘隐藏于字词表面之下的文本内涵。虽然国际上已有很多关于小世界结构及基于其上的应用研究,但利用小世界特性进行主题分析还是一个崭新的课题。实验表明,本文所给方法的结果明显好于其他方法,说明可以为下一步文本推理的工作提供有价值的预处理。 ",MESS200703013
用于文本分类的改进KNN算法,,7,计算机应用; 中文信息处理; 文本分类; 神经网络; Chi-square距离; KNN算法;,"最近邻分类器是假定局部的类条件概率不变,而这个假定在高维特征空间中无效。因此在高维特征空间中使用k最近邻分类器,不对特征权重进行修正就会引起严重的偏差。本文采用灵敏度法,利用前馈神经网络获得初始特征权重并进行二次降维。在初始权重下,根据样本间相似度采用SS树方法将训练样本划分成若干小区域,以此寻找待分类样本的近似k0个最近邻,并根据近似k0个最近邻和Chi-square距离原理计算新权重,搜索出新的k个最近邻。此方法在付出较小时间代价的情况下,在文本分离中可获得较好的分类精度的提高。 ",MESS200703014
《综合型语言知识库》通过技术鉴定,,1, , ,MESS200703015
中文网络聊天语言的奇异性与动态性研究,夏云庆1:09209372|黄锦辉2:06432471|张普3:10931903,9,计算机应用; 中文信息处理; 网络聊天语言; 奇异性; 动态性; 语言信息处理;,"随着互联网走入社会生活,网络聊天逐渐成为一种新的沟通渠道,网络聊天语言便应运而生。这类语言的日益丰富,给语言信息处理带来了新的挑战。研究发现,困难主要来自网络聊天语言的奇异性和动态性。本文借助真实网络聊天语言文本,对网络聊天语言的奇异性和动态性进行详细分析和归纳,并设计了面向解决奇异性和动态性问题的网络聊天语言文本识别与转换方法。我们先以网络聊天语言语料库为基础建立网络聊天语言模型和语言转换模型,通过信源?信道模型实现网络聊天语言向标准语言的转换。但该方法过于依赖网络聊天语言语料库,虽然能较好解决奇异性问题,但不能处理动态性问题。因此,我们进而以标准汉语语料库为基础建立文字语音映射模型,对信源?信道模型进行改进,最终有效解决了网络聊天语言的动态性问题。 ",MESS200703016
面向中文陌生文本的人机交互式分词方法,李斌:08075606|陈小荷:08109709,7,计算机应用; 中文信息处理; 自动分词; 未登录词识别; 陌生文本; 人机交互;,"自动分词是中文信息处理的基础课题之一。为了克服传统分词方法在处理特殊领域文本时遇到的困难,本文提出了一种新的分词方法,在没有词表和训练语料的条件下,让用户参与到分词过程中,增加系统的语言知识,以适应于不同的语料和分词标准。系统采用改进的后缀数组算法,不断提取出候选词语,交给用户进行筛选,最后得到词表进行分词。四个不同语料的实验结果显示,不经过人工筛选,分词F值可以达到72%左右;而经过较少的人机交互,分词F值可以提高12%以上。随着用户工作量的增加,系统还能够进一步提高分词效果。 ",MESS200703017
中文词语语义相似度计算——基于《知网》2000,李峰:08517385|李芳:09595202,7,计算机应用; 中文信息处理; 词语语义相似度; 知网; “义原”; 语义信息量;,"词语语义相似度的计算,一种比较常用的方法是使用分类体系的语义词典(如Wordnet)。本文首先利用Hownet中“义原”的树状层次结构,得到“义原”的相似度,再通过“义原”的相似度得到词语(“概念”)的相似度。本文通过引入事物信息量的思想,提出了自己的观点:认为知网中的“义原”对“概念”描述的作用大小取决于其本身所含的语义信息量;“义原”对“概念”的描述划分为直接描述和间接描述两类,并据此计算中文词语语义相似度,在一定程度上得到了和人的直观更加符合的结果。 ",MESS200703018
首届中国语言学期刊主编论坛在绍兴举行,,1, , ,MESS200703019
基于广义置信度的样本选择算法,任俊玲:10612309,5,人工智能; 模式识别; 广义置信度; 样本选择; 手写汉字识别; HCL2004;,"对模式识别系统而言,不同的训练样本在建立模式类模型时所起的作用不同,因此必须对训练样本进行选择。而在训练样本中,边界样本的判定方式以及训练样本中包含边界样本数量的多少对分类的精度起主要作用。为此,结合基于模板匹配的脱机手写汉字识别,定义了一种通过广义置信度判定边界样本的方法,并且在此基础上建立了基于广义置信度的训练样本选择算法。通过在脱机手写汉字数据库HCL2004上进行实验,由该算法选择出的训练样本集在训练样本数减少的同时,使得系统识别率有了较大的提高,从而证实了该算法的有效性。 ",MESS200703020
OpenOffice.org对非BMP平面字符支持的实现,,6,人工智能; 模式识别; OpenOffice.org; surrogatepair; 非BMP平面字符;,"Unicode标准中的非BMP平面字符多用于古籍研究或者少数民族语言文字,由于这些字符的使用面特别窄,多数软件系统包括办公软件都不支持对这些字符的处理。本文以开源办公套件OpenOffice.org为基础,分析了它对非BMP平面支持的现状,然后着重探讨了实现对非BMP平面字符的全面支持所需要解决的一系列问题,并分别给出了合理的改进方案,最后以CJK和藏文为例展示了改进后的效果。 ",MESS200703021
《中文信息学报》征稿简则,,1, , ,MESS200703022
基于弹性网格模糊特征的手写体汉字识别方法,刘伟:07437308|朱宁波:07427007|何浩智:10838676|李德鑫:10756585|孙发军:10839090,5,人工智能; 模式识别; 弹性网格; 相关模糊特征; 手写体汉字识别;,"网格方向特征在手写体汉字识别系统中得到广泛应用,被认为是目前较成熟的手写体汉字特征之一。网格技术是网格方向特征的关键技术之一。根据汉字笔画分布特点及拓扑结构的相关性,提出了一种新的基于弹性网格及其相关模糊特征的提取方法。该方法使特征向量的信息量增加,特征更加稳定。对银行支票图像大写金额的识别率达到97.64%,实验结果证明本文方法比其他网格方向特征更有效。 ",MESS200703023
支持重音合成的汉语语音合成系统,朱维彬:17250923,7,计算机应用; 中文信息处理; 重音; 韵律模型; 语音合成;,"针对基于单元挑选的汉语语音合成系统中重音预测及实现,本文采用了知识指导下的数据驱动建模策略。首先,采用经过感知结果优化的重音检测器,实现了语音数据库的自动标注;其次,利用重音标注数据库,训练得到支持重音预测的韵律预测模型;用重音韵律预测模型替代原语音合成系统中的相应模型,从而构成了支持重音合成的语音合成系统。实验结果分析表明,基于感知结果优化的重音检测器的标注结果是可靠的;支持重音的韵律声学预测模型是合理的;新的合成系统能够合成出带有轻重变化的语音。 ",MESS200703024
商务印书馆对外汉语教学专题研究书系,,1, , ,MESS200703025
基于词典属性特征的粗粒度词义消歧,吴云芳:11712467|金澎:11677067|郭涛:06270718,6,人工智能; 自然语言处理; 特征; 词义; 词义消歧; 贝叶斯分类法;,"本文依据《现代汉语语法信息词典》中对词语多义的属性特征描述,对《人民日报》语料中155个词语共4996个同形实例进行了粗粒度词义自动消歧实验,同时用贝叶斯算法进行了比较测试。基于词典属性特征的消歧方法在同形层面上准确率达到90%,但召回率偏低。其优点在于两个方面:1)不受词义标注语料库规模的影响;2)对特定词语意义的消歧准确率可达到100%。本文也讨论了适用于不同词类的消歧特征。 ",MESS200702000
一种用于词性标注的相关投票融合策略,郭永辉:00009022|吴保民:20647410|王炳锡:20282683,5,人工智能; 自然语言处理; 词性标注; 融合策略; 相关投票;,"各种词性标注方法总是利用从某一侧面描述的语言学知识,当训练语料达到一定规模、训练模型完善到一定程度后,标注精度很难再有进一步的提高。本文在对TBED、DT、HMM和ME四种基于语料库的词性标注方法研究的基础上,提出了一种新的词性标注融合策略——相关投票法。从理论上分析了该方法的优越性,并与其他融合策略进行了对比实验。实验结果表明,应用融合策略可以更加全面地描述词性标注知识,从而更好地完成词性标注任务;在几种融合策略中,相关投票法是最优秀的,它使标注的平均错误率降低27.85%。 ",MESS200702001
实体提及的多层嵌套识别方法研究,刘非凡:10983611|赵军:11467321|徐波:10891784,8,人工智能; 自然语言处理; 实体提及嵌套识别; 条件随机场; 支持向量机;,"实体识别在许多自然语言处理应用系统中发挥着极其重要的作用。目前大部分研究集中在命名实体识别,且不考虑实体之间的嵌套,本文在自动内容抽取评测(Automatic Content Extraction,ACE)背景下,对汉语文本中各种实体提及(命名性,名词性,代词性)的多层嵌套识别进行了研究。我们将嵌套实体识别分成两个子任务:嵌套实体边界检测和实体多层信息标注。首先,本文提出了一种层次结构信息编码方法,将多层嵌套边界检测问题转化为传统的序列标注问题,利用条件随机场模型融合多种特征进行统计决策。其次,将多层信息标注问题看作分类问题,从实现的角度设计了含有两个分类引擎的并行SVM分类器,避免了对每层信息标注都设计一个分类器,比采用单一分类器在性能上有明显提高。在标准ACE语料上的实验表明,基于条件随机场的多层实体边界检测模型正确率达到71%,融合特征选择策略的两个并行分类引擎的正确率也分别达到了89.05%和82.17%。 ",MESS200702002
基于混合模型的中国人名自动识别,毛婷婷:06527360|李丽双:06521783|黄德根:06522316,7,计算机应用; 中文信息处理; 支持向量机; 概率统计; 混合模型; 人名识别;,"本文提出了一种支持向量机(SVM)和概率统计模型相结合的中国人名自动识别方法。该方法首先按字抽取特征向量的属性得到训练集,采用多项式核函数建立SVM人名识别模型,然后在特征空间中计算测试样本到SVM最优超平面的距离,当该距离大于给定的阈值时使用SVM对测试样本进行分类,否则使用概率统计方法。实验表明,采用混合模型,对样本在空间的不同分布使用不同的方法可以取得比单独使用SVM或概率统计更好的分类效果,系统开式综合指标F-值比单纯使用支持向量机方法提高了1.51%。 ",MESS200702003
基于标点符号分割的汉语句法分析算法,毛奇:11399062|连乐新:11667876|周文翠:11599061|袁春风:08045971,6,计算机应用; 中文信息处理; 句法解析器; 单独解析块; 决策树(Id3);,"目前大部分句法解析器都忽略标点符号这一重要的句法特征或者只进行非常简单的处理。本文根据标点符号的句法结构特性,提出单独解析块的概念,并且根据标点符号在句子中的特有特征和位置关系,给出了基于决策树算法(Id3)单独解析块识别方法,将标点融入汉语句法分析中。本文所用的实验数据(包括训练集和测试集)均来自中文宾州树库5.0。对句长大于40个词的汉语长句单独进行了实验,句法分析精度和召回率分别提高1.59%和0.93%,同时时间开销降低了近2/3。实验结果表明,标点对汉语长句句法分析非常有利,系统性能获得了较大提高。 ",MESS200702004
自然语言处理在信息检索中的应用综述,王灿辉:11090658|张敏:08186086|马少平:08177513,11,人工智能; 自然语言处理; 综述; 信息检索;,"在信息检索①发展的过程中,研究者们不断尝试着将自然语言处理应用到检索里,希望能够为检索效果提高带来帮助。然而这些尝试的结果大多和研究者们最初的设想相反,自然语言处理在大多数情况下没有改进信息检索效果,甚至反而起了负面作用。即便有一些帮助,也往往是微小的,远远不如自然语言处理所需要的计算消耗那么大。研究者们对这些现象进行了分析,认为:自然语言处理更适合于应用在需要精确结果的任务中,例如问答系统、信息抽取等;自然语言处理需要针对信息检索进行优化才可能发挥积极作用。最新的一些进展(例如在语言模型中加入自然语言处理)在一定程度上印证了这一结论。 ",MESS200702005
基于决策树和马尔可夫链的问答对自动提取,刘佳宾:11284561|胡国平:09572145|陈超:09504972|邵正荣:09508096,6,人工智能; 模式识别; 信息抽取; DOM树; 决策树; 马尔可夫链;,"问答系统能用准确、简洁的答案回答用户用自然语言提出的问题,很明显系统中问答对的规模是影响问答系统最终性能的主要因素。为了提高问答对的规模、充分利用互联网资源,本文提出了一种基于决策树和马尔科夫链的在互联网上自动抽取问答对的算法。先根据网页中的HTML标记把网页表示成一棵DOM树;然后利用树中每个节点的结构和文字信息,抽取相应的特征;最后将得到的节点特征通过由决策树和一阶马尔可夫链结合得出的分类模型进行分类。试验结果表明准确率达到了90.398%,召回率达到了86.032%。对大量网页抽取的结果表明该分类模型能够适应对各种各样的网页的抽取。 ",MESS200702006
基于统计抽词和格律的全宋词切分语料库建立,,6,计算机应用; 中文信息处理; 宋词; 语料库; 统计抽词; 格律;,"全宋词切分语料库的建立是计算机研究宋词的基础。本文对宋词中“词”的界定提出了自己的看法,并在综合考虑统计抽词方法和基于诗词格律切分方法各自优点的基础上,提出建立全宋词切分语料库的新方法。我们首先通过统计抽词来抽取结合程度较强的二字词,并结合相关资源建立词表;在此基础上,结合宋词的格律特点按照一定的规则来对全宋词进行了切分。实验证明,本文中的方法具有较好的效果。 ",MESS200702007
一种基于主题的文本聚类方法,赵世奇:06994824|刘挺:06989058|李生:07005452,5,人工智能; 模式识别; 基于主题文本聚类; 基本类索引; 语言学特征;,"现有的文本聚类方法难以正确识别和描述文本的主题,从而难以实现按照主题对文本进行聚类。本文提出了一种新的基于主题的文本聚类方法:LFIC。该方法能够准确识别文本主题并根据文本的主题对其进行聚类。本方法定义和抽取了“主题元素”,并利用其进行基本类索引。同时还整合利用了语言学特征。实验表明,LFIC的聚类准确率达到94.66%,优于几种传统聚类方法。 ",MESS200702008
面向变异短文本的快速聚类算法,黄永光:06994824|刘挺:06987220|车万翔:06988018|胡晓光:06988363,6,人工智能; 模式识别; 检索; 特征串; 聚类;,"本文主要针对近些年来大量出现在聊天语言中和手机短信中的短文本,提出了一种快速有效的聚类算法。这些短文本由于具有不规范性和大量相似性等特点,我们称其为变异短文本。本文在原有的网页去重算法[1~3]的基础上,根据变异短文本的特点,采取了特定的特征串抽取方法,并融合了压缩编码的思想,从而加快了处理速度。实验表明,基于该算法的聚类系统对于大量的变异短文本处理速度可以达到每小时百万级以上,并且有比较高的准确率。 ",MESS200702009
基于无监督学习的问答模式抽取技术,吴友政:11504594|赵军:10983611|徐波:10891784,8,人工智能; 自然语言处理; 汉语问答系统; 问答模式; 机器学习;,"本文提出了一种基于无监督学习算法的问答模式抽取技术从互联网上抽取应用于汉语问答系统的答案模式。该算法可以避免有监督学习算法的不足,它无需用户提供<提问,答案>对作为训练集,只需用户提供每种提问类型两个或以上的提问实例,算法即可通过Web检索、主题划分、模式提取、垂直聚类和水平聚类等步骤完成该类型提问的答案模式的学习。实验结果表明,论文提出的无监督问答模式学习方法是有效的,基于模式匹配的答案抽取技术能够较大幅度地提高汉语问答系统的性能。 ",MESS200702010
一种基于图划分的无监督汉语指代消解算法,,6,人工智能; 自然语言处理; 聚类; 指代消解; 模块函数;,"指代消解是自然语言处理领域中的一个重要问题。针对当前中文指代标注训练语料非常缺乏的现状,本文提出一种无监督聚类算法实现对名词短语的指代消解。引入图对名词短语的指代消解问题进行建模,将指代消解问题转化为图划分问题,并引入一个有效的模块函数实现对图的自动划分,使得指代消解过程并不是孤立地对每一对名词短语分别进行共指决策,而是充分考虑了多个待消解项之间的相关性,并且避免了阈值选择问题。通过在ACE中文语料上的人称代词消解和名词短语消解实验结果表明,该算法是一种有效可行的无监督指代消解算法。 ",MESS200702011
古籍自动校勘的研究和实现,常娥:08100422|侯汉清:00019656|曹玲:08100408,6,计算机应用; 中文信息处理; 古籍整理; 自动校勘; 校勘辅助工具;,"古籍自动校勘是指利用计算机自动发现并标记出古籍不同版本之间的文字差异,并提供各种校勘辅助工具帮助专家勘误。本文讨论了古籍自动校勘的意义,接着详细阐述了古籍自动校勘系统的总体设计及其实现,包括选题和资料收集、自动校勘的对象和方法,最深入讨论了古代官名表、人名表、地名表等自动校勘辅助工具的建设问题。最后,设计了实验检查校勘系统的效果。实验结果表明,本系统的召回率和精确率分别达到了92.3%、95.2%。 ",MESS200702012
一种新的加权动态网格汉字特征抽取方法,陈光:06426169|张洪刚:06426678|郭军:06426063,5,人工智能; 模式识别; 手写汉字识别; 非线性归一化; 加权动态网格; 特征提取;,"为了更有效地提取手写汉字的特征,提高识别精度,本文提出了一种利用非线性归一化过程产生的坐标变换信息来提取手写汉字有效特征的方法。该方法通过非线性归一化获得各有效像素点在原汉字图像及规整后汉字图像中的坐标变换关系,在原图像上抽取各点特征,在归一化图像上进行网格的均匀划分和特征统计并形成用于分类的特征向量。该方法有效克服了以往先进行归一化预处理方法和动态网格方法的一些不足,兼顾了与传统结构特征提取方法的有效结合。针对HCL2000脱机手写汉字库大字符集样本的实验结果表明,该特征提取方法可有效提高识别精度和特征抽取速度。 ",MESS200702013
汉语普通话语音合成语料库TH-CoSS的建设和分析,蔡莲红:00009725|崔丹丹:08819901|蔡锐:11716699,6,计算机应用; 中文信息处理; 语音合成; 汉语; 语料库;,"本文介绍了汉语语音合成语料库TH-CoSS的建设和分析。本语料库包括男女声朗读语句约2万个。语料库分为四个部分:TTS系统建库用语句、TTS系统测试用语句、特殊语调语句和特殊音节组。语料设计考虑了语料的平衡和音段、韵律信息的丰富。语料库中除了文本、语音数据外,还带有音段切分标志,标注文件采用XML格式。为了方便语音分析与开发,特研制了标注软件。本文还给出了语境特征对语音韵律影响的分析结果。 ",MESS200702014
基于支持向量机的音字转换模型,姜维:06993371|关毅:06991644|王晓龙:06988938|刘秉权:06993266,6,人工智能; 自然语言处理; 支持向量机; 音字转换; 粗糙集理论; 远距离特征;,"针对N-gram在音字转换中不易融合更多特征,本文提出了一种基于支持向量机(SVM)的音字转换模型,有效提供可以融合多种知识源的音字转换框架。同时,SVM优越的泛化能力减轻了传统模型易于过度拟合的问题,而通过软间隔分类又在一定程度上克服小样本中噪声问题。此外,本文利用粗糙集理论提取复杂特征以及长距离特征,并将其融合于SVM模型中,克服了传统模型难于实现远距离约束的问题。实验结果表明,基于SVM音字转换模型比传统采用绝对平滑算法的Trigram模型精度提高了1.2%;增加远距离特征的SVM模型精度提高1.6%。 ",MESS200702015
一种两层次无监督的音频分割算法,张世磊:11658015|张树武:10983611|徐波:11563432,6,人工智能; 模式识别; 两层次无监督音频分割; 修正广义似然比; 区域层次; 边界层次;,"本文提出一种两层次无监督音频分割算法,它用于检测音频流中的说话人、环境、信道等声学特征变化点,该方法将音频分割过程分为两个层次:区域层次和边界层次,通过固定检测窗移动,它快速定位到声学特征变化点存在的区域,然后在潜在变化区域内采用T2统计值和贝叶斯信息准则(BIC)结合的方法快速确定片断边界。在区域检测层次,将修正的广义对数似然比准则应用于潜在的变化区域检测,它即无需设定阈值门限又可保证低的漏检率,在1997年Hub4中文广播语音数据库上的实验结果表明,同传统的混合分割算法比较,该算法在处理速度得到提高的同时,声学特征变化点的召回率提高10.5%。 ",MESS200702016
维文版Office设计中关键技术的研究与实现,,5,计算机应用; 中文信息处理; 维吾尔文处理; 算法; 自动选形; 自动拉长; 断行;,"维吾尔文,汉文和英文等多文种办公套件,对少数民族地区信息化的发展,起着重要作用。该文首先介绍了维吾尔文的特点,然后分析并实现了永中集成Office维吾尔文版设计中的自动选形、按音节断行和自动拉长等处理维吾尔文的关键技术。这些关键技术在维吾尔文版Office中应用后,通过测试能使维吾尔文排版非常规整。同时这些关键技术对维吾尔文文字处理,对其他维吾尔文软件的开发都有普遍地指导作用。 ",MESS200702017
《中文信息学报》征稿简则,,1, , ,MESS200702018
蒙古文显示在OpenOffice.org办公套件中的实现,孟凡强:11390943|吴健:09573880|贾彦民:10830205,5,计算机应用; 中文信息处理; 复杂文字; 复杂文本布局引擎; ICU; Uniscribe;,"蒙古文是一种复杂文字,目前操作系统和办公套件都还不支持蒙古文的显示。OpenOffice.org是可以运行在Linux和Windows上跨平台的办公套件,它分别使用ICU LayoutEngine和Uniscribe进行复杂文字处理。本文以支持蒙古文处理的Linux版本OpenOiffice.org为基础,详细分析了OpenOffice.org在Linux和Windows系统上的复杂文本处理过程,采用Uniscribe与ICU相结合的方案,实现了OpenOffice.org在Windows平台上对蒙古文的显示。 ",MESS200702019
藏文编码字符集的扩充集在Linux上的实现,张兴亮:14056745|芮建武:11563825|谢谦:09573880|程伟:09573886|吴健:09612997,7,计算机应用; 中文信息处理; 藏文字丁; 扩充集; OpenType; 扩充QT方案;,"国内藏文软件开发普遍使用的是基于垂直预组合字符的实现方案,但是缺乏统一的编码标准。藏文编码字符集扩充集的推出,对于国内藏文软件的标准化、国际化具有重要意义。本文通过分析ISO/IEC 10646藏文编码字符集基本集、藏文编码字符集扩充集国家标准,区分它们描述字丁的差异,分析由编码方案所导致的实现上的关键问题。最后,针对藏文扩充集B的特殊性,提出并实现了基于Linux国际化架构下支持藏文扩充集标准的解决方案。 ",MESS200702020
一个字 一个词 用汉语盘点2006年的中国和世界,,1, , ,MESS200702021
COLING/ACL 2006会议报道,邹煜:11606604,2, , ,MESS200701021
汉语分词中组合歧义字段的研究,,6,计算机应用; 中文信息处理; 汉语切分; 组合歧义; 最大熵; 特征;,"汉语自动分词中组合歧义是难点问题,难在两点:组合歧义字段的发现和歧义的消解。本文研究了组合歧义字段在切开与不切时的词性变化规律,提出了一种新的组合歧义字段自动采集方法,实验结果表明该方法可以有效地自动发现组合歧义字段,在1998年1月《人民日报》中就检测到400多个组合歧义字段,远大于常规方法检测到的歧义字段数目。之后利用最大熵模型对60个组合歧义字段进行消歧,考察了六种特征及其组合对消歧性能的影响,消歧的平均准确度达88.05%。 ",MESS200701000
面向机器辅助翻译的汉语语块自动抽取研究,姜柄圭:11465450|张秦龙:11381602|谌贻荣:06266614|常宝宝:06253581,8,人工智能; 机器翻译; 语块抽取; 串频统计; 内部结合紧密度; 信息熵; 语块组合规则;,"本文提出了一种统计和规则相结合的语块抽取方法。本文使用Nagao串频统计算法进行基于词语的串频统计,进一步分别利用统计方法、语块边界过滤规则对2-gram到10-gram语块进行过滤,得到候选语块,取得了令人满意的结果。通过实验发现,在统计方法中互信息和信息熵相结合的方法较单一的互信息方法好;在语块边界规则过滤方法中语块左右边界规则和停用词对语块抽取的结果有较大影响。实验结果表明统计和过滤规则相结合的方法要优于纯粹的统计方法。应用本文方法,再辅以人工校对,可以方便地获取重复出现的多词语块。在机器辅助翻译系统中,使用现有的语块抽取方法抽取重复的语言单位,就可以方便地建设翻译记忆库,提高翻译的工作效率。 ",MESS200701001
基于本体的专业机器翻译术语词典研究,,6,人工智能; 机器翻译; 本体; 术语词典;,"在专业机器翻译系统的设计和实现中,要解决的一个关键问题是如何有效地组织面向不同专业领域的专业术语,以及如何根据当前所处理的文本选择相应的术语定义。本文首先分析现有专业机器翻译系统在术语词典组织和建设方面存在的主要问题,以及基于本体(Ontology)的领域知识概念体系的特点;其次,探讨面向专业机器翻译的术语词典研究的几个重要方面,包括通用领域本体的设计、专业术语的描述和向本体的映射、双语或多语MT专业词库的组织和应用等;最后,介绍我们初步已完成的工作,主要包括机器翻译专业领域分类系统设计、专业词典向专业分类系统的映射I、CS标准向专业领域分类系统的映射等。映射实验结果表明,专业领域分类系统对于机器翻译专业词典具有良好的覆盖性。 ",MESS200701002
利用音译和网络挖掘翻译命名实体, ,7,人工智能; 机器翻译; 音译; 命名实体翻译; 网络挖掘;,"本文提出了一种新颖的方法,综合利用音译和网络挖掘来提高命名实体翻译的效果。具体而言,首先利用音译模型生成一个候选翻译,然后利用音译信息配合网络挖掘获得更多的候选翻译。最后,使用最大熵(MaximumEntropy)模型综合考虑源词和候选翻译之间的各种特征,如发音相似度,上下文本特征,网页共现关系等,来排序得到的候选翻译,从而决定最终的翻译结果。实验结果显示我们的方法显著的提高了命名实体翻译的精确度。 ",MESS200701003
跨语言相似文档检索,,8,计算机应用; 中文信息处理; 跨语言相似文档检索; 文档相似度; 双语文档对齐;,"检索一篇文档在其他语言中的译文对于双语平行语料库的建立是一件很有意义的工作。本文提出一种改进的跨语言相似文档检索算法,该算法使用双语词典或统计翻译模型作为双语知识库,查找两篇文档的共同翻译词对,把翻译词对的权重作为一种特征来进行相似度计算,用Dice方法的改进算法计算双语文档的相似度。在实验中,统计检索文档的译文排在检索结果前N位的总次数来评价算法的性能,并使用了两个噪音数据集来评价算法的有效性。实验表明,在噪音数据干扰比较大的情况下,译文排在检索结果前5位的译文结果接近90%。实验证明,翻译词对的权重对于相似度计算有很大帮助,本算法可以有效地发现一种语言书写的文档在另一种语言中的译稿。 ",MESS200701004
基于中文机构名简称的检索方法研究,钟良伍:08188525|郑方:11701670,5,计算机应用; 中文信息处理; 多级索引; 模糊匹配; 分词算法;,"对于是否是中文机构名或机构名简称的自动判别,已经有广泛和深入的研究;但是对机构名简称和全称的匹配,目前鲜有研究成果。本文针对基于中文机构名简称的检索方法,研究了机构名的结构特征,总结出两种规则,定制了一个基于关键词类的分词工具,提出简称和全称匹配的一种算法,并且结合多级索引技术,实现了基于中文机构名简称的检索系统。实验结果表明,本文所提方法的准确性较好,首选准确率达到近95%,在全称机构名总数达到51万的情况下,检索平均耗时约0.21秒,达到实用要求。 ",MESS200701005
基于段落匹配和分布密度的偏重摘要实现机制,林鸿飞:06504899|杨志豪:06508715|赵晶:06523490,6,计算机应用; 中文信息处理; 文本摘要; 偏重摘要; 同义扩充; 段落匹配; 分布密度;,"本文提出了基于段落匹配和分布密度的偏重文本摘要实现机制,旨在满足摘要的个性化要求。首先在关键字同义扩充的基础上,利用基于侧面相似度的段落匹配方法,获取相关的文本段落集合。然后通过计算文本窗口的分布密度函数,获取关键字集聚区域,依据覆盖区域的句子权重,输出的最终偏重摘要。最后进行了评价实验,通过问答测验和相似比较,效果良好,而且表明偏重摘要对于多主题文本更为有效。 ",MESS200701006
基于SDC特征和GMM-UBM模型的自动语种识别,姜洪臣:11507922|郑榕:11602010|张树武:11658015|徐波:10983611,5,计算机应用; 中文信息处理; SDC特征; GMM-UBM模型; 贝叶斯自适应; 自动语种识别;,"本文提出了一种基于SDC特征和GMM-UBM模型的自动语种识别方法。SDC特征由许多语音帧的一阶差分谱连接扩展而成,与传统的MFCC特征相比,包含了更多的时序特征信息。UBM模型反映了所有待识别语种的特征分布特性,借助贝叶斯自适应算法可以快速得到每个语种的模型。与传统的GMM方法相比,该方法的训练和识别的速度更快。该方法对OGI电话语音库中11个语种进行了测试,其10秒、30秒和45秒句子的最佳识别正确率分别为72.38%、82.62%和85.23%,识别速度约为0.03倍实时。 ",MESS200701007
基于约束模型的韵律短语预测,董宏辉1:10983611|陶建华1:11607992|徐波2:11672781,6,计算机应用; 中文信息处理; 语法约束; 长度约束; 韵律短语;,"本文提出了基于语法约束和长度约束的韵律短语预测模型。在语法约束模型中,我们引入了组块作为基本的节律分析单元。韵律短语的长度约束模型是利用隐马尔科夫模型对语句中韵律短语的长度规划进行建模,这个模型对短语的长度分布及韵律词与韵律短语的关系进行了描述。最后,利用一个称为k-候选的方法来融合这两个约束模型。整个方法充分利用了韵律短语的语法约束和长度约束,并将之有机地结合起来。试验表明,该预测模型达到了很好的效果,韵律短语边界识别的调和平均值达到82.9%。 ",MESS200701008
一种支持多语言文本布局方向的文档处理模型,贾彦民:10830205|吴健:09573880,7,计算机应用; 中文信息处理; 文档格式化; 文本布局方向; 文字处理;,"文档处理是文字处理的关键组成部分,针对多语言混合排版的需求,本文提出了基于“框”的支持不同方向的多语言文本布局的文档处理模型。该模型把对文本布局方向的处理封装在文档格式化模块中,将多文本布局方向的问题规约为文本布局方向为从左向右(水平)的文档格式化的问题,并设计了多文本布局方向文档格式化的递归算法。该模型可以很好支持包括我国民族文字蒙古文、维吾尔文、藏文在内的各种不同书写方向文字的文本布局。 ",MESS200701009
试论汉字数字输入法评价,周克兰:11497680|吕强:09891152|张玉华:05970941|潘吉斯:09891719|钱培德:09887587,7,计算机应用; 中文信息处理; 数字输入法; 重码键选率; 输入法软件功能;,"GB18031对如何科学评价数字输入法起到非常重要的指导作用。但是GB18031的部分性能指标在执行时存在一定的难度。数字输入法软件功能至今缺乏相应的国家标准。建立科学的数字输入法软件功能国家标准成为相当迫切的问题。本文讨论了GB18031中规定的易学性的可判定性,并对重码键选率的执行难点进行了定量分析。本文还分析了面向普及型汉字录入人员的数字输入法的特点,对进一步完善GB18031提出了具体的建议。本文还说明了建立数字输入法功能国家标准的必要性,对如何建立数字输入法功能国家标准进行了初步研究。 ",MESS200701010
汉语拼音的短韵母编码与汉字输入,,5,计算机应用; 中文信息处理; 汉语拼音方案; 声母韵母; 数字键盘的汉字输入; 拼音输入法;,"《汉语拼音方案》在中文信息处理中具有重要地位,拼音输入法更是电脑汉字输入的大众化方法。由于韵母采用1~4个字母,显得长短不齐。本文提出短韵母编码方案,除原来单字母韵母外,其他韵母用{aoeiuv}中的两个字母来表示,使得拼音编码变短。由于韵母采用的字母与声母采用的20个字母不同,在键盘输入汉字时可以采用“声韵声”方式输入词组。此方案可用于字母键盘,在数字键盘更有优势。声调的4个键与短韵母编码的6个键互不相同,拼音串输入时容易切分各字拼音,即使省略了韵母。每对模糊音设有3个数字键盘编码,以方便部分字音需要模糊的用户。 ",MESS200701011
中文语义角色标注的特征工程,刘怀军:06994824|车万翔:11456266|刘挺:06987220,6,计算机应用; 中文信息处理; 语义分析; 语义角色标注; 特征工程; 最大熵分类器;,"基于统计机器学习的语义角色标注在自然语言处理领域越来越受到重视,丰富多样的特征直接决定语义角色标注系统的性能。本文针对中文的特点,在英文语义角色标注特征的基础上,提出了一些更有效的新特征和组合特征:例如,句法成分后一个词、谓语动词和短语类型的组合、谓语动词类别信息和路径的组合等,并在Chinese Proposition Bank(CPB)语料数据上,使用最大熵分类器进行了实验,系统F-Score由89.76%增加到91.31%。结果表明,这些新特征和组合特征显著提高了系统的性能。因此,目前进行语义角色标注应集中精力寻找丰富有效的特征。 ",MESS200701012
统计机器翻译中短语切分的新方法,,5,人工智能; 机器翻译; 统计机器翻译; 翻译模型; 短语切分;,"基于短语的统计机器翻译是目前主流的一种统计机器翻译方法,但是目前基于短语的翻译系统都没有对短语切分作专门处理,认为一个句子的所有短语切分都是等概率的。本文提出了一种短语切分方法,将句子的短语切分概率化:首先,识别出汉语语料库中所有出现次数大于2次的词语串,将其作为汉语短语;其次,用最短路径方法进行短语切分,并利用Viterbi算法迭代统计短语的出现频率。在2005年863汉英机器翻译评测测试集上的实验结果(BLEU4)是:0.1764(篇章),0.2231(对话)。实验表明,对于长句子(如篇章),短语切分模型的加入有助于提高翻译质量,比原来约提高了0.5个百分点。 ",MESS200701013
基于知网的中文问题自动分类,孙景广:09718345|蔡东风:08670703|吕德新:10928205|董燕举:11069180,6,计算机应用; 中文信息处理; 问答系统; 问题分类; 知网; 最大熵模型; 分类特征;,"问答系统应能用准确、简洁的答案回答用户用自然语言提出的问题。问题分类是问答系统所要处理的第一步,分类结果的正确率直接影响后续工作的进行。本文提出了一种使用知网作为语义资源选取分类特征,并使用最大熵模型进行分类的新方法。该方法以问题的疑问词、句法结构、疑问意向词、疑问意向词在知网中的首义原作为分类特征。实验结果表明,在知网中选取的首义原能很好的表达问题焦点词的语义信息,可作为问题分类的一个主要特征。该方法能显著地提高问题分类的精度,大类和小类的分类精度分别达到了92.18%和83.86%。 ",MESS200701014
基于语义理解的文本倾向性识别机制,徐琳宏:11554092|林鸿飞:06504899|杨志豪:06523490,5,计算机应用; 中文信息处理; 倾向性识别; 知网; 语义相似度; 否定句; 程度副词;,"文本倾向性识别在垃圾邮件过滤、信息安全和自动文摘等领域都有广泛的应用。本文提出了基于语义理解的文本倾向性识别机制。其主要思想是首先计算词汇与知网中已标注褒贬性的词汇间的相似度,获取词汇的倾向性;再选择倾向性明显的词汇作为特征值,用SVM分类器分析文本的褒贬性;最后采用否定规则匹配文本中的语义否定的策略提高分类效果,同时处理程度副词附近的褒义词和贬义词,以加强对文本褒贬义强度的识别。 ",MESS200701015
基于非连续短语的统计翻译模型研究,张大鲲:09658372|张玮:10352504|冯元勇:11694024|孙乐:11437472,8,人工智能; 机器翻译; 非连续短语; 统计机器翻译; 短语模型;,"目前统计机器翻译的主流方法仍然是基于短语的翻译模型。然而,该模型并没有考虑对非连续短语的处理。本文提出了一种基于非连续短语的统计翻译模型,利用该模型可以使翻译的基本单元从连续短语扩展到带有间隔的非连续短语,以更好地解决词语翻译时的上下文依赖问题。同时,由于该方法抽取的短语数量较少,也使得解码的效率得到了提高。实验表明,在效率提高的情况下,非连续短语模型可以取得与层次型短语模型相当的翻译结果。 ",MESS200701016
基于大规模日志分析的搜索引擎用户行为分析,余慧佳1:11444250|刘奕群1:08176974|张敏1:08186086|茹立云2:16527346|马少平1:08177513,6,计算机应用; 中文信息处理; 网络信息检索; 搜索引擎; 用户行为分析; 点击信息分析;,"用户行为分析是网络信息检索技术得以前进的重要基石,也是能够在商用搜索引擎中发挥重要作用的各种算法的基本出发点之一。为了更好的理解中文搜索用户的检索行为,本文对搜狗搜索引擎在一个月内的近5 000万条查询日志进行了分析。我们从独立查询词分布、同一session内的用户查询习惯及用户是否使用高级检索功能等方面对用户行为进行了分析。分析结论对于改进中文搜索引擎的检索算法和更准确的评测检索效果都有较好的指导意义。 ",MESS200701017
《中文信息学报》征稿简则,,1, , ,MESS200701018
中文Base NP识别:错误驱动的组合分类器方法,徐昉1:11650643|宗成庆1:10815045|王霞2:11181882,5,计算机应用; 中文信息处理; 错误驱动; 中文BaseNP识别; 组合分类器;,"本文采用一种新的错误驱动的组合分类器方法来实现中文Base NP识别。本文首先对中文和英文BaseNP识别技术现状进行了简要分析和概述,明确了中文Base NP识别的任务,然后,基于前人的工作提出了错误驱动的组合分类器方法,其基本思路是:通过对比两种不同类型的分类器—基于转化的方法和条件随机场方法的分类结果,再利用支持向量机学习其中的错误规律,对两分类器产生的不同结果进行纠错,从而达到提高系统整体性能的效果。我们在宾州中文树库转化得到的Base NP语料集上进行了Base NP识别交叉验证实验,与单独使用基于转化的方法、条件随机场方法以及支持向量机方法相比较,错误驱动的组合分类器方法的实验结果都有所提高,最佳结果F值达到了89.72%,相对于文中Base NP识别的其他方法,最大提高幅度为2.35%。 ",MESS200701019
词汇化句法分析与子语类框架获取的互动方法,冀铁亮:06244170|穗志方:06268960,7,计算机应用; 中文信息处理; 词汇化概率句法分析; 子语类框架; 词汇知识自动获取;,"概率句法分析器(PCFG Parser)是基于概率规则集的上下文无关文法的句法分析器。规则集主要是针对词类和短语类。然而事实上,词性相同而词汇不同,其所常用的句法规则也通常不同。目前NLP研究的一个趋势和热点就是词汇化的句法分析。针对概率句法分析独立性假设中缺乏词汇化的缺陷,本文将谓语动词的子语类信息与概率句法分析结合起来,提出一种基于动词子语类信息的词汇化概率句法分析方法。论文建立了基于汉语动词子语类框架的统计句法分析模型,并且针对动词子语类框架难以获取的问题,提出一种词汇化概率句法分析与动词子语类框架获取的互动方法。实验利用这种互动的方法获取了汉语中十个常用高频动词的概率化子语类信息,并结合原有的概率句法分析器PCFG实现了一个基于动词子语类信息的概率句法分析器原型系统S-PCFG。实验证明了基于动词子语类信息的概率句法分析对自然语言句法分析的准确率和速度均有所提高。同时分析了新的概率句法分析器的不足之处,为进一步的改进提供条件。 ",MESS200701020
《中国语言生活状况报告(2005)》由商务印书馆出版,,1, , ,MESS200701022
基于双层决策的新闻网页正文精确抽取,胡国平:09578638|张巍:10336843|王仁华:09504972,10,计算机应用; 中文信息处理; 信息抽取; 特征向量; 决策树; 正文抽取;,"本文提出了基于双层决策的新闻网页正文的精确抽取算法,双层决策是指对新闻网页正文所在区域的全局范围决策和对正文范围内每段文字是否确是正文的局部内容决策。首先根据实际应用的需要给出了新闻网页正文的严格界定,然后分析了新闻网页及其正文的特性,提出了基于双层决策的正文抽取策略,基于特征向量提取和决策树学习算法对上述双层决策进行了建模,并在国内10个主要新闻网站的1687个新闻页面上开展了模型训练和测试实验。实验结果表明,上述基于双层决策的方法能够精确地抽取出新闻网页的正文,最终正文抽取与人工标注不完全一致的网页比例仅为18.14%,比单纯局部正文内容决策的方法相对下降了29.85%,同时抽取误差率大于10%的网页比例更是仅为7.11%,满足了实际应用的需要。 ",MESS200606000
应用于长频繁集挖掘的基于变动邻域搜索的遗传算法设计,章舜仲1:09638848|王树梅1:08059511|黄河燕2:05975602|陈肇雄2:08740667,7,计算机应用; 中文信息处理; 遗传算法; 频繁集; 搜索空间; 邻域搜索; apriori性质;,"提出了一种基于变动邻域搜索的长频繁集挖掘方法(VNS-GA),利用遗传算法的高效搜索性能快速挖掘最大频繁集。在遗传算法的适应度函数设计中,综合考虑项集支持度、长度以及项集支持度和邻域中心支持度的距离,算法一次运行可找出邻域内的最大频繁集,改变邻域中心即可找到我们需要的最大频繁集。算法有效性通过实验得到了验证,且实验表明该算法的时间复杂度与支持度阈值大小无关,因此对于长模式挖掘问题具有很高的效率。 ",MESS200606001
基于SVM的组块识别及其错误驱动学习方法,黄德根:06527360|王莹莹:11566944,8,计算机应用; 中文信息处理; 组块分析; 错误驱动学习; 支持向量机(SVM); 规则集;,"给出了一种错误驱动学习机制与SVM相结合的汉语组块识别方法。该方法在SVM组块识别的基础上,对SVM识别结果中的错误词语序列的词性、组块标注信息等进行分析,获得候选校正规则集;之后按照阈值条件对候选集进行筛选,得到最终的校正规则集;最后应用该规则集对SVM的组块识别结果进行校正。实验结果表明,与单独采用SVM模型的组块识别相比,加入错误驱动学习方法后,组块识别的精确率、召回率和F值均得到了提高。 ",MESS200606002
一种基于词汇链的关键词抽取方法,,6,计算机应用; 中文信息处理; 关键词标引; 关键词抽取; 词汇链; 词义相似度; 知网;,"关键词在文献检索、自动文摘、文本聚类/分类等方面有十分重要的作用。词汇链是由一系列词义相关的词语组成,最初被用于分析文本的结构。本文提出了利用词汇链进行中文文本关键词自动标引的方法,并给出了利用《知网》为知识库构建词汇链的算法。通过计算词义相似度首先构建词汇链,然后结合词频与区域特征进行关键词选择。该方法考虑了词汇之间的语义信息,能够改善关键词标引的性能。实验结果表明,与单纯的词频、区域方法相比,召回率提高了7.78%,准确率提高了9.33%。 ",MESS200606003
自动获取汉语词语搭配,,7,计算机应用; 中文信息处理; 词语搭配; 互信息; 熵;,"作为一种词汇现象,词语搭配在自然语言处理的许多领域具有重要的应用。本文对4种词语相关性度量和3种词语结构分布度量分别进行了比较分析,并提出了一种基于互信息与熵融合的获取词语搭配的方法。实验结果表明:在同现频率较高情况下,互信息、Cosine系数、x2测试和似然比测试4种相关性度量对搭配判定有大致相同的效果;在度量词语的结构分布方面,熵要优于方差和离散度。本文所提方法依赖度量指标少,阈值容易选取,且与其他已有的方法具有同等效果。 ",MESS200606004
基于词语属性的计算机辅助获取流行词语研究,,8,计算机应用; 中文信息处理; 流行词语; 词语活动能力; 走势曲线图;,"本文以2005年的1月1日至6月25日新浪网上下载的各类页面上的文本内容为研究资源集合,从中提取出有效词语,对词语的流行程度的判定属性做了定性定量的分析研究,对词语的流行特性进行了定义,在此基础上,引入衡量关注程度的量化方法,并配合依据词语判定属性与时间关系而绘制的走势曲线图,设置淘汰机制与评分机制,得到了候选流行词语,验证了流行词语判定属性规范的合理性,为机器辅助判定词语特性提供了参考数据。 ",MESS200606005
一种基于演化算法进行句子抽取的多文档自动摘要系统SBGA,,8,计算机应用; 中文信息处理; 多文档自动摘要; 演化算法; 句子抽取; 评价函数; TFS;,"SBGA系统将多文档自动摘要过程视为一个从源文档集中抽取句子的组合优化过程,并用演化算法来求得近似最优解。与基于聚类的句子抽取方法相比,基于演化算法进行句子抽取的方法是面向摘要整体的,因此能获得更好的近似最优摘要。演化算法的评价函数中考虑了衡量摘要的4个标准:长度符合用户要求、信息覆盖率高、更多地保留原文传递的重要信息、无冗余。另外,为了提高词频计算的精度,SBGA采用了一种改进的词频计算方法TFS,将加权后词的同义词频率加到了原词频中。在DUC2004测试数据集上的实验结果表明,基于演化算法进行句子抽取的方法有很好的性能,其ROUGE-1分值比DUC2004最优参赛系统仅低0.55%。改进的词频计算方法TFS对提高文档质量也起到了良好的作用。 ",MESS200606006
基于Web的文摘技术研究,耿增民:06341301|贾云得:06347971|刘万春:06346131|朱玉文:06349499,8,计算机应用; 中文信息处理; Web文摘; 文本文摘; Web文档预处理; 文摘后处理;,"W eb文档的迅猛增长使W eb文摘技术成了当今的一个研究热点。由于W eb文档的特殊性,使得W eb文摘不同于传统的文本自动文摘。本文分析了W eb文档的特点;给出了W eb文摘的定义;提出了基于句子抽取的W eb文摘生成算法。算法中将每个W eb句子权重分解为W eb特征词权重和W eb句子结构权重,并用机器学习的方法来计算二者所占的比重。W eb特征词权重根据文档分类树图进行权值调整,W eb句子结构权重充分考虑排版格式和超连接属性。通过对1000篇W eb文档的文摘实验,证明文中所提W eb文摘算法切实可行。 ",MESS200606007
基于语义分析的作者身份识别方法研究,武晓春:06705247|黄萱菁:11586438|吴立德:06698167,8,计算机应用; 中文信息处理; 身份识别; 语义分析; 文档相似度;,"作者身份识别是一项应用广泛的研究,身份识别的关键问题是从作品中提取出代表语体风格的识别特征,并根据这些风格特征,评估作品与作品之间的风格相似度。传统的身份识别方法,主要考察作者遣词造句、段落组织等各种代表文体风格的特征,其中基于标点符号和最常见功能词频数的分析方法受到较为普遍的认同。本文依据文体学理论,利用HowNet知识库,提出一种新的基于词汇语义分析的相似度评估方法,有效利用了功能词以外的其他词汇,达到了较好的身份识别性能。 ",MESS200606008
手写中文地址识别后处理方法的研究,,6,人工智能; 模式识别; OCR; 语言模型; 后处理;,"OCR(光学字符识别技术)作为方便有效的字体识别技术,在办公自动化、信息恢复、数字图书馆等方面发挥着日益重要的作用。语言模型在OCR后处理,特别是在中文的文字识别后处理方面有着广泛的应用。本文针对手写中文地址的后处理,讨论了语言模型的粒度对识别正确率的影响,分析了基于字和基于词的语言模型各自的优点和缺点,并采用了基于词的语言模型,在此基础上提出了加权词图搜索算法。实验证明,在58269条中文手写地址的测试集上,手写地址的整体识别率由原来的28.56%上升到了75.66%,错误率下降了65.93%,大大提高了系统的性能。 ",MESS200606009
基于特征规整和评分规整的说话人确认研究,郑榕:11602010|张树武:11658015|徐波:10983611,8,计算机应用; 中文信息处理; 说话人确认; 特征规整; 评分规整; NIST说话人评测;,"在说话人确认系统中,训练和测试的声学环境不匹配将造成性能急剧下降。本文提出了从特征规整和评分规整两个方面进行补偿的方法。首先,改进了基于分段的倒谱均值方差规整(SCMVN)方法,将倒谱系数都规整到相同的段内高斯统计分布,以提高不同环境条件下特征匹配程度;其次,针对由于不同说话人和不同测试环境引起的输出评分分布变化,提出了两阶段的评分规整方法,即先零规整再测试规整(TZnorm)和先测试规整再零规整(ZTnorm)两种得分变换方法,使得失配条件下与说话人无关的决策门限更加鲁棒。基于NIST2002说话人识别评测库上的实验表明,采用SCMVN的特征规整和ZTnorm的评分规整方法能够明显地提高系统性能。与采用倒谱均值减和零规整的基线系统相比,等错误率和最小检测代价分别降低了20.3%和18.1%。 ",MESS200606010
汉语连续语音中HMM模型状态数优化方法研究,何珏:10560054|刘加:08175975,6,计算机应用; 中文信息处理; 声学模型; 隐型Markov模型; 语音识别;,"为了优化汉语连续语音中HMM模型系统以提高识别性能,提出了分别为每个声母和韵母半音节声学模型选择最优的状态数的方法。通过综合考虑每个声母和韵母半音节声学模型在不同状态数下的段长均值、方差以及各自识别率这三者信息,作为进行最优模型状态数的选择准则。优化后的声学模型系统由状态数各不相同的声母半音节声学模型组成,同未优化前状态数统一的模型系统相比,音节识别性能提高了5.07个百分点。研究表明,每个声母和韵母半音节志学模型应根据情况选择不同的状态数,优化后的模型系统识别性能得到了提高。 ",MESS200606011
普通话水平测试电子化系统,魏思:09540699|刘庆升:09578638|胡郁:10894587|王仁华:09506428,8,计算机应用; 中文信息处理; 普通话水平测试; 语音评测; 普通话水平测试数据库; 电子化系统;,"普通话水平测试电子化系统有助于高效地进行普通话水平测试。本文在100小时标准发音人数据库的基础上,针对汉语发音特点,利用语言学专家知识,引入语料选择的自适应算法改进了传统的语音评测算法。在500人普通话水平测试数据库上的测试结果表明,新评测算法能有效提升评测性能。经过分段线性映射,机器评分和人工评分的误差(2.44)和人工与人工评分之间的误差(2.30)相当。这表明可以使用机器代替人工进行普通话水平测试的前三项评分工作。 ",MESS200606012
ISO 2022的有限状态机描述,谢谦:14056745|芮建武:09573880|吴健:09573886,7,计算机应用; 中文信息处理; 编码字符集; ISO2022; 有限状态机;,"ISO 2022编码体系对字符集国家标准的制订有很大影响,然而标准条款存在不确定性,有时难于理解。本文引入有限状态机(FSM)模型来形式化地刻画ISO 2022的特征。针对FSM五元组,详细说明了其状态空间的构成,提出了输入字母表的等效分类方法,给出了初始状态以及终结状态集合,分析了状态转移函数的规模,并采用FSM描述方法分析了ISO-2022-CN、EUC-CN、复合文本等标准,揭示了这些标准与ISO 2022的内在联系。这些工作有助于ISO 2022标准符合性检测、扩展标准的制订与系统实现复杂度评估。鉴于形式化描述方法在编码字符集标准领域未得到广泛应用,本文工作为该类研究引入了新的思路和方法。 ",MESS200606013
一个适用于手持设备的多层汉字输入法模型,朱晓旭:09882340|李培峰:08869654|朱巧明:09886822|刁红军:09891804,5,计算机应用; 中文信息处理; 手持设备; 汉字输入法;,"随着以PDA和智能手机为代表的手持设备快速发展,汉字输入法选择余地小的缺点已经成为影响其普及的障碍之一。究其原因是手持设备中的操作系统和物理设备类型多,而开发的汉字输入法在不同手持设备中不通用,造成开发效率低。本文介绍了一个适用于手持设备的多层的通用汉字输入法模型,详细描述了模型中每一层的功能和特点,讲解了如何基于该模型实现一个输入法,并概要论述了本模型的优点。 ",MESS200606014
《中文信息学报》征稿简则,,1, , ,MESS200606015
基于双层决策的新闻网页正文精确抽取,胡国平:09578638|张巍:10336843|王仁华:09504972,10,计算机应用; 中文信息处理; 信息抽取; 特征向量; 决策树; 正文抽取;,"本文提出了基于双层决策的新闻网页正文的精确抽取算法,双层决策是指对新闻网页正文所在区域的全局范围决策和对正文范围内每段文字是否确是正文的局部内容决策。首先根据实际应用的需要给出了新闻网页正文的严格界定,然后分析了新闻网页及其正文的特性,提出了基于双层决策的正文抽取策略,基于特征向量提取和决策树学习算法对上述双层决策进行了建模,并在国内10个主要新闻网站的1687个新闻页面上开展了模型训练和测试实验。实验结果表明,上述基于双层决策的方法能够精确地抽取出新闻网页的正文,最终正文抽取与人工标注不完全一致的网页比例仅为18.14%,比单纯局部正文内容决策的方法相对下降了29.85%,同时抽取误差率大于10%的网页比例更是仅为7.11%,满足了实际应用的需要。 ",MESS200606000
基于规则和统计的中文自动文摘系统,傅间莲:08164877|陈群秀:08167062,7,计算机应用; 中文信息处理; 自动文摘; 向量空间模型; 主题划分; 可读性; 评价;,"自动文摘是自然语言处理领域里一个重要课题,本文在传统方法基础上提出了一种中文自动文摘的方法。在篇章结构分析里,我们提出了基于连续段落相似度的主题划分算法,使生成的文摘更具内容全面性与结构平衡性。同时结合了若干规则对生成的文摘初稿进行可读性加工处理,使最终生成的文摘更具可读性。最后提出了一种新的文摘评价方法(F-new-m easure)对系统进行测试。系统测试表明该方法在不同文摘压缩率时,评价值均较为稳定。 ",MESS200605001
一种快速获取领域新词语的新方法,刘华:07758375,7,人工智能; 自然语言处理; 新词语; 识别; 聚类;,"本文提出一种新词语识别新方法。该方法直接抽取分类网页上人工标引的关键词,并按照其网页栏目所属类目存储进各分类词表,从而快速完成新词语识别和聚类任务。该方法简单快捷。我们利用该方法从15类6亿字网页中抽取到229237个词条,其中新词语175187个,新词率为76.42%,其中游戏类新词率最高,时政_社会类新词率最低。新词语以命名实体为主,结构固定,意义完整性和专指性强,有助于解决歧义切分和未登录词问题,并能提高文本表示如分类和关键词标引的效果。 ",MESS200605002
双数组Trie树算法优化及其应用研究,王思力:10348504|张华平:09559997|王斌:09560076,7,计算机应用; 中文信息处理; 双数组; Trie树; 词典; 分词;,"本文对双数组Trie树(Doub le-Array Trie)算法提出了一种优化策略,即在采用Trie树构造数组的过程中,优先处理分支结点数更多的结点。这种优化策略可以在保证该算法数据查找效率不变的同时,进一步减少数据稀疏,提高空间利用率。我们基于该优化算法实现了一个词典管理程序,并与利用其他索引机制的词典进行了实验对比。实验结果表明,利用优化的双数组Trie树算法的词典不仅在查询速度上优于用其他索引机制的词典,而且存储数据的空间占用也比较小。 ",MESS200605003
汉语词典的快速查询算法研究,李江波:08225570|周强:08174297|陈祖舜:08836151,9,计算计应用; 中文信息处理; 汉语词典查询; 双数组TRIE; 双编码算法;,"汉语词典查询是中文信息处理系统的重要基础部分,对系统效率有重要的影响。本文对汉语词典查询算法研究作了简要回顾,设计实现了基于双数组TR IE机制的汉语词典查询算法,并提出了基于双编码机制的词典查询算法。最后以逐字二分法查询性能为基准,使用这两种词典询机制进行了词语直接查询和分词查询两种应用的性能测试。经过实验分析,双数组TR IE机制的词典查询算法在查询速度上提高明显,查询速度约是逐字二分法的5倍。双编码机制的的词典查询算法查询速度有一定提高,而且调整机制更加灵活。 ",MESS200605004
一种基于信息熵的中文高频词抽取算法,任禾:15237437|曾隽芳:11063983,5,人工智能; 自然语言处理; 分词; 中文抽词; 信息熵; 高频词;,"为扩展分词词典,提高分词的准确率,本文提出了一种基于信息熵的中文高频词抽取算法,其结果可以用来识别未登录词并扩充现有词典。我们首先对文本进行预处理,将文本中的噪音字和非中文字符转化为分隔符,这样文本就可以被视为用分隔符分开的中文字符串的集合,然后统计这些中文字符串的所有子串的相关频次信息,最后根据这些频次信息计算每一个子串的信息熵来判断其是否为词。实验证明,该算法不仅简单易行,而且可以比较有效地从文本中抽取高频词,可接受率可达到91.68%。 ",MESS200605005
边界模板和局部统计相结合的中国人名识别,李中国:15171726|刘颖:08230768,7,计算机应用; 中文信息处理; 人名识别; 命名实体识别; 边界模板; 局部统计量; 词法分析;,"本文提出了一种基于篇章信息的中国人名识别算法。我们从标注语料中提取人名左右边界词语及人名用字频度作为系统知识源。识别过程是:首先利用带有频度的边界模板识别出可能的人名,并把识别结果扩散到整篇文章以召回数据稀疏导致的遗漏人名。然后应用上下文局部统计量及几条启发式规则对识别结果进行边界校正。该算法具有线性时间复杂度,大规模开放测试(针对1354篇新闻报道约304万字,含人名3.7万个)的正确率为94.52%,召回率为98.97%,效果非常令人满意。 ",MESS200605006
中文语言资源联盟,,2, , ,MESS200605007
SVM与规则相结合的中文地名自动识别,李丽双:06527360|黄德根:06525741|陈春荣:06507781|杨元生:06521783,7,计算机应用; 中文信息处理; 中文地名识别; 支持向量机; 机器学习; 基于规则的后处理;,"在分析中文文本中地名特点的基础上,提出了一种支持向量机(SVM)与规则相结合的中文地名自动识别方法:按字抽取特征向量的属性,然后将这些属性转换成二进制向量并建立训练集,采用多项式Kernel函数,得到SVM识别地名的机器学习模型;通过对错误识别结果的分析,构建规则库对识别结果进行后处理,弥补了机器学习模型获取知识不够全面导致召回率偏低的不足。实验表明,用SVM与规则相结合的机制识别中文文本中的地名是有效的:系统开式召回率、精确率和F-值分别达89.57%、93.52%和91.50%。 ",MESS200605008
面向连续字符识别的手写汉字部件集及统计规律,赵巍:06989508|李春娣:06988238|刘家锋:07004232|唐降龙:06997946,7,人工智能; 模式识别; 连续字符识别; 手写汉字部件; 对数正态分布;,"本文面向手写字符序列输入信号连续识别研究,分析了汉字及联机手写文本的特点,提出并构建了手写汉字部件集。基于该部件集,完成了GB2312-80的6,763个汉字的部件拆分编码和部件集的测试。统计编码数据发现,汉字依手写部件数的分布规律呈对数正态分布。本文从统计学和字符识别技术的角度对手写部件的构字能力作了分析和讨论,部件集的设计方案在部件选择和汉字拆分上均满足设计要求。实验表明,基于手写部件构造的部件识别器对手写汉字和连续汉字的部件识别率分别达到70.21%和58.49%。 ",MESS200605009
基于高阶统计的手写字符形变弹性匹配法,马瑞:05967691|杨静宇:08058220,6,人工智能; 模式识别; 手写字符识别; 高阶统计; 弹性匹配; 内在形变; 独立分量分析(ICA);,"针对传统弹性匹配法在手写字符识别中存在着由于过匹配而造成误识别的不足,提出一种基于高阶统计的形变弹性匹配法。根据高阶统计量包含字符形状上的细节变化信息,采用独立分量分析抽取出每个字符类的内在变化方向,并将其应用到弹性匹配的形变模型中。字符的任意种形状变化由这组独立分量的线性叠加来表示。通过形变模型,类模板字符发生形变逐次向输入待识别字符趋近,从而在两个字符之间求得一种最佳匹配。在实验结果中,识别率达到92.81%,得到了提高,表明该方法的有效性。 ",MESS200605010
基于时域单元融合的拼接平滑算法,郭武:09539908|吴义坚:11678826,6,计算机应用; 中文信息处理; 时域单元融合; 拼接单元; 融合单元;,"针对基于大语料库的拼接合成系统中经常出现的拼接单元不匹配问题,特别是浊音拼接处不匹配对合成效果会产生较大的损伤,本文提出一种基于时域单元融合技术的平滑算法。它通过模板匹配选取合适的过渡段模板作为融合单元,并同时进行相位对齐,然后采用TD-PSOLA的方法对拼接单元和融合单元进行时域上的基音同步迭加融合。它的优点是对音质损伤很小,而且直接在时域上进行,效率高。通过对平滑前后语谱及主观听感两个方面的对比评测,平滑后的效果比平滑前有明显改善。 ",MESS200605011
基于语音配列的汉语方言自动辨识,顾明亮1:09297977|沈兆勇2:09249636,6,计算机应用; 中文信息处理; GMM符号化器; N元语言模型; 汉语方言辨识;,"本文首先讨论了汉语方言辨识的依据及特征选取的基本原则,并由此导出了区间差分倒谱特征。然后利用GMM符号发生器和N元语言模型及ANN建立了一个方言辨识系统,该系统与传统的语种识别系统相比,具有以下特点:第一,系统不需要标注好的语音库,从而降低了汉语方言语音库建设的劳动强度和要求;第二,GMM符号化器计算量远远低于音素辨识器,从而提高了方言辨识速度,便于今后实时处理。第三,具有更高的辨识效果和更好的容错性。汉语普通话和三种方言辨识实验结果表明,系统平均辨识率可以达到83.8%。 ",MESS200605012
编码字符集标准及分类研究,谢谦:09573886|芮建武:14056745|吴健:09573880,8,计算机应用; 中文信息处理; 编码字符集;,"编码字符集标准是计算机处理文字信息的基础,本文提出了编码字符集三元组抽象,对现有编码字符集标准进行了简单回顾和总结,深入剖析了影响巨大的ISO 2022标准及其派生标准,对ISO 2022编码机制应用于多语言环境的局限性进行了探讨,阐明了使用通用编码字符集UCS的必要性,并对其进行了分析。探讨了现有编码分类方法存在的问题,引入了一种对编码字符集以及实现方法进行分类的新方法,使用该方法对现有标准进行了归类;最后对汉字字符集相关的国家标准进行了分析评介。 ",MESS200605013
一个基于ISO/IEC10646的汉字输入模型,李培峰:05968617|朱巧明:05970941|钱培德:09886822,6,计算机应用; 中文信息处理; 输入法模型; ISO/IEC10646; Unicode; 输入码对照表;,"计算机中各国文字编码的统一是必然趋势,而ISO/IEC 10646正是顺应这种趋势而诞生的一个国际标准。现有的输入法绝大多数是基于本地代码页(ANSI CODE),存在着移植困难、不能跨语言平台以及向国际化标准过渡困难等缺点。本文首先分析了现有本地化输入法存在的问题,并在此基础上阐述了基于ISO10646的汉字输入法的实现方法,并给出了一个以ISO 10646为核心的通用汉字输入法模型和原理,该模型由输入法管理/服务器、ISO 10646输入码对照表、码本检索/过滤模块、输入法与OS接口模块、输入法内核和本地化接口六部分构成。最后,本文重点论述了输入法的核心—输入码对照表的设计和检索技术。 ",MESS200605014
汉字输入编码优劣评测方法的探讨,孙基寿:07592140,8,计算机应用; 中文信息处理; 汉字编码; 评测方法; 轻松性; 速度潜力;,"字形编码的优劣必须进行科学的评测。编码规则的轻松性和速度潜力是评价字形编码优劣的两个关键指标。本文共分四部分,第一部分简单地陈述了什么是简单、规范、易学、轻松,提出了选择轻松的理由;第二部分通过具体的例子说明了导致轻松与不轻松的内在因素,提出了评测轻松的实验草案;第三部分分析了考核一种通用键盘汉字输入系统速度素质的现状,认为字形编码应将编码层次和软件层次分割开来进行性能考核,编码层次应评测编码规则的轻松性和速度潜力;第四部分从实践和理论两个方面分析了平均偏移量与速度潜力之间的关系,即平均偏移量越小,速度潜力就越大,并提出了反映速度潜力的参数指标。 ",MESS200605015
基于规则与统计相结合的中文文本自动查错模型与算法,张仰森1:06277175|曹元大2:05964615|俞士汶1:06272028,8,计算机应用; 中文信息处理; 中文文本自动查错; 规则与统计相结合; 非多字词错误; 真多字词错误;,"中文文本自动校对是自然语言处理领域具有挑战性的研究课题。本文提出了一种规则与统计相结合的中文文本自动查错模型与算法。根据正确文本分词后单字词的出现规律以及“非多字词错误”的概念,提出一组错误发现规则,并与针对分词后单字散串建立的字二元、三元统计模型和词性二元、三元统计模型相结合,建立了文本自动查错模型与实现算法。通过对30篇含有578个错误测试点的文本进行实验,所提算法的查错召回率为86.85%、准确率为69.43%,误报率为30.57%。 ",MESS200604000
引入标点处理的层次化汉语长句句法分析方法,李幸:15666685|宗成庆:10815045,8,人工智能; 自然语言处理; 句法分析; 标点符号; 层次化分析方法;,"在分析汉语标点符号用法和句法功能的基础上,本文提出了一种新的面向汉语长句的层次化句法分析方法。这种方法和传统的不考虑标点符号的一遍分析方法的主要区别在于两个方面:第一,利用部分标点符号的特殊功能将复杂长句分割成子句序列,从而把整句的句法分析分成两级来进行。这种“分而治之”的策略大大降低了在传统的一遍分析方法中同时识别子句或短语之间的句法关系以及子句和短语内部成分的句法关系的困难。第二,从大规模树库中提取包含所有标点符号的语法规则和相应概率分布信息,有利于句法分析和歧义消解。实验证明我们的方法与传统的一遍图表(chart)分析方法相比,能够大大减少时间消耗和歧义边的个数,并且提高了复杂长句分析的正确率和召回率约7%。 ",MESS200604001
隐喻的计算研究与进展,王治敏:06260491,9,计算机应用; 中文信息处理; 综述; 隐喻计算模型; 源域; 目标域; 隐喻概念;,"隐喻作为自然语言处理最棘手的问题之一逐渐引起了学者们的关注,国外学者在隐喻模型设计和隐喻知识库建设方面进行了很多尝试,也取得了一定效果。相比较而言,中文隐喻计算研究却显得有些薄弱,因此本文在传统隐喻研究的基础上综述了隐喻计算模型和隐喻知识库建设方面的进展,重点介绍了基于优选限制思想的M et5系统,基于实例方法的M IDAS系统,以及以统计为手段,基于大规模语料库提取的隐喻分析模型CorM et系统。通过总结国外的相关研究成果,探索面向信息处理的汉语隐喻形式化的研究方向。 ",MESS200604002
复述技术研究综述,刘挺:06994824|李维刚:06993862|张宇:06997645|李生:06989058,8,人工智能; 自然语言处理; 综述; 句子复述; 复述语料库; 复述抽取; 复述生成;,"复述是自然语言中比较普遍的一个现象,它集中反映了语言的多样性。复述研究的对象主要是短语或者句子的同义现象。自然语言处理各种底层技术的不断发展和成熟,为复述研究提高了可能,使之受到越来越多的关注。在英文和日文方面,复述技术已经被成功的应用到信息检索、自动问答、信息抽取、自动文摘以及机器翻译等多个领域,有效地提高了系统的性能。本文主要对复述实例库的构建、复述规则的抽取以及复述的生成等几方面的最新研究进展进行详细的综述,并简要介绍了我们在中文复述方面进行的初步研究工作。在文章的最后一部分,我们对复述技术的难点及未来的发展方向进行了展望,并对全文进行了总结。 ",MESS200604003
重新审视跨语言信息检索,闵金明:15681628|孙乐:00585957|张俊林:10352504,8,计算机应用; 中文信息处理; 跨语言信息检索; 未登录词; 词义消歧; 多语言信息检索;,"阻碍互联网资源在世界范围内广泛共享的一个主要障碍是多语言问题,而跨语言信息检索是解决这个问题的有效方法之一。本文从定义跨语言信息检索系统开始,给出了一个标准的跨语言信息检索系统框架和评价方法,对主流研究方法进行了重新审视,进一步明确指出了跨语言信息检索中必须解决的核心问题,最后通过分析研究现状给出了未来可能的重点研究方向。 ",MESS200604004
基于混合语言模型的文档相似性计算模型,李晓光:05968072|于戈:00098281|王大玲:06577763,8,人工智能; 自然语言处理; 文档相似性; 统计语言模型; 混合模型; EM算法;,"为了克服现有文档相似性模型对文档特性拟合的不完全性和缺乏理论根据的弱点,本文在统计语言模型的基础上,提出了一种基于混合语言模型(M ixture Language Model,MLM)文档相似性计算模型。MLM利用统计语言模型描述文档特征,将相关影响因素作为模型的潜在子模型,文档语言模型由各子模型混合构成,从而准确和全面地反映文档特征。由于MLM根据具体应用确定相关影响因素,并以此构建相应文档描述模型,因此具有很强的灵活性和扩展性。在MLM的基础上,本文给出了一个基于文档主题内容相似性的实例,在TREC9数据集上的实验表明MLM优于向量空间模型(VSM)。 ",MESS200604005
基于概念匹配的中文问答处理模型核心问题探讨,吴晨1:09550277|张全2:09634516,7,计算机应用; 中文信息处理; 中文问答系统; 语言概念空间; 核心问题研究; 概念匹配; 算法;,"为了解决问答处理系统中的语义模糊问题,提高问答处理的性能,研究人员尝试采用概念作为系统处理的对象,而不再是语言表层符号,然而,在引入概念进行处理的同时引来了一些新的问题,如概念的抽取、概念关联计算以及特定于问答系统的问题理解、问题求解、答案生成等问题。在概念抽取、概念关联计算方面,已有一些比较成功的算法。本文将在此基础上,针对实现这样一个问答处理系统所存在的一些未涉及的核心问题进行一个探讨,同时提出解决以上问题的方法。实验及实际应用表明基于所提出算法的概念问答系统具有较强的性能,系统总体自动处理准确率将近达到40%。在实际应用中也表现出较高的应用价值。 ",MESS200604006
蒙古语语言-文字的自动化处理,伊·达瓦1:15486918|张玉洁1:15323088|上园一知2:10337854,8,计算机应用; 中文信息处理; 蒙文语言文字信息处理; 文本-口语语料库; 多文种-多语言电子词典;,"本文首先叙述了蒙文电子化的意义以及蒙文电子化数据的现状。然后重点讨论了在不同地区和国家使用的蒙文书面语以及口语的不同和蒙文在计算机处理时所面临的问题。最后,介绍了我们在日本建设的针对蒙古语语言信息处理的两种语言资源:蒙古语多方言口语语料库和蒙文多文种-多语言并行语法标注电子词典,后者得到了2005年中日蒙韩国际合作课题“蒙文自然语言处理技术的研究”的资助。 ",MESS200604007
基于HMM的满文文本识别后处理的研究,赵骥1:06223233|李晶皎2:06572246|王丽君1:06216612|张继生1:06216663,5,计算机应用; 中文信息处理; 满文; 后处理; 模糊矩阵; 贝叶斯准则; 特征矢量;,"将满文单词识别系统的识别信息和满文的词组信息有机的结合起来,建立满文词组和待定词集统计信息库,采用基于统计的隐马尔可夫模型的方法,依据贝叶斯准则,综合满文待定词的后验概率和词组的先验概率信息,建立合理有效便于实现的数据结构,采用动态规划法对满文单词识别系统输出存在的拒识词和错识词进行检测和纠正,从而有效的提高满文文本识别系统的识别率。实验表明:后处理性能除取决于语言模型外,还取决于概率的精确估计。另外,在单词识别系统识别率高的情况下,后处理的纠错能力会增强。 ",MESS200604008
基于trigram语体特征分类的语言模型自适应方法,梁奇:11290263|郑方:08188525|徐明星:08239495|吴文虎:08834271,7,计算机应用; 中文信息处理; 统计语言模型; trigram; 自适应; 语体; 插值算法;,"本文从书面语和口语存在的差异出发,提出了语言模型的语体自适应方法。自适应采用了几种不同的计数意义上的插值算法。考虑Katz平滑的插值算法根据trigram单元的可信度来分配权值。基于trigram语体特征分类的自适应算法根据trigram单元的语体特征倾向动态分配权值,并选取了几种不同的权值生成函数。对口语语料做音转字的实验证明,使用这几种自适应算法可以让基准模型的性能有不同程度的提高,其中综合考虑单元可信度和特征倾向的算法效果最好,相对于本文的两个基准的汉字错误率下降率分别达到了50.2%和23.7%。 ",MESS200604009
基于HMM的可训练中文语音合成,吴义坚:09578638|王仁华:11678826,7,计算机应用; 中文信息处理; 语音合成; HMM; 可训练语音合成; 时长模型;,"本文将基于HMM的可训练语音合成方法应用到中文语音合成。通过对HMM建模参数的合理选择和优化,并基于中文语音特性设计上下文属性集以及用于模型聚类的问题集,提高其建模和训练效果。从对比评测实验结果来看,98.5%的合成语音在改进后其音质得到改善。此外,针对合成语音节奏感不强的问题,提出了一种基于状态和声韵母单元的两层模型用于时长建模和预测,集外时长预测RMSE由29.56m s降为27.01m s。从最终的合成系统效果来看,合成语音整体稳定流畅,而且节奏感也比较强。由于合成系统所需的存贮量非常小,特别适合嵌入式应用。 ",MESS200604010
一种新的基于主题的语言模型自适应方法,任纪生:08823377|王作英:00006332,6,计算机应用; 中文信息处理; 语言模型; 主题自适应; 语音识别; 文本分类;,"基于主题的语言模型自适应方法应尽可能提高语言模型权重系数的更新速度并降低语言模型的调用量以满足语音识别实时性要求。本文采用基于聚类的方法实现连续相邻二元词对的量化表示并以此刻画语音识别预测历史和各个文本主题中心,依据语音识别历史矢量和各个文本主题中心矢量的相似度更新语言模型权重系数并摒弃全局语言模型。同传统的基于EM算法的自适应方法相比,实验表明该方法明显提高了语音识别性能和实时性,识别错误率相对下降5.1%,说明该方法可比较准确地判断测试内容所属文本主题。 ",MESS200604011
LINUX下维、哈、柯文多语种图形化处理平台的设计与实现,苏国平1:11282674|缪成2:06312730|夏国平1:11051601,6,计算机应用; 中文信息处理; 多语种; 图形化处理平台; Linux;,"针对维吾尔文字、哈萨克文字、柯尔克孜文字(以下简称“维哈柯文”)的特点以及进行维哈柯文、西文等多语种混合处理时的特殊需求,本文通过对L inux的I18N体系中NLS(National Language Support)研究分析,提出了基于L inux的多语种图形化处理平台的设计目标与总体架构。该平台由维哈柯文本地化环境、维哈柯文显示、自适应维哈柯文输入和维哈柯文打印输出等4个子系统的十余个模块组成。本文详细介绍了各子系统主要模块的实现技术。通过在redhat linux 8.0、turbolinux上测试表明,该平台在桌面环境、编辑软件、网络浏览、数据库软件、多媒体软件、图形处理软件等应用中均能较好的实现维哈柯文、汉文、西文的混合输入、显示、编辑、排版、打印等功能。 ",MESS200604012
基于Qt的国际化图形用户界面设计与实现,刘汇丹:14056745|芮建武:01840467|姚延栋:09573880|吴健:09573793,6,计算机应用; 中文信息处理; 图形用户界面; Qt库; 国际化; 民族文字处理;,"一次开发多语言使用是国际化软件开发的主要目标。但是世界上的文字多种多样,它们的书写方向也有所不同,除了水平从左向右书写的英文、水平从右往左书写的阿拉伯文外,还有类似蒙古文这样垂直排列的文字,这对计算机图形用户界面提出了更高的要求,现有的计算机系统将这类垂直排列的文字沿水平方向输出,极不符合少数民族人民的习惯。在分析现有Qt库对类似阿拉伯文这样从右向左书写的文字的部分支持机制的基础上,我们设计并实现了支持四种方向模式的国际化的图形用户界面,现在它已经能够适应世界上几乎所有的文字。这对于软件国际化以及民族语言信息处理有重要意义。 ",MESS200604013
智能型汉字数码输入技术的研究,顾平:08866518|朱巧明:09891804|李培峰:08841773|钱培德:09886822,6,计算机应用; 中文信息处理; 汉字输入; 数字编码; 智能输入; 动态自学习语言模型;,"针对数字编码的特点,本文提出了一种在不改变编码方案的情况下通过改进输入规则,结合语言模型,实现汉字数字编码的智能输入技术。文章首先讨论了怎样设计字词码本结构,使之能够满足灵活多样的输入方式,继而设计了一种动态自学习语言模型,重点分析了数据平滑算法在语言模型中的应用与改进,最后通过一个输入法示例程序,对改进前后不同情况下的输入效果进行了测试。实验表明,这种输入技术不但降低了输入法的平均码长,而且显著地提高了首字命中率。 ",MESS200604014
应用二叉树剪枝识别韵律短语边界,荀恩东1:15684985|钱揖丽1:05982879|郭庆2:06433984|宋柔1:15649004,6,人工智能; 自然语言处理; 统计语言模型; 二叉树; 韵律短语; 最大熵;,"句子的韵律短语识别是语音合成的重要研究内容。本文提出了应用统计语言模型生成的二叉树,结合最大熵方法识别待合成汉语句子的语音停顿点。文中给出了二叉树相关的模型训练和生成算法;二叉树与语音停顿点之间的关系;在最大熵方法中应用二叉树剪枝识别句子的韵律短语。实验结果表明,在搜索算法中,利用二叉树进行剪枝,可以很大程度上提高语音停顿预测的正确率和召回率,基于试验数据的f-Score提高了近35%。 ",MESS200603000
基于AdaBoost.MH算法的汉语多义词消歧,,8,人工智能; 自然语言处理; 词义消歧; AdaBoost.MH算法; 多知识源;,"本文提出一种基于AdaBoost.MH算法的有指导的汉语多义词消歧方法,该方法利用AdaBoost.MH算法对决策树产生的弱规则进行加强,经过若干次迭代后,最终得到一个准确度更高的分类规则;并给出了一种简单的终止算法中迭代的方法;为获取多义词上下文中的知识源,在采用传统的词性标注和局部搭配序列等知识源的基础上,引入了一种新的知识源,即语义范畴,提高了算法的学习效率和排歧的正确率。通过对6个典型多义词和SENSEVAL3中文语料中20个多义词的词义消歧实验,AdaBoost.MH算法获得了较高的开放测试正确率(85.75%)。 ",MESS200603001
基于粗糙集的基本名词短语识别,,8,人工智能; 自然语言处理; 基本名词短语; 粗糙集; 机器学习; 规则方法; 算法;,"本文提出了一种基于粗糙集的基本名词短语(BaseNP)识别方法。该方法首先进行BaseNP标注,然后实现BaseNP识别。它把BaseNP标注看作一个决策问题用粗糙集理论解决,因而具有特征约简和规则优化的特点。文章介绍了基于粗糙集的规则学习方法和相应的算法,同时也给出了BaseNP标注和识别的算法流程,提出了解决实例冲突问题的方法,并提高了识别效果。文章最后给出了详细的实验步骤和结果,并与几个典型系统进行了比较与分析,提出了进一步改进的方向。 ",MESS200603002
中文文本分类中基于概念屏蔽层的特征提取方法,廖莎莎:15669476|江铭虎:08821580,7,计算机应用; 中文信息处理; 文本分类; 特征提取; 概念抽取; 属性特征树; 屏蔽层; 描述能力;,"本文提出了一种新的基于概念抽取和屏蔽层的特征选择方法。该方法利用HowNet概念词典中的概念树,通过义原在概念树中的位置信息进行概念抽取,并赋予其适当权值来说明其描述能力。对于权值低于屏蔽层的义原,我们不将其选入特征集,并相应保留原词。具体到每个词,我们计算其DEF条目中的权值,决定是将原词选入特征集还是进行概念抽取。本文重点研究了如何给义原设定一个合适的权值,如何在选取原词和概念之间取得平衡以及针对非概念词的加权处理。实验证明,设定合适的屏蔽层,不仅可以缩小特征维数,使分类正确率得到一定的提高,而且可以减少不同类别间的分类正确率的差别。 ",MESS200603003
基于n-gram语言模型和链状朴素贝叶斯分类器的中文文本分类系统,,7,计算机应用; 中文信息处理; 中文文本分类; n-gram语言模型; 链状朴素贝叶斯分类器;,"本文提出了一个基于n-gram语言模型进行文本表示,采用链状朴素贝叶斯分类器进行分类的中文文本分类系统。介绍了如何用n-gram语言模型进行文本表示,阐述了链状朴素贝叶斯分类器与n-gram语言模型相结合的优势,分析了n-gram语言模型参数的选取,讨论了分类系统的若干重要问题,研究了训练集的规模和质量对分类系统的影响。根据863计划文本分类测评组所提供的测试标准、训练集以及测试集对本文所设计的分类系统进行测试,实验结果表明该分类系统有良好的分类效果。 ",MESS200603004
《元朝秘史》电子文本检索系统的研制,江荻1:45692054|严海林2:15383562|孙伯君1:09954589|斯钦朝克图1:09889701|孟达来1:06343566,7,计算机应用; 中文信息处理; 元朝秘史; 复杂文本; 电子检索系统;,"本文概要地介绍了13世纪《元朝秘史》的文献背景及原文所独有的复杂文本形式,通过对文本的内涵分析和版面分析,设计了关于《元朝秘史》电子检索系统的研制方案。其中主要解决了原文三行一体显示格式的还原问题,而且系统可以分别对原文汉字音写、汉语译文、汉字旁译、语音语法标注等不同部分进行检索和统计。检索输出结果包括研究者最重视的传统学术章节号、卷页码、在电子文本出现的具体位置。另外,系统对检索词采用了上下文检索技术,输出文本包括检索词的部分上下文内容。本系统基本满足历史、文学和语言研究的应用需求。 ",MESS200603005
面向自然语言信息处理的维吾尔语名词形态分析研究,,7,人工智能; 自然语言处理; 维吾尔语信息处理; 名词; 形态;,"名词是人类语言中的基本词类之一。维吾尔语是一种形态变化很复杂的语言,其中名词是一种形态变化复杂的词类。因此名词的形态分析研究无论在语法研究还是在语言信息处理中都非常重要。本文对维吾尔语名词的形态变化(名词的数、人称、格等语法范畴)进行了形式化的描述和分析。指出了维吾尔语名词的基本形态参数,总结出参数的组配规律并统计了其类型,探索了维吾尔语名词的削尾方法。这些工作将为维吾尔语名词形态处理提供有效的方法和新的思路。 ",MESS200603006
藏文支持在OpenOffice.org办公套件中的实现,,7,计算机应用; 中文信息处理; 藏文字符集; 办公套件; 藏文信息处理; 文本断行;,"办公套件是人们日常应用最为广泛的信息处理软件之一,但真正意义的藏文办公套件至今都尚未问世,成为藏文信息技术发展的“瓶颈”。开源项目OpenO ffice.org的不断发展和日益成熟,为藏文办公套件的研制开发提供了有利的契机。以OpenO ffice.org为源代码基础,采用藏文编码字符集(扩充集A)国家标准,研制的藏文办公套件可支持藏文排版习惯和藏文本地环境,着重解决了藏文文本自动断行的问题,能够满足藏语文用户日常办公需要。 ",MESS200603007
文档聚类综述,,8,计算机应用; 中文信息处理; 综述; 文档聚类; 降维; 概念相关; 聚类算法;,"聚类作为一种自动化程度较高的无监督机器学习方法,近年来在信息检索、多文档自动文摘等领域获得了广泛的应用。本文首先讨论了文档聚类的应用背景和体系结构,然后对文档聚类算法、聚类空间的构造和降维方法、文档聚类中的语义问题进行了综述。最后还介绍了聚类质量评测问题。 ",MESS200603008
以本体构造中文信息过滤中的需求模型,,7,计算机应用; 中文信息处理; 信息过滤; 本体; 语义关联; 用户模板;,"在信息过滤系统中,用户模板是机器可理解的用户需求表示形式,是否能准确地反映出用户的真实需求将直接影响着过滤系统的性能。在向量空间模型中,用户的模板表现为一组带权重的特征词集,但由于在这样的用户模板中缺少必要的语义信息,很难准确地反映出用户的需求。本文提出了以本体构造需求模板的方法,以本体的形式定义需求中概念间的语义关联关系,将向量空间模型中的特征向量定义为本体中的实例,通过实例间的关联路径计算特征项间的语义关联,并通过特征项间的语义关联计算出文档与模板的语义关联度。 ",MESS200603009
面向信息检索需要的网络数据清理研究,刘奕群:08176974|张敏:08186086|马少平:08177513,8,计算机应用; 中文信息处理; 网络信息检索; 数据清理; 机器学习;,"W eb数据中的质量参差不齐、可信度不高以及冗余现象造成了网络信息检索工具存储和运算资源的极大浪费,并直接影响着检索性能的提高。现有的网络数据清理方式并非专门针对网络信息检索的需要,因而存在着较大不足。本文根据对检索用户的查询行为分析,提出了一种利用查询无关特征分析和先验知识学习的方法计算页面成为检索结果页面的概率,从而进行网络数据清理的算法。基于文本信息检索会议标准测试平台的实验结果证明,此算法可以在保留近95%检索结果页面的基础上清理占语料库页面总数45%以上的低质量页面,这意味着使用更少的存储和运算资源获取更高的检索性能将成为可能。 ",MESS200603010
基于相关文档池建模的查询扩展,,6,计算机应用; 中文信息处理; 信息检索; 相关反馈; 查询扩展;,"在信息检索领域,相关反馈是提高检索性能的有效方法之一。所谓相关反馈,指用户按照一定策略从查找到的相关文档中选择一些和主题相关的词进行查询扩展的技术。本文介绍了概率模型和向量空间模型下的常用查询扩展方法,并提出了一种基于语言模型的相关反馈方法,该方法同时考虑了扩展词应该具备的两个特征,即相关性和覆盖性。在TREC测试集上对这些算法进行了比较,结果表明这种新算法在平均准确率上比传统方法有所提高。 ",MESS200603011
一种基于局部共现的查询扩展方法,丁国栋1:09559503|白硕2:09559997|王斌1:15765208,8,计算机应用; 中文信息处理; 信息检索; 局部共现; 查询扩展; LOCOOC;,"针对信息检索中文档与查询之间的词不匹配问题,本文提出了一种基于局部共现的查询扩展方法LOCOOC。LOCOOC利用词项与所有查询词在局部文档集合中的共现程度来评估扩展词的质量,并整合了词项在语料集中的全局统计信息,使得选取的扩展词与初始查询所表征的主题或概念具有更好的相关性。实验结果表明:与未进行查询扩展时相比,采用LOCOOC方法进行扩展后,平均准确率提高40%以上;与传统的局部反馈方法以及局部上下文分析方法(LCA,Local ContextAnalysis)相比,LOCOOC不仅具有更优的检索性能,而且有着更好的鲁棒性。 ",MESS200603012
基于反馈学习自适应的中文话题追踪,,7,计算机应用; 中文信息处理; 话题追踪; 基于反馈学习的自适应方法; 增量学习;,"在话题追踪研究领域,由于话题是动态发展的,在追踪过程中会产生话题漂移的问题。针对该问题以及现有自适应方法的不足,本文提出基于反馈学习的自适应方法。该方法采用增量学习的思想,对话题追踪任务中的自适应学习机制提出了新的算法。该算法能够解决话题漂移现象,并能够弥补现有自适应方法的不足。该算法中还考虑了话题追踪任务的时序性,将时间信息引入到了算法中。本文实验采用TDT4语料中的中文部分作为测试语料,使用TDT2004的评测方法对基于反馈学习的自适应的中文话题追踪系统进行评价,实验数据表明基于反馈学习的自适应方法能够提高话题追踪的性能。 ",MESS200603013
语音识别准确率与检索性能的关联性研究,周梁:15734996|高鹏:15646144|丁鹏:10983611|徐波:11144381,6,计算机应用; 中文信息处理; 语音识别; 关键词检索; 查全率; 查准率;,"对海量语音进行基于内容的检索需要语音识别技术和检索技术的结合。本文通过调节语言模型的途径研究在不同识别率的语音识别文本上进行关键词检索的差异,由此研究语音识别性能和检索性能之间的关联性。通过对114小时语音数据的实验表明:语音识别性能与检索性能有一定的相关性,同时也说明改进检索的方法可以消除一部分由于语音识别所带来的误差。研究结果为进一步针对性地改进识别引擎、语音识别输出的表示和相应的快速检索方法提供了基础。 ",MESS200603014
一种基于概率上下文无关文法的汉语句法分析,,8,人工智能; 自然语言处理; 统计句法分析; 概率上下文无关文法; 汉语自动分析;,"本文研究了PCFG独立性假设的局限性,并针对这一局限性提出了句法结构共现的概念以引入上下文信息,给出了计算方法;为了打破中文树库规模过小的局限性,对于句法规则参数的获取,本文利用In-side-Outside算法进行迭代,最后提出了一个基于统计模型的自顶向下的汉语句法分析器。在封闭测试下,其标记精确率和标记召回率分别为88.1%和86.8%。实验结果表明,这种方法确实能够提高标记的精确率和召回率,值得深入研究。 ",MESS200602000
基于语义分类树的汉语口语理解方法,左云存:15738556|宗成庆:10815045,8,人工智能; 自然语言处理; 语义分类树; 浅层语义分析; 口语理解;,"口语理解在口语自动翻译和人机对话系统中具有非常重要的作用。本文面向口语自动翻译提出了一种统计和规则相结合的汉语口语理解方法,该方法利用统计方法从训练语料中自动获取语义规则,生成语义分类树,然后利用语义分类树对待解析的汉语句子中与句子浅层语义密切相关的词语进行解析,最后再利用统计理解模型对各个词语的解析结果进行组合,从而获得整个句子的浅层语义领域行为。实验结果表明,该方法具有较高的准确率和鲁棒性,适合应用在限定领域的汉语口语浅层语义理解。 ",MESS200602001
基于Web数据的特定领域双语词典抽取,张永臣1:15728913|孙乐1:10352504|李飞1:27032742|李文波1:09659441|西野文人2:13041011|于浩2:11577051|方高林2:11567301,8,计算机应用; 中文信息处理; 双语词典; 词间关系矩阵; 非平行语料; 种子词;,"双语词典是跨语言检索以及机器翻译等自然语言处理应用的基础资源。本文提出了一种从非平行语料中抽取特定领域双语词典的算法。首先给出了算法的基本假设并回顾了相关的研究方法,然后详细给出了利用词间关系矩阵法从特定领域非平行语料中抽取双语词典的过程,最后通过大量实验分析了种子词选择对词典抽取结果的影响,实验结果表明种子词的数量和频率对词典抽取结果有积极作用。 ",MESS200602002
中文文本体裁的自动分类机制,方鸷飞:06504899|林鸿飞:06526775|杨志豪:06523490|赵晶:06508715,9,计算机应用; 中文信息处理; 体裁分类; 特征项选取; 样本分布决策; 支撑向量机;,"文本按体裁自动分类属于按文本的形式分类的范畴,所以它与按内容自动分类问题有许多的不同之处,本文提出了一种关于中文文本体裁自动分类的新机制。在体裁分类过程中首要的问题是分类特征的选取,体裁分类特征项分为两种方式加以描述,一是集合形式,如基于分类词典和语料统计的政论性词汇和情感词汇等,二是规则形式,如公文标识信息和条文句等。基于根据特征之间的关联性和差异性,采用样本分布决策的方法抽取相应的特征项。最后利用支撑向量机算法进行自动分类。该机制已经在五类体裁的语料上得到实现,并获得了较好的效果。 ",MESS200602003
基于句法结构分析的中文问题分类,,7,计算机应用; 中文信息处理; 问答系统; 问题分类; 特征提取; 句法分析;,"问题分类是问答系统中重要的组成部分,问题分类结果的好坏直接影响问答系统的质量。本文提出了一种用于问题分类的特征提取的新方法,该方法主要使用句法分析的结果,提取问题的主干和疑问词及其附属成分作为分类的特征,此方法大幅度地减少了噪音,突出了问题分类的主要特征,利用贝叶斯分类器分类,有效地提高了问题分类的精度。实验结果证明了该方法的有效性,大类和小类的分类精度分别达到了86.62%和71.92%,取得了较好的效果。 ",MESS200602004
基于事件框架的信息抽取系统,梁晗1:15668688|陈群秀2:08164877|吴平博2:08833686,7,计算机应用; 中文信息处理; 信息抽取; 框架; 继承; 灾难性事件;,"信息抽取技术能够提供高质量的检索服务。本文提出一种基于框架的信息抽取模式并建立统一的灾难性事件框架,利用框架的继承-归纳特性简化系统实现过程,概括事件信息,并提出按时间流顺序的线索性文件抽取的输出方式。本文使用这种方法建立了一个灾难性事件信息抽取系统。实验证明本文中的方法是有效的。 ",MESS200602005
一种改进的Wu-Manber多模式匹配算法及应用,,6,计算机应用; 中文信息处理; 多模式匹配; 后缀模式; 字符串匹配; 全文检索; 信息检索;,"本文针对Wu-Manber多模式匹配算法在处理后缀模式情况下的不足,给出了一种改进的后缀模式处理算法,减少了匹配过程中字符比较的次数,提高了算法的运行效率。本文在随机选择的TREC2000的52,067篇文档上进行了全文检索实验,对比了Wu-Manber算法、使用后缀模式的改进算法、不使用后缀模式的简单改进等三种算法的匹配过程中字符比较的次数。实验结果说明,本文的改进能够比较稳定的减少匹配过程中字符比较的次数,提高匹配的速度和效率。 ",MESS200602006
《说文解字》音义关系的产生式表达,宋继华1:06398884|李国玉2:06365544|王宁3:06364557,7,计算机应用; 中文信息处理; 说文解字; 音义关系; 同源; 产生式规则; 产生式框架;,"汉语语义关系的探求离不开汉字音义关系的探求,汉字的音义关系分为同音、同义和同源三种。探求汉字之间的音义关系、利用汉字的字音来推求字义之间的关系,是《说文解字》研究的一项重要内容。为了便于基于计算机技术更全面地探求音义关系尤其是同源关系中的“音近”、“义通”关系,本文对音韵通转规则进行了形式化表述。在《说文》知识库中,建立了《说文》双声规则库和叠韵规则库(含8个规则表),它们通过“规则槽”与传统框架表示法中的“属性槽”和“属性库”共同构成产生式框架,有效地表达了《说文》中的各项描述性知识和规则性知识,为后续研究奠定了基础。 ",MESS200602007
基于小波分析的大词汇汉语连续语音识别系统鲁棒性的研究,,6,计算机应用; 中文信息处理; 大词汇连续语音识别; 小波分析; 声学模型;,"本文提出一种基于小波分析的大词汇汉语连续语音识别的方法,即采用一维小波变换将原始语音信号进行五层小波分解,然后对各层小波系数进行重构,得到五层语音信号,分别对各层语音信号进行训练,得到各层的声学模型,然后结合语言模型对各层声学模型的性能进行测试。通过对纯净语音和带噪语音的各层重构语音数据进行测试。结果表明对于含有高斯白噪声的带噪语音,该方法能使系统性能有所提高,但对于粉红噪声,该方法效果不明显。对于含有真实环境噪声的带噪语音,该方法能获得比基线系统更好的性能。 ",MESS200602008
印刷体朝鲜文字符中字母的分割与识别研究,许日俊:13621865|刘昌平:10654982,6,人工智能; 模式识别; 字母分割; 字母识别; 朝鲜文字符识别;,"朝鲜文是一种由元音和辅音构成的字母文字。因此经常使用的一种朝鲜文识别方法是:从朝鲜文字符中分离出每一个字母,然后对这些字母进行识别,最后确定识别字符。本文结合结构分析法,通过对字符图像背景进行细化处理,找到字母之间的分割线分离出了每个字母,并且利用两层外围距离特征对这些字母进行了识别。在对4种经常使用的朝鲜文印刷字体进行初步实验的结果表明,字母分割正确率平均达到了97.4%,而字母样本集识别率为99%以上。 ",MESS200602009
维吾尔文手机输入关键技术研究与实现,,6,计算机应用; 中文信息处理; 维吾尔文; 输入法; 自动选型; 多文种混合显示; 手机键盘;,"维吾尔文,汉文和英文等多文种手机,对于发展少数民族地区通讯和经济,有非常重要的实用和商业价值。针对以上实际情况,本文首先研究了维吾尔文的书写特点、手机输入法设计中的难点、以及不等宽、不同输入方向的汉、英、维多文种信息的屏幕混合显示问题。根据维吾尔文的特征和手机显示屏幕的物理特征设计了维吾尔文的手机键盘布局,实现了支持多文种混合显示的维吾尔文手机输入法,给出了实现其关键模块功能的程序流程图。 ",MESS200602010
藏文计算机通用键盘布局与输入法研究,卢亚军:10207616,9,计算机应用; 中文信息处理; 藏文; 计算机键盘; 键盘布局; 输入法;,"为了改进现有各种藏文计算机键盘布局与输入法,本文依据键盘布局的基本理论、若干原则、相关科学数据和基于藏文语料库的字符、部件、音节、词汇统计数据,遵循藏语语法规则及其特殊性,在对键盘键位的属性进行专门研究的基础上,研制出“一键多符”和“一键到位”的智能化藏文计算机通用键盘布局与输入法,其藏文文本的键盘输入速度和效率成倍提高,对藏文印刷、办公自动化和信息处理具有广泛的使用价值。 ",MESS200602011
国际化文字处理综述,,7,计算机应用; 中文信息处理; 综述文字处理; 复杂文字; 字体模型;,"计算机与不同用户的交互通常必须实现通过多种文字信息的输入/输出以实现,因此操作系统对多种文字的支持程度是其功能性的一个衡量标准。各种文字特征的巨大差异导致现代操作系统的文字处理实现非常复杂。本文总结了操作系统文字处理的范围与内容,包括文本输入与存储,文本处理以及用户交互处理;归纳了通用的文字处理模型和可能采取的技术途径及其优缺点;分析了常用操作系统的文字处理实现;最后展望了文字处理仍面临的挑战。 ",MESS200602012
数据库管理系统多民族语言支持研究,程伟:09612997|林河水:15118777|吴健:10352507|孙玉芳:09573880,7,计算机应用; 中文信息处理; 数据库管理系统; 民族语言支持; 藏文; 字典序;,"目前流行的各种大型数据库系统都缺乏对民族语言如藏、蒙、维文的支持。如何实现民文信息在数据库中存储、查询和检索等处理及支持各种基于民文的数据库应用,是一个重要问题。本文提出了一个数据库管理系统多民族语言支持框架,支持多民族语言、数据库客户端工具和应用编程接口;并在此框架下提出了一种符合ISO/IEC 14651语义的藏文排序方法,从而实现了PostgreSQL数据库对藏文信息处理的全面支持。并在Linux平台的PostgreSQL数据库系统上加以实现。 ",MESS200602013
消除同音查询的死角——汉语言文字多音同音查询解决方案,,4,计算机应用; 中文信息处理; 汉字; 多音字; 同音字; 拼音; 数据库;,"本文通过分析汉语言文字“读音-字形”之间的“多-多”对应关系,阐明了现有数据库同音查询技术中因忽视多音字问题而导致漏查的缺陷,提出了以汉字字形输入代替拼音字母输入,同时在查询逻辑上加以扩展和改造,从而弥补上述缺陷,实现汉语言文字多音同音查询的完整解决方案。此外,本文试图通过对本方案的扩展及延伸,从汉语言文字问题推导出方言、译音、乃至其它种类语言文字类似问题的解决思路,进而为发掘事物的内在联系、发展人工智能提供参考。 ",MESS200602014
基于语料库的高频最大交集型歧义字段考察,,6,计算机应用; 中文信息处理; 最大交集型歧义字段; 全切分; 强势切分;,"交集型歧义是中文分词的一大难题,构建大规模高频最大交集型歧义字段(MOAS)的数据库,对于掌握其分布状况和自动消歧都具有重要意义。本文首先通过实验指出,与FBMM相比,全切分才能检测出数量完整、严格定义的MOAS,检测出的MOAS在数量上也与词典规模基本成正比。然后,在4亿字人民日报语料中采集出高频MOAS14906条,并随机抽取了1354270条带有上下文信息的实例进行人工判定。数据分析表明,约70%的真歧义MOAS存在着强势切分现象,并给出了相应的消歧策略。 ",MESS200601000
面向商务信息抽取的产品命名实体识别研究,,7,计算机应用; 中文信息处理; 产品命名实体识别; 商务信息抽取; 层级隐马尔可夫模型;,"市场信息化使得商务信息抽取、市场内容管理日益成为信息科学领域的一个研究热点。产品命名实体识别作为其中非常重要的关键技术之一也逐渐受到人们的关注。本文面向商务信息抽取对产品命名实体进行了定义并系统分析了其识别任务的特点和难点,提出了一种基于层级隐马尔可夫模型(hierarchical hid-den Markov model)的产品命名实体识别方法,实现了汉语自由文本中产品命名实体识别和标注的原型系统。实验表明,该系统在电子数码和手机领域均取得了令人满意的实验结果,对产品名实体、产品型号实体、产品品牌实体整体识别性能的F值分别为79.7%,86.9%,75.8%。通过和最大熵模型相比较,验证了HHMM对于处理多尺度嵌套序列有更强的表征能力。 ",MESS200601001
基于HowNet的词汇语义倾向计算,,7,计算机应用; 中文信息处理; 态度分类; 语义倾向; 知网;,"在互联网技术快速发展、网络信息爆炸的今天,通过计算机自动分析大规模文本中的态度倾向信息的技术,在企业商业智能系统、政府舆情分析等诸多领域有着广阔的应用空间和发展前景。同时,语义褒贬倾向研究也为文本分类、自动文摘、文本过滤等自然语言处理的研究提供了新的思路和手段。篇章语义倾向研究的基础工作是对词汇的褒贬倾向判别。本文基于HowNet,提出了两种词汇语义倾向性计算的方法:基于语义相似度的方法和基于语义相关场的方法。实验表明,本文的方法在汉语常用词中的效果较好,词频加权后的判别准确率可达80%以上,具有一定的实用价值。 ",MESS200601002
基于时空分析的线索性事件的抽取与集成系统研究,吴平博:08833686|陈群秀:08164877|马亮:08231465,8,计算机应用; 中文信息处理; 信息抽取; 句型模板; 线索性事件; 时空信息; 事件合并;,"信息抽取技术能够提供高质量的检索服务。本文面向网络新闻事件,对人们感兴趣的事件关键信息进行了抽取和集成。系统中采用了如下的方法、策略:(1)利用句型模板构造抽取规则,然后直接从经过时间短语和空间短语识别和规范化处理的文本中抽取事件信息,从而跳过了深层句法分析,降低了实现系统的难度;(2)利用事件的规范化的时空信息关联不同文档中的同一事件,进行事件合并;(3)文档发生事件转移时对文档进行事件切分,从而解决了文档内不同事件信息的归并问题。初步实验结果表明:本文采用的方法和策略是有效的。 ",MESS200601003
基于多策略优化的分治多层聚类算法的话题发现研究,骆卫华:09559496|于满泉:09596632|许洪波:10348555|王斌:10348532|程学旗:09559997,8,计算机应用; 中文信息处理; 话题发现与跟踪; 分治多层聚类; 系统聚类;,"话题发现与跟踪是一项评测驱动的研究,旨在依据事件对语言文本信息流进行组织利用。自1996年提出以来,该研究得到了越来越广泛的关注。本文在研究已有成熟算法的基础上,提出了基于分治多层聚类的话题发现算法,其核心思想是把全部数据分割成具有一定相关性的分组,对各个分组分别进行聚类,得到各个分组内部的话题(微类),然后对所有的微类再进行聚类,得到最终的话题,在聚类的过程中采用多种策略进行优化,以保证聚类的效果。基于该算法的系统在TDT4中文语料上进行了测试,结果表明该算法属于目前结果最好的算法之一。 ",MESS200601004
中文语言资源联盟,,1, , ,MESS200601005
现代藏语动词的句法语义分类及相关语法句式,江荻:09954589,7,计算机应用; 中文信息处理; 藏语; 动词句法语义分类; 句法结构; 句法标记;,"本文突破了传统藏文文法关于动词分类的简单描述,建立起以句法语义为纲要的动词类别和相关句法规则。本文区分了藏语12大类动词,各类动词都有不同论元数量和不同句法性质的要求。因此,动词的句法语义类别划分能够较细致和全面反映各种类型藏语句式的语法结构框架,包括句子的语序、词格标记和句法助词。动词的句法语义分类结果可以直接应用于藏语语法信息词典的构建,是藏语计算处理的重要基础。 ",MESS200601006
汉语自动分词和词性标注评测,,7,计算机应用; 中文信息处理; 自动分词; 词性标注; 评测;,"本文介绍了2003年“863中文与接口技术”汉语自动分词与词性标注一体化评测的一些基本情况,主要包括评测的内容、评测方法、测试试题的选择与产生、测试指标以及测试结果,并对参评系统的切分和标注错误进行了总结。文中着重介绍了测试中所采用的一种柔性化的自动测试方法,该方法在一定程度上克服了界定一个具体分词单位的困难。同时,对评测的结果进行了一些分析,对今后的评测提出了一些建议。 ",MESS200601007
基于Multigram语言模型的主动学习中文分词,冯冲1:05975602|陈肇雄2:09638848|黄河燕2:09559462|关真珍2:09539189,9,计算机应用; 中文信息处理; 分词; 无督导机器学习; 主动学习; EM算法;,"分词是中文处理中的重要基础问题。为了克服Web文本分析中传统方法在适应繁杂的专业领域和多变的语言现象时存在的困难,本文以无督导分词方法为基本框架,使用EM算法建立n元multigram语言模型,提出了一种基于置信度的主动学习分词算法,使得系统在主要利用大量未标注数据的同时,还能够主动选择少量最有价值的数据提交人工标注。实验结果表明算法性能优于相关的几种无督导分词算法。 ",MESS200601008
基于双层级联文本分类的简历信息抽取,,8,计算机应用; 中文信息处理; 信息抽取; 文本分类; 简历管理;,"本文提出了一种基于双层级联文本分类的方法,用于简历信息的自动抽取。本方法将简历文本分解为文本块和文本串,并将简历中包含的信息分解为概要信息与详细信息。首先对简历文本中的文本块进行切分与分类,抽取出概要信息,然后选择可能包含详细信息的文本块,将其切分为文本串,再通过对文本串的分类抽取出详细信息。对1200份中文简历的实验结果表明,本方法适用于简历信息的自动抽取和管理。 ",MESS200601009
基于模式分类的汉语时态确定方法研究,林达真:09196278|李绍滋:09227519,9,计算机应用; 中文信息处理; 汉语; 时态; 特征词; 线性判别函数; 感知器准则函数;,"汉语时态是中文信息处理领域的一个难点。基于规则的处理方法在无时态特征词的句子,多时态特征词的句子处理等方面存在很大问题。本文从统计的角度,提出一种基于模式分类的时态确定方法,该方法综合评价句子中每个词对时态确定所作的贡献,能够处理无时态特征词的句子和多时态特征词的句子,并且该方法使用线性判别函数,具有对多维数据分析,训练与判别速度快的特性。在开放测试环境下,对单句的汉语时态确定正确率与召回率分别为79.8%和95.3%。 ",MESS200601010
基于知网的文本推理,,9,计算机应用; 中文信息处理; 文本推理; 构造-融合模型; 标记传递; 语义网;,"文本推理在自然语言处理的应用中占有极为重要的位置,本文介绍了基于知网的一种推理方法,该方法以语义网络的形式表示知网中的知识,利用“标记传递”实现推理。其特点是引入构造-融合模型的思想,动态生成知识结构,有引导地在文本词汇间建立推理路径。利用16种推理类的实例对其进行测试,结果表明在有足够上下文的条件下,该方法能够得出较为理想的推理,并且代价不高。 ",MESS200601011
手写中文信封的地址行字符切分算法,韩智:10654982|刘昌平:13621896|殷绪成:13621510,6,人工智能; 模式识别; 邮政信封地址; 脱机手写体汉字; 字符切分; OCR;,"在手写体中文信封处理系统中,地址行字符切分是实现地址行识别的关键步骤。本文根据邮政信封地址行字符的特点,有针对性的提出了一种字符切分算法。首先对地址行图像利用投影、求连通区域、笔划穿越数分析等基于字符结构的方法进行初始切分,得到基本字段序列;然后通过对相邻的基本字段进行组合形成多条候选切分路径,再通过识别的可信度和邮政目标地址库的先验知识信息对路径进行评价分析,从而得到最优的切分路径。该算法经过邮政分拣机采集的实际信封图像测试,纯地址行识别正确率达到78.61%,地址行识别与邮政编码识别相结合的分拣正确率达到95.42%。 ",MESS200601012
北京大学软件与微电子学院与北京大学计算语言学研究所联合新建语言技术系,,1, , ,MESS200601013
噪声环境下的鲁棒性说话人识别,,7,计算机应用; 中文信息处理; 说话人辨认; 维纳滤波; F0-MFCC;,"在实际应用中,噪声或信道干扰导致说话人识别(SR)识别性能急剧下降。针对该问题,本文分析传统方法的优缺点并提出相应的系统解决方案:采用维纳滤波对语音信号进行前端处理;以MFCC声道特征结合基频(F0)韵律特征来提高识别系统的鲁棒性。实验结果表明:维纳滤波能有效地消除噪声影响;经维纳滤波处理后,使得F0-MFCC联合模型能更好的区分说话人。可以看出在噪声环境下系统的综合性能得到很大改善。 ",MESS200601014
汉语韵律词F0曲线的优化,刘浩杰:05978393|杜利民:09682495,7,计算机应用; 中文信息处理; 语音合成; F0曲线; 优化; x2估计;,"汉语韵律词内部音节重音的强弱对总的F0曲线的特征有很大影响。本文参考生成F0曲线的数学优化模型[1],提出了对由孤立单音节调型曲线串接而成的汉语韵律词的F0曲线的连续性、平滑性、曲线形状、平均值进行整体优化的x2估计方法,实现了在重音作用下的F0曲线的优化。在谐波+噪声合成系统上实验研究了汉语三音节韵律词的64种不包含轻声的调型组合和10种结尾为轻声的调型组合的F0曲线的优化效果,展示优化过程中三个控制参数———平滑因子(smooth)、音节重音强度(stress)、音节F0形状失真度(Distor-tion)对F0曲线整体形状的控制效果和参数取值的有效范围。非正式的听觉实验表明合成语音的自然度有明显提高。 ",MESS200601015
基于统计学习的机器翻译模板自动获取方法,胡日勒:13621527|宗成庆:10815045|徐波:10983611,6,人工智能; 机器翻译; 双语语法归纳; 翻译模板获取; 结构对齐;,"本文提出了一种从未经深层次处理的双语口语语料库中自动获取机器翻译模板的方法。这种算法是一种无监督的、基于统计的、数据驱动的方法。这种方法有两个基本的步骤。首先,通过语法归纳分别从源语言和目标语言中获取语义类和短语结构类。然后,利用双语划界文法将短语结构类进行对齐。对齐的结果经过后处理就可以得到翻译的模板。初步的试验结果表明,本方法是有效的和切实可行的。 ",MESS200506000
班智达汉藏公文翻译系统中基于二分法的句法分析方法研究,才藏太:08163472|华关加:23006731,6,人工智能; 机器翻译; 二分法; 语句结构; 句法分析;,"机器翻译系统是一种典型的自然语言处理系统,语言技术是机器翻译系统中居于核心地位的技术。本文结合863项目《班智达汉藏公文机器翻译系统》的研制实践,论述了词项信息同语法规则相结合的原则,提出了以动词为中心的句法分析二分法,从而在受限语言的范围内,为建立有较大适应性的机器翻译规则系统,有效地提高机器翻译语法分析的效率提供了有益的方法。 ",MESS200506001
多文档自动文摘综述,秦兵:06990821|刘挺:06994824|李生:06989058,9,人工智能; 自然语言处理; 多文档文摘; 文本压缩;,"多文档文摘是将同一主题下的多个文本描述的主要的信息按压缩比提炼为一个文本的自然语言处理技术。随着互联网上信息的日益丰富,多文档文摘技术成为新的研究热点。本文介绍了多文档文摘的产生和应用背景,阐述了多文档文摘和其他自然语言处理技术的关系,对多文档文摘国内外研究现状进行了分析,在此基础上汇总提出了多文档文摘研究的基本路线及关键技术,并总结了多文档文摘的未来及发展趋势。 ",MESS200506002
基于类别特征域的文本分类特征选择方法,赵世奇:06988018|张宇:06989058|刘挺:07005452|陈毅恒:06991005|黄永光:06994824|李生:06997645,7,计算机应用; 中文信息处理; 文本分类; 特征选择; 类别特征域;,"特征选择是文本分类的关键问题之一,而噪音与数据稀疏则是特征选择过程中遇到的主要障碍。本文介绍了一种基于类别特征域的特征选择方法。该方法首先利用“组合特征抽取”[1]的方法去除原始特征空间中的噪音,从中抽取出候选特征。这里,“组合特征抽取”是指先利用文档频率(DF)的方法去掉一部分低频词,再用互信息的方法选择出候选特征。接下来,本方法为分类体系中的每个类别构建一个类别特征域,对出现在类别特征域中的候选特征进行特征的合并和强化,从而解决数据稀疏的问题。实验表明,这种新的方法较之各种传统方法在特征选择的效果上有着明显改善,并能显著提高文本分类系统的性能。 ",MESS200506003
自动文摘系统中的主题划分问题研究,傅间莲:08164877|陈群秀:08167062,8,计算机应用; 中文信息处理; 自动文摘; 向量空间模型; 段落相似度; 主题划分;,"随着网络的发展,电子文本大量涌现,自动文摘以迅速、快捷、有效、客观等手工文摘无可比拟的优势,使得其实用价值得到充分体现。而主题划分是自动文摘系统中文本结构分析阶段所要解决的一个重要问题。本文提出了一个通过建立段落向量空间模型,根据连续段落相似度进行文本主题划分的算法,解决了文章的篇章结构分析问题,使得多主题文章的文摘更具内容全面性与结构平衡性。实验结果表明,该算法对多主题文章的主题划分准确率为92.2%,对单主题文章的主题划分准确率为99.1%。 ",MESS200506004
词表的自动丰富——从元数据中提取关键词及其定位,王军:06263051,8,计算机应用; 中文信息处理; 词表; 元数据; 关键词提取;,"词表和分类法是传统纸质文献环境下最重要的知识组织工具。它的更新和维护一直依靠手工进行。这限制了它在数字图书馆和网络信息环境下的应用。本文介绍了一项基于统计的、从元数据的标题中抽取关键词并定位在词表中的方法。定位的依据是抽取出的关键词所对应的标引词集的收敛性质。标引词是用于标引文献主题的、来自于词表的受控词汇,即主题词。在《中国分类主题词表》和北京大学图书馆提供的5千余条计算机科技领域的书目数据上所进行实验证明了文中所述的方法是可行的、有效的。这一方法可以直接用来实现基于已标引语料库的自动编目和元数据自动生成。 ",MESS200506005
特征词提取中同义处理的新方法,邹娟:09243790|周经野:09214087|邓成:09240552|高南莎:14745458,6,人工智图; 自然语言处理; 文本分类; 特征值提取; 同义词;,"本文利用文本分类中文本的特点提出了一种基于模糊集的同义词处理的新方法。本方法充分考虑不同文本类型中同义(近义)词之间的差别,在训练中自动计算不同类型文本中特征词对其对应的同义概念的隶属度,从而实现了用模糊集来定义同义概念;然后应用同义概念来提取文本中的特征值。另外,本系统还利用模糊集来处理多义词的问题。文中给出了系统的处理算法。比较试验的结果表明该方法提高了分类的正确率,效果是令人满意的。整个系统达到了较高的自动化水平和较强的可移植性。 ",MESS200506006
汉英双语平行语料库的词义标注,刘冬明:08452366|杨尔弘:09166846|方莹:15080973,7,人工智能; 自然语言处理; 词义排歧; HowNet; 双语平行语料库;,"本文充分利用当前HowNet资源中概念的可计算性和句子对齐的汉英双语平行语料库信息,将词义排歧的问题转化为两种语言相对应句子词义组合的相似度计算问题,进而利用动态规划法的思想设计出一种在一定的时间复杂度内,有效的标出多义词义项的算法。该方法从以前对每个多义词进行排歧时只考察其上下文环境和对应信息,改变到对句子中所有的词同时考察上下文环境,这样就可以站在句子高度来进行词义标注,最终取得了满意的实验结果。 ",MESS200506007
汉语语义分析模型研究述评,由丽萍:08408610|范开泰:08587620|刘开瑛:09629273,7,计算机应用; 中文信息处理; 依存语法; 概念依存理论; 框架语义学; 语义表示;,"这篇述评的目的是为汉语语义处理的研究工作提供参考。我们首先分别分析了三种语义分析模型———词语依存(WD)、概念依存(CD)和核心依存(KD)的理论基础和表达方式;然后,重点从功能和可操作性方面比较三者在语义表示方面的特点。结论是(1)词语依存可操作性好但功能弱,概念依存功能强但可操作性差,二者的缺点都是极难解决的问题,核心依存兼顾词语和概念,可能是最适合汉语语义处理需要的;(2)要使模型达到实用要求,需要在句法标注、词典编纂和规范化方面做大量复杂的工作。 ",MESS200506008
潜在语义分析权重计算的改进,刘云峰:07593002|齐欢:05968020,6,计算机应用; 中文信息处理; 潜在语义分析; 权重; 文档全局权重; 文档自检索矩阵;,"自从潜在语义分析方法诞生以来,被广泛应用于信息检索、文本分类、自动问答系统等领域中。潜在语义分析的一个重要过程是对词语文档矩阵作加权转换,加权函数直接影响潜在语义分析结果的优劣。本文首先总结了传统的、已成熟的权重计算方法,包括局部权重部分和词语全局权重部分,随后指出已有方法的不足之处,并对权重计算方法进行扩展,提出文档全局权重的概念。在最后的实验中,提出了一种新的检验潜在语义分析结果优劣的方法———文档自检索矩阵,实验结果证明改进后的权重计算方法提高了检索效率。 ",MESS200506009
层次型金融票据图像分类方法,,8,人工智能; 模式识别; 金融票据图像识别; 票据分类; 层次型;,"金融票据图像识别处理是当今的一个热点研究方向,而票据分类是其中重要的基础部分。针对种类繁多、数量巨大、版面复杂和噪声干扰严重的金融票据彩色图像,本文提出了一种基于二叉树决策的层次型票据类型匹配方法。该方法利用三个类型判断器:基于票据版面结构的松弛匹配、基于OCR的票据标题识别和基于票据颜色的色彩分析,层次化的进行票据类型判断。实验表明,层次型金融票据图像分类方法具有良好的效果;基于该方法的银行票据识别处理系统已经广泛应用于各大银行的相关业务系统中。 ",MESS200506010
汉语朗读话语重音自动分类研究,胡伟湘:11707134|董宏辉:11607992|陶建华:11672781|黄泰翼:13621530,6,计算机应用; 中文信息处理; 重音; 韵律结构;,"汉语的重音由于受到声调、语调以及韵律单元层级的干扰和制约,对于重音的自动感知一直是比较困难的问题。针对标准的朗读普通话语,本文在广义韵律结构的框架下研究了重音的声学表现,设计并实现了重音的自动感知模型。本文提出的基于分类树结构的区分度模型能有效地结合韵律单元结构对重音的制约。研究结果表明,音高高线、调域、音长是表达重音最重要线索,利用这些线索能有效地实现对重音的自动感知。我们的模型能一般能达到80%左右的重音检出水平。 ",MESS200506011
多预测子融合实时连续语音识别输出词正误判别,付跃文:09633783|杜利民:09633791,8,计算机应用; 中文信息处理; 连续语音识别; 预测子; 决策树;,"本文在采用堆栈译码词网重估输出作为识别最终输出的连续语音识别实时解码条件下,利用决策树方法将多个预测子融合,对识别输出词进行正确和错误的判别。本文首先构造了词后验概率、词长、相邻词的后验概率、词的声学和语言得分等共13个预测子,然后利用决策树方法,通过选择不同的预测子组合方式和适当的决策树建树参数,筛选出预测子的最佳组合,建立优化的决策树进行输出词的正误判别。实验结果表明:利用局域词图计算的词后验概率与词长、相邻词的后验概率等几种实时预测子融合后,对识别输出词的正误判别能力得到提高,并且在实时性和分类效果两个方面优于n-best输出的相应结果,相对于基线系统,则分类错误率下降41.4%。实验结果也表明本文提出的相邻词的后验概率是相对重要的预测子。 ",MESS200506012
藏文键盘布局的优化设计方法,高定国:09504314|龚育昌:09504260,6,计算机应用; 中文信息处理; 优化设计方法; 藏字; 键位布局;,"键位设计是实现藏字编码输入的关键步骤。由于藏字构件数多于标准键盘的可用键位数,较好地解决方法是把几个构件归并到一个键位上,但键位的归并可能会带来重码。为了有效地解决这一矛盾,本文采用了键位布局的优化设计方法,利用图论和概率方法求出藏字构件的极大独立集,以使得键位归并所产生的重码现象降到最低。文中详细介绍了求极大独立集的算法、矛盾构件的查找法、极大独立集数目的控制法、极大独立集最优划分的选择以及算法的流程图。并根据工程心理学方法把现代藏字的构件布局到标准键盘上,使得该布局的标准键盘可以一键一构件地输入现代藏字,且仅产生二对重码。 ",MESS200506013
基于词联接的诗词风格评价技术,李良炎:10192216|何中市:10191626|易勇:10493364,7,计算机应用; 中文信息处理; 文学语言处理; 诗词风格; 评价技术; 词联接;,"在当前自然语言处理的研究状况下,文学语言处理应当受到足够的重视。诗词艺术集中体现了文学语言的形象性、情感性、个性等特征,是文学语言处理研究很好的切入点。风格评价是文学语言处理的重要课题,极具挑战性。本文以诗词语言为具体研究对象,以基于词联接的自然语言处理技术为技术背景,着重介绍并验证基于词联接的诗词风格评价技术。提出了计算方法,设计了诗词风格评价问卷调查实验。结果表明,人的诗词风格评价共性大于个性,基于词联接的诗词风格评价技术能够有效地评价诗词风格。 ",MESS200506014
基于内容的垃圾邮件过滤技术综述,王斌:09639404|潘文锋:09559997,10,计算机应用; 中文信息处理; 综述; 垃圾邮件; 反垃圾邮件; 信息过滤; 文本分类;,"垃圾邮件问题日益严重,受到研究人员的广泛关注。基于内容的过滤是当前解决垃圾邮件问题的主流技术之一。目前基于内容的垃圾邮件过滤主要包括基于规则的方法和基于概率统计的方法。本文综述了目前用于垃圾邮件过滤研究的各种语料和评价方法,并总结了目前使用的垃圾邮件过滤技术以及它们之间的对比实验,包括Ripper、决策树、Rough Set、Rocchio、Boosting、Bayes、kNN、SVM、Winnow等等。实验结果表明,Boosting、Flexible Bayes、SVM、Winnow方法是目前较好的垃圾邮件过滤方法,它们在评测语料上的结果已经达到很高水平,但是,要走向真正实用化,还有很多的工作要做。 ",MESS200505000
一种文本分类的在线SVM学习算法,代六玲:05975602|黄河燕:09638848|陈肇雄:06336478,6,计算机应用; 中文信息处理:文本分类; 在线学习; 增量学习; 支持向量机; SMO;,"本文提出了一种用于文本分类的RBF支持向量机在线学习算法。利用RBF核函数的局部性,该算法仅对新训练样本的某一大小邻域内且位于“可能带”中的训练样本集进行重新训练,以实现对现有SVM的更新。为高效的实现该邻域大小的自适应确定,使用ξa泛化错误估计在所有现有训练样本集上对当前SVM的泛化错误进行定性估计。同时引入泛化能力进化因子,使得结果SVM在分类效果上具有自动调整能力,并防止分类能力的退化。在TREC-5真实语料上的对比测试结果表明,该算法显著地加速了增量学习的过程而同时保证结果SVM的分类效果。 ",MESS200505001
基于后缀树模型的文本实时分类系统的研究和实现,郭莉:09559531|张吉:09596687|谭建龙:09560077,8,计算机应用; 中文信息处理; 实时文本分类; 向量空间模型; 后缀树;,"本文在面向网络内容分析的前提下,提出了一种基于后缀树的文本向量空间模型(VSM),并在此模型之上实现了文本分类系统。对比基于词的VSM,该模型利用后缀树的快速匹配,实时获得文本的向量表示,不需要对文本进行分词、特征抽取等复杂计算。同时,该模型能够保证训练集中文本的更改,对分类结果产生实时影响。实验结果和算法分析表明,我们系统的文本预处理的时间复杂度为O(N),远远优于分词系统的预处理时间复杂度。此外,由于不需要分词和特征抽取,分类过程与具体语种无关,所以是一种独立语种的分类方法。 ",MESS200505002
面向体育领域的句子主干翻译技术研究,薛永增:06996935|杨沐昀:06987836|赵铁军:06997742|韩习武:07002572|齐浩亮:06997147,7,人工智能; 机器翻译; 句子主干翻译; 模板; 体育领域;,"为了有效翻译体育领域文本,特别是文本中的长句,本文提出了一种面向体育领域的句子主干翻译方法。该方法采用模板来表示句子主干,主要包括句法主干分析、模板转换和句子主干译文生成三个步骤。本文研究中特别针对体育领域的语言特点进行了模板的设计和获取;在译文生成过程中,则分别利用规则和模板,采用了短语级全译和句子级摘译相结合的混合生成策略,并引入翻译函数来处理形态变化。实验结果表明句子主干翻译方法能够获取句子的关键信息,在可懂度上优于完全翻译,其忠实度也令人满意,是处理体育领域文本的有效方法。 ",MESS200505003
基于长度的扩展方法的汉英句子对齐,张艳:15187845|柏冈秀纪:15228104,7,人工智能; 机器翻译; 句子对齐; 中文处理; 双语语料库;,"本文提出了一种用于汉英平行语料库对齐的扩展方法。该扩展方法以基于长度的统计对齐方法为主,然后根据双语词典引入了词汇信息,而基于标点的方法作为对齐的后处理部分。这种扩展方法不仅避免了复杂的中文处理,例如,汉语分词和词性标注,而且在统计方法中引入了关键词信息,以提高句子对齐的正确率。本文中所用的双语语料是LDC的关于香港的双语新闻报道。动态规划算法用于系统的实现。和单纯的基于长度的方法和词汇方法相比,我们的扩展方法提高了句子对齐的正确率,并且结果是比较理想的。 ",MESS200505004
用动词的论元结构跟事件模板相匹配——一种由动词驱动的信息抽取方法,袁毓林:06263991,7,计算机应用; 中文信息处理; 信息抽取; 事件模板; 论元结构; 模板元素; 论元角色;,"本文以文献[2]中信息抽取模型(InfoX)的测试语料(职务变动文本)为主要对象,具体说明怎样建立从动词的论元结构到相关的事件模板的匹配关系。首先根据职务变更动词的有关句法、语义特点,把它分成六个小类:任命、担任、免职、辞职、调遣、受命;然后,分别描写每一小类动词的论元结构,特别是它们所支配的论元角色及其句法配置方式。最后,建立动词的论元角色跟事件模板元素的匹配关系,并揭示动词对文本筛选和合并都有导向作用,说明发展由动词驱动的信息抽取方法的可行性。 ",MESS200505005
面向主题会话的扩展语义框架,施海虎:06349288|邢宣宇:09659485|李冬梅:07422304,8,计算机应用; 中文信息处理; 语义框架; 扩展语义框架; 人机会话; 主题会话;,"随着人工智能技术的发展,基于人机会话的智能化技术成为当前研究热点,知识表示是人机会话领域的研究难点之一。在众多的知识表示方法中,框架表示法由于具有适应性强、概括性高、结构化良好、推理方式灵活的特点而得到人们的广泛应用。本文在基于篮球运动主题会话课题研究中,提出了一种扩展语义框架表示方法。与传统的表示方法相比,该扩展语义框架能够解决基于领域的知识处理、常识推理和语句生成问题,能够很好地满足受限人机会话系统的要求。 ",MESS200505006
对蒙古语语料库基本名词短语的定界与统计分析,华沙宝:08639277|达胡白乙拉:07994523,7,计算机应用; 中文信息处理; 蒙古语; 基本名词短语; 短语结构; 形式化描述;,"解决蒙古语基本名词短语的定界问题,是在蒙古语词性标注语料库的基础上进行的探索性研究。基本名词短语的内部结构信息对其定界问题具有重要作用。确定基本名词短语内部结构的因素有多种,但基本名词短语成分的词类信息是最基本的因素。我们以词类信息为核心,附加一些限定条件,构建识别基本名词短语的形式规则集,并在实际语料中进行基本名词短语标注测试。 ",MESS200505007
基于ISO/IEC10646标准的藏文操作系统若干问题研究,芮建武:10352507|吴健:09573880|孙玉芳:14056745,8,计算机应用; 中文信息处理; 藏文字符集; 藏文叠加字符; OpenType;,"长期以来尚未有完整的藏文操作系统,原因是藏文文字的特性要求特定的文字处理。本文基于ISO/IEC10646的藏文字符集标准,结合藏文正字法要求,详细分析了藏文操作系统实现中的关键问题:(1)藏文字符集方案比较与藏文存储;(2)藏文输入;(3)藏文显现。藏文显现是公认的“瓶颈”问题。对此,本文提出基于音节划分、使用OpenType字体及相应的文本引擎来解决藏文“叠加”字符的显现。此方案应用于Qt库的实验及相关测试证明基于ISO/IEC10646标准的藏文操作系统实现是较合理的方案。 ",MESS200505008
图文互斥版面中文字阅读顺序的确定,贾娟:06238962|陈堃銶:21551851|周东浩:06244186,9,计算机应用; 中文信息处理; 阅读顺序; 图文互斥; 有序树;,"图文互斥版面中确定文字的阅读顺序是排版及版面理解过程中的一个难点。尤其是中文等东方文字特有的分栏串文互斥,其空间关系的复杂性使得阅读顺序存在歧义。针对此问题,建立新的版面布局模型,并引入新的版面对象PMRegion。给出了版面逐层快速分解构造版面对象和基于有序树的阅读顺序确定算法。已成功运用于专业中日文排版系统,取得了满意的效果,并对更深入研究文档图像理解具有十分重要的理论和实践意义。 ",MESS200505009
印刷维吾尔文本切割,靳简明:00007412|丁晓青:08178634|彭良瑞:08821739|王华:08832216,8,计算机应用; 中文信息处理; 文本切割; 字符切割; 字符识别; 维吾尔文;,"我国新疆地区使用的维吾尔文借用阿拉伯文字母书写。因为阿拉伯文字母自身书写的特点,造成维文文本的切割和识别极其困难。本文在连通体分类的基础上,结合水平投影和连通体分析的方法实现维文文本的文字行切分和单词切分。然后定位单词基线位置,计算单词轮廓和基线的距离,寻找所有可能的切点实现维文单词过切割,最后利用规则合并过切分字符。实验结果表明,字符切割准确率达到99%以上。 ",MESS200505010
传统蒙古文变形显示机制研究与实现,姚延栋:09573880|吴健:10352507|孙玉芳:01840467|呼斯勒:12978023,6,计算机应用; 中文信息处理; 蒙文; OpenType; 复杂文字布局; CTLUnicode; 布局引擎;,"多年来蒙古文处理系统重复开发、互不兼容的根本原因就是没有统一的标准:编码标准不统一、字库标准不统一、输入法不统一。随着国际化、多语言化的发展,开发基于ISO/IEC10646和UNICODE国际编码标准、OpenType智能字体技术的不同语言文字处理系统已经成为趋势。本文阐述了一个蒙古文显示系统,它完全支持Unicode标准并使用了OpenType技术自动进行字形选型,其实现是基于QT库的,但核心实现很容易移植到Pango,ICU等其他复杂文本布局(CTL)处理项目中。 ",MESS200505011
一个基于多代码页的中文屏幕实时解释引擎的设计,李培峰:09886822|朱巧明:05968617|钱培德:05970941,7,计算机应用; 中文信息处理; 汉字代码页自动识别; 屏幕取词; ISO10646;,"目前,在计算机中汉字有多种代码页,汉字的多代码页并存现象将长期存在。为了实现汉字多代码页并存,需要汉字代码页自动识别技术的支撑。屏幕实时解释引擎是目前各种在线字典、词典以及教学软件的核心技术,此技术目前存在不能跨代码页,取词不全面、不正确等缺陷。本文主要针对以上情况,描述了采用汉字内码的代码页自动识别技术以及优化的自动屏幕取词技术的中文屏幕实时解释引擎的系统架构,并阐述了数据词典的设计以及在设计中采用的关键技术。对五百万汉字样本的测试中,应用此引擎的在线词典对有意义短字符串(不包括单字)代码页的识别率可以达到99%以上。 ",MESS200505012
HCL2000手写汉字数据库的更新及相关研究,任俊玲:06426169|郭军:06430683,8,人工智能; 模式识别; HCL2000; 手写汉字数据库; 样本选择; HCL2004;,"HCL2000是目前最具影响力的手写汉字数据库之一,基于研究手写汉字规律的设计初衷,该数据库采用了以书写者为单位按文件形式组织和存放的方式。本文则从研究样本选择的应用角度出发,对HCL2000中的样本进行了重新组织,同时对该数据库中的错误进行了纠正,生成了一个新的手写汉字数据库HCL2004。文章最后基于HCL2004数据库和方向线素特征进行了有关训练样本数对识别性能影响的研究,给出了3755类大字符集情况下的最佳训练样本数为300的结论,同时还对识别过程中的样本选择问题进行了探讨。 ",MESS200505013
多策略机器翻译系统IHSMTS中实例模式泛化匹配算法,张孝飞:05975602|陈肇雄:09638848|黄河燕:09596140|胡春玲:09596136,9,人工智能; 机器翻译; 基于实例的机器翻译; 泛化匹配; 翻译覆盖率;,"基于精确匹配的EBMT,由于翻译覆盖率过低,导致其难以大规模实际应用。本文提出一种实例模式泛化匹配算法,试图改善EBMT的翻译覆盖率:以输入的待翻译句子为目标导向,对候选翻译实例有针对性地进行实时泛化,使得算法既能满足实时文档翻译对速度的要求,又能充分利用系统使用过程中用户新添加和修改的翻译知识,从而总体上提高了系统的翻译覆盖率和翻译质量。实验结果表明,在语料规模为16万句对的情况下,系统翻译覆盖率达到了75%左右,充分说明了本文算法的有效性。 ",MESS200504000
基于k-means聚类的无导词义消歧,陈浩:09217421|何婷婷:07624442|姬东鸿:07640959,7,计算机应用; 中文信息处理; 词义消歧; HowNet; 二阶context; k-means聚类;,"无导词义消歧避免了人工词义标注的巨大工作量,可以适应大规模的多义词消歧工作,具有广阔的应用前景。这篇文章提出了一种无导词义消歧的方法,该方法采用二阶context构造上下文向量,使用k-means算法进行聚类,最后通过计算相似度来进行词义的排歧.实验是在抽取术语的基础上进行的,在多个汉语高频多义词的两组测试中取得了平均准确率82·67%和80·87%的较好的效果。 ",MESS200504001
汉语介词短语的自动识别,干俊伟:06521208|黄德根:06527360,7,计算机应用; 中文信息处理; 短语识别; 介词短语;,"本文运用规则和统计相结合的方法构造了一个汉语介词短语识别算法。首先,根据介词和介词短语右边界组成的搭配模板自动提取可信搭配关系,并用这些搭配关系对介词短语进行识别。之后,用基于词性的三元边界统计模型和规则相结合的方法识别其它未处理的介词短语。通过对含有7323个介词短语的语料作交叉测试,精确率达到87·48%,召回率达到87·27%。 ",MESS200504002
采用优先选择策略的中文人称代词的指代消解,李国臣:08407515|罗云飞:08453449,7,计算机应用; 中文信息处理; 语料库; 人称代词; 指代消解; 最优选择;,"指代是自然语言中常见的语言现象,指代消解是文本信息处理中的一个重要任务。随着篇章处理相关应用日益广泛,指代消解也显示出前所未有的重要性。本文针对中文人称代词的指代特点,提出了一种基于语料库的,运用决策树机器学习算法并结合优先选择策略,进行指代消解的方法。该方法充分考虑了与指代相关的若干属性,及相互之间的影响。实验表明,对中文人称代词的消解特别是第三人称的消解获得了一定的效果。 ",MESS200504003
词语间依存关系的定量识别,王建会:06705003|王雷:06701114|胡运发:05964539,8,计算机应用; 中文信息处理; 词语搭配; 依存关系; 定量识别;,"本文扩展和改进了现有的词语间依存关系定量识别算法,充分考虑词项概率分布的影响;明确区分词项之间的搭配关系、并列关系和从属关系,针对它们不同的特点,提出不同的识别算法;提出字串匹配模型;充分考虑两个词项之间相互位置的离散分布和距离的影响、以及它们的概率分布特性,提出词项间的依存强度模型,并据此构建词语间依存关系树;提出更新策略,对已经建好的依存关系树进行裁剪,并挖掘出潜在的依存关系。应用实验结果表明,本文提出的算法可以有效地识别出词语间的依存关系。 ",MESS200504004
用逻辑和篇章知识来约束模板匹配——逻辑结构和篇章结构知识在信息抽取中的运用,袁毓林:06263991,7,计算机应用; 中文信息处理; 信息抽取; 论元结构; 逻辑结构; 篇章结构; 代词; 指示词;,"本文以文献[2]的语料为主要对象,讨论语句的逻辑结构和篇章结构怎样约束信息模板的类型,并约束对当前句中缺失的或以代词等形式表达的信息项目的求解。首先说明什么是基于论元结构的逻辑结构和篇章结构知识,然后分析否定算子、时体成分怎样改变事件的类型及其跟有关事件模板的匹配关系。接着,讨论动词的论元结构的内嵌和名词化等句法操作,怎样造成有关论元及相应的信息项目的分布位置发生变化。最后,讨论怎样利用篇章结构知识来求解本句中缺失的或以代词、指示词形式表达的信息项目。 ",MESS200504005
基于互信息的统计语言模型平滑技术,黄永文:10191626|何中市:10095478,6,计算机应用; 中文信息处理; 统计语言模型; 平滑技术; 互信息; 困惑度;,"数据平滑主要是用来解决统计语言模型在实际应用中数据稀疏问题。现有平滑技术虽然已有效地对数据稀疏问题进行了处理,但对已出现事件频率分布的合理性并没有作出有效的分析。本文则针对二元模型,提出了一种基于互信息的平滑技术,其基本思想是根据模型中每个二元对的互信息的高低对其概率进行折扣或补偿,并用极小化困惑度原则体现了模型的合理性。实验结果表明该技术优于目前常用的Katz平滑技术。 ",MESS200504006
规则加权的文本关联分类,陈晓云:05964539|胡运发:06702975,8,计算机应用; 中文信息处理; 关联分类; 规则强度; 权重;,"近年来,基于关联规则的文本分类方法受到普遍关注。虽然在一般情况下这种方法可获得较好的分类效果。但当样本特征词分布明显不均时,分类规则在各类别的分布也出现不均,从而导致分类准确率下降。本文设计和实现的基于规则权重调整的关联规则文本分类算法可有效地解决这一问题。该算法根据误分类训练样本的数量定义规则强度。对强规则通过乘以小于1的调整因子降低其权重,而弱规则乘以大于1的调整因子提高其权重。实验结果表明经过规则权重的调整,分类质量显著提高。 ",MESS200504007
基于投影寻踪的中文网页分类算法,万中英:08472511|王明文:07877579|廖海波:08472484,8,计算机应用; 中文信息处理; 投影寻踪; 网页分类; 遗传算法; KNN算法;,"随着Web信息迅猛发展,网络用户对网页自动分类器的需求日益增长。为了提高分类精度,本文提出了一种新的基于投影寻踪(ProjectionPursuit,简称PP)的中文网页分类算法。我们首先利用遗传算法找到一个最好的投影方向,然后将已被表示成为n维向量的网页投影到一维空间。最后采用KNN分类算法对其进行分类。此方法能解决“维数灾难”问题。实验结果表明,我们提出的算法是可行而且是有效的。 ",MESS200504008
一种基于超链接结构的向量空间模型改进算法,原福永:09316074|褚蓓蓓:10255165,5,计算机应用; 中文信息处理; 搜索引擎; 信息检索; 向量空间模型; 超链接;,"在基于向量空间模型的信息检索系统中,TF-IDF算法被广泛的应用在基于关键字的信息检索中。然而,对于网页独特的超链接结构,需要有一种技术在表示网页内容的同时将与它相邻链接的网页内容考虑进去。本文分析了向量空间模型的实质,并找出了其精度低的原因,在传统模型基础上提出了一种基于网页超链接结构的向量空间模型改进算法。实验分析表明改进后的算法与原算法相比检索精确度提高了10%,在一定程度上改善了检索效果。 ",MESS200504009
基于遗传和BP算法的车牌图像快速匹配,刘栓:21557379|孟庆春:09479762,6,人工智能; 模式识别; 遗传算法; BP(backpro pagation)神经网络; 图像匹配; 小波变换;,"将基于遗传的BP神经网络算法用于智能交通中的车牌图像匹配,结合了遗传算法和BP算法的优点。先采用遗传学习算法进行全局寻优、再利用BP算法进行精确训练、优化BP(BackPropagation)神经网络权重学习和训练的神经网络图像匹配算法。实验结果表明:本文设计算法较好地达到了匹配要求,能够对目标图像与样本图像进行正确匹配,匹配概率达到了92%,而传统的BP神经网络仅有79%,并且在匹配速度上也明显优于传统的BP神经网络及其他改进算法,具有精确性、收敛性和匹配快等特点。 ",MESS200504010
一种有效的手写体汉字组合特征的抽取与识别算法,孙权森:00004756|金忠:08094960|王平安:09209478|夏德深:08057177,7,人工智能; 模式识别; 手写体汉字识别; 广义的典型相关分析; 特征融合;,"基于特征融合的思想,从有利于模式分类的角度,推广了典型相关分析的理论,建立了广义的典型相关分析用于图像识别的理论框架。在该框架下,首先利用广义的典型相关判据准则函数,求取两组特征矢量的广义投影矢量集,构成一对变换矩阵;然后根据所提出的新的特征融合策略,对两种手写体汉字特征进行融合,所抽取的模式的相关特征矩阵,在普通分类器下取得了良好的分类效果,优于已有的特征融合方法及基于单一特征的PCA方法和FLDA方法。 ",MESS200504011
语音识别中的一种说话人聚类算法,肖述才:08183521|欧智坚:08173688|王作英:00006332,5,计算机应用; 中文信息处理; 说话人聚类; 说话人自适应; 语音识别;,"本文介绍了稳健语音识别中的一种说话人聚类算法,包括它在语音识别中的作用和具体的用法,聚类中常用的特征、距离测度,聚类的具体实现步骤等。我们从两个方面对该算法的性能进行了测试,一是直接计算句子聚类的正确率,二是对说话人自适应效果的改进的作用,即比较使用此算法后系统性能的改进进行评价。实验表明:在使用GLR距离作为距离测度的时候,该算法对句子的聚类正确率达85·69%;在识别实验中,该聚类算法的使用,使得用于说话人自适应的数据更加充分,提高了自适应的效果,系统的误识率已经接近利用已知说话人信息进行自适应时的误识率。 ",MESS200504012
口语对话中的语句主题分析,徐为群:11707134|徐波:10983611|黄泰翼:13621864,8,人工智能; 自然语言处理; 语句主题; 句子类型; 对话; 计算分析;,"本文研究如何根据浅层的语义分析确定自然口语对话中的语句主题。首先将对话中的语句主题定义为说话者所关注的显著语义实体,并讨论了这样的语句主题所具有的两个特点(即话语性和连续性)以及语句主题跟(扩展)句子类型的关系(因而也介绍了句子类型及其扩展和扩展句子类型的识别)。然后根据这些建立了语句主题分析算法,并在实际的对话语料中进行分析。实验结果表明,语句主题的分析正确率可达到61·1~87·6%,取决于不同的扩展句子类型和不同的正确率定义。 ",MESS200504013
X Window核心系统的民文支持,谢谦:10352507|吴健:09573880|孙玉芳:09573886,8,计算机应用; 中文信息处理; X窗口系统; 国际化; 藏文;,"Linux系统对少数民族文字的支持需要建立在国际化机制基础上,本文在总结现有Linux国际化框架层次结构基础上,分析了X核心系统国际化的一些关键问题,并以增加藏文支持的实践为例,系统说明了增加民族文字支持所需对X核心系统进行的改动,对在相关项目中的实施情况和效果进行了评估,最后结合其他民族文字系统的研究,对这些工作的局限性进行了深入分析,并提出了今后的工作方向。 ",MESS200504014
问答式检索技术及评测研究综述,吴友政:10891784|赵军:10975495|段湘煜:10983611|徐波:11504594,13,人工智能; 自然语言处理; 综述; 问答系统; 问答评测; 信息抽取; 信息检索;,"问答式检索系统(简称问答系统)是集自然语言处理技术和信息检索技术于一身的新一代搜索引擎。它的出现旨在提供更有力的信息获取工具,以应对信息爆炸带来的严重挑战。经过这几年的发展,问答系统已经成为自然语言处理领域和信息检索领域的一个重要分支和新兴的研究热点,其“通过系统化、大规模地定量评测推动研究向前发展”的发展轨迹,以及某些成功的启示,如基于字符表层的文本分析技术(模板技术)的有效性,快速、浅层自然语言处理技术的必要性,都极大地推动了自然语言处理研究的发展,促进了NLP研究与应用的紧密结合。回顾问答系统研究的历史,总结问答技术的研究现状,将有助于这方面工作向前发展。 ",MESS200503000
基于主题语言模型的中文信息检索系统研究,张俊林:10352507|孙乐:10352504|孙玉芳:00585957,7,人工智能; 自然语言处理; 主题语言模型; 信息检索;,"准确的文档语言模型估计对于改善语言模型检索系统的性能是非常重要的。在本文中我们提出了基于主题语言模型的信息检索系统,首先设计了“改进的两阶段K Means聚类算法”来对文档集合进行聚类,通过引入AspectModel结合聚类结果可以得到基于主题的语言模型。这个新的语言模型较深入地刻画了词汇在不同主题下的分布规律以及文档所蕴含不同主题的分布规律。将主题语言模型和文档本身的语言模型通过线性插值可以更准确地估计文档语言模型。实验结果表明我们提出的这个方法显著改善了检索系统的性能,与Jelinek Mercer模型方法相比较,主题语言模型检索系统的平均精度提高大约16 17% ,召回率提高大约9 6 4%。 ",MESS200503001
短语树到依存树的自动转换研究,党政法:08836151|周强:08820449,7,人工智能; 自然语言处理; 树库; 短语树; 依存树; 自动转换;,"不同标注体系的树库之间的相互转换是计算语言学研究的重要内容之一。本文在总结国内外几种树库标注体系及相互转换实践的基础上,结合清华汉语树库(TsinghuaChineseTreebank ,简称TCT)标注体系的特点,提出了一种将TCT从短语结构转换成依存结构(DependencyStructure)的算法。这种算法充分利用了TCT具有的功能、结构的双重标记,转换得到的依存树不仅包含了各个节点之间相互依存的层次关系,更包含了相互依存的两个节点的具体的依存关系类型。我们对转换的效果进行了抽样评估,准确率可以达到97 37%。 ",MESS200503002
“第十届少数民族语言信息处理研讨会”征文通知,,1, , ,MESS200503003
面向语言信息处理的朝鲜语知识库研究,毕玉德:20374626,6,计算机应用; 中文信息处理; 朝鲜语; 知识库; 一体化描述; 结构体在;,"在自然语言处理系统(包括机器翻译系统)中,语法、语义信息词典是必不可少的构件。本文以国内外语义工程研究成果为基础,通过对朝鲜语谓词进行句法语义一体化描述,建立面向信息处理的朝鲜语知识库。该研究的语言学理论根据是论元结构理论和语义场理论。我们首先对谓词进行语义分类,然后再对谓词义项作详细的属性描述。在知识库构建上,采用结构体方式将谓词的句法、语义等属性整合在一起。 ",MESS200503004
基于笔式交互的中文字处理系统:SketchEditor,韩勇:05972322|须德:06327029,7,计算机应用; 中文信息处理; 人机交互; 笔式界面; 手势识别; POST-WIMP;,"纸笔是人们日常生活中常用的交流方式之一。但传统的纸笔工具有许多缺点,如纸上记录的内容难以修改和再加工,大量的信息缺乏有效的维护和检索等等。然而,纸笔工作方式的这些弱点却正好是计算机在信息处理方面的优势。笔式界面的研究就是要将这些传统的工作可计算化并且保持传统工作方式的自然性。本文的研究中,通过笔设备的输入事件描述了文本输入、编辑等交互任务,并且结合改进后的Rubin识别算法和基于规则的识别等方法,模拟人们日常生活中纸———笔工作方式,设计实现了以用户为中心的新型笔式文本编辑器。 ",MESS200503005
汉字双向有穷自动机的研究,蔡增玉:06596522|谷文祥:06596676,5,计算机应用; 中文信息处理; 汉字输入; 数学模型; 双向有穷自动机;,"汉字的计算机输入是中文信息处理的关键问题之一,而汉字计算机输入的数学模型对汉字的计算机输入的研究有重要的意义。本文从自动机理论的角度对汉字输入的数学模型进行了研究,把控制操作引入了输入模型,并给出确定汉字双向有穷自动机和不确定汉字双向有穷自动机的模型。新的模型较之以前的数学模型,能刻画出汉字输入的控制操作,表达能力进一步增强,是对以前汉字键盘输入数学模型的推广。 ",MESS200503006
机器翻译评测中的模糊匹配,刘洋:09638994|刘群:09559596|林守勋:09638999,9,人工智能; 机器翻译; 机器翻译评测; 模糊匹配;,"目前,大多数机器翻译自动评测方法都没有考虑在未匹配的词语中可能包含被忽略的信息。本文提出一种在参考译文和待评测译文之间自动搜索模糊匹配词对的方法,并给出相似度的计算方法。模糊匹配和计算相似度的整个过程将通过一个例子进行说明。实验表明,我们的方法能够较好地找到被忽略的、有意义的词对。更重要的是,通过引入模糊匹配,BLEU的性能得到显著的提高。模糊匹配可以用来提高其他机器翻译自动评测方法的性能。 ",MESS200503007
《统计自然语言处理基础》,,1, , ,MESS200503008
基于多层过滤的统计机器翻译,周玉:10815045|宗成庆:11134711|徐波:10983611,7,人工智能; 机器翻译; 多层过滤; 双语语块识别与对齐;,"本文提出了一种基于多层过滤的算法。该算法主要实现从对齐的中英文句子中自动的抽取与对齐双语语块。根据不同语块具备的不同特性,采用不同的层次对其处理。该算法不同于传统的算法,它不需要对句子进行标注,句法分析,词法分析甚至不需要对汉语句子进行分词等操作。初步的实验结果表明该算法性能较好,测试的结果是:抽取语块的准确率能达到F =0 70 ,对齐语块的准确率能达到F =0 80 ;而且将此算法获得的对齐双语语块用于统计机器翻译系统,跟基于词的系统做对比,结果表明基于语块的翻译系统明显提高了翻译水平,差不多能提高10 %。 ",MESS200503009
融合丰富语言知识的汉语统计句法分析,熊德意:09560032|刘群:09559596|林守勋:09638994,6,人工智能; 自然语言处理; 统计句法分析; 非递归短语; 中心词映射表; 上下文配置框架;,"知识获取一直以来是自然语言处理中的瓶颈,基于树库的统计句法分析也不例外。树库中潜在隐含的语言知识是非常丰富的,但它们并不是可以直接得到,往往需要特定的策略才能将它们融合到模型中。我们的汉语统计句法分析模型从3个方面融合潜在的丰富语言知识:1)重新标注树库中的非递归名词短语和非递归动词短语;2 )设计新的中心词映射表;3)引进上下文配置框架以更具体地描述二元依存结构。由于融合了以上三种潜在语言知识,模型的F1值提高了2 37% ,完全匹配正确率提高了5 36 %。 ",MESS200503010
一种基于可信度的人名识别方法,罗智勇:06299384|宋柔:05982879,7,计算机应用; 中文信息处理; 自动分词; 人名识别; 统计方法; 可信度;,"专名识别技术是影响中文自动分词精度的一个重要方面,也是自动分词技术的难点之一。本文以人名识别为例,分析了目前流行的基于语料库和统计语言模型的专名识别方法中在概率估值问题上存在的弊端;同时在规则和统计相结合的基础上,提出了一种基于可信度的人名识别方法,并给出了一个渐进式模型训练方法,克服了人工标注语料库规模的限制。从我们对《人民日报》1998年1月、2 0 0 0年12月(共约379万字)语料的测试结果来看,基于可信度的人名识别方法比传统的概率估值方法识别效果有一定的提高。 ",MESS200503011
Co-training机器学习方法在中文组块识别中的应用,刘世岳:06579782|李珩:06577886|张俐:05968474|姚天顺:06574957,7,计算机应用; 中文信息处理; co-training算法; 中文组块; 分类器;,"采用半指导机器学习方法co training实现中文组块识别。首先明确了中文组块的定义,co training算法的形式化定义。文中提出了基于一致性的co training选取方法将增益的隐马尔可夫模型(TransductiveHMM)和基于转换规则的分类器(fnTBL)组合成一个分类体系,并与自我训练方法进行了比较,在小规模汉语树库语料和大规模未带标汉语语料上进行中文组块识别,实验结果要比单纯使用小规模的树库语料有所提高,F值分别达到了85 34%和83 4 1% ,分别提高了2 13%和7 2 1%。 ",MESS200503012
现代汉语介词短语边界识别研究,王立霞:06433925|孙宏林:06432401,7,计算机应用; 中文信息处理; 右边界; 概率信息; 删除插值法;,"汉语中介词结构右边界歧义是汉语结构歧义中最突出的现象之一,这给汉语的句法分析带来了很大的困难。本文研究的目标是:在不引进复杂的句法分析的前提下实现介词短语边界的自动识别,期望其作为句法分析预处理的一部分为句法分析提供一定的帮助。本文对汉语中最常用的介词“在”进行了实验,封闭测试和开放测试的准确率分别达到97%和93%。与前人的同类研究相比,准确率有了较大的提高,解决了过去遗留的一些问题。 ",MESS200503013
基于HowNet概念获取的中文自动文摘系统,王萌:07640959|何婷婷:07646972|姬东鸿:07629429|王晓荣:09217421,7,计算机应用; 中文信息处理; HowNet; 自动文摘; 概念向量空间模型;,"本文提出了一种中文自动文摘的方法。不同于其它的基于词频统计的一般方法,运用概念(词义)作为特征取代词语。用概念统计代替传统的词形频率统计方法,建立概念向量空间模型,计算出句子重要度,并对句子进行冗余度计算,抽取文摘句。对于文摘测试,采用两种不同的方法进行测试:一是用机器文摘和专家文摘进行比较的内部测试;二是对不同文摘方法进行分类,通过对分类正确率的比较的外部评测方法。 ",MESS200503014
怎样计算现代汉语句子的时间信息,陈振宇:06703030|陈振宁:09871770,11,计算机应用; 中文信息处理; 现代汉语; 时间认知模型; 时间翻译式; 时间运算;,"现代汉语句子的时间信息,是由句中的各个单位及其关系共同编码的,因此必须建立起整体的时间认知模型才能计算。包括三个方面:1 将时间性质分解为事件的基本阶段(起始、持续、终结)、事件的时段(确定时段、相对小量、相对大量)和认知窗口的时间基点等认知要素,对事件类型进行分类,在此基础上,构建有关时间的认知模型。2 对现代汉语句子中可能出现的每一单位和关系,用事件类型符号和时间要素符号进行翻译,所得的结果———该单位或关系的元语言表述式(翻译式)———表明了该单位或关系在编码时间信息时究竟表现什么意义。3 在认知模型中建立一个由规则驱动的运算系统,将元语言表述式化简为最简表述,它即是句子整体编码的时间信息。 ",MESS200503015
《中文信息学报》征稿简则,,1, , ,MESS200503016
实体关系自动抽取,车万翔:06994824|刘挺:06987220|李生:06989058,6,计算机应用; 中文信息处理; 实体关系抽取; ACE评测; 特征选择;,"实体关系抽取是信息抽取领域中的重要研究课题。本文使用两种基于特征向量的机器学习算法 ,Winnow和支持向量机 (SVM) ,在 2 0 0 4年ACE(AutomaticContentExtraction)评测的训练数据上进行实体关系抽取实验。两种算法都进行适当的特征选择 ,当选择每个实体的左右两个词为特征时 ,达到最好的抽取效果 ,Win now和SVM算法的加权平均F Score分别为 73 0 8%和 73 2 7%。可见在使用相同的特征集 ,不同的学习算法进行实体关系的识别时 ,最终性能差别不大。因此使用自动的方法进行实体关系抽取时 ,应当集中精力寻找好的特征。 ",MESS200502000
利用未标注语料改进实体名识别性能,陈宁昱:06698167|周雅倩:06690146|黄萱菁:06710223|吴立德:06705247,6,计算机应用; 中文信息处理; 实体名识别; 最大熵; 未标注语料;,"本文主要介绍了一个利用最大熵进行实体名识别的系统以及所采用的模型和选取的特征。这些特征包括单词本身的词法词态特征和上下文信息。利用这些在任何语言的文本上都极易获得的特征 ,我们采用最大熵分类器构建了一个基准系统。在此基础上 ,我们首先通过网络资源建立了实体名词典知识库 ;并利用词典和基准系统在未标注语料上抽取出现的实体名作为辅助的训练语料 ;最后再将这些语料加入训练。实验结果表明 ,辅助的训练语料能够在一定程度上提高系统的性能。 ",MESS200502001
短语结构制导的范畴表达式演算,赵章界:09640503|白硕:09596143,8,人工智能; 自然语言处理; 语法; 范畴表达式; 短语结构制导; 信息处理;,"对于语言表达式的组成成分及它们间的关系的刻画 ,目前大多数语法研究都着重在句法层面 ,而本文的范畴表达式演算理论则着重在语义层面。我们首先考察了完全表达式与不完全表达式、句法类型与语义类型、继承、顺序、提取、并列等若干重要的语言现象以及各种语法理论对这些现象的解释 ,然后提出范畴表达式的形式化定义 ,分析了句法层面的形式约束对语义层面的内容组织的制导作用 ,并且用典型的语言例子直观的说明了如何利用短语结构制导 ,进行范畴表达式的演算。这种机制可形式化、可验证 ,能很好的捕捉语言的组成成分及它们间的相互关系 ,揭示一个句子所说的内容。 ",MESS200502002
XML内容筛选中的快速串匹配算法,刘萍:10348418|谭建龙:09596687,8,计算机应用; 中文信息处理; XML数据处理; 串匹配; 多关键词匹配;,"本文提出了一种对XML文本进行快速串匹配的算法 -XMatch。在对于XML文本的含路径信息的模式串匹配中 ,由于XML文本的结构化特点 ,使得传统的串匹配算法不能直接有效的使用 ;而现有的大部分XML内容筛选方法都是基于SAX分析的事件驱动过程 ,效率普遍较低。XMatch在对XML文本的结构 -schema进行分析的同时 ,结合模式串的路径信息 ,建立一个扫描自动机的有限状态自动机 ;此外 ,算法还支持带循环引用路径信息的模式串匹配。XMatch容易扩展 ,可以支持普通的结构化文本的串匹配。实验结果显示 ,本算法的效率比使用SAX事件驱动的方法有明显的提高。 ",MESS200502003
一种义项矩阵模型SMM,孙斌:06262061,8,计算机应用; 中文信息处理; 信息检索; 检索模型; 义项矩阵;,"本文介绍了一个同时利用词语和义项来索引和检索文档的信息检索模型 ,称为“义项矩阵模型”SMM(SenseMatrixModel) .利用词语和义项的关联提出了一种新的文档表示 ,即把文档表示成为一个term×sense矩阵 ,由此引进或建立起一些很有效用的数据分析技术 ,包括基于矩阵范数的文档相似度计算、文档向量和矩阵的离散余弦变换 (DCT)、多维数据正交分解 (MAD)等 ,并提供了一种新的、无需翻译或者模型训练集的跨语言检索和多语言文本分类的技术。另外 ,还讨论了对文档进行DCT的部分试验结果。 ",MESS200502004
文本的图表示初探,周昭涛:09559474|卜东波:09559496|程学旗:09560271,8,计算机应用; 中文信息处理; 文本表示; VSM模型; 图表示;,"文本表示是文本信息处理中的基础问题 ,以向量空间模型 (VSM)为代表的多数文本表示模型没有考虑文本中特征项之间的序关系 ,这样的表示造成文本语义信息的损失。我们尝试在文本表示中引入序关系 ,用图结构来表示文本 ,提出了一种新的文本表示模型—图表示模型 ,并对该模型的表示效果进行了验证。实验结果表明目前我们的表示模型仍达不到VSM模型所取得的表示效果。本文总结了文本表示过程 ,提出了一种新颖的用于度量文本表示模型表示能力的方法 ,同时也提出了一系列与文本图表示相关的值得探讨的问题。 ",MESS200502005
利用虚拟站点定位技术的网络信息检索研究,刘奕群:08176974|张敏:08186086|马少平:08177513,7,计算机应用; 中文信息处理; 网络信息检索; 非内容特征; 虚拟组织;,"虚拟组织是网格体系结构中的基本组织单元 ,借鉴网格研究中对虚拟组织的特性分析 ,可以在网络信息检索研究中定义虚拟站点的概念。实验发现 ,虚拟站点入口页面是网络信息环境中具有较高质量的一个网页集合 :实验表明 ,仅为全部页面数量 2 1%的此类页面就涵盖了 70 %以上的超链接 ,对这个集合进行的内容检索也比对网页全集的检索有超过 6 0 %的性能提高。这提供了一种在减少索引规模前提下提高网络信息检索性能的解决方案。 ",MESS200502006
基于Ontology的信息检索技术研究,陈康:08029133|武港山:08044172,7,人工智能; 自然语言处理; 信息检索; Ontology; 自然语言理解;,"随着Web的迅速发展 ,网上信息资源越来越丰富 ,网络已经成为了一个全球最大的信息库。而用户要从中得到所需的信息一般是通过各种信息检索工具。但是现有的信息检索工具都存在着检索精度不高等问题。本文针对这些问题 ,提出了将Ontology融合到信息检索技术中的思路。利用Ontology中拥有的领域知识 ,可以大大提高检索系统对自然语言文本的理解能力 ,同时方便用户以自然语言的方式提出检索请求 ,从而提高检索的效果。 ",MESS200502007
词性标注对信息检索系统性能的影响,苏祺:06275641|昝红英:06277525|胡景贺:06262656|项锟:06262035,8,人工智能; 自然语言处理; 信息检索; 向量空间模型; 词性标注; SMART;,"在信息检索中引入NLP技术是信息检索发展的主要趋势 ,本文将NLP中较为成熟的词性标注技术加入信息检索 ,采用大规模TREC数据集 ,试图发现词性标注对检索系统性能的影响。笔者在SMART检索系统上使用不同标注集、不同索引项权重进行了检索实验。实验表明 ,在信息检索中加入词性标注信息可能会对某些特定Topic和Document的检索效果有所改进 ,但词性标注的影响能力弱于索引项权重选择的影响能力。词性标注对检索性能的影响涉及到Topic和Document中的具体用词 ,普遍规律有待进一步研究。 ",MESS200502008
基于粗糙集的文本分类方法研究,卢娇丽:08401945|郑家恒:09167346,5,人工智能; 自然语言处理; 文本分类; 粗糙集; 决策规则;,"本文旨在利用粗糙集优越的约简理论对文本进行分类。主要完成了以下几个方面的任务 :对文本进行了预处理 ;改进了Okapi权重计算公式 ,并对权值进行了离散化 ;实现了属性约简和规则抽取 ,首先利用区分矩阵对特征向量维数进行了初次压缩 ,然后通过相对约简计算再次压缩了特征向量维数 ,并生成了决策规则 ;采取了规则合成的策略 ,生成最终的决策规则 ;设计了一种文本与规则的匹配算法 ,使匹配过程尽可能简单有序。试验结果表明该方法是行之有效的。 ",MESS200502009
一种自举的二元关系和二元关系模式获取方法,姜吉发:09596233|王树西:09596710,7,人工智能; 自然语言处理; 信息抽取; 二元关系; 模式获取;,"本文提出一种自举的二元关系和二元关系模式获取方法BRPAM ,并根据该法设计了一个能够从自由文本中进行二元关系抽取的IE系统BRPAM2Texts。将BRPAM2Texts用于从自由文本中抽取〈组织、组织总部所在地〉类二元关系的实验表明 ,BRPAM2Texts能够根据用户初始给出的几个种子二元关系从一个大的自由文本集合中抽取出更多的二元关系 ,而且有较高的抽全率和抽准率。 ",MESS200502010
基于语料库的字母词语自动提取研究,郑泽之:08869300|张普:06432471|杨建国:06432442,8,人工智能; 自然语言处理; 字母词语; 自动提取;,"目前 ,很多最新的术语和专有名词 ,首先以字母词语的形式出现在汉语中 ,并日益广泛应用。而字母词语多数是汉语自动分词中的未登录词 ,其正确识别 ,将有助于提高中文分词、信息检索、搜索引擎、机器翻译等应用软件的质量。本文在对字母词语进行先期考察的基础上 ,分析了字母词语组成情况的复杂特征和自动识别的难点 ,结合字母词语的各种统计特征和其独有的特点———字母串“锚点” ,提出了从中心往两边扩展的规则加统计辅助的字母词语自动提取的算法。并且对字母词语的双语同现问题进行了处理。算法简单 ,但有效。召回率为 10 0 % ,准确率在 80 %以上。 ",MESS200502011
基于Bootstrapping的文本分类模型,陈文亮:05968474|朱慕华:06569435|朱靖波:06581713|姚天顺:06577453,7,计算机应用; 中文信息处理; 文本分类; 最大熵模型; 权重因子;,"本文提出一种基于Bootstrapping的文本分类模型 ,该模型采用最大熵模型作为分类器 ,从少量的种子集出发 ,自动学习更多的文本作为新的种子样本 ,这样不断学习来提高最大熵分类器的文本分类性能。文中提出一个权重因子来调整新的种子样本在分类器训练过程中的权重。实验结果表明 ,在相同的手工训练语料的条件下 ,与传统的文本分类模型相比这种基于Bootstrapping的文本分类模型具有明显优势 ,仅使用每类10 0篇种子训练集 ,分类结果的F1值为 70 5 6 % ,比传统模型高出 4 70 %。该模型通过使用适当的权重因子可以更好改善分类器的训练效果。 ",MESS200502012
一种新的句子相似度度量及其在文本自动摘要中的应用,张奇:06698167|黄萱菁:06708764|吴立德:06705247,7,计算机应用; 中文信息处理; 文本自动摘要; 向量模型; 相似度计算;,"本文提出了一种新的句子相似度度量的方法并应用于文本自动摘要中。其创新处在于相似度计算不仅考虑句子中的uni gram ,还考虑了bi gram和tri gram ,通过回归方法将这几种相似度结果综合起来。实验证明这种相似度计算方法是有效的。同时本文还提出了一种新的 ,利用句子间相似度以及句子的权重的抽句式文摘算法 ,在抽取出句子的同时也去掉了冗余。DUC2 0 0 3、DUC2 0 0 4 (DocumentUnderstandingConference 2 0 0 3,2 0 0 4 )的评测结果征明了方法的有效性。我们的系统在DUC2 0 0 4的评测中列第二位。 ",MESS200502013
基于改进贝叶斯模型的问题分类,张宇:07001626|刘挺:06994824|文勖:06997645,6,计算机应用; 中文信息处理; 贝叶斯模型; 问题分类; 问答系统;,"随着计算机及互联网络技术的发展 ,开放域问答系统越来越受到人们的关注 ,因为它能够给用户提供相对简洁、准确的结果。开放域问答系统通常包括问题分类、问题扩展、搜索引擎、答案抽取和答案选择五个主要部分。问题分类在问答系统中起着很重要的作用 ,它的准确性直接影响到最终抽取的答案的准确性。本文在对已有的贝叶斯分类方法进行分析的基础上 ,对该方法进行了改进。为了验证该方法的效果 ,构造了问题的训练集和测试集。从实验结果可以看出 ,该方法在实际应用中获得了较好的效果。 ",MESS200502014
利用主语和谓语的句法关系识别谓语中心词,李国臣:08407515|孟静:08454046,8,人工智能; 自然语言处理; 谓语中心词识别; 主谓语之间的句法关系;,"谓语中心词识别对于整个句子的句法分析起着重要的作用。目前已有的谓语中心词识别方法 ,利用谓语中心词候选项的静态语法特征和动态语法特征来确定谓语中心词。在此基础上 ,本文提出一种利用句子的主语和谓语之间的句法关系来识别谓语中心词的方法。该方法除了利用谓语中心词候选项的静态语法特征和动态语法特征外 ,还利用主谓语之间的句法关系识别谓语中心词。实验表明 ,与传统方法相比 ,这种方法对谓语中心词的识别正确率可以提高 3%左右。 ",MESS200501000
一种改进的基于记忆的自适应汉语语言模型,张俊林:10352504|孙乐:10352507|孙玉芳:00585957,6,人工智能; 自然语言处理; 语言模型; 自适应; 同义词词林; 困惑度;,"基于记忆的自适应语言模型虽然在一定程度上增强了语言模型对不同领域的适应性 ,但其假设过于简单 ,即认为一个在文章的前面部分出现过的词往往会在后面重复出现。通过对一些文本的观察分析 ,我们认为作者在书写文章的时候 ,除了常常使用前文中出现过的词汇外 ,为了避免用词单调 ,还会在行文过程中使用前文出现过词汇的近义词或者同义词。另外 ,一篇文章总是围绕某个主题展开 ,所以在文章中出现的许多词汇往往在语义上有很大的相关性。我们对基于记忆的语言模型进行了扩展 ,利用汉语义类词典 ,将与缓存中所保留词汇语义上相近或者相关的词汇也引入缓存。实验表明这种改进在很大程度上提高了原有模型的性能 ,与n元语言模型相比困惑度下降了 4 0 1% ,有效地增强了语言模型的自适应性。 ",MESS200501001
汉语中的零形回指及其在汉英机器翻译中的处理对策,侯敏:10316023|孙建军:12159253,7,人工智能; 机器翻译; 汉英机器翻译; 零形回指; 句组;,"回指是语篇衔接的重要手段 ,零形回指是汉语中常见的一种回指形式。由于汉语、英语是不同类型的语言 ,因此零形回指对汉英机器翻译会产生一定的影响。本文详细分析了汉语零形回指的确认、类型、产生的原因及使用的条件 ,指出其对汉英机器翻译造成的主要障碍是生成的英语句子在结构上不合语法 ,并提出在句组层面上解决问题的算法。 ",MESS200501002
基于词类串的汉语句子结构相似度计算方法,王荣波:09238769|池哲儒:09235803,9,人工智能; 机器翻译; 基于实例机器翻译; 汉英机器翻译; 句子相似度衡量; 自然语言处理;,"句子相似度的衡量是基于实例机器翻译研究中最重要的一个内容。对于基于实例的汉英机器翻译研究 ,汉语句子相似度衡量的准确性 ,直接影响到最后翻译结果的输出。本文提出了一种汉语句子结构相似性的计算方法。该方法比较两个句子的词类信息串 ,进行最优匹配 ,得到一个结构相似性的值。在小句子集上的初步实验结果表明 ,该方法可行 ,有效 ,符合人的直观判断。 ",MESS200501003
从搭配知识获取最优种子的词义消歧方法,全昌勤:16109720|何婷婷:07646488|姬东鸿:07640959|刘辉:07631172,6,人工智能; 自然语言处理; 词义消歧; 搭配; 种子优选;,"基于统计的词义消歧模型的一个关键问题是如何自动从语料库中获取指示词 ,虽然通过学习初始搭配实例能够在语料库中获取更多的搭配知识 ,但人工获取质量较好的初始搭配是比较困难的 ,并且无法保证有效的扩大搭配知识。针对该问题 ,提出了通过机器学习初始搭配实例获取最优种子 ,再由最优种子扩增更多指示词 ,最后利用这些指示词实现具有多个义项的多义词消歧。采用该方法对 8个多义词进行消歧的测试实验中取得了 87 7%的平均正确率。 ",MESS200501004
基于向量空间模型的文本分类系统的研究与实现,陈治纲:08909347|何丕廉:08905652|孙越恒:00014362|郑小慎:08894239,6,计算机应用; 中文信息处理; 文本分类; 测试指标; 特征抽取; 二级分类模式;,"文本分类是信息处理的一个重要的研究课题 ,它可以有效的解决信息杂乱的现象并有助于定位所需的信息。本文综合考虑了频度、分散度和集中度等几项测试指标 ,提出了一种新的特征抽取算法 ,克服了传统的从单一或片面的测试指标进行特征抽取所造成的特征“过度拟合”问题 ,并基于此实现了二级分类模式的文本分类系统。和类中心分类法相比 ,实验结果表明二级分类模式具有较高的精度和召回率。 ",MESS200501005
信息检索策略性能的云模型评价方法,康海燕:05968220|李彦芳:06337526|林培光:06346618|樊孝忠:08673896,6,计算机应用; 中文信息处理; 信息检索; 云模型; 策略性能评价;,"在信息检索中 ,目前常见的评价方法仅能反映检索策略的平均性能 ,不能反映策略的稳定性、随机性等问题 ,因此对检索策略的评价不够全面。本研究提出了基于云模型的检索策略评价方法 ,该方法建立了定性评价和定量数据之间的自然转换 ,这种转换是通过严格的数学方法来实现的 ,用该方法评价检索策略 ,不仅能反映策略的平均性能 ,而且能反映策略的稳定性。实验数据表明 ,该方法是切实可行的 ,评价结果更加逼近实际情况。该方法也可以用于文本分类策略的评价。 ",MESS200501006
基于内容和合作模式的信息推荐机制,林鸿飞:06523490|杨志豪:06508715|赵晶:06504899,8,计算机应用; 中文信息处理; 潜在语义分析; 用户评注; Fisher判别分析; 推荐机制; 访问模式;,"如何根据用户的兴趣向用户推荐相关信息成为目前研究的热点 ,本文提出了基于内容和合作模式的信息推荐机制。其基本思想是根据用户所关心的文本内容将用户划分为不同的内容类 ,同时按照用户的访问模式以及用户评注的一致性 ,将用户分成不同的合作类。综合考虑其内容类和合作类对于用户评注影响 ,利用Fisher判别分析 ,给出了信息推荐机制 ,将相关文本推送给用户。此外 ,随着信息数量的增加和用户的增加 ,自动调节各项参数 ,适应系统的变化 ,同时考虑到系统负荷和响应速度等方面的约束。 ",MESS200501007
自然语言文本水印,张宇:06989058|刘挺:06997645|陈毅恒:06994824|赵世奇:06991005|李生:07005452,8,人工智能; 自然语言处理; 文本水印; 二次余数; 本体语义;,"本文主要介绍了基于自然语言处理的文本水印技术 ,也即自然语言文本水印技术。该技术是在不改变文本原意的前提下 ,将需要隐藏的文本信息 (水印信息 )插入到原始文本中的一种信息隐藏技术。这种技术对于确认信息来源和信息的秘密传送 ,以及版权维护等方面都有着很大的应用价值。本文首先给出了基于自然语言处理技术的文本水印的概念、特点及攻击模型 ,并对文本水印的研究现状进行了分析。通过分析可以看出 ,自然语言文本水印技术有着更好的灵活性 ,并且在适度的攻击下 ,不会破坏水印信息。本文详细介绍了文本水印系统的设计过程 ,包括该技术的基础数学理论 -二次余数理论。最后详细介绍了两种自然语言文本水印嵌入方法 ,分别是基于句法分析和基于语义的水印嵌入方法。 ",MESS200501008
知网与同义词词林的信息融合研究,梅立军:08185307|周强:08177593|臧路:08225570|陈祖舜:08836151,8,计算机应用; 中文信息处理; 词典信息融合; 知网; 同义词词林; 分类;,"本文主要探讨了将知网 (HowNet)和同义词词林进行信息融合的方法。我们针对知网对词的概念描述和同义词词林对词的语义分类的特点 ,提出了一种词典信息融合的方法 :首先为词林的每个词集确定一个与知网中DEF类似的概念描述 ,在此基础上对两部词典中同时收录且均只有一个义项的词语进行双向意义联结 ,最后根据分类算法对两部词典中同时收录非单一义项的词语进行双向意义联结。实验表明 ,本文提出的处理策略达到了 93%的信息融合正确率 ,融合后形成的新词典兼有词林的分类学信息和知网的概念描述信息。 ",MESS200501009
现代藏字全集的属性统计研究,高定国:09504260|龚育昌:09504314,5,计算机应用; 中文信息处理; 藏字全集; 藏字结构; 藏字频度;,"藏文基本属性的研究是藏文信息处理技术的基础 ,现代藏字的研究是藏文信息处理的重点。藏字全集是有限集 ,为了更好地研究现代藏字 ,本文以现代藏字为研究对象 ,按照现代藏文文法的规律 ,对全部现代藏字用计算机辅助统计了藏字全集的个数、藏字的字长、藏字的结构方式、位置特征、字符频度以及所有现代藏字中的整基字丁 ,并且简要地分析了这些数据。这些数据可以较全面地反映现代藏字的本质特征 ,可为藏文研究和藏字信息处理提供基础数据。 ",MESS200501010
汉语口语对话系统中语义分析的消歧策略,刘蓓:10357447|杜利民:05978393,8,计算机应用; 中文信息处理; 口语对话系统; 语义分析; 消歧; 算法;,"框架语义分析是目前汉语口语对话系统中常用的语义解析方法 ,本文分析了语义分析过程中容易产生的两种典型歧义现象 -结构歧义和语义关系歧义。并针对这两种歧义结构 ,分别提出基于语义PCFG模型的结构歧义消歧策略以及基于语义期待模型EM的语义关系歧义消歧策略 ,并给出了有效的消歧算法。实验结果表明综合运用本文提出的消歧策略后 ,基线系统理解模块的句子语义分析正确率大大提高 ,从原来的75 7%上升到 91 5 % ,而且标志语义单元理解率的三项指标 ,准确率 ,召回率和精度也平均提高了 10 %。 ",MESS200501011
多项式回归的汉语时长预测模型,孙璐:11502164|胡郁:09578638|王仁华:09540699,7,计算机应用; 中文信息处理; 时长建模; 多项式; 交互作用;,"时长信息是韵律的重要组成部分 ,对于语音合成的自然度和可懂度都有不可忽视的作用。时长预测是建立对时长有影响的韵律环境与自然语流中音段时长的对应关系。本文引入了统计学中etasquared的概念研究汉语中韵律环境因素对时长的影响 ,设计了残差算法定量分析属性之间的交互作用 ,由此建立了多项式回归的汉语时长预测模型。实验结果表明 ,使用 5～ 6个韵律属性基本上就能够建立比较相关的对应关系 ,和使用同样韵律属性的Wagon回归树的效果相比有明显的优势。 ",MESS200501012
基于凸包像素比特征的粘连汉字切分,魏湘辉:09613144|马少平:08177513,7,人工智能; 模式识别; 粘连汉字; 汉字切分; 背景细化; 凸包;,"汉字切分正确与否直接影响了汉字识别系统的识别率 ,粘连汉字则是切分中的难点。本文将基于背景细化的切分方法应用于《四库全书》的两字符粘连汉字数据集 ,并针对其中切分路径选择问题 ,提出了一种新特征 -凸包像素比 ,反映了在不同切分路径下汉字结构变化的特性。实验结果表明该特征对多种分类器均能有效地提高切分路径选择的正确率。其中在使用基于高斯混合模型分类器时取得了 88 6 %正确率。 ",MESS200501013
进一步的“正易全”——三级汉字编码输入法,张小衡:10235273,7,计算机应用; 中文信息处理; 汉字输入; 字形码; 笔组;,"本文报告“正易全”汉字输入法的新进展。从整体上来讲 ,正易全已发展成为全字笔顺、全字笔组和2 2 1笔组三级输入法系列。前两级简单灵活 ,键选率极低 ,方便大字集查检 ;第三级在常用字和通用字中表现极佳 ,适合日常快速打字。在编码技术上 ,多笔笔组码元的选用、单结构的定义和多结构字的二部划分等方面都作了进一步的简化、系统化和规律化。此外 ,码表在GB130 0 0 1字符集的基础上增加了 116 4个港澳台地区用字或字形。 ",MESS200501014
面向Internet的中文新词语检测,邹纲:11428550|刘洋:13041011|刘群:11577051|孟遥:20410464|于浩:09640519|西野文人:09638999|亢世勇:09638994,9,计算机应用; 中文信息处理; 新词语; 自动检测;,"随着社会的飞速发展 ,新词语不断地在日常生活中涌现出来。搜集和整理这些新词语 ,是中文信息处理中的一个重要研究课题。本文提出了一种自动检测新词语的方法 ,通过大规模地分析从Internet上采集而来的网页 ,建立巨大的词和字串的集合 ,从中自动检测新词语 ,而后再根据构词规则对自动检测的结果进行进一步的过滤 ,最终抽取出采集语料中存在的新词语。根据该方法实现的系统 ,可以寻找不限长度和不限领域的新词语 ,目前正应用于《现代汉语新词语信息 (电子 )词典》的编纂 ,在实用中大大的减轻了人工查找新词语的负担。 ",MESS200406000
结合决策树方法的中文姓名识别,王振华:16349598|孔祥龙:08573760|陆汝占:05969178|刘绍明:08568493,6,人工智能; 自然语言处理; 中文姓名识别; 决策树;,"中文姓名识别是自然语言处理中专名识别的一个重要的子问题 ,本文将中文姓名的识别过程细分为三个步骤 :抽取阶段、分类阶段和消歧阶段。利用中文姓和名的用字概率信息 ,在文本中抽取潜在的中文姓名 ,以及其相关的上下文词法、语法和语义特征 ,并将潜在姓名是否是真实姓名的判别看作是两分类问题 ,并利用决策树算法来实现初步判别 ,最后消除初步判别结果中的歧义现象。实验结果表明 ,该方法的召回率和准确率都可达到 90 %以上。 ",MESS200406001
基于词汇吸引与排斥模型的共现词提取,郭锋:10230230|李绍滋:09227519|周昌乐:09227738|林颖:10232529|李胜睿:09215178,7,计算机应用; 中文信息处理; 共现词; 词汇吸引与排斥模型; 共现距离;,"共现词提取在信息挖掘和自然语言处理中有着十分重要的地位。而传统的共现词提取方法仅仅局限在单一的一种统计量上 ,其结果十分不精确 ,需要人工再进行整理。本文提出了一种基于词汇吸引与排斥模型的共现词提取算法 ,并通过将多种常用统计量进行组合 ,改进了算法的效果。在开放测试环境下 ,所提取的共现词其用户感兴趣度为 6 0 87%。将该算法应用于基于Web的共现词检索系统 ,在速度和共现词的提取精度上均取得了比较好的效果 ",MESS200406002
基于小规模语料库和机器可读词典的二元分布语义获取,郝秀兰:08872553|杨尔弘:09166846,7,人工智能; 自然语言处理; 机器可读词典; 二元分布; 语义; 知识获取;,"本文提出了一种基于小规模语料库和机器可读词典 (MachineReadableDictionary ,MRD)的无指导的动词语义获取方法。该方法不需要使用有义项标注的语料库 ,而是使用从语料中获得的V +N搭配以及MRD中多义词定义的应用实例中获得的知识。使用两种方法解决数据稀疏问题 :首先 ,将词的相似性度量由直接共现扩展到共现词的共现 ,以共现聚类而不是共现词来计算词的相似度。其次 ,从MRD定义中获取名词的IS-A关系。通过这些方法 ,即使两个词不共享任何词 ,也可认为是相似的。实验表明 ,该方法可从很小规模的语料中获取知识 ,并在不限制词义的情况下达到 85 7%的正确排歧率。 ",MESS200406003
结合类频率的关联中文文本分类,钱铁云:07591861|王元珍:11088483|冯小年:00011368,7,计算机应用; 中文信息处理; 基于关联的分类; 中文文本分类; 词类频率; 类别特征词集合;,"该文提出一种词类频率和关联中文文本分类相结合的算法ARCTC。此算法将文档视作事务 ,关键词视作项 ,并针对文本事务的特性 ,提出利用词的类频率筛选与分类相关性不大的词汇 ,然后将改进的关联规则挖掘算法用于挖掘项和类别间的相关关系。挖掘出的规则用于形成类别特征词的集合 ,可用来和类标号未知文档的词的集合求交集 ,交集元素个数最多者即为所分类别。实验证明 ,该算法在提高训练时间和测试时间的同时具有较好的召回率、准确率和F Measure。 ",MESS200406004
面向电子商务的知识描述语言,何坚:05966073|覃征:21411503|贾晓琳:10177763|谢国彤:09056498,6,人工智能; 自然语言处理; 本体论; 电子商务; 描述逻辑; 框架系统; 一阶逻辑;,"针对电子商务自动化、智能化和移动化的新趋势 ,应用本体论对电子商务知识建模 ,提出电子商务知识描述的分层框架 ,结合描述逻辑、框架系统设计了基于XML和本体论技术的电子商务知识描述语言(KDL)。介绍了KDL的语法 ,从一阶逻辑的角度分析KDL的语义特征 ,提供KDL描述到一阶逻辑表达式的映射方法。最后 ,通过实例证明KDL具有规范的语法、精确的语义和较强的逻辑推理能力。 ",MESS200406005
基于HNC理论的句法结构歧义消解,张克亮:09591153,10,人工智能; 自然语言处理; HNC理论; 句法结构歧义; V+NP1+的+NP2; 消解策略; 消解准则;,"歧义消解是自然语言理解和处理所面对的核心问题。基于词组和短语的消歧不能保证消歧结果的正确 ,歧义的成功消解基于对语境或上下文 (context)的正确理解。HNC理论采取的概念基元化、层次化、网络化、形式化策略以及在此基础上建立的句类和句式体系 ,为自然语言的歧义消解提供了最大的可能。基于HNC理论的歧义消解的总体原则是 ,以语句为基础 ,充分利用语句语境提供的句类知识 ,采取宏观消歧与微观消歧相结合的策略。对于经典句法歧义结构V +NP1+的 +NP2 ,本文描述了其三重性歧义性质 ,并提出了三条准则和十个推论以实现对其歧义的消解 ",MESS200406006
语言工程的软件体系结构研究综述,冯冲:09559461|陈肇雄:05975602|黄河燕:09638848,9,人工智能; 自然语言处理; 综述; 语言工程; 软件体系结构;,"语言工程的软件体系结构已经逐渐发展成为语言工程的主要研究领域之一。它面向通用的自然语言应用 ,为其提供架构层次的参考方案。研究内容涵盖与体系结构相关的计算资源、语言资源、方法和应用等多个方面。在一定意义上 ,可以把它看作是在语言工程领域内的特定领域软件体系结构 (DSSA)。本文概要介绍了该领域的发展历程和研究意义 ,然后对其基本概念和当前主要研究进展进行了阐述和分析 ,并展望了进一步的发展趋势。 ",MESS200406007
维吾尔语词切分方法初探,古丽拉·阿东别克:09255276|米吉提·阿布力米提:09251929,5,人工智能; 自然语言处理; 维吾尔语; 词干; 词附加成分; 切分;,"维语词的词干 -词附加成分切分、音节切分的规律对维吾尔语自然语言处理方面提供更多方便。本文提出了以“词 =词根 +附加成分”结构。维语附加成分种类繁多 ,连接形式各式各样 ,在句子中起着非常重要的作用 ,同时有相当的规律性。本文提出了维语中可能出现的基本语音规律的处理方法 ,如 :语音同化、音节切分、语音和谐规律处理。本文对维文词的词法和语音法结构进行了归纳 ,提出了维语词切分的一些规律和实现方法。以新疆高校学报为语料来测试 ,对规则词准确率达到 95 %。 ",MESS200406008
上海普通话与普通话元音系统的声学特征对比研究,于珏:12177792|李爱军:20739125,7,计算机应用; 中文信息处理; 上海普通话; 标准普通话; 声学元音图; 共振峰模式; 口音;,"本文通过对单音节字的声学测量及分析 ,对比上海市的地方普通话和普通话的元音系统 ,从而为汉语口语处理基本元音系统提供可靠的声学参数。发现 :1 受上海话自身元音系统的影响 ,上海普通话男女声学元音图都表现出一定的外延性。 2 上海普通话无论男女 ,[ , ]在声学元音图上的分布都有很大的重叠区。3 从共振峰模式图上看 :上海普通话 [y ,i, , ]的F1-F2距离都较标准普通话的大 ,其中 [ ]的共振峰模式几乎接近于 [ ]。 4 多数发音人的 [ ]都或多或少表现出双元音化趋势。 ",MESS200406009
嵌入式语音识别系统的研究和实现,方敏:10527904|浦剑涛:11417197|李成荣:13621479|台宪青:11322334,6,计算机应用; 中文信息处理; 嵌入式平台; 非特定人语音识别; 语音识别SOC;,"本文首先给出了一种适合于在嵌入式平台上实现的可变命令集的非特定人语音识别系统 ,同传统的基于PC的非特定人语音识别系统相比 ,该系统具备内存消耗小 ,运算速度快的优点。然后给出了该语音识别系统在多种嵌入式平台上的实现和评估结果 ,论证了非特定人语音识别系统在嵌入式平台上实现的可行性及其对硬件的最低配置要求 ,在技术层次上分析了目前实现高性能语音识别SOC的主要问题和困难 ,并指出了今后相关的研究方向 ",MESS200406010
分级语音识别研究,徐明星:08184190|杨大利:08834271|吴文虎:08239495,6,计算机应用; 中文信息处理; 语音识别; 分级识别; 空间划分;,"分级识别的策略在模式识别领域中提出相当长的时间了。尽管人类可以训练地使用这个策略进行识别 ,但对语音识别而言 ,缺少一个有效的系统化的方法来实现它。本文给出了我们最近在这方面做的一些研究工作 ,使用了子空间划分原理来实现一个分级识别器 ,并用树型结构来组织多个识别器。实验结果表明 ,该方法与传统方法相比 ,误识率降低 10 %。我们将在未来的研究工作中 ,测试全部汉语音节 ,并将该方法扩展到连续语音识别 ",MESS200406011
《中文信息学报》征稿简则,,1, , ,MESS200406012
汉语句法树库标注体系,周强:08836151,8,计算机应用; 中文信息处理; 句法树库; 标注规范; 语料库语言学;,"语料库的句法标注是语料库语言学研究的前沿课题。本文在研究和总结国内外句法树库标注实践的基础上 ,提出了一套汉语真实文本的句法树标注体系。它以完整的层次结构树为基础 ,对句法树上的每个非终结符节点都给出两个标记 :成分标记和关系标记 ,形成双标记集的句法信息描述体系。目前 ,这两个标记集分别包含了 1 6和 2 7个标记 ,对汉语句子的不同句法组合的外部功能分布和内部组合特点进行了详细描述。在此基础上 ,我们开发完成了 1 0 0万词规模的汉语句法树库TCT ,对其中各种复杂语言现象的标注实践显示了这套标注体系具有很好的信息覆盖率和语料适应性 ",MESS200404000
基于规则的自动分类在文本分类中的应用,李渝勤:12183654|孙丽华:06402959,6,计算机应用; 中文信息处理; 文本挖掘; 文本分类; 规则分类;,"文本自动分类是指将文本按一定的策略归于一个或多个类别中的应用技术。本文首先介绍三种基于统计的自动分类技术 (k近邻分类器、支持向量机分类器和朴素贝叶斯分类器 ) ,剖析了基于统计的自动分类的优势及不足。基于统计的自动分类的不足主要表现为 :当类别之间分类特征的交叉变大时 ,分类精度呈下降趋势 ,在多层分类的情况下 ,此局限尤为突出。针对此局限性 ,为了提高自动分类的精度 ,我们引入了基于规则的自动分类来对其进行改进和扩充 ,并整合两种自动分类技术的优点 ,设计出了混合分类器系统 ,从而获得了比较理想的分类效果 ",MESS200404001
半结构化中文信息检索中查询结果相关度算法的研究,曲卫民:00913383|孙乐:10352507|孙玉芳:10352504,8,计算机应用; 中文信息处理; XML; 信息检索; 相关度算法;,"本文研究了对富含文本信息的XML数据进行基于关键字的查询时 ,查询结果与查询条件之间相关度的计算问题 ,分析了利用传统信息检索技术解决该问题时存在的一些不足 ,提出了一种基于节点的动态的关键字权重计算法 ,以及综合考虑关键字在查询结果中的频率分布特征和结构分布特征的查询结果相关度计算法 ,有效解决了XML数据中的结构信息对相关度计算的影响 ,实验证明本文中的方法取得了较好的检索性能 ",MESS200404002
基于转换的时间-事件关系映射,王昀:08182403|苑春法:08185290,8,计算机应用; 中文信息处理; 时间信息处理; 基于转换的错误驱动学习; 信息抽取;,"近些年来 ,中文时间信息抽取和处理已经变得越来越重要。然而 ,很少有研究者关注中文文本中事件信息所对应的时间信息的识别和分析。本文的目的就是确定文本中时间信息和事件信息之间的映射关系。区别于传统的基于规则的方法 ,本文采用了一种机器学习的方法—基于转换的错误驱动学习—来确定事件相应的时间表达 ,这种学习算法可以自动的获取和改进规则。使用训练得到的转换规则集后 ,系统的时间 -事件映射错误率减少了 9 74 % ,实验结果表明本系统对基于规则的方法有很好的改进效果 ",MESS200404003
基于机器理解的汉语隐喻分类研究初步,杨芸:09222501|周昌乐:10230031|王雪梅:10232529|戴帅湘:09198455,6,计算机应用; 中文信息处理; 隐喻; 分类; 计算模型; 相似性;,"本文将汉语隐喻分类计算模型的研究引入汉语的机器理解当中 ,通过对大规模汉语隐喻语料的研究分析 ,结合汉语隐喻的认知特征 ,笔者构建了一套基于理解的汉语隐喻分类体系。分类主要以汉语隐喻句中本体和喻体的内在相似性作为切入点 ,从隐喻理解的方式、理解的难易程度以及理解所涉及的相关知识结构等方面进行综合分析 ,同时 ,辅以真实语料的统计分析 ,对分类的合理性作出了验证和修订 ,最终给出了基于理解的汉语隐喻分类体系 ,并对该体系作出了语言学上的比较和解释 ",MESS200404004
基于互连网的术语定义获取系统,许勇:06291336|荀恩东:05982879|贾爱平:06433829|宋柔:06433984,7,人工智能; 自然语言处理; 术语定义; 信息抽取;,"文中介绍了一个实验性的基于互联网的术语定义获取系统 ,可以方便、迅速的从互连网上查找术语的定义以及与定义有关的内容 ,给用户迅速获得新生术语以及新技术词汇的定义方面的知识提供方便。系统采用一组术语定义的语言学模式 ,以多线程方式高效下载网页 ,并从中匹配符合术语定义模式的文本段落 ,再经一定后续处理 ,形成返回给用户的结果。系统中使用的语言学模式是在一定量的科技期刊语料库中获取的。试验结果表明系统的运行效率高 ,结果的准确度比较令人满意 ",MESS200404005
灰度图像中字符切分方法的研究,陈艳:09639559|孙羽菲:09639431|张玉志:09638874,6,人工智能; 模式识别; 字符切分; 灰度图像; OCR;,"字符切分目前已经成为限制OCR技术发展的瓶颈 ,对于图像质量较差、中英文混排和背景色变化的文本图像 ,传统切分方法造成的切分错误使得文字识别率大大降低。针对这些问题 ,本文提出了新型文字切分方法。该方法先将灰度图像的灰度值进行分级处理 ,再根据分级连通域的概念把整个图像构造成树状结构 ,然后确定主层次级别 ,根据一定的规则在部分节点上进行合并、分割等进一步处理 ,最后得到最优的切分结果。实验结果表明 ,该方法能够取得比常规切分方法更好的切分效果 ",MESS200404006
基于规则库的汉字输入法自动评测系统的设计,张玉华:09891152|周克兰:09891719,5,计算机应用; 中文信息处理; 码本; 规则库; 自动评测系统;,"汉字编码输入法是汉字输入电脑的主要方式。对输入法进行科学评价 ,从而帮助软件开发人员和输入法用户进行自我改进或评估 ,有其十分积极的意义。本文在实际应用基础上 ,提出了通过汉字输入系统输入规则库的建立 ,在选定的输入法状态下 ,通过计算机自动模拟汉字输入得到输入法码本 ,并以码本为基础根据信息技术国家标准完成输入法性能自动评价的思路 ",MESS200404007
一种计算汉字串之间相关程度的新方法,曹娟:09239999|周经野:09214087,5,计算机应用; 中文信息处理; 黏结度; 相关信息[5]; 分词;,"本文提出了一种能更准确的反映两个汉字串之间相关程度的新概念———黏结度 ,并给出了其计算方法。该方法把需要计算相关程度的汉字串放在一个大环境中进行讨论 ,通过加入上下文信息来提高分词的准确度 ;另外 ,该方法在引用汉字词频时 ,增加了对动态词频的考虑 ,可以自动识别未登陆的专业词汇。文中同时给出了黏结度在分词领域中的应用实例。通过与前人提出的相关信息的方法相比较 ,这种计算方法能够解决分词中一些难于解决的问题并提高分词的精确度 ",MESS200404008
《信息处理用GB13000.1字符集汉字部件规范》在输入法应用中的难点讨论,张小衡:10235273,6,计算机应用; 中文信息处理; 汉字输入; 汉字部件; 规范;,"《信息处理用GB1 30 0 0 1字符集汉字部件规范》对于规范汉字形码输入法具有非常重要的意义。然而 ,在实际运用上却存在着部件数量太大 ,部件定义难以操作 ,部件拆分组合不易掌握等难处。造成困难的原因主要有 :(1 )基础部件主要靠列表来确定 ,(2 )部件强调按理切分和成字组合 ,(3)过多依赖“组字能力”的判别 ,(4 )过分注重部件数量的限制。要走出“难”的困境 ,应该在现有规范的基础上根据汉字的形态特征制定出简便可靠的部件识别规则和切分规则。实验证明 ,这种方法是行之有效的 ",MESS200404009
自然言语的韵律组织中的不确定性及其在语音合成中的应用,初敏:08983522,6,计算机应用; 中文信息处理; 言语; 韵律的不确定性; 单元选择; 最小错误准则;,"本文对自然言语的韵律组织中的不确定性及其对合成语音自然度的影响进行了初步探讨 ,并在此基础上 ,提出在韵律预测中用最小错误概率准则代替传统的最大生成概率准则 ,从而在预测结果中保留多种等价的韵律实现。本文还进一步提出一种将基于最小错误准则的韵律预测与单元选择结合的算法 ,首先根据最小错误准则在所有候选单元中筛选出最不可能造成韵律错误的样本 ,然后再依据最平滑拼接准则从各种韵律等价的路径中选出一条能达到最平滑拼接的作为最后输出 ",MESS200404010
盲人用计算机软件系统中的语音和自然语言处理技术,庄丽:08188193|包塔:08187758|朱小燕:08224966,7,计算机应用; 中文信息处理; 语音合成; 文本分析; 汉语自动分词; 语言模型;,"本文介绍了智能技术与系统国家重点实验室开发的“北极光”盲人用计算机软件系统中涉及的语音和语言处理技术。该系统能够获取和分析需要反馈的屏幕信息 ,通过语音合成平台将其内容朗读出来 ,对用户进行语音提示 ;与汉语自动分词、语言模型等自然语言处理技术的结合 ,使系统能够进行汉字和盲文的转换 ,反馈信息可以通过盲文点显器输出 ,使用户能够摸读盲文点字来获取所需要的信息 ,用户也可以采用盲文输入法进行输入 ,输入结果可转换为汉字文本形式 ",MESS200404011
多模式汉语连续语音识别中视觉特征的提取和应用,刘鹏:08230660|王作英:00006332,6,计算机应用; 中文信息处理; 多模式; 听-视觉融合; 视觉特征提取; 鲁棒性;,"本文对在汉语多模式汉语语音识别系统中利用视觉特征进行了研究 ,给出了基于多流隐马尔科夫模型 (Multi streamHMM ,MSHMM)的听视觉融合方案 ,并对有关视觉特征的两项关键技术 :嘴唇定位和视觉特征提取进行了详细讨论。首先 ,我们研究了基于模板匹配的嘴唇跟踪方法 ;然后研究了基于线性变换的低级视觉特征 ,并与基于动态形状模型的特征作了比较 ;实验结果表明 ,引入视觉信息后无噪环境下语音识别声学层首选错误率相对下降 36 0 9% ,在噪声环境下的鲁棒性也有明显提高 ",MESS200404012
基于SVM的中文组块分析,李珩:05968474|朱靖波:06569435|姚天顺:06579782,7,计算机应用; 中文信息处理; 支持向量机; 结构风险最小化; 文本组块;,"基于SVM(supportvectormachine)理论的分类算法 ,由于其完善的理论基础和良好的实验结果 ,目前已逐渐引起国内外研究者的关注。和其他分类算法相比 ,基于结构风险最小化原则的SVM在小样本模式识别中表现较好的泛化能力。文本组块分析作为句法分析的预处理阶段 ,通过将文本划分成一组互不重叠的片断 ,来达到降低句法分析的难度。本文将中文组块识别问题看成分类问题 ,并利用SVM加以解决。实验结果证明 ,SVM算法在汉语组块识别方面是有效的 ,在哈尔滨工业大学树库语料测试的结果是F =88 6 7%,并且特别适用于有限的汉语带标信息的情况。 ",MESS200402000
Web信息检索结果融合中的按位加权插入合并算法,张敏:08186086|金奕江:08169589|马少平:08177513,7,计算机应用; 中文信息处理; Web信息检索; 数据集选择; 结果融合; 基于排序的融合;,"在Internet中 ,由于海量数据的多样性 ,在分布式数据集合上进行有效的检索就成为Web信息检索的一种必要方式。由此 ,引出多个检索结果的融合问题。对不同检索结果的相似度评分可能完全不可比的情况 ,本文给出一种新的解决方案 :按位加权插入合并算法。在 18GB的大规模web标准测试集上的实验证明 ,该算法始终能够提高综合检索性能 ,且分布数据集检索结果越好 ,则合并后性能改善越多。其中系统平均精度提高接近 10 %,突破了传统方法对分布数据集结果合并的综合效果总是低于使用集中数据集检索的性能局限。 ",MESS200402001
OpenE:一种基于n-gram共现的自动机器翻译评测方法,孙连恒:05968474|杨莹:06581070|姚天顺:06573282,8,人工智能; 机器翻译; 机器翻译评测; 信息量计算; n-gram共现;,"在机器翻译研究领域中 ,评测工作发挥着重要的作用 ,它不仅仅是简单地对各个系统输出结果进行比较 ,它还对关键技术的发展起到了促进作用。译文质量的评测工作长期以来一直以人工的方式进行。随着机器翻译研究发展的需要 ,自动的译文评测研究已经成为机器翻译研究中的一个重要课题。本文讨论了基于n gram共现的自动机器翻译评测框架 ,介绍了BLEU、NIST、OpenE三种自动评价方法 ,并通过实验详细分析了三种方法的优缺点。其中的OpenE采用了本文提出了一种新的片断信息量计算方法。它有效地利用了一个局部语料库 (参考译文库 )和全局语料库 (目标语句子库 )。实验结果表明这种方法对于机器翻译评价来说是比较有效的。 ",MESS200402002
一种改善的基于语言模型的中文检索系统研究,张俊林:10352504|曲为民:10352507|孙乐:09573827|孙玉芳:00585957,8,计算机应用; 中文信息处理; 语言模型; 信息检索; 触发;,"最近几年提出的语言模型检索系统将语音识别领域的语言模型技术引入信息检索领域并改善了检索系统的性能 ,但是其隐含的词汇间相互独立的假设并不符合实际情况。尽管统计翻译模型考虑了词汇间的同义词因素 ,但是由于它没有考虑词汇上下文信息 ,所以对于解决多义词词义的区分并无帮助。我们提出了触发语言模型检索方法来改善这一状况 ,通过训练语料得到词汇在一定上下文中的相关比率 ,同时利用查询条件所含词汇计算触发词汇集合来区别查询条件词汇的具体含义并将相关参数引入文档语言模型形成触发语言模型。实验结果表明我们提出的这个方法显著改善了检索系统的性能 ,与经典语言模型方法相比 ,触发语言模型方法的平均查准率提高了约 12 %,召回率提高了 10 8%。 ",MESS200402003
汉语语料词性标注自动校对方法的研究,钱揖丽:09167346|郑家恒:09166197,6,计算机应用; 中文信息处理; 兼类词; 汉语词性标注; 自动校对; 粗糙集;,"兼类词的词类排歧是汉语语料词性标注中的难点问题 ,它严重影响语料的词性标注质量。针对这一难点问题 ,本文提出了一种兼类词词性标注的自动校对方法。它利用数据挖掘的方法从正确标注的训练语料中挖掘获取有效信息 ,自动生成兼类词词性校对规则 ,并应用获取的规则实现对机器初始标注语料的自动校对 ,从而提高语料中兼类词的词性标注质量。分别对 5 0万汉语语料做封闭测试和开放测试 ,结果显示 ,校对后语料的兼类词词性标注正确率分别可提高 11 32 %和 5 97%。 ",MESS200402004
基于对话语音的与文本无关的说话人确认系统的研究,陈雁翔:10337065|戴蓓倩:10334498|周曦:09572233|李辉:09505709,8,计算机应用; 中文信息处理; 对话语音; GLR距离测度; 无监督语音分割;,"本文建立了一个基于对话语音的与文本无关的说话人确认系统 ,它和传统的与文本无关的说话人确认系统的关键不同在于 ,训练及测试语音不再只包含一个人而都是对话语音 ,因此需要分割出属于不同说话人的语音段 ,以建立说话人模型和实现最终判决。文中详细介绍了高斯混合模型 -背景模型 (GMM UBM)这种说话人确认系统的框架 ,重点讨论了基于GLR(GeneralizedLikelihoodRatio)距离测度的无监督语音分割算法。最终阐述的输出评分的规整方法即ZNORM (ZeroNormalization)和持续时间修正 ,可以使确认系统的性能提高近 10 %。 ",MESS200402005
语音合成中的韵律关联模型,吴志勇:08183194|蔡莲红:00009725,7,计算机应用; 中文信息处理; 文语转换; 基元选取; 韵律关联;,"基于大规模语音数据库的文语转换系统 (Text to Speech ,TTS)中 ,如何选取合适的语音基元是提高合成语音自然度的重要因素。本文研究了连续语流中的韵律关联现象 ,提出了包含韵律关联参数的汉语韵律特征参数集 ,基于数据挖掘中的关联规则模型 (AssociationRulesModel)建立韵律关联模型 ,并将该模型应用于基元选取。实验表明 ,该方法有效地利用了语音基元的韵律及关联信息 ,符合人耳的知觉感受 ,使得合成语音自然度的主观评测MOS(MeanOpinionScore)得分与不考虑韵律关联时的结果相比提高了 12 2 2 %(3 4 9/3 11)。 ",MESS200402006
基于不对称性的相似汉字识别方法,孙羽菲:09638874|陈艳:09639431|张玉志:09639559,7,人工智能; 模式识别; 不对称性; 相似汉字识别; 部分空间法; 分类;,"相似字识别的正确与否对整个识别系统的准确性和可用性都有着极大的影响。在实际应用中 ,我们发现相似汉字之间的误识存在不对称性 ,并对这种不对称现象的成因进行了细致的探讨和分析。基于这种不对称性 ,本文提出了一种分类的部分空间方法来解决相似字的识别问题。相似字按其结构特点被分成若干基本类别 ,不同类别在相应的部分空间提取不同的特征进行比较 ,以达到正确识别相似字的目的。实验结果表明了本方法的有效性 ,相似字识别的准确性得到了很大的提高 ,其中易错相似字的识别正确率平均提高了4 5 5个百分点 ,不易错相似字的识别正确率平均提高了 0 38个百分点。 ",MESS200402007
快速中文字符串模糊匹配算法,陈开渠:22933128|赵洁:22715602|彭志威:22839335,8,计算机应用; 中文信息处理; 字符串匹配; 模糊匹配; 中文字符串匹配;,"本文解决了中文字符串模糊匹配的两个主要问题 :空间问题和时间问题。目前字符串模糊匹配的两个主要方法是位向量方法和过滤方法。由于汉字众多 ,应用位向量方法时 ,需要大量空间。对于某些内存很少的小型计算机 ,比如嵌入式系统 ,这将会是一个问题。本文改进了位向量方法 ,使其在应用于中文字符串时 ,空间需求降低到约 5 %。本文还利用汉字非常多的特点 ,提出一种新的基于过滤方法的中文字符串模糊匹配算法 ,BPM BM ,其速度比世界上最快的算法至少提高 14 %;在大部分情况下 ,是其速度的 1 5～ 2倍。 ",MESS200402008
在ICU中实现少数民族文字的处理,董治江:06426123|吴健:00004563|钟义信:09573880,7,计算机应用; 中文信息处理; 复杂文本; Unicode; OpenType; 布局引擎;,"基于ISO/IEC 10 6 46和UNICODE国际标准 ,用传统的字体技术 (如TrueType)来实现少数民族文字处理所面临的一个“瓶颈”问题是 :“变形显现字符”不存在确定的码位。这也是多年来民文系统重复开发、互不兼容的根本原因。本文基于ICU的文字处理体系结构 ,阐述了完全支持Unicode标准的少数民族文字(本文主要指蒙古文字、维文、藏文等 )的实现方法。文中首先介绍了少数民族文字的特点 ,分析其与拉丁文字、汉字在计算机输入、输出过程中的不同之处 ,并指出少数民族文字处理的难点。其次介绍了一种能满足少数民族文字处理需求的字体技术———OpenType。最后 ,阐述了文字处理引擎的工作原理 ,以及ICU中如何实现对少数民族文字的支持。 ",MESS200402009
多文种环境下汉字内码识别算法的研究,李培峰:05968617|朱巧明:05970941|钱培德:09886822,7,计算机应用; 中文信息处理; 多文种环境; 汉字内码; 识别算法;,"汉字内码向ISO/IEC 10 6 46过渡是实现计算机用文字编码统一的必然趋势 ,但目前在一段时间内仍将存在多种汉字内码并存的情况 ,所以实现汉字内码的自动识别是保证汉字多内码并存的关键。本文主要探讨了如何在多内码并存的多文种环境中实现汉字内码自动识别的问题 ,并提供了多种汉字内码识别算法 ,包括基于内码分布、标点符号特征、字频特征和语义特征的识别算法等。在此基础上 ,本文对不同的识别算法进行分析和评估。在对目标样本的测试中 ,以上算法的识别率最高可以达到 99 9%以上。 ",MESS200402010
信息技术名词定名的系统分析方法与评价指标体系,王有志:21083548|赵敏:20017373|陈俊峰:08186671,6,计算机应用; 中文信息处理; 科技名词; 英汉名词定名; 信息技术; IT; 系统分析;,"在多年学习、使用、翻译与参与评审几种规范IT名词集的基础上 ,本文将系统分析方法用于对此类名词集的定名与评价。其基本方法 ,一是从名词集中拆分出基础要素———名词元 ;二是提出八项量化指标 :印误率 ,英语拼写不一致与不规范率 ,非必要的一多与多一对应率 ,英汉名词不对等率 ,与交叉学科名词有异率 ,与国标定名不符率 ,收词欠完备与冗余率及总体值得修榷率。并以目前收录最全的IT规范名词集为例 ,通过名词元对这些量化指标进行了模拟计算 ,计算结果证明该方法是合理可行的。这种方法原则上也适用于自然科学技术其他学科的名词或术语定名。 ",MESS200402011
面向特定领域的汉语句法主干分析,齐浩亮:11428550|杨沐昀:06997147|孟遥:06987836|韩习武:06996935|赵铁军:06997742,6,人工智能; 自然语言处理; 浅层句法分析; 句法主干分析; 模板;,"本文提出了一种面向特定领域的汉语句法主干分析方法。该方法中包括浅层句法分析、模板匹配两个关键环节 ,形成用模板表示的句法主干。在浅层句法分析中 ,本文使用了级联的隐马尔可夫模型进行了短语的归并 ;而后以已有的汉语句子模板为基础 ,进行模板匹配以达到句法主干分析的目标。在针对体育新闻领域语料的开放测试中 ,模板匹配的精确率和召回率分别达到了 98 0 4 %和 81 4 3% ,句子级的精确率和召回率分别达到了 96 97%、84 85 % ,实验表明该方法在特定领域是有效的 ",MESS200401000
Web页面信息块的自动分割,瞿有利:13041011|于浩:11577051|徐国伟:13041003|西野文人:16861537,8,计算机应用; 中文信息处理; Web页面; 信息提取; 信息块;,"随着Internet的发展 ,Web页面数量的急剧增加 ,如何快速有效地获取信息变得越来越重要。一类Web页面往往包含着多个信息单元 ,它们在展现上排列紧凑、风格相似 ,在HTML语法上具有类似的模式 ,例如一个BBS页面上多个发言 ,每个信息被称为一个信息块。对于信息抽取、信息过滤等应用 ,需要首先将原始页面中分割为若干合适的信息块以便于后续的处理。本文提出了一种自动将Web页面分割为信息块的方法 :首先通过创建Web页面结构化的HMTL分析树 ,然后根据包含有效文本量等确定包含信息块的子树 ,最后根据子树深度信息利用 2 -rankPAT算法进行分割。通过对BBS页面的信息块抽取实验 ,证明了该方法的有效性。 ",MESS200401001
基于决策树的汉语未登录词识别,秦文:08185290|苑春法:08234325,6,人工智能; 自然语言处理; 未登录词识别; 数据挖掘; 决策树; C4.5算法;,"未登录词识别是汉语分词处理中的一个难点。在大规模中文文本的自动分词处理中 ,未登录词是造成分词错识误的一个重要原因。本文首先把未登录词识别问题看成一种分类问题。即分词程序处理后产生的分词碎片分为‘合’(合成未登录词 )和‘分’(分为两单字词 )两类。然后用决策树的方法来解决这个分类的问题。从语料库及现代汉语语素数据库中共统计出六类知识 :前字前位成词概率、后字后位成词概率、前字自由度、后字自由度、互信息、单字词共现概率。用这些知识作为属性构建了训练集。最后用C4 5算法生成了决策树。在分词程序已经识别出一定数量的未登录词[6 ] 而仍有分词碎片情况下使用该方法 ,开放测试的召回率 ;6 9 4 2 % ,正确率 :4 0 4 1%。实验结果表明 ,基于决策树的未登录词识别是一种值得继续探讨的方法。 ",MESS200401002
语料库中熟语的标记问题,安娜:06301610|刘海涛:06301544|侯敏:06301801,7,人工智能; 自然语言处理; 熟语; 固定语; 标注; 语料库;,"熟语是自然语言中普遍存在的语言现象。本文分析了国内现有语料库对熟语的标注方式 ,发现这种方式对语料库的进一步加工是有问题的。为了在语料库标注阶段把熟语问题处理好 ,本文从信息处理的角度将熟语中的成语、惯用语、歇后语、习用语、专门语以及缩略语归为固定语的范畴 ,进而提出根据固定语的语法功能给定词性标记 ,再根据它们的词汇特征给定词汇范畴标记的双层标记法 ,这样在一定程度上解决了熟语的语料库标注问题。 ",MESS200401003
中文文本分类中特征抽取方法的比较研究,代六玲:09638848|黄河燕:05975602|陈肇雄:08062700,7,计算机应用; 中文信息处理; 文本自动分类; 特征抽取; 支持向量机; KNN;,"本文比较研究了在中文文本分类中特征选取方法对分类效果的影响。考察了文档频率DF、信息增益IG、互信息MI、χ2分布CHI四种不同的特征选取方法。采用支持向量机 (SVM )和KNN两种不同的分类器以考察不同抽取方法的有效性。实验结果表明 ,在英文文本分类中表现良好的特征抽取方法 (IG、MI和CHI)在不加修正的情况下并不适合中文文本分类。文中从理论上分析了产生差异的原因 ,并分析了可能的矫正方法包括采用超大规模训练语料和采用组合的特征抽取方法。最后通过实验验证组合特征抽取方法的有效性。 ",MESS200401004
基于邻接矩阵全文索引模型的文本压缩技术,陶晓鹏:05964539|胡运发:06704293,9,计算机应用; 中文信息处理; 邻接矩阵; 文本压缩; 压缩模型; 基于不定长单词的Huffman编码;,"基于不定长单词的压缩模型的压缩效率高于基于字符的压缩模型 ,但是它的最优符号集的寻找算法是NP完全问题 ,本文提出了一种基于贪心算法的计算最小汉字平均熵的方法 ,发现一个局部最优的单词表。这种方法的关键是将文本的邻接矩阵索引作为统计基础 ,邻接矩阵全文索引是论文 [9]提出的一种新的全文索引模型 ,它忠实地反映了原始文本 ,很利于进行原始文本的初步统计 ,因此算法效率得以提高 ,其时间复杂度与文本的汉字种数成线性关系 ,能够适应在线需要。并且 ,算法生成的压缩模型的压缩比是 0 4 7,比基于字的压缩模型的压缩效率提高 2 5 %。 ",MESS200401005
基于文本集密度的特征选择与权重计算方案,吴科:08255677|石冰:08211434|卢军:08208143|牛小飞:08214796,6,计算机应用; 中文信息处理; 信息检索; 文本集密度; 权重计算方案; 元打分法;,"在信息检索的向量空间模型中 ,文本被形式化表示为由词语权重组成的向量。因此如何让这种向量尽量准确的有效的表示出文本内容一直是该模型中的基础性问题。在这篇论文中 ,我们提出了一种基于文本集密度的特征词选择与权重计算方案的方法。它是一种使用词对文本集密度的贡献衡量该词的价值的方法。使用这种方法 ,我们能找出不损失文本有效信息的最小特征词语集 ,并且创造出更为合理权重计算方案。在文中还用了一种新的衡量权重好坏的标准———元打分法 ,来证明提出的方法是有效的 ",MESS200401006
信息抽取模式自动生成方法的研究,郑家恒:09167346|王兴义:08409116|李飞:08407512,7,人工智能; 自然语言处理; 信息抽取; 模式匹配; 信息抽取模式;,"模式匹配是信息抽取系统通常使用的方法 ,如何生成信息抽取模式就成为信息抽取的关键问题。由于手工编写模式的代价太大 ,本文尝试采用聚类方法自动生成针对中文文本的信息抽取模式。通过计算模式实例间的相似度 ,采用单链法聚类 ,将模式实例划分为不同的类别 ,每个类别对应一个模式 ,将同一类别中的模式实例进行合并就可以得到最终的信息抽取模式。以农作物信息文本为实验语料 ,进行了聚类测试 ,错分率与漏分率分别为 0 2 1%和 1 0 7% ,合并后的模式覆盖了人工分析提出的 2 5类中的 2 4类 ",MESS200401007
第2届学生计算语言学研讨会(SWCL 2004),,1, , ,MESS200401008
EBMT系统中的多词单元翻译词典获取研究,程洁:05978393|杜利民:09590239,7,人工智能; 机器翻译; EBMT; 翻译词典; 多词单元;,"EBMT系统是一种基于语料库的机器翻译方法 ,其主要思想是通过类比原理进行翻译。如何从语料库中提取出一个实用的翻译词典进行系统的辅助翻译已经越来越多的引起关注。本文探讨了如何结合阈值和关联度提取的方法获取多词单元翻译词典 ,在这两种方法中 ,阈值提取受主观影响太大 ,关联值提取效率太低 ,都不能很好的满足翻译词典提取的要求。本文提出的算法利用阈值提取出备选多词单元 ,其中提出了四点规则弱化主观影响且保证全面覆盖所有多词单元 ,降低了阈值本身所带来的不精确度的影响 ,然后对计算结果进行三层过滤 ,进一步提高了准确率 ;该算法还合并了单词译成多词单元和多词单元互译两部分词典的提取 ,提高了工作效率 ",MESS200401009
灰度名片图像快速倾斜检测和校正方法,卜飞宇:08819880|刘长松:08171740|丁晓青:00007412,8,人工智能; 模式识别; 灰度图像; 倾斜检测; 倾斜校正; 边缘拟合直线;,"本文针对名片OCR系统的要求 ,提出了一种新的根据图像扫描时产生的黑色边缘来检测灰度名片图像倾斜角度的方法。该方法先检测出名片的四条边缘拟合直线 ,由四条边缘拟合直线的倾斜角度来确定名片图像倾斜角度 ,然后采用逐段整块搬移的方法来对图像进行倾斜校正 ,再根据边缘拟合直线位置去除黑边。实验表明 ,该方法具有很快的速度和很高的正确率 ,是一种实用价值较高的方法。而且 ,该方法能推广应用于其它灰度和彩色扫描图像的倾斜检测和校正 ",MESS200401010
首届全国少数民族青年计算语言学家学术研讨会,,1, , ,MESS200401011
分段模型在解码假设检验中的应用,张翼燕:13621948|刘文举:10983611|徐波:11459454,8,人工智能; 自然语言处理; 解码假设检验; 分段模型; 参数轨迹模型;,"本文主要研究了分段模型 (以参数轨迹模型为例 )在解码假设检验中的应用。分段模型与传统的HMM相比 ,具有更加精确的建模能力。多年来人们一直致力于研究它对语音识别性能的提高 ,而忽视了其它方面的应用。本文提出了分段模型校验的方法 ,对HMM的识别结果进行二次处理 ,克服了传统方法在不同句子间不具有可比性的缺点 ,简单而有效 ;在此基础上 ,为了满足系统的特殊要求 ,训练Fisher分类器 ,选择分段模型而非HMM的N Best信息作为特征输入 ,验证了分段模型得分作为可信度指标时的优秀区分能力。实验结果表明 ,在第一类错误率为 5 %的情况下 ,最好的第二类错误率可以降到 2 5 2 6 5 %。这体现了系统良好的拒识性能。 ",MESS200401012
基于遗传径向基神经网络的声音转换,左国玉:13622010|刘文举:05972460|阮晓钢:11459454,7,人工智能; 自然语言处理; 声音转换; RBF神经网络; 遗传算法; 线谱频;,"声音转换技术可以将一个人的语音模式转换为与其特性不同的另一个人语音模式 ,使转换语音保持源说话人原有语音信息内容不变 ,而具有目标说话人的声音特点。本文研究了由遗传算法训练的RBF神经网络捕获说话人的语音频谱包络映射关系 ,以实现不同说话人之间声音特性的转换。实验对六个普通话单元音音素的转换语音质量分别作了客观和主观评估 ,结果表明用神经网络方法可以获得所期望的转换语音性能。实验结果还说明 ,与K -均值法相比 ,用遗传算法训练神经网络可以增强网络的全局寻优能力 ,使转换语音与目标语音的平均频谱失真距离减小约 10 %。 ",MESS200401013
《中文信息学报》征稿简则,,1, , ,MESS200401014
《中文信息学报》第三届编辑委员会,,1, , ,MESS200401015
机器翻译评测的新进展,张剑:06304865|吴际:10120319|周明:06431473,8,人工智能; 机器翻译; 自动评测;,"机器翻译评测对机器翻译的研究和开发具有至关重要的作用 ,对其的研究一直是国内外机器翻译界的重点课题。本文首先全面地介绍了最近出现的而且受到极大关注的机器翻译评测技术 ,即IBM公司的BLEU机器翻译评测标准和NIST采用的机器翻译评测技术。实验表明 ,自动翻译评测技术能够接近人工评价 ,评测结果也是可接受的。因此 ,采用自动翻译评测技术能够给自然语言处理的研究人员和开发人员带来很大的便利性。本文还展示了一个开放式的可扩展的自动翻译评测的平台 ,完全实现了BLEU和NIST评测标准 ,并做出了一定的改进使得该系统具有良好的使用性和可扩展性 ",MESS200306000
汉语术语定义的结构分析和提取,张艳:10983611|宗成庆:10815045|徐波:13621945,8,计算机应用; 中文信息处理; 句法分析; 知识发现; 术语定义;,"本文介绍的工作是在汉语句法分析研究基础上的一种应用研究 ,对术语如何下定义问题进行了理论上的探讨。术语的定义形式在汉语语法结构方面提供了模板结构和构成方式 ,可以作为知识发现研究的数据基础 ,也可以作为特定领域的语法知识系统。本文针对电子学和计算机领域的语料进行了分词和词性标注处理 ,然后应用句法分析工具分析出句子中的短语成分 ,并根据汉语句子的句型结构 ,总结出术语定义的结构特点 ,自动提取定义的模板。最后根据已建立的数据和概念描述 ,给出了术语发现的算法 ",MESS200306001
从汉语格关系表示生成日语,戴新宇:08061509|陈家骏:08035597|王启祥:08043445,8,人工智能; 机器翻译; 格语法; 汉语分析; 日语生成;,"本文介绍了一个基于转换翻译的汉日机器翻译系统中日语生成子系统的设计和实现。文章首先描述了一种基于格关系的汉语依存分析树 ,分析树结点记录语法语义以及格关系信息 ;然后 ,针对日语的特征 ,分析了日语生成中的主要问题 ,包括译词选择、用言活用形确定、助词添加等 ;给出基于规则的日语生成系统的组织结构 ,重点介绍生成规则系统的设计和实现。最后 ,给出规则描述的实例以及翻译实例 ,提出进一步改进本系统的初步想法 ",MESS200306002
基于事件框架的事件相关文档的智能检索研究,吴平博:08164877|陈群秀:08231465|马亮:08833686,7,计算机应用; 中文信息处理; 智能检索; 事件相关文档; 事件框架; 事件主体;,"在事件相关文档的检索中 ,事件主题的迁移和分化与相似事件的干扰是影响系统性能的两个主要因素。本文提出了一种基于事件框架知识和事件主体信息的检索方法。该方法对事件相关评价函数进行了的改进 :首先 ,从事件语料中提炼出事件的框架知识、从事件文档中挖掘出表达事件主体的信息 ,然后将这些知识和信息进行向量化 ,最后利用向量化的结果对相关度评价函数进行优化。实验结果表明该方法是有效的 ,明显提高了事件相关文档的检索性能。 ",MESS200306003
汉语语句的自动改写,张玉洁:15222599,8,人工智能; 机器翻译; 语句改写; 汉语口语; 模板匹配; 语句改写语料库;,"在基于转换方式的口语机器翻译中 ,口语的多样性和不规则性加重了转换模块的处理负担。另外 ,由于缺少双语语料库和懂双语的语言学家 ,使得翻译知识的开发很困难或成本很高。为了解决这些问题 ,我们提出了在翻译前对源语言的语句进行自动改写的方法 ,试图通过加强源语言的处理来分散转换模块的负担。本文介绍了汉日口语机器翻译系统中汉语语句改写模块的开发。作者在分析了口语句子的改写目标后 ,提出了基于模板匹配的改写方法和从改写语料库中获取改写模板的半自动化方法。作者还介绍了改写模块的设计与实现 ,以及评价试验和结果。 ",MESS200306004
基于目标驱动的多层MLLR自适应算法,穆向禹:13621678|贾磊:11658015|张树武:13621550|徐波:10983611,8,计算机应用; 中文信息处理; 语音识别; 模型自适应; 自适应回归树; 极大似然线性变换;,"本文在对语音识别中基于自适应回归树的极大似然线性变换 (MLLR)模型自适应算法深刻分析的基础上 ,提出了一种基于目标驱动的多层MLLR自适应 (TMLLR)算法。这种算法基于目标驱动的原则 ,引入反馈机制 ,根据目标函数似然概率的增加来动态决定MLLR变换的变换类 ,大大提高了系统的识别率。并且由于这种算法的特殊多层结构 ,减少了许多中间的冗余计算 ,算法在具有较高的自适应精度的同时还具有较快的自适应速度。在有监督自适应实验中 ,经过此算法自适应后的系统识别率比基于自适应回归树的MLLR算法自适应后系统的误识率降低了 10 % ,自适应速度也比基于自适应回归树的MLLR算法快近一倍。 ",MESS200306005
多字体印刷藏文字符识别,王华:08832216|丁晓青:00007412,6,人工智能; 模式识别; 藏文字符识别; 方向线素特征; 线性鉴别分析; 带偏差欧氏距离; 修正二次鉴别函数;,"藏文字符识别系统是中文多文种信息处理系统的重要组成部分 ,但至今国内外的研究基本处于空白。本文提出了一种基于统计模式识别的多字体印刷藏文字符识别方法 :从字符轮廓中抽取方向线素特征 ,利用线性鉴别分析 (LDA)压缩降维后得到紧凑的字符特征向量。采用基于置信度分析的两级分类策略 ,设计了带偏差欧氏距离分类器 (EDD)完成高效的粗分类 ,细分类采用修正二次鉴别函数 (MQDF)。通过实验选取恰当的分类器参数后 ,在容量为 177,6 0 0字符 (30 0样本 /字符类 )的测试集上的识别率达到 99.79% ,证明了该方法的有效性 ",MESS200306006
基于智能技术的远程教育答疑系统研究,高光来:05981929|王玉峰:08639684,7,计算机应用; 中文信息处理; 智能答疑; 智能体; 语义网络; 数据挖掘; 远程教育; 导航器;,"网上答疑系统是现代远程教育系统中不可缺少的一部分 ,然而当前的答疑系统只是根据用户的输入对题库中的问题进行简单的关键词匹配 ,查询精度和用户界面满足不了用户的需求。针对以上缺点 ,本文给出一个应用语义网络原理构筑起来的智能答疑系统。文章分析了建立智能答疑系统的必要性 ,由此提出了一个基于限定领域的智能答疑系统模型及其技术路线 ,并以两门大学计算机课程作为知识库来源 ,实现了系统的功能。试验结果表明 ,本文所提出的方法有效地提高了查询精度 ,用户界面友好方便 ",MESS200306007
古文字字库建设的几个问题,张再兴:07536902,6,计算机应用; 中文信息处理; 古文字; 字库; 字形;,"随着古文字信息化处理研究的发展 ,古文字的标准字库建设已经显得十分迫切。本文探讨了古文字标准字库建设中需要注意的四个方面的问题 :通过建立古文字资料库 ,穷尽性地收集整理古文字字形保证字形收集的全面性 ,通过拓片扫描造字保证所造字形的准确性 ;在字形与字之间建立对应关系时须考虑两者之间的异用、歧释、异体等复杂关系 ;字形归纳过程中应遵循形体的归并原则和区别原则 ;字符进入标准字符集时的分级应根据字频原则和形频原则 ",MESS200306008
《中文信息学报》第三届编辑委员会,,1, , ,MESS200306009
词性标注中生词处理算法研究,张孝飞:09511825|陈肇雄:10334293|黄河燕:05975602|蔡智:09638848,5,计算机应用; 中文信息处理; 自然语言理解; 词性兼类; 隐马尔科夫模型; 语料库;,"词性兼类是自然语言理解必须解决的一类非常重要的歧义现象,尤其是对生词的词性歧义处理有很大的难度。文章基于隐马尔科夫模型(HMM),通过将生词的词性标注问题转化为求词汇发射概率,在词性标注中提出了一种生词处理的新方法。该方法除了用到一个标注好的单语语料库外,没使用任何其他资源(比如语法词典、语法规则等),封闭测试正确率达97%左右,开放测试正确率也达95%左右,基本上达到了实用的程度。同时还给出了与其他同样基于HMM的词性标注方法的测试比较结果,结果表明本文方法的标注正确率有较大的提高。 ",MESS200305001
汉英双语语料库中名词短语的自动对应,刘冬明:08401875|赵军:09166846|杨尔弘:10891784,7,人工智能; 机器翻译; 名词短语识别; 短语对齐; 迭代重估; 相似度;,"本文提出了一种在汉英双语语料库句子对齐的基础上,自动进行汉英名词短语划分和对应的方法。该方法的主要特点在于在无需严格识别汉语名词短语的情况下,对高频短语和低频短语分别进行处理,对于高频短语,利用英语短语和汉语词在双语语料库中的关联信息,采用一种迭代重估算法进行双语短语的对应;对于低频短语,根据双语词典中源词和译词之间的对应信息,结合一套人工编写的句法规则进行双语低频短语的对应。该方法能够从整体上把握对应信息,并具有很高的覆盖率。 ",MESS200305002
基于记忆的自适应汉语语言模型的研究,曲卫民:00585957|张俊林:00913383|孙乐:10352507|孙玉芳:10352504,7,计算机应用; 中文信息处理; 语言模型; 自适应; TFIDF公式; 扩展二元模型;,"基于记忆的自适应语言模型虽然在一定程度上增强了语言模型对不同领域的适应性,但其假设过于简单,即认为一个在文章的前面部分出现过的词往往会在后面重复出现,它没有考虑到常用词的影响,以及不同单词间的相互影响。本文针对这一问题从两个方面对原有模型进行了改进,一是采用TFIDF公式代替了原有的简单频率统计法;二是建立了一种基于记忆的扩展二元模型,并采用权重过滤法以节省模型计算量。实验表明这两种改进在很大程度上提高了原有模型的性能,增强了模型的自适应性。 ",MESS200305003
HNC作用效应句的汉英句类转换,,8,人工智能; 机器翻译; HNC理论; 作用效应句; 句类转换; 语句格式转换; 转换框架;,"作用效应句是作用句的一个特殊子类,是HNC57组基本句类中一个极富个性的重要句类。从HNC概念网络的角度看,作用效应句主要由使役类动词和逼迫类动词直接形成,或者由一般作用类动词(含泛动类动词)通过""得""字结构间接形成。由这三类动词形成的作用效应句遵循不同的句类转换和格式转换规则,因此在汉英机器翻译中,需要采取不同的句类转换框架,以确保译文语句句法语义结构的正确性。初步的试验表明,有关作用效应句的这些句类-格式转换规则具有很好的适用性和覆盖率。 ",MESS200305004
名人网页的相关度评价,昝红英:06268948|苏玉梅:06262061|孙斌:06272028|俞士汶:06277525,7,计算机应用; 中文信息处理; 相关度; 检索服务; 信息提取; 特征信息;,"本文介绍了北京大学天网知名度系统的设计与开发工作,重点论述了中文名人网页相关度评价的因素、算法和相应的检索结果。针对目前搜索引擎服务的不足之处,该工作旨在改进网上信息服务的质量,提高个性化网上信息服务的能力。本系统在北京大学天网搜索引擎的基础上,利用自然语言处理、特别是中文信息提取的新技术,结合网页信息的特点,针对名人网页的检索提出了一种新的网页相关度评价算法,改善了检索结果排序的合理性,提高了名人网页检索服务的质量。 ",MESS200305005
关于“中文网页自动分类竞赛”结果的分析,冯是聪:06259353|王继民:06241860,7,计算机应用; 中文信息处理; 机器学习; 中文网页自动分类; TREC评测;,"在最近召开的""全国搜索引擎与网上信息挖掘学术研讨会""上,举办了一场""中文网页自动分类竞赛"",共有来自全国各地的10个队参加。本文在介绍本次竞赛活动规则和过程的基础上,详细分析了竞赛的结果,从而使我们对于目前中文网页自动分类技术的现状有了一种具体的认识:目前已有分类器的性能没有呈现出明显的差距,中文网页的分类比普通文本的分类要困难的多。同时,本文还尝试推出一个标准的中文网页分类的实例样本集,希望通过不断完善,最终作为中文网页分类技术研究的基本语料。 ",MESS200305006
基于对话回合衰减的cache语言模型在线自适应研究,何伟:06247687|李红莲:05964390|袁保宗:06238493|林碧琴:06253777,7,计算机应用; 中文信息处理; 口语对话系统; 语言模型; cache自适应;,"目前由于特定任务域语料的稀疏并且难以收集,这严重阻碍了对话系统的可移植性。如何利用在线收集的少量训练语料,实现语言模型的快速自适应,从而有效提高对话系统在新任务域的识别率是本文的目的所在。本文对传统cache模型修正后,提出了基于历史单元衰减的cache语言模型,以在线递增方式收集语料进行自适应,并与通用语言模型进行线性插值。在对话系统中,以对话回合为历史单元,也可称为基于对话回合衰减的cache语言模型。在两个完全不同任务域———颐和园导游与火车票订票任务域进行的实验表明,在自适应语料不到1千句时,与无自适应模型相比,有监督模式下的识别错误率分别降低了47 8%和74 0%,无监督模式下的识别错误率分别降低了30 1%和51 1%。 ",MESS200305007
基于韵律特征和语法信息的韵律边界检测模型,吴晓如:09578638|王仁华:09509718|刘庆峰:09575724,7,计算机应用; 中文信息处理; 韵律边界的自动检测; 韵律预测; 决策树; 分类与回归树;,"韵律短语边界的自动检测,对语音合成中语料库的韵律标注以及语音识别中韵律短语的自动划分都有重要意义。本文通过对影响韵律短语边界的声学、韵律等参量的分析,得到和韵律短语边界关联性较大的一组声学特征参数、韵律环境参数和语法信息;同时引入语音合成中的韵律预测思想,在假定所有音节边界均为非韵律短语边界时,预测每个音节的基频。最后使用决策树模型,将音节边界处的韵律环境信息、语法信息以及预测结果作为决策树的输入,利用决策树综合判定当前音节边界是否为韵律短语的边界。实验表明,这种方法对于基于确定性文本(text dependent)的语音韵律短语边界的检测,具有较好效果,同时可以显著提高语音合成中语料库的标注效率和标注结果的一致性。 ",MESS200305008
复杂彩色文本图像中字符的提取,陈又新:08820244|刘长松:08171740|丁晓青:00007412,5,人工智能; 模式识别; 字符提取; 图像分割; CRAG算法; 区域生长; 彩色文本图像;,"从复杂彩色文本图像中提取和识别字符已经成为一个既困难又有趣的问题。本文给出了一个具有创新性和实用性的区域生长算法用于彩色图像的分割:彩色图像游程邻接算法CRAG(colorrun lengthadja cencygraphalgorithm)。我们将该算法用于彩色文本图像,首先得到图像的彩色连通域,再对这些连通域的平均颜色进行颜色聚类,可得到若干个聚类中心,然后根据不同的颜色中心将图像分为相应的彩色层面,最后通过连通域分析判断所需的文字层。该生长算法修改并扩展了传统的BAG算法,并将其运用于彩色印刷体文本图像中,充分利用了彩色图像的颜色和位置信息。实验结果表明新的方法能很好的从彩色印刷图像中提取多种常见的艺术字,并具有较高的提取速度,同时保留了文字和背景图像的原始色彩,便于将来的图像恢复。 ",MESS200305009
甲骨文象形码编码方法研究,肖明:07631911|赵慧:07644948|甘仲惟:07647651,6,计算机应用; 中文信息处理; 甲骨文; 字根; 象形码; 模糊聚类; 熵; 码长;,"甲骨文因字形独特、年代久远,所以一直没能进行有效编码。本文吸取现代编码思想,采用模糊数学模型分析甲骨文的部件(字根)特点,对其进行模糊聚类,并使用32个字符(25个英文字母和7个阿拉伯数字)作为码元,与甲骨文中的500多个字根相对应,实现了一字一码的编码方案。在此基础上,运用信息论中的熵理论,分析了这种编码的效率和科学性,得出甲骨文编码的最佳码长大致接近于3,从而为5000多个甲骨文字进行科学编码提供理论基础。 ",MESS200305010
统计机器翻译综述,刘群:06267889,12,人工智能; 机器翻译; 综述; 统计机器翻译; 信源信道模型; 最大熵方法;,"本文综述了基于信源信道思想和基于最大熵思想的统计机器翻译方法并介绍了统计机器翻译的评测方法。基于信源信道的方法将翻译概率表示为一个语言模型和一个翻译模型。而基于最大熵的方法则是利用一系列实数值特征函数的线性组合来求解最优的译文。基于最大熵的统计机器翻译方法比基于信源信道的方法更具有一般性 ,后者可以看做前者的一个特例。 ",MESS200304000
一种中文分词词典新机制——双字哈希机制,李庆虎:08225535|陈玉健:08174368|孙家广:05966573,6,计算机应用; 中文信息处理; 中文分词; 双字哈希;,"汉语自动分词是汉语信息处理的前提 ,词典是汉语自动分词的基础 ,分词词典机制的优劣直接影响到中文分词的速度和效率。本文首先分析了分词词典机制在中文分词中的重要性及已有的三种典型词典机制 ,并在此基础上根据汉语中双字词语较多的特点提出了一种新的分词词典机制———双字哈希机制 ,在不提升已有典型词典机制空间复杂度与维护复杂度的情况下 ,提高了中文分词的速度和效率。 ",MESS200304001
一种提高中文搜索引擎检索质量的HTML解析方法,宋睿华:08179607|马少平:08177513|陈刚:00072973|李景阳:08228629,8,计算机应用; 中文信息处理; HTML解析; 降噪; 分块模型; 搜索引擎;,"中文搜索引擎经常会返回大量的无关项或者不含具体信息的间接项 ,产生这类问题的一个原因是网页中存在着大量与主题无关的文字。对使用关键字检索方法的搜索引擎来说 ,想在检索或者后处理阶段解决这类问题不仅要付出一定代价 ,而且在大多数情况下是不可能的。在这篇论文中 ,我们提出了网页噪声的概念 ,并针对中文网页的特点 ,实现了一种对网页自动分块并去噪的HTML解析方法 ,从而达到在预处理阶段消除潜在无关项和间接项的目的。实验结果表明 ,该方法能够在不占用查询时间的前提下 10 0 %地消除中文搜索引擎隐藏的间接项 ,以及大约 11%的无法过滤或隐藏的无关项或间接项 ,从而大幅度提高检索结果的查准率。 ",MESS200304002
基于综合因素的汉语连续语音库语料自动选取,康恒:11459454|刘文举:11448045,6,计算机应用; 中文信息处理; 语音库; 三音子; 高频词; 覆盖率;,"大词汇量连续语音识别系统的性能很大程度上取决于语音库的质量 ,而语音库设计的中心环节就是语料选取。但是传统语料选取方法往往考虑因素单一 ,不利于语音识别系统有效利用语言信息。本语音库的语料选取方法综合考虑了多种因素 :三音子覆盖率、三音子覆盖效率、三音子稀疏度、常用词分布等 ,并完全实现程序自动选取 ,充分利用了原始语料 ,使选取结果的信息量更加丰富。程序自动选取结果可以覆盖94 1%的三音子 ,75 4 %的最常用词 ,覆盖效率和稀疏度也比传统方法有了较大改善。 ",MESS200304003
连续语音识别中声学建模的组合聚类算法研究,韩兆兵:11482162|贾磊:11658015|张树武:10983611|徐波:13621550,6,计算机应用; 中文信息处理; 语音识别; 合并聚类; 决策树聚类; 声学建模;,"基于三音子连续语音识别的一个关键问题是在有限训练数据的条件下对大量声学模型参数的鲁棒性估计。为了解决这个问题 ,有两个主要的上下文相关的聚类算法被提出 ,它们是合并 (AgglomerativeClustering)聚类 (AGG)和决策树 (Tree based)聚类 (TB)。本文分析了这两种算法的优缺点 ,并分别对其进行了改进 ,然后提出了最大似然框架下组合聚类算法。大词汇量连续语音识别 (LVCSR)的实验结果表明 ,和单一的决策树聚类算法比较 ,提出的组合聚类算法对识别率有显著的提高。 ",MESS200304004
汉语语句中短语间停顿的自动预测方法,聂鑫:08823097|王作英:00006332,6,计算机应用; 中文信息处理; 短语间停顿; 词性标注; 马尔可夫模型;,"在文语转换 (TTS)系统中 ,正确标记短语间的停顿对提高合成语音的自然度起着重要作用。本文介绍了一种在汉语语句中自动预测短语间停顿的方法。首先 ,文本进行分词 ,并转换为一列由词性标记所组成的序列 ;然后使用马尔可夫模型 ,利用人工标注数据库训练词语连接处词性标注序列的概率分布和连接类型序列的距离信息 ,得到输入的词性标记序列对应的具有最大似然概率的连接类型序列 ,最后利用后处理规则进行适当的纠错。本文针对不同的模型参数进行了测试 ,短语间停顿自动预测的召回率和连接类型正确率分别达到了 6 8 2 %和 85 1% ,取得了比较满意的结果。 ",MESS200304005
中文语音合成系统中的文本标准化方法,陈志刚:09538381|胡国平:09579231|王熙法:09504972,7,计算机应用; 中文信息处理; 文本标准化; 特殊符号; 外部规则;,"文本标准化是对输入文本进行分析 ,生成其中非汉字符号的拼音、节奏等信息的过程。本文提出了一种层次化的、基于外部规则的标准化方法 ,通过规则匹配识别这些符号 ,并给出各种正确信息。本文首先介绍了分析树的概念 ,其次给出构造规则的步骤 ,利用权值控制规则的匹配顺序 ,最后给出实验结果。实验结果表明 :这种方法具有很好的易维护性和可扩展性 ,开放测试的正确率达到 99 76 %。 ",MESS200304006
基于独立分量分析的笔迹识别,黄雅平:06229634|罗四维:06254562|陈恩义:08820030,7,人工智能; 模式识别; 笔迹识别; 独立分量分析; 竞争学习;,"笔迹识别作为一种身份识别技术 ,具有自然 ,非入侵等优点 ,因此成为模式识别和机器学习领域的一个研究热点。本文提出了一种与文本无关的笔迹识别方法 ,该方法利用独立分量分析 (IndependentCompo nentAnalysis ,ICA)来提取笔迹的纹理特征 ,并利用竞争学习方法确定笔迹的特征编码。实验结果证明利用该方法进行笔迹识别具有很好的效果。 ",MESS200304007
一种基于ICA的汉字信息隐秘传输方法,陆红琳:09578494|程义民:09545462|王以孝:09539019|田源:09542392,7,计算机应用; 中文信息处理:隐秘传输; 独立成份分析(ICA); 彩色图像; 汉字编码;,"本文描述了一种基于独立成份分析 (ICA)的汉字信息隐密传输方法。该方法以彩色图像为寄主图像 ,对其进行ICA分解 ,求出其中的独立成分 ,再将汉字信息以编码形式 ,隐藏在对彩色图像质量影响最小的独立成分低位端 ,从而实现汉字信息的隐秘传输。该方法已经在PC机上进行了模拟 ,实验结果表明 ,该方法在保证图像质量条件下 ,有较高的嵌入率和较好的可靠性。 ",MESS200304008
四种基本统计句法分析模型在汉语句法分析中的性能比较,孟遥:06983570|李生:06997742|赵铁军:06989791|曹海龙:06989058,8,计算机应用; 中文信息处理; 统计句法分析; 基本模型; 汉语分析;,"统计模型的选择是统计句法分析的关键。目前句法分析常用的有四种经典统计模型—PCFG模型 ,基于历史模型、分层渐近式模型和头驱动模型。本文通过实验 ,在已有的 10 0 0 0句汉语树库基础上 ,测试了这四种经典模型在现有数据规模下各自的性能 ,并论述了这四种经典模型的各自特点。本文旨在通过对四种基本模型的比较研究 ,为具体应用中句法分析模型的选择提供参考和依据。 ",MESS200303000
基于字串内部结合紧密度的汉语自动抽词实验研究,罗盛芬:08173141|孙茂松:08823738,6,计算机应用; 中文信息处理; 自动抽词; 统计量的组合; 遗传算法;,"自动抽词是文本信息处理中的重要课题之一。当前比较通行的解决策略是通过评估候选字串内部结合紧密度来判断该串成词与否。本文分别考察了九种常用统计量在汉语自动抽词中的表现 ,进而尝试将它们组合在一起 ,以期提高性能。为了达到尽可能好的组合效果 ,采用了遗传算法来自动调整组合权重。对二字词的自动抽词实验结果表明 ,这九种常用统计量中 ,互信息的抽词能力最强 ,F measure可达 5 4 77% ,而组合后的F measure为 5 5 4 7% ,仅比互信息提高了 0 70 % ,效果并不显著。我们的结论是 :( 1)上述统计量并不具备良好的互补性 ;( 2 )通常情况下 ,建议直接选用互信息进行自动抽词 ,简单有效。 ",MESS200303001
藏文自动分词系统的设计与实现,陈玉忠:06272028|李保利:06260061|俞士汶:06267078,7,计算机应用; 中文信息处理; 格助词; 接续特征; 藏文; 自动分词;,"藏文自动分词系统的研制目前在国内仍是空白。本文从四个方面详细报告了书面藏文自动分词系统的具体实现过程 ,内容包括系统结构、分词知识库的组织与实现以及分词策略、算法设计及其详细的自动分词过程实例。文章最后给出了实验结果 ,结果表明系统具有较高的切分精度和较好的通用性。 ",MESS200303002
基于主题的Web文档聚类研究,孙学刚:08180140|陈群秀:08231465|马亮:08164877,6,计算机应用; 中文信息处理; Web文档聚类; OPTICS算法; 特征提取; K近邻准则; 二次特征提取和聚类的方法;,"网络资源的不断膨胀和新旧信息的迅速更迭 ,使传统的手工分检的方法难以适应对海量电子数据的管理需要。Web文档聚类可以快速地将文档进行自动归类 ,并能够发现新的信息资源。针对Web文档数据的复杂性 ,本文提出了通过二次特征提取和聚类的方法 ,将Web文档按照主题进行自动聚类。在主题特征被有效提取的同时 ,实现了较高质量的Web文档聚类。 ",MESS200303003
自组织中文语义映射网络的优化特征编码方法, ,7,计算机应用; 中文信息处理; 中文语义映射; 自组织映射; 特征编码; 相似度计算; Kohonen网络;,"本文介绍自组织中文语义映射网络 ,并分别基于集合论、代数理论和概率论研究和提出六种不同的特征编码方法 ,这对自组织语义映射效果有很重要的影响。通过性能评价得出如下结论 :使用TFIDF修正的频率密度编码能得到最佳效果 ,其语义映射的精确度和召回率分别为 94 .4 %和 90 .7% ,而基于向量模型的方法则都不适用于中文自组织语义映射。文中给出结果分析。另外比较实验结果表明文中的最好方法其系统性能好于目前广泛采用的分层聚类技术 ,并远好于多元统计分析技术 ,例如主成分分析的特征降维编码。 ",MESS200303004
基于“相同与差异”的机译单元的自动提取研究,陈博兴:05978393|杜利民:09682400,7,人工智能; 机器翻译; 双语语料库; 机译单元; 相同和差异;,"从双语语料库中提取的机译单元能更好地覆盖真实语言文本 ,本文提供了一个通过找出两个双语句对之间非全部为高频功能词的“相同和差异”部分 ,并且利用翻译词典和动态规划算法对齐“相同和差异”部分来获取机译单元的算法。对于获取的候选机译单元 ,本算法设计了三个过滤器来考察其正确性 :双语词串相似度过滤考察其语义对应性 ,词性相似度过滤考察其语法对应性 ,首尾禁用词过滤考察其搭配正确性。通过抽样检验 ,最后提取的机译单元的正确率为 86% ,召回率约为 61 34 % ,该算法对于获取机译单元提供了一种新的实用的方法。 ",MESS200303005
基于语法信息的汉语韵律结构预测,曹剑芬:20385040,6,计算机应用; 中文信息处理; 韵律结构; 语法信息; 韵律边界; 重音;,"韵律结构的预测 ,主要包括短语的自动切分和重音的等级分布两个大的方面。本文在概述汉语韵律结构的基础上 ,根据从自然话语中获得的韵律结构与句法结构和词性的关系 ,用一种新的方法 ,通过文本分析 ,全面地预测韵律边界的位置分布及其等级差异 ,并进一步预测重音的位置分布及其等级差异。 ",MESS200303006
汉语三音子模型观测概率比较,刘玉宇:00006332|吴及:08239433|王作英:08230778,6,人工智能; 机器翻译; 语音识别; 三音子模型; 观测概率;,"HMM的观测概率能否很好描述模型的实际分布对识别性能有很大的影响。为了比较汉语三音子模型在不同观测概率情况下的差异 ,本文构造了三种不同模型 ,及其训练和识别算法。通过从多方面对这三个模型进行比较 ,得出结论 ,为今后汉语三音子模型观测概率的选择提供依据。 ",MESS200303007
汉语基调的调模与语音合成的质量提高,吴禀雅:09386137|周昌乐:09349164|吴洁敏:09393468,6,人工智能; 机器翻译; 调模; 属性文法和合一运算; 语速和语阶; 质量提高;,"本文根据输入的汉语语篇中各个语词的感情色彩属性和语体色彩属性 ,通过一种语词属性文法及其合一运算 ,来得到整个语篇的调模。并通过调模得到相对应的音高和音长的基准值 ,来调整机器合成语音的语阶和语速 ,从而使机器合成的语音更加自然、流畅 ,丰富了机器合成语音的表现力 ,提高了语音合成的质量。 ",MESS200303008
正易全:一个动态结构笔组汉字编码输入法,张小衡:10235273,7,计算机应用; 中文信息处理; 动态结构笔组; 字形码; 汉字输入;,"“正易全”是一个以“正”、“易”和“全”为基本指导思想的笔组型汉字编码输入法。在“正”方面 ,采用国际标准汉字集ISO10 646CJK ,并以《GB130 0 0 1字符集汉字字序 (笔画序 )规范》和《信息处理用GB130 0 0 1字符集汉字部件规范》指导编码 ;在“易”方面 ,以单双笔笔组和十来个常用部件为码元 ,按笔顺和音托等简单原则映射到 2 6个英文字母建元上 ,从而避免了传统的繁复字根 -键元对应表 ;在“全”方面 ,支持CJK中的所有 2 0 90 2字符 ,包括简体字、繁体字、日韩字和偏旁部首等 ,而且可以在不改变编码方案的前提下进一步扩充字集。正易全的单字最大码长为 5个字母 ,平均码长 4 315 ,键选率 16 4 %。该输入法的笔组 -键元设计和取码模式是在对整个CJK字集作了全字编码以后多次试验、统计和优化后确定下来的。 ",MESS200303009
搭建中华字符集大平台,李宇明:10567518,7,计算机应用; 中文信息处理; 综述; 中华字符集; 文献保存; 数字化; 知识发掘; 互联网;,"为使中华文献有一个可进行文字加工的永久性本面目保存本 ,为满足数字化图书馆、博物馆、档案馆的建设要求 ,为促进用于知识发掘数据库的建设 ,为保证中华文化信息在国际互联网上的无障碍交际 ,必须尽快构建中华字符集。本文主要讨论中华字符集的内容及需要解决的技术问题 ",MESS200302000
汉语句子谓语中心词的自动识别,龚小谨:08173162|罗振声:08170792|骆卫华:08177474,7,计算机应用; 中文信息处理; 谓语中心词的识别; 基于规则; 特征选择; 粗筛选; 精筛选;,"谓语中心词的识别是句法成分分析中的一个非常重要的部分。本文提出了一种规则和特征学习相结合的谓语识别方法 ,将整个谓语识别的过程分为语片捆绑、谓语粗筛选和谓语精筛选三个阶段。在谓语粗筛选中 ,利用规则过滤掉明显不能充当谓语的词 ,得到一个准谓语集 ;在精筛选阶段 ,选择谓语的支持特征 ,根据统计计算得到每个特征对谓语的支持度 ,然后利用准谓语在句子中的上下文出现的特征对准谓语集中的词进行再次筛选 ,从而确定出句子的谓语中心词。经过测试表明 ,该方法是有效可行的 ",MESS200302001
古文字字库建设与古文字研究手段现代化学术研讨会,张德劭:07547671,1, , ,MESS200302002
基于概念统计和语义层次分析的英文自动文摘研究,季姮:08820902|罗振声:08237081|万敏:08172799|高小云:08173162,7,计算机应用; 中文信息处理; 概念统计; 主题概念; 向量空间模型; 句子重要度; 意义块划分;,"传统的自动文摘方法基于词语统计抽取文摘句 ,未进行文本的语义分析 ,导致文摘精度不高。为了克服传统方法的缺点 ,本文提出了一种基于主题概念的自动文摘方法 ,以概念统计和层次分析为基础设计并实现了一个英文自动文摘系统。系统利用WordNet以概念统计代替传统的词频统计 ,基于主题概念构建向量空间模型 ,计算句子重要度。并且根据主题概念在概念层次树上的分布进行文本结构分析划分意义块 ,以意义块为单元抽取文摘 ,初步解决了多主题文章的文摘结构不平衡问题。本文主要介绍了概念层次树的构造 ,主题概念的抽取步骤 ,基于主题概念的句子重要度的计算和意义块的划分算法。测试表明 ,通过概念统计和语义层次分析的方法 ,我们设计了更理想的向量空间模型 ,系统生成的文摘精度较高 ,并更全面地反映了原文的主要内容 ",MESS200302003
一种面向汉英口语翻译的双语语块处理方法,程葳:10983611|赵军:10891784|徐波:13621445|刘非凡:11467321,7,人工智能; 机器翻译; 统计机器翻译; 口语翻译; 语料库; 语块;,"基于语块的处理方法是近年来自然语言处理领域兴起的一条新思路。但是 ,要将其应用于口语翻译当中 ,还需按照口语特点对涉及双语的语块概念做出合理界定。本文在已有单语语块定义的基础上 ,根据中、英文差异和口语翻译特性 ,从句法和语义两个层次提出了一种汉英双语语块概念 ,并对其特点进行了分析。同时 ,针对中、英文并行语料库 ,建立了一套计算机自动划分与人工校对相结合的双语语块加工方法。应用该方法 ,对汉英句子级对齐的口语语料进行双语语块划分和对整 ,并以此为基础进行了基于双语语块的口语统计机器翻译实验。结果表明 ,本文提出的双语语块定义符合口语翻译的实际需要 ,使用基于双语语块的语料处理方法 ,能有效地提高口语系统的翻译性能 ",MESS200302004
基于特征串的大规模中文网页快速去重算法研究,吴平博:08164877|陈群秀:08833686|马亮:08231465,8,计算机应用; 中文信息处理; 特征串; 模糊匹配; 去重算法; 冗余网页;,"网页检索结果中 ,用户经常会得到内容相同的冗余页面 ,其中大量是由于网站之间的转载造成。它们不但浪费了存储资源 ,并给用户的检索带来诸多不便。本文依据冗余网页的特点引入模糊匹配的思想 ,利用网页文本的内容、结构信息 ,提出了基于特征串的中文网页的快速去重算法 ,同时对算法进行了优化处理。实验结果表明该算法是有效的 ,大规模开放测试的重复网页召回率达 97 3% ,去重正确率达 99 5 %。 ",MESS200302005
基于统计的中文地名识别,黄德根:06527360|岳广玲:06507781|杨元生:06508165,6,计算机应用; 中文信息处理; 中文地名识别; 构词可信度; 接续可信度; 自动分词;,"本文针对有特征词的中文地名识别进行了研究。该系统使用从大规模地名词典和真实文本语料库得到的统计信息以及针对地名特点总结出来的规则 ,通过计算地名的构词可信度和接续可信度从而识别中文地名。该模型对自动分词的切分作了有效的调整 ,系统闭式召回率和精确率分别为 90 2 4 %和 93 14 % ,开式召回率和精确率分别达 86 86 %和 91 4 8%。 ",MESS200302006
银行支票中小写金额图像的提取,张重阳:00092549|娄震:05967691|杨静宇:08068032,6,计算机应用; 中文信息处理; 图像分割; 二值化; 阈值; 文档图像分析;,"支票图像的分割与识别是目前文档自动处理领域中讨论的一个热点问题。其中字符图像的分割是预处理过程中的一个重要环节 ,对识别系统有很大的影响。在我国的支票图像中常含有较深的印章图像叠加在被分割的字符上 ,增加了字符分割的难度。本文以支票中小写金额的图像为例 ,提出了字符的逐层分割方法以及用于判断印章图像是否去除的评判准则。首先去除图像中的底纹和定位格线 ;然后通过迭代的方法选取阈值去除印章图像 ;最后采用基于连通区的区域增长算法提取字符图像 ,去除碎块。在 2 72 5张实地采集的我国现行支票上的实验结果表明 ,本文的方法能够有效的去除印章图像 ,分割出字符。 ",MESS200302007
论汉字码本数据库管理技术,吴娴:05970941|吕强:08868260|杨涛:09887587|杨季文:08849530|钱培德:08849282,6,计算机应用; 中文信息处理; 码本; 数据库; 汉字码本数据库; 管理技术;,"任何一种中文输入法的研究中都会遇到码本的处理问题。在不同的时期 ,由于应用需求的不同 ,使得码本呈现出不同的表现形式。本文首先提出了汉字码本数据库的概念 ,它是指能够实现汉字字符信息到其相应属性的对应关系的数据结构。之后 ,本文讨论了不同层次上的两种码本 :数据库码本和二进制码本。根据实践的经验 ,文中将不同阶段的汉字码本数据库分成文本文件形式、数据库码本形式和二进制文件形式 ,并且分别讨论了对这些码本的管理技术 ",MESS200302008
XML——中文信息处理的变革之路,李宁:00503403,6,计算机应用; 中文信息处理; 综述; 中文信息处理平台; 统一中文API; XML; Web服务;,"本文从中文信息面临的问题出发 ,阐述了中文信息处理走Internet开放变革之路的必要性。文中还介绍了Internet上已经开展的与中文信息处理相关的部分工作 ,重点论述了XML在中文信息处理方面的优势 ,指出以XML为基础的Web服务是分布式环境中文信息处理技术的发展方向。作者为此提出了一个中文信息处理服务体系框架的构想。 ",MESS200302009
汉字键盘输入智能处理软件综述,陈一凡:06402942|朱亮:12292946,6,计算机应用; 中文信息处理; 综述; 自然语言理解; 语用统计; 模板匹配; 上下文关联; 后处理;,"作为输入编码的后处理 ,各种类型输入软件智能化的共同目标是由软件来识别和选定上屏的重码字、词与缩短平均码长 ,并促使编码简单化和规范化。本文简要地论述了基于理解的智能输入、基于语用统计的智能输入、基于模板匹配的智能输入和基于上下文关联的智能输入等四种类型的汉字键盘输入智能处理软件的原理、优点和有待解决的问题 ,并列举了每种类型的典型作品。 ",MESS200302010
搭建中华字符集大平台,李宇明:10567518,7,计算机应用; 中文信息处理; 综述; 中华字符集; 文献保存; 数字化; 知识发掘; 互联网;,"为使中华文献有一个可进行文字加工的永久性本面目保存本 ,为满足数字化图书馆、博物馆、档案馆的建设要求 ,为促进用于知识发掘数据库的建设 ,为保证中华文化信息在国际互联网上的无障碍交际 ,必须尽快构建中华字符集。本文主要讨论中华字符集的内容及需要解决的技术问题 ",MESS200302000
日汉机器翻译系统中的多Agent研究,张捷:08164877|陈群秀:08835546,6,人工智能; 机器翻译; 多Agent; 类工程组织结构; 登记表通讯策略; 日汉机器翻译;,"机器翻译系统提高译文质量是一个关键性的难题。本文探讨如何在多方法的机器翻译系统中引入多Agent组织结构 ,并提出一种多层次多Agent组织结构 -类工程组织结构 ,使用登记表通讯策略。该组织结构应用在多翻译方法的日汉MTS中 ,使翻译质量有了较大的改善。 ",MESS200301001
基于双语语料的单个源语词汇和目标语多词单元的对齐,陈博兴:09682400|杜利民:05978393,7,人工智能; 机器翻译; 双语对齐; 多词单元; 翻译词典; 平均关联值; 关联值归一化差值;,"多词单元包括固定搭配、多词习语和多词术语等。本文提供了一个基于双语口语语料库的自动对齐单个源语词汇和目标语多词单元的算法 ,算法一方面通过计算对应于同一个源语词汇 ,多个目标语词汇之间的互信息和t值的归一化差值的大小来衡量目标语多个词语之间的关联程度以提取多词单元 ,另一方面通过计算互信息和t值的平均值作为多词单元和单个源语词汇之间互为相互翻译的衡量程度 ,用局部最优、首尾禁用词过滤以及长词优先等策略很好地解决了这个问题。另外 ,对短语翻译词典的分级 ,有效地减少了高级别词典中非正确翻译项的数目 ,使得翻译词典具有更好的实用性。 ",MESS200301002
基于链接的方法进行Web信息检索的TREC实验研究,张敏:08186086|马少平:08177513|高剑锋:08983523,6,计算机应用; 中文信息处理; 基于链接检索; 基于链接的方法; Web信息检索; 信息查询; 网页定位;,"本文通过TREC实验研究基于链接信息的检索对Web信息检索的影响 ,包括使用链接描述文本 ,链接结构以及将基于链接的方法和传统基于内容检索的方法合并。得到如下结论 :首先 ,链接描述文档对网页主题的概括有高度的精确性 ,但是对网页内容的描述有极大的不完全性 ;其次 ,与传统检索方法相比 ,使用链接文本在网页定位的任务上能够使系统性能提高 96 % ,但是在信息查询任务上没有帮助 ;最后 ,将基于链接信息的检索与传统的基于内容检索技术合并 ,在网页入口定位任务上总能将系统性能提高 4 8%到 12 4 .8% ,而对特定信息查询任务也能在一定程度上改善检索效果。 ",MESS200301003
基于遗传算法的定题信息搜索策略,许欢庆:09601264|王永成:09603174|孙强:09600138,7,计算机应用; 中文信息处理; 定题检索; 定题信息搜索; 遗传算法; Hub; authority;,"定题检索将信息检索限定在特定主题领域 ,提供主题领域内信息的检索服务。它是新一代搜索引擎的发展方向之一。定题检索的关键技术是主题相关信息的搜索。本文提出了基于遗传算法的定题信息搜索策略 ,提高链接于内容相似度不高的网页之后的页面被搜索的机会 ,扩大了相关网页的搜索范围。同时 ,借助超链Metadata的提示信息预测链接页面的主题相关度 ,加快了搜索速度。对比搜索试验证明了算法具有较好的性能。 ",MESS200301004
从「悬、挂、吊」看现代汉语近义词的区辨,吴欣达:21391731,6,计算机应用; 中文信息处理; 近义词; 事件结构; 使动结构; 事件焦点;,"本文以中央研究院词库小组所完成的「研究院语料库 (SinicaCorpus)」为语料 ,分析「悬」、「挂」、「吊」这一组近义词。藉由观察这三个词个别的出现分布与句法表现 ,抽离出区隔这三个动词的关键语意成分。我们发现事件焦点 (eventfocus)在这一组动词的区分上扮演着重要的角色。分析显示 ,这三个动词的语意都可以表现在使动结构 (causativeconstruction)上 ,而三者的区分就在于它们各自表示这个结构不同的组成成分。「悬」倾向于以使动句构中的下位事象 (subevent)为焦点 ,「挂」则可涵盖整个使动结构 ,而「吊」则偏向于将焦点集中在使动句构中的上位事象 (superevent)的部分。由这一组近义动词的表现 ,证明在事件结构的分析上 ,「事件焦点」这个概念 ,在区分动词语意时 ,有一定的重要性。 ",MESS200301005
“才”字句的句法语义分析,王楠:06588624,8,计算机应用; 中文信息处理; “才”字句; 句法语义; 副词;,"本文结合“才”字句的基本句式 ,考察了副词“才”的句法组合功能 ,并着重分析了“才”的四种基本语义。指出这四种基本语义可以两两地归并为“表示事物的量”和“表示限定 /排他”两种语义。并在此基础上进一步地归纳出副词“才”的深层语法意义———表示说话者对比客观事实与主观标准后作出的倾向性评判。 ",MESS200301006
基于语义依存关系的汉语语料库的构建,尤昉:08185652|李涓子:08821985|王作英:00006332,8,计算机应用; 中文信息处理; 语料库; 语义依存关系; 《知网》; 动态角色与属性;,"语料库是自然语言处理中用于知识获取的重要资源。本文以句子理解为出发点 ,讨论了在设计和建设一个基于语义依存关系的汉语大规模语料库过程中的几个基础问题 ,包括 :标注体系的选择、标注关系集的确定 ,标注工具的设计 ,以及标注过程中的质量控制。该语料库设计规模 10 0万词次 ,利用 70个语义、句法依存关系 ,在已具有语义类标记的语料上进一步标注句子的语义结构。其突出特点在于将《知网》语义关系体系的研究成果和具体语言应用相结合 ,对实际语言环境中词与词之间的依存关系进行了有效的描述 ,它的建成将为句子理解或基于内容的信息检索等应用提供更强大的知识库支持。 ",MESS200301007
利用梯度投影法实现语言模型的主题自适应,苏韬:00006332|汪俊杰:08181326|孙甲松:08175024|王作英:08179655,6,计算机应用; 中文信息处理; 语言模型; 主题自适应; 梯度投影; 最大似然估计;,"本文研究了在汉语语音识别中如何根据识别任务的主题相关性自动调整语言模型 ,即语言模型的主题自适应问题。提出了利用梯度投影法在最大似然估计准则下将不同主题的语言模型进行线性插值的方法。实验表明 ,该方法可以有效地提高系统的识别率和稳健性 ,特别是对于主题明确的识别任务改善尤为明显。同时 ,为了解决新系统识别速度较慢的问题 ,本文在音字转换过程中采取了多路搜索策略 ,在与基线系统识别速度相当的情况下识别率仍获得了明显改善。 ",MESS200301008
一种文本相似度及其在语音识别中的应用,李红莲:05964390|何伟:06253777|袁保宗:06247687,5,计算机应用; 中文信息处理; 相似度; 语音识别; web语音浏览; 语音拨号;,"随着语音识别研究的深入 ,提高通用识别引擎的精度变得越来越困难。但对具体的语音识别任务 ,结合相应的背景 ,采取相应的措施 ,有可能达到很理想的识别精度。在已知语音输入为某有限集元素之一的情形 ,利用文本在发音上的相似度可以大大提高识别的精度。本文对原有文本相似度的定义进行了改进与完善 ,并就其在语音识别任务中的作用进行了深入的研究。 ",MESS200301009
